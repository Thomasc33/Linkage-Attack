{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "X_RF_path = 'C:\\\\Users\\\\Carrt\\\\OneDrive\\\\Code\\\\Motion Privacy\\\\Attacking Models\\\\RF Attack Model\\\\X.pkl'\n",
    "X_SGN_path = 'C:\\\\Users\\\\Carrt\\\\OneDrive\\\\Code\\\\Motion Privacy\\\\Attacking Models\\\\SGN Attack Model\\\\data\\\\X.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('average-skeleton-joints.pkl', 'rb') as f:\n",
    "    average_skeleton_joints = pickle.load(f)\n",
    "\n",
    "def rad_to_deg(rad): return rad * 180 / np.pi\n",
    "\n",
    "paths_to_end_effectors = [\n",
    "    [0,1,20,2,3],\n",
    "    [0,1,20,8,9,10,11,23],\n",
    "    [0,1,20,8,9,10,11,24],\n",
    "    [0,1,20,4,5,6,7,21],\n",
    "    [0,1,20,4,5,6,7,22],\n",
    "    [0,12,13,14,15],\n",
    "    [0,16,17,18,19]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize_skeleton(skeleton, format='rf', verbose=False):\n",
    "    if format == 'rf':\n",
    "        new_skele = [0 for i in range(25 * 3)]\n",
    "        new_skele[0:3] = skeleton[0:3]\n",
    "        for path in paths_to_end_effectors:\n",
    "            for connection in range(len(path) - 1):\n",
    "                # If second joint in connection is already calculated, skip\n",
    "                if new_skele[path[connection + 1] * 3] != 0:\n",
    "                    continue\n",
    "\n",
    "                vector = skeleton[path[connection] * 3: path[connection] * 3 + 3] - skeleton[path[connection + 1] * 3: path[connection + 1] * 3 + 3]\n",
    "                length = np.linalg.norm(vector)\n",
    "                normalized_vector = vector / length\n",
    "                if verbose: print(f\"{path[connection]}-{path[connection + 1]}: {length} - {normalized_vector}\")\n",
    "\n",
    "                x_rotation = np.arctan2(normalized_vector[1], normalized_vector[2])\n",
    "                y_rotation = np.arctan2(normalized_vector[0], normalized_vector[2])\n",
    "                z_rotation = np.arctan2(normalized_vector[0], normalized_vector[1])\n",
    "\n",
    "                if verbose:\n",
    "                    print(f\"Radians: X: {x_rotation} Y: {y_rotation} Z: {z_rotation}\")\n",
    "                    print(f\"Degrees: X: {rad_to_deg(x_rotation)} Y: {rad_to_deg(y_rotation)} Z: {rad_to_deg(z_rotation)}\")\n",
    "\n",
    "                distance = average_skeleton_joints[f\"{path[connection]}-{path[connection + 1]}\"]\n",
    "                if verbose: print(f\"Distance: {distance}\")\n",
    "\n",
    "                dx = distance * np.cos(y_rotation) * np.cos(z_rotation)\n",
    "                dy = distance * np.sin(z_rotation) * np.cos(x_rotation)\n",
    "                dz = distance * np.sin(x_rotation) * np.cos(y_rotation)\n",
    "                if verbose: print(f\"dx: {dx} dy: {dy} dz: {dz}\")\n",
    "\n",
    "                new_pos = skeleton[path[connection] * 3: path[connection] * 3 + 3] + np.array([dx, dy, dz])\n",
    "                if verbose: print(f\"New Position: {new_pos}\")\n",
    "                new_skele[path[connection + 1] * 3: path[connection + 1] * 3 + 3] = new_pos\n",
    "\n",
    "    elif format == 'sgn':\n",
    "        new_skele = np.zeros((300,150))\n",
    "        i = 0\n",
    "        for frame in skeleton:\n",
    "            skele1 = frame[0:75]\n",
    "            skele2 = frame[75:150]\n",
    "            \n",
    "            if not skele1.any(): new_skele1 = np.zeros(75)\n",
    "            else: new_skele1 = normalize_skeleton(skele1, format='rf').flatten()\n",
    "            if not skele2.any(): new_skele2 = np.zeros(75)\n",
    "            else: new_skele2 = normalize_skeleton(skele2, format='rf').flatten()\n",
    "\n",
    "            new_skeleton = np.concatenate((new_skele1, new_skele2))\n",
    "            new_skele[i] = new_skeleton\n",
    "            i += 1\n",
    "    return np.array(new_skele)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Random Forest\n",
    "# (75)\n",
    "\n",
    "with (open(X_RF_path, \"rb\")) as f:\n",
    "    X = pickle.load(f)\n",
    "    \n",
    "X_ = {}\n",
    "\n",
    "for key in tqdm(X.keys()):\n",
    "    X_[key] = []\n",
    "    for skeleton in X[key]:\n",
    "        skeleton = normalize_skeleton(skeleton, format='rf')\n",
    "        if np.isnan(skeleton).any(): continue\n",
    "        X_[key].append(skeleton)\n",
    "    X_[key] = np.array(X_[key])\n",
    "\n",
    "with open('X_RF_normalized.pkl', 'wb') as f:\n",
    "    pickle.dump(X_, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with (open(X_SGN_path, \"rb\")) as f:\n",
    "    X = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Actor:   0%|          | 0/106 [00:00<?, ?it/s]C:\\Users\\Carrt\\AppData\\Local\\Temp\\ipykernel_14888\\623741319.py:13: RuntimeWarning: invalid value encountered in divide\n",
      "  normalized_vector = vector / length\n",
      "Actor: 100%|██████████| 106/106 [1:06:11<00:00, 37.46s/it]\n"
     ]
    }
   ],
   "source": [
    "# For SGN\n",
    "# (300, 150)\n",
    "\n",
    "X_ = {}\n",
    "\n",
    "for key in tqdm(X.keys(), desc='Actor', position=0, leave=True):\n",
    "    X_[key] = []\n",
    "    for video in tqdm(X[key], desc='Video', position=1, leave=False, miniters=20):\n",
    "        skeleton = normalize_skeleton(video, format='sgn')\n",
    "        if np.isnan(skeleton).any(): continue\n",
    "        X_[key].append(skeleton)\n",
    "    X_[key] = np.array(X_[key])\n",
    "\n",
    "with open('X_SGN_normalized.pkl', 'wb') as f:\n",
    "    pickle.dump(X_, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
