{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports / Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = '/Users/thomas/Downloads/nturgb+d_skeletons'\n",
    "path = 'D:\\\\Datasets\\\\Motion Privacy\\\\NTU RGB+D 120\\\\Skeleton Data'\n",
    "X_path = 'data/X.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data organization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_files():\n",
    "    # Read the files\n",
    "    files = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "\n",
    "    # Get stats for each file based on name\n",
    "    files_ = []\n",
    "    for file in files:\n",
    "        data = {'file': file,\n",
    "                's': file[0:4],\n",
    "                'c': file[4:8],\n",
    "                'p': file[8:12],\n",
    "                'r': file[12:16],\n",
    "                'a': file[16:20]\n",
    "                }\n",
    "        files_.append(data)\n",
    "\n",
    "    return files_\n",
    "files_ = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load X from pickle\n",
      "X loaded from pickle\n"
     ]
    }
   ],
   "source": [
    "# Attempt to load X and Y from pickle before generating them\n",
    "X = {}\n",
    "try:\n",
    "    print('Attempting to load X from pickle')\n",
    "    with open(X_path, 'rb') as f:\n",
    "        X = pickle.load(f)\n",
    "    print('X loaded from pickle')\n",
    "except:\n",
    "    print('Could not load X and Y, generating them now')\n",
    "    \n",
    "    # Read the files\n",
    "    files = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "\n",
    "    # Get stats for each file based on name\n",
    "    files_ = []\n",
    "    for file in files:\n",
    "        data = {'file': file,\n",
    "                's': file[0:4],\n",
    "                'c': file[4:8],\n",
    "                'p': file[8:12],\n",
    "                'r': file[12:16],\n",
    "                'a': file[16:20]\n",
    "                }\n",
    "        files_.append(data)\n",
    "\n",
    "    # Generate X and Y\n",
    "    for file_ in tqdm(files_, desc='Files Parsed', position=0):\n",
    "        try:\n",
    "            file = join(path, file_['file'])\n",
    "            data = open(file, 'r')\n",
    "            lines = data.readlines()\n",
    "            frames_count = int(lines.pop(0).replace('\\n', ''))\n",
    "            file_['frames'] = frames_count\n",
    "        except UnicodeDecodeError: # .DS_Store file\n",
    "            print('UnicodeDecodeError: ', file)\n",
    "            continue\n",
    "\n",
    "        # Add filename as key to X\n",
    "        X[file_['file']] = []\n",
    "\n",
    "        # Skip file if 2 actors\n",
    "        if lines[0].replace('\\n', '') != '1': continue\n",
    "\n",
    "        for f in tqdm(range(frames_count), desc='Frames Parsed', position=1, leave=False):\n",
    "            try:\n",
    "                # Get actor count\n",
    "                actors = int(lines.pop(0).replace('\\n', ''))\n",
    "            \n",
    "                # Get actor info\n",
    "                t = lines.pop(0)\n",
    "\n",
    "                # Get joint count\n",
    "                joint_count = int(lines.pop(0).replace('\\n', ''))\n",
    "\n",
    "                # Get joint info\n",
    "                d = []\n",
    "                for j in range(joint_count):\n",
    "                    joint = lines.pop(0).replace('\\n', '').split(' ')\n",
    "                    d.extend(joint[0:3])\n",
    "\n",
    "                # Skip if not 25 joints\n",
    "                if len(d) != 75: continue\n",
    "\n",
    "                # Convert to numpy array\n",
    "                d = np.array(d)\n",
    "\n",
    "                # Append to X and Y\n",
    "                X[file_['file']].append(d)\n",
    "            except:\n",
    "                break\n",
    "        \n",
    "        # Convert to numpy array\n",
    "        X[file_['file']] = np.array(X[file_['file']], dtype=np.float16)\n",
    "\n",
    "        # Pad X size to 300 frames (300 is max frames in dataset)\n",
    "        X[file_['file']] = np.pad(X[file_['file']], ((0, 300-X[file_['file']].shape[0]), (0, 0)), 'constant')\n",
    "\n",
    "\n",
    "    print('X Generated, saving to pickle...')\n",
    "\n",
    "    # Save the data\n",
    "    with open(X_path, 'wb') as f:\n",
    "        pickle.dump(X, f)\n",
    "\n",
    "    print('X Saved to pickle')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "same_samples_per_actor = 1000\n",
    "diff_samples_per_actor = 1000\n",
    "train_samples = 0\n",
    "test_samples = 0\n",
    "\n",
    "per_actor = False\n",
    "\n",
    "def data_generator_per_actor(X, same_samples_per_actor=1000, diff_samples_per_actor=1000, train=True, val_split=0.25):\n",
    "    actor_data = {}\n",
    "    for file in X:\n",
    "        actor = int(file[9:12])\n",
    "        action = int(file[17:20])\n",
    "\n",
    "        split_threshold = int((1 - val_split) * 60) if train else int(val_split * 60)\n",
    "\n",
    "        is_train_or_val = action <= split_threshold\n",
    "        if train != is_train_or_val:\n",
    "            continue\n",
    "\n",
    "        if actor not in actor_data:\n",
    "            actor_data[actor] = []\n",
    "        if len(X[file]) == 0:\n",
    "            continue\n",
    "        actor_data[actor].append(X[file])\n",
    "\n",
    "    actor_keys = list(actor_data.keys())\n",
    "\n",
    "    while True:\n",
    "        for actor in actor_keys:\n",
    "            samples = []\n",
    "\n",
    "            for _ in range(same_samples_per_actor):\n",
    "                same_video1 = random.choice(actor_data[actor])\n",
    "                same_video2 = random.choice(actor_data[actor])\n",
    "                samples.append((np.array([same_video1, same_video2]).astype(np.float32), 1))\n",
    "\n",
    "            while True:\n",
    "                diff_actor = random.choice(actor_keys)\n",
    "                if diff_actor != actor:\n",
    "                    break\n",
    "\n",
    "            for _ in range(diff_samples_per_actor):\n",
    "                same_video1 = random.choice(actor_data[actor])\n",
    "                diff_video = random.choice(actor_data[diff_actor])\n",
    "                samples.append((np.array([same_video1, diff_video]).astype(np.float32), 0))\n",
    "\n",
    "            random.shuffle(samples)\n",
    "\n",
    "            for sample in samples:\n",
    "                yield sample\n",
    "\n",
    "def data_generator(X, same_samples=10000, diff_samples=10000, train=True, val_split=0.25):\n",
    "    actor_data = {}\n",
    "    for file in X:\n",
    "        actor = int(file[9:12])\n",
    "        action = int(file[17:20])\n",
    "\n",
    "        split_threshold = int((1 - val_split) * 60) if train else int(val_split * 60)\n",
    "\n",
    "        is_train_or_val = action <= split_threshold\n",
    "        if train != is_train_or_val:\n",
    "            continue\n",
    "\n",
    "        if actor not in actor_data:\n",
    "            actor_data[actor] = []\n",
    "        if len(X[file]) == 0:\n",
    "            continue\n",
    "        actor_data[actor].append(X[file])\n",
    "\n",
    "    samples = []\n",
    "    \n",
    "    for _ in range(same_samples):\n",
    "        actor = random.choice(list(actor_data.keys()))\n",
    "        video1 = random.choice(actor_data[actor])\n",
    "        video2 = random.choice(actor_data[actor])\n",
    "        samples.append((np.array([video1, video2]).astype(np.float32), 1))\n",
    "\n",
    "    for _ in range(diff_samples):\n",
    "        actor1 = random.choice(list(actor_data.keys()))\n",
    "        actor2 = random.choice(list(actor_data.keys()))\n",
    "        while actor1 == actor2:\n",
    "            actor2 = random.choice(list(actor_data.keys()))\n",
    "        video1 = random.choice(actor_data[actor1])\n",
    "        video2 = random.choice(actor_data[actor2])\n",
    "        samples.append((np.array([video1, video2]).astype(np.float32), 0))\n",
    "    \n",
    "    random.shuffle(samples)\n",
    "\n",
    "    while True:\n",
    "        for sample in samples:\n",
    "            yield sample\n",
    "\n",
    "\n",
    "if per_actor:\n",
    "    train_gen = data_generator_per_actor(X, same_samples_per_actor, diff_samples_per_actor, train=True, val_split=0.25)\n",
    "    val_gen = data_generator_per_actor(X, same_samples_per_actor, diff_samples_per_actor, train=False, val_split=0.5)\n",
    "    test_gen = data_generator_per_actor(X, same_samples_per_actor, diff_samples_per_actor, train=False, val_split=0)\n",
    "else:\n",
    "    train_gen = data_generator(X, same_samples_per_actor, diff_samples_per_actor, train=True, val_split=0.25)\n",
    "    val_gen = data_generator(X, same_samples_per_actor, diff_samples_per_actor, train=False, val_split=0.5)\n",
    "    test_gen = data_generator(X, same_samples_per_actor, diff_samples_per_actor, train=False, val_split=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "mnist = torchvision.datasets.MNIST('/data/mnist', train=True, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.data.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGN\n",
    "\n",
    "All code in this section is adapted from Microsoft's SGN. [Github](https://github.com/microsoft/SGN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters/Tuning Parameters\n",
    "dataset='NTU'\n",
    "batch_size=32\n",
    "max_epochs=10000\n",
    "lr=.1\n",
    "weight_decay=0.001\n",
    "do_train=1\n",
    "seg=20\n",
    "# load_model='best_model'\n",
    "load_model=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import shutil\n",
    "import os\n",
    "import os.path as osp\n",
    "import csv\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from model import SGN\n",
    "from data import AverageMeter#, NTUDataLoaders\n",
    "from util import make_dir\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, accuracy_score\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.nn import TransformerEncoder, TransformerEncoderLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tweaks for Linkage Attack\n",
    "class SGN_Linkage_Attack(nn.Module):\n",
    "    def __init__(self, model_a, model_b, output_size):\n",
    "        super(SGN_Linkage_Attack, self).__init__()\n",
    "        self.model_a = model_a\n",
    "        self.model_b = model_b\n",
    "        self.fc = nn.Linear(1024, output_size)\n",
    "        pretrained = torch.load('C:\\\\Users\\\\Carrt\\\\OneDrive\\\\Code\\\\Motion Privacy\\\\Attacking Models\\\\SGN Attack Model\\\\results\\\\NTU\\\\SGN\\\\0_best.pth')['state_dict']\n",
    "        del pretrained['fc.weight']\n",
    "        del pretrained['fc.bias']\n",
    "        self.model_a.load_state_dict(pretrained)\n",
    "        self.model_b.load_state_dict(pretrained)\n",
    "        for param in self.model_a.parameters():\n",
    "            param.requires_grad = False\n",
    "        for param in self.model_b.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    def forward(self, x_a, x_b):\n",
    "        a_out = self.model_a(x_a).cuda()\n",
    "        b_out = self.model_b(x_b).cuda()\n",
    "        out = torch.cat((a_out, b_out), dim=1)\n",
    "        out = self.fc(out)\n",
    "        out = torch.sigmoid(out)\n",
    "        return out\n",
    "    \n",
    "    def print_weights(self):\n",
    "        print('FC Weights: ', self.fc[0].weight)\n",
    "        print('FC Bias: ', self.fc[0].bias)\n",
    "        print('Model A state_dict:', self.model_a.state_dict())\n",
    "        print('Model B state_dict:', self.model_b.state_dict())\n",
    "\n",
    "class SGN_Embedding_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SGN_Embedding_Model, self).__init__()\n",
    "        \n",
    "        self.fc0 = nn.Linear(seg*75*2, 2048)\n",
    "        self.conv1 = nn.Conv1d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 2048, 2048)\n",
    "        self.fc2 = nn.Linear(2048, 1024)\n",
    "        self.fc3 = nn.Linear(1024, 512)\n",
    "        self.fc4 = nn.Linear(512, 256)\n",
    "        self.lstm = nn.LSTM(256, 128, num_layers=2, bidirectional=True, batch_first=True)\n",
    "        encoder_layers = TransformerEncoderLayer(256, 8, 2048)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layers, num_layers=6)\n",
    "        self.attention = nn.MultiheadAttention(256, 8)\n",
    "        self.fc5 = nn.Linear(256, 128)\n",
    "        self.fc6 = nn.Linear(128, 64)\n",
    "        self.fc7 = nn.Linear(64, 32)\n",
    "        self.fc8 = nn.Linear(32, 16)\n",
    "        self.fc9 = nn.Linear(16, 1)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc0(x))\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.relu(self.conv1(x))\n",
    "        # x = self.dropout(x)\n",
    "        x = self.relu(self.conv2(x))\n",
    "        # x = self.dropout(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        # x = self.dropout(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        # x = self.dropout(x)\n",
    "        x = self.relu(self.fc3(x))\n",
    "        # x = self.dropout(x)\n",
    "        x = self.relu(self.fc4(x))\n",
    "        # x = self.dropout(x)\n",
    "        x = x.unsqueeze(1)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = x.squeeze(1)\n",
    "        x = self.transformer_encoder(x)\n",
    "        x, _ = self.attention(x, x, x)\n",
    "        x = self.relu(self.fc5(x))\n",
    "        # x = self.dropout(x)\n",
    "        x = self.relu(self.fc6(x))\n",
    "        # x = self.dropout(x)\n",
    "        x = self.relu(self.fc7(x))\n",
    "        # x = self.dropout(x)\n",
    "        x = self.relu(self.fc8(x))\n",
    "        # x = self.dropout(x)\n",
    "        x = self.sigmoid(self.fc9(x))\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class SGN_Linkage_Dataset(Dataset):\n",
    "    def __init__(self, data_gen, dataset_len, seg=20):\n",
    "        self.data_gen = data_gen\n",
    "        self.len = dataset_len\n",
    "        self.seg = seg\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x, y = next(self.data_gen)\n",
    "        x_a, x_b = self.preprocess(x)\n",
    "        return x_a, x_b, y\n",
    "\n",
    "    def preprocess(self, x):\n",
    "        x_a = x[0]\n",
    "        x_b = x[1]\n",
    "\n",
    "        x_a = self.tolist_fix([x_a])\n",
    "        x_a = torch.tensor(x_a).cuda()\n",
    "        x_b = self.tolist_fix([x_b])\n",
    "        x_b = torch.tensor(x_b).cuda()\n",
    "\n",
    "        # epsilon = 1e-8\n",
    "        # x_a = (x_a - x_a.mean(dim=1, keepdim=True)) / (x_a.std(dim=1, keepdim=True) + epsilon)\n",
    "        # x_b = (x_b - x_b.mean(dim=1, keepdim=True)) / (x_b.std(dim=1, keepdim=True) + epsilon)\n",
    "\n",
    "        return x_a, x_b\n",
    "\n",
    "    def tolist_fix(self, joints, train=1):\n",
    "        seqs = []\n",
    "\n",
    "        for idx, seq in enumerate(joints):\n",
    "            zero_row = []\n",
    "            for i in range(len(seq)):\n",
    "                if np.array_equal(seq[i, :], np.zeros(75)):\n",
    "                    zero_row.append(i)\n",
    "\n",
    "            seq = np.delete(seq, zero_row, axis=0)\n",
    "            seqs = self.sub_seq(seqs, seq, train=train)\n",
    "\n",
    "        return seqs\n",
    "\n",
    "    def sub_seq(self, seqs, seq, train=1):\n",
    "        group = self.seg\n",
    "\n",
    "        if seq.shape[0] < self.seg:\n",
    "            pad = np.zeros(\n",
    "                (self.seg - seq.shape[0], seq.shape[1])).astype(np.float32)\n",
    "            seq = np.concatenate([seq, pad], axis=0)\n",
    "\n",
    "        ave_duration = seq.shape[0] // group\n",
    "\n",
    "        if train == 1:\n",
    "            offsets = np.multiply(\n",
    "                list(range(group)), ave_duration) + np.random.randint(ave_duration, size=group)\n",
    "            seq = seq[offsets]\n",
    "            seqs.append(seq)\n",
    "\n",
    "        return seqs\n",
    "\n",
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, classes, smoothing=0.0, dim=-1):\n",
    "        super(LabelSmoothingLoss, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.cls = classes\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        pred = pred.log_softmax(dim=self.dim)\n",
    "        with torch.no_grad():\n",
    "            true_dist = torch.zeros_like(pred)\n",
    "            true_dist.fill_(self.smoothing / (self.cls - 1))\n",
    "            target = target.long()  # Convert target tensor to long\n",
    "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=1, gamma=2, reduction='mean'):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        BCE_loss = nn.functional.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n",
    "        pt = torch.exp(-BCE_loss)\n",
    "        F_loss = self.alpha * (1 - pt) ** self.gamma * BCE_loss\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return F_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return F_loss.sum()\n",
    "        else:\n",
    "            return F_loss\n",
    "\n",
    "class CategoricalHingeLoss(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CategoricalHingeLoss, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        # Convert targets to one-hot encoding\n",
    "        targets_one_hot = torch.zeros(targets.shape[0], self.num_classes).cuda()\n",
    "        targets_one_hot.scatter_(1, targets.unsqueeze(1), 1)\n",
    "        pos_scores = (inputs * targets_one_hot).sum(dim=1)\n",
    "        neg_scores = (inputs * (1 - targets_one_hot)).sum(dim=1)\n",
    "        hinge_loss = torch.clamp(1 + neg_scores - pos_scores, min=0)\n",
    "        return hinge_loss.mean()\n",
    "\n",
    "def evaluate(model, criterion, validation_loader, encoder=None):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_samples = 0\n",
    "    all_targets = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # for x_a, x_b, targets in tqdm(validation_loader, leave=True, desc='Validation', position=1):\n",
    "        for x_a, x_b, targets in validation_loader:\n",
    "            x_a, x_b, targets = x_a.cuda(), x_b.cuda(), targets.float().cuda()\n",
    "\n",
    "            if encoder is not None:\n",
    "                x_a = x_a.squeeze(1)\n",
    "                x_b = x_b.squeeze(1)\n",
    "                # x_a = encoder(x_a)\n",
    "                # x_b = encoder(x_b)\n",
    "                x_a = x_a.reshape(x_a.shape[0], -1)\n",
    "                x_b = x_b.reshape(x_b.shape[0], -1)\n",
    "                x = torch.cat((x_a, x_b), dim=1)\n",
    "                outputs = model(x)\n",
    "            else:\n",
    "                outputs = model(x_a, x_b)\n",
    "\n",
    "            loss = criterion(outputs.squeeze(), targets)\n",
    "\n",
    "            total_loss += loss.item() * targets.size(0)\n",
    "            total_samples += targets.size(0)\n",
    "\n",
    "            predictions = (torch.sigmoid(outputs) > 0.5).long().squeeze()  # Convert outputs to binary format\n",
    "            all_targets.extend(targets.tolist())\n",
    "            all_predictions.extend(predictions.tolist())\n",
    "\n",
    "    # Calculate validation loss and accuracy\n",
    "    val_loss = total_loss / total_samples\n",
    "    val_accuracy = accuracy_score(all_targets, all_predictions)\n",
    "\n",
    "    return val_loss, val_accuracy\n",
    "\n",
    "def evaluate_metrics(model, criterion, data_loader, encoder=None):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_samples = 0\n",
    "    all_targets = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # for x_a, x_b, targets in tqdm(data_loader, leave=False, desc='Testing', position=1):\n",
    "        for x_a, x_b, targets in data_loader:\n",
    "            x_a, x_b, targets = x_a.cuda(), x_b.cuda(), targets.cuda()\n",
    "\n",
    "            if encoder is not None:\n",
    "                x_a = x_a.squeeze(1)\n",
    "                x_b = x_b.squeeze(1)\n",
    "                # x_a = encoder(x_a)\n",
    "                # x_b = encoder(x_b)\n",
    "                x_a = x_a.reshape(x_a.shape[0], -1)\n",
    "                x_b = x_b.reshape(x_b.shape[0], -1)\n",
    "                x = torch.cat((x_a, x_b), dim=1)\n",
    "                outputs = model(x)\n",
    "            else:\n",
    "                outputs = model(x_a, x_b)\n",
    "\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            total_loss += loss.item() * targets.size(0)\n",
    "            total_samples += targets.size(0)\n",
    "\n",
    "            predictions = (torch.sigmoid(outputs) > 0.5).long().squeeze()  # Convert one-hot encoded predictions to binary format\n",
    "            all_targets.extend(targets.tolist())\n",
    "            all_predictions.extend(predictions.tolist())\n",
    "\n",
    "    # Calculate metrics\n",
    "    loss = total_loss / total_samples\n",
    "    accuracy = accuracy_score(all_targets, all_predictions)\n",
    "    cm = confusion_matrix(all_targets, all_predictions)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(all_targets, all_predictions, average='binary')\n",
    "\n",
    "    return accuracy, loss, cm, precision, recall, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "853d6ee286884175be42e21e667a2fba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Carrt\\AppData\\Local\\Temp\\ipykernel_29620\\1384854213.py:110: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:233.)\n",
      "  x_a = torch.tensor(x_a).cuda()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 0.1762578977692512, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.4479166666666667\n",
      "New best validation loss, checkpoint saved\n",
      "Epoch 2, Training Loss: 0.17373974669364192, Validation Loss: 0.1743897467851639, Validation Accuracy: 0.475\n",
      "Epoch 3, Training Loss: 0.17410813223931096, Validation Loss: 0.17327362298965454, Validation Accuracy: 0.5125\n",
      "New best validation loss, checkpoint saved\n",
      "Epoch 4, Training Loss: 0.17370515244622384, Validation Loss: 0.1743025501569112, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 5, Training Loss: 0.17397659392126144, Validation Loss: 0.1732246975104014, Validation Accuracy: 0.5375\n",
      "New best validation loss, checkpoint saved\n",
      "Epoch 6, Training Loss: 0.17360245941146726, Validation Loss: 0.1741805245478948, Validation Accuracy: 0.4875\n",
      "Epoch 7, Training Loss: 0.17434929888094625, Validation Loss: 0.17331353724002838, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 8, Training Loss: 0.17378547979939368, Validation Loss: 0.17505724231402078, Validation Accuracy: 0.475\n",
      "Epoch 9, Training Loss: 0.1742255812691104, Validation Loss: 0.1730598896741867, Validation Accuracy: 0.5604166666666667\n",
      "New best validation loss, checkpoint saved\n",
      "Epoch 10, Training Loss: 0.17364669951700396, Validation Loss: 0.17492050131162007, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 11, Training Loss: 0.17438744248882418, Validation Loss: 0.17355244954427082, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 12, Training Loss: 0.1736137468007303, Validation Loss: 0.1754381130139033, Validation Accuracy: 0.4875\n",
      "Epoch 13, Training Loss: 0.17438872639209993, Validation Loss: 0.17275752524534863, Validation Accuracy: 0.5354166666666667\n",
      "New best validation loss, checkpoint saved\n",
      "Epoch 14, Training Loss: 0.17355211511734994, Validation Loss: 0.17482525606950125, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 15, Training Loss: 0.17443891975187487, Validation Loss: 0.17392586171627045, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 16, Training Loss: 0.1736090447633497, Validation Loss: 0.17515975932280223, Validation Accuracy: 0.49375\n",
      "Epoch 17, Training Loss: 0.1743868483651069, Validation Loss: 0.17370530168215434, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 18, Training Loss: 0.17362093637066503, Validation Loss: 0.1739983985821406, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 19, Training Loss: 0.1743799308615346, Validation Loss: 0.173764838774999, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 20, Training Loss: 0.17345709425787773, Validation Loss: 0.17396334906419117, Validation Accuracy: 0.5125\n",
      "Epoch 21, Training Loss: 0.17450018900056039, Validation Loss: 0.17456809679667154, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 22, Training Loss: 0.17357486390298413, Validation Loss: 0.17313097218672435, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 23, Training Loss: 0.17434265007895808, Validation Loss: 0.17491035262743632, Validation Accuracy: 0.48125\n",
      "Epoch 24, Training Loss: 0.17361685489454576, Validation Loss: 0.17423508067925772, Validation Accuracy: 0.50625\n",
      "Epoch 25, Training Loss: 0.1745531823365919, Validation Loss: 0.1757061243057251, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 26, Training Loss: 0.17375119703431283, Validation Loss: 0.1720886359612147, Validation Accuracy: 0.5520833333333334\n",
      "New best validation loss, checkpoint saved\n",
      "Epoch 27, Training Loss: 0.17427158259576367, Validation Loss: 0.1757104496161143, Validation Accuracy: 0.475\n",
      "Epoch 28, Training Loss: 0.17383239971053216, Validation Loss: 0.17372188965479532, Validation Accuracy: 0.5125\n",
      "Epoch 29, Training Loss: 0.17400200088177958, Validation Loss: 0.17620820105075835, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 30, Training Loss: 0.1740102940990079, Validation Loss: 0.17267864644527436, Validation Accuracy: 0.5375\n",
      "Epoch 31, Training Loss: 0.17391003139557376, Validation Loss: 0.17574438353379568, Validation Accuracy: 0.4875\n",
      "Epoch 32, Training Loss: 0.17398290191927263, Validation Loss: 0.1745215207338333, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 33, Training Loss: 0.1740112626744855, Validation Loss: 0.17606863379478455, Validation Accuracy: 0.475\n",
      "Epoch 34, Training Loss: 0.17413279606449988, Validation Loss: 0.17178241312503814, Validation Accuracy: 0.5604166666666667\n",
      "New best validation loss, checkpoint saved\n",
      "Epoch 35, Training Loss: 0.17382318069857935, Validation Loss: 0.17667180597782134, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 36, Training Loss: 0.17423451763968315, Validation Loss: 0.17420420447985333, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 37, Training Loss: 0.1737439776620557, Validation Loss: 0.17513496577739715, Validation Accuracy: 0.4875\n",
      "Epoch 38, Training Loss: 0.17437696504977443, Validation Loss: 0.17275891304016114, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 39, Training Loss: 0.17341893190337765, Validation Loss: 0.1762352685133616, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 40, Training Loss: 0.17467761664621292, Validation Loss: 0.17395730018615724, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 41, Training Loss: 0.17366712997036596, Validation Loss: 0.1744380791982015, Validation Accuracy: 0.49375\n",
      "Epoch 42, Training Loss: 0.17430833847292007, Validation Loss: 0.17393436034520468, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 43, Training Loss: 0.17365402127465895, Validation Loss: 0.17413615385691325, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 44, Training Loss: 0.17436319589614868, Validation Loss: 0.1743275006612142, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 45, Training Loss: 0.1737713073530505, Validation Loss: 0.1736101448535919, Validation Accuracy: 0.5125\n",
      "Epoch 46, Training Loss: 0.17425235481031479, Validation Loss: 0.1746448278427124, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 47, Training Loss: 0.17365281331923701, Validation Loss: 0.173272634545962, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 48, Training Loss: 0.17427547708634408, Validation Loss: 0.17419546047846476, Validation Accuracy: 0.48125\n",
      "Epoch 49, Training Loss: 0.17385503361302038, Validation Loss: 0.173672150572141, Validation Accuracy: 0.50625\n",
      "Epoch 50, Training Loss: 0.17419974650106124, Validation Loss: 0.1749519536892573, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 51, Training Loss: 0.17374527742785792, Validation Loss: 0.17207591036955516, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 52, Training Loss: 0.17432170962133714, Validation Loss: 0.17413777709007264, Validation Accuracy: 0.475\n",
      "Epoch 53, Training Loss: 0.17379171233023366, Validation Loss: 0.17362192769845328, Validation Accuracy: 0.5125\n",
      "Epoch 54, Training Loss: 0.17433694341490347, Validation Loss: 0.1743178794781367, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 55, Training Loss: 0.17367851974502688, Validation Loss: 0.17267117500305176, Validation Accuracy: 0.5375\n",
      "Epoch 56, Training Loss: 0.17434859083544824, Validation Loss: 0.1737489253282547, Validation Accuracy: 0.4875\n",
      "Epoch 57, Training Loss: 0.1738504671281384, Validation Loss: 0.17402470111846924, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 58, Training Loss: 0.17409891707281913, Validation Loss: 0.17502345343430836, Validation Accuracy: 0.475\n",
      "Epoch 59, Training Loss: 0.17373163805853936, Validation Loss: 0.17183863619963327, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 60, Training Loss: 0.1743218490192967, Validation Loss: 0.17377770841121673, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 61, Training Loss: 0.17390690119035782, Validation Loss: 0.17368829449017842, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 62, Training Loss: 0.17408397361155478, Validation Loss: 0.17395820220311484, Validation Accuracy: 0.4875\n",
      "Epoch 63, Training Loss: 0.17389593826186273, Validation Loss: 0.17290613452593487, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 64, Training Loss: 0.17420884149689828, Validation Loss: 0.17345187862714131, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 65, Training Loss: 0.17394203187957888, Validation Loss: 0.17353248298168183, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 66, Training Loss: 0.174067382370272, Validation Loss: 0.17366068363189696, Validation Accuracy: 0.49375\n",
      "Epoch 67, Training Loss: 0.17387146334494313, Validation Loss: 0.17331247528394064, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 68, Training Loss: 0.1741504866269327, Validation Loss: 0.17326990962028505, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 69, Training Loss: 0.17403575922212294, Validation Loss: 0.17352115511894226, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 70, Training Loss: 0.1738601831659194, Validation Loss: 0.17328977187474567, Validation Accuracy: 0.5125\n",
      "Epoch 71, Training Loss: 0.17401515043550922, Validation Loss: 0.17353420853614807, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 72, Training Loss: 0.1741258453938269, Validation Loss: 0.17305539151032764, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 73, Training Loss: 0.17402779863726708, Validation Loss: 0.17352843085924785, Validation Accuracy: 0.48125\n",
      "Epoch 74, Training Loss: 0.1739958457408413, Validation Loss: 0.17332632839679718, Validation Accuracy: 0.50625\n",
      "Epoch 75, Training Loss: 0.17395340867580905, Validation Loss: 0.17362348437309266, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 76, Training Loss: 0.1741307988282173, Validation Loss: 0.17283192972342173, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 77, Training Loss: 0.17403142827172433, Validation Loss: 0.17368733485539753, Validation Accuracy: 0.475\n",
      "Epoch 78, Training Loss: 0.17398248853222018, Validation Loss: 0.1732234497865041, Validation Accuracy: 0.5125\n",
      "Epoch 79, Training Loss: 0.1738863520083889, Validation Loss: 0.17373552918434143, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 80, Training Loss: 0.17416784936381924, Validation Loss: 0.17300038933753967, Validation Accuracy: 0.5375\n",
      "Epoch 81, Training Loss: 0.1738993881210204, Validation Loss: 0.17362246016661326, Validation Accuracy: 0.4875\n",
      "Epoch 82, Training Loss: 0.17397844358797995, Validation Loss: 0.17362082501252493, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 83, Training Loss: 0.17386321627324627, Validation Loss: 0.174044136206309, Validation Accuracy: 0.475\n",
      "Epoch 84, Training Loss: 0.17420630685744748, Validation Loss: 0.1728738417228063, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 85, Training Loss: 0.17392473018938495, Validation Loss: 0.17398902674516042, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 86, Training Loss: 0.17409006289897427, Validation Loss: 0.17344356079896292, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 87, Training Loss: 0.17379115810317378, Validation Loss: 0.17376699844996135, Validation Accuracy: 0.4875\n",
      "Epoch 88, Training Loss: 0.17427034243460623, Validation Loss: 0.17309605479240417, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 89, Training Loss: 0.17377621704532253, Validation Loss: 0.17368723452091217, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 90, Training Loss: 0.17418240299147944, Validation Loss: 0.17349456151326498, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 91, Training Loss: 0.17372572181686277, Validation Loss: 0.17376289268334708, Validation Accuracy: 0.49375\n",
      "Epoch 92, Training Loss: 0.1743155809179429, Validation Loss: 0.17328381538391113, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 93, Training Loss: 0.17387121579339426, Validation Loss: 0.17340900798638662, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 94, Training Loss: 0.17407328659488308, Validation Loss: 0.1735990285873413, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 95, Training Loss: 0.17378553363584703, Validation Loss: 0.17328835328420003, Validation Accuracy: 0.5125\n",
      "Epoch 96, Training Loss: 0.17430065476125287, Validation Loss: 0.1734082599480947, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 97, Training Loss: 0.1737613038670632, Validation Loss: 0.17293521662553152, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 98, Training Loss: 0.17428379481838596, Validation Loss: 0.17340912421544394, Validation Accuracy: 0.48125\n",
      "Epoch 99, Training Loss: 0.1736706115545765, Validation Loss: 0.1735796183347702, Validation Accuracy: 0.50625\n",
      "Epoch 100, Training Loss: 0.17429716164065945, Validation Loss: 0.17359509766101838, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 101, Training Loss: 0.1737659910032826, Validation Loss: 0.17225002845128376, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 102, Training Loss: 0.1742245074241392, Validation Loss: 0.17360998094081878, Validation Accuracy: 0.475\n",
      "Epoch 103, Training Loss: 0.17366571484073515, Validation Loss: 0.17327401240666707, Validation Accuracy: 0.5125\n",
      "Epoch 104, Training Loss: 0.17438860814417562, Validation Loss: 0.17345041235287983, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 105, Training Loss: 0.17368855735948008, Validation Loss: 0.17268112103144329, Validation Accuracy: 0.5375\n",
      "Epoch 106, Training Loss: 0.17392302328540432, Validation Loss: 0.1741419603427251, Validation Accuracy: 0.4875\n",
      "Epoch 107, Training Loss: 0.17375808521624533, Validation Loss: 0.1739999125401179, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 108, Training Loss: 0.17444104484973416, Validation Loss: 0.1733699599901835, Validation Accuracy: 0.475\n",
      "Epoch 109, Training Loss: 0.17364599339423642, Validation Loss: 0.17250358959039053, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 110, Training Loss: 0.17420971633926516, Validation Loss: 0.17347800234953561, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 111, Training Loss: 0.17364503299036332, Validation Loss: 0.17368242939313253, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 112, Training Loss: 0.174350461652202, Validation Loss: 0.17331562836964926, Validation Accuracy: 0.4875\n",
      "Epoch 113, Training Loss: 0.17378495970079977, Validation Loss: 0.17273569703102112, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 114, Training Loss: 0.17425526870835212, Validation Loss: 0.17332670986652374, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 115, Training Loss: 0.17366072631651355, Validation Loss: 0.17369327545166016, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 116, Training Loss: 0.17437986596938101, Validation Loss: 0.17332620124022166, Validation Accuracy: 0.49375\n",
      "Epoch 117, Training Loss: 0.1737744591889843, Validation Loss: 0.1734281897544861, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 118, Training Loss: 0.17406527649971745, Validation Loss: 0.1732659250497818, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 119, Training Loss: 0.17367985652339074, Validation Loss: 0.17420811851819357, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 120, Training Loss: 0.17445680018394225, Validation Loss: 0.1732376992702484, Validation Accuracy: 0.5125\n",
      "Epoch 121, Training Loss: 0.17371569814220553, Validation Loss: 0.17485131025314332, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 122, Training Loss: 0.17427801893603417, Validation Loss: 0.17310565213362375, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 123, Training Loss: 0.1736630907943172, Validation Loss: 0.17496641675631205, Validation Accuracy: 0.48125\n",
      "Epoch 124, Training Loss: 0.1743802192711061, Validation Loss: 0.17327566643555958, Validation Accuracy: 0.50625\n",
      "Epoch 125, Training Loss: 0.17355415994121182, Validation Loss: 0.1756911337375641, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 126, Training Loss: 0.17451679706573486, Validation Loss: 0.17273403306802113, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 127, Training Loss: 0.17346545284794224, Validation Loss: 0.17536944647630057, Validation Accuracy: 0.475\n",
      "Epoch 128, Training Loss: 0.1745223758682128, Validation Loss: 0.17321718831857044, Validation Accuracy: 0.5125\n",
      "Epoch 129, Training Loss: 0.17347482087150698, Validation Loss: 0.17568052609761556, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 130, Training Loss: 0.174174111216299, Validation Loss: 0.17318947116533914, Validation Accuracy: 0.5375\n",
      "Epoch 131, Training Loss: 0.17361239704393572, Validation Loss: 0.17429931660493214, Validation Accuracy: 0.4875\n",
      "Epoch 132, Training Loss: 0.17458903597247216, Validation Loss: 0.17345145841439566, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 133, Training Loss: 0.17360881259364466, Validation Loss: 0.17556660374005637, Validation Accuracy: 0.475\n",
      "Epoch 134, Training Loss: 0.17436424474562368, Validation Loss: 0.1722306897242864, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 135, Training Loss: 0.17362827062606812, Validation Loss: 0.1751442124446233, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 136, Training Loss: 0.1744138829169735, Validation Loss: 0.17371703187624613, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 137, Training Loss: 0.17351983439537785, Validation Loss: 0.17506535549958546, Validation Accuracy: 0.4875\n",
      "Epoch 138, Training Loss: 0.17436361505139258, Validation Loss: 0.17274017830689747, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 139, Training Loss: 0.17356625535795767, Validation Loss: 0.17464450101057688, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 140, Training Loss: 0.17433938047578257, Validation Loss: 0.1740549643834432, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 141, Training Loss: 0.17364490320605616, Validation Loss: 0.1747949053843816, Validation Accuracy: 0.49375\n",
      "Epoch 142, Training Loss: 0.17443650287966575, Validation Loss: 0.1736812909444173, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 143, Training Loss: 0.17353953565320662, Validation Loss: 0.1739838570356369, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 144, Training Loss: 0.17431745413810976, Validation Loss: 0.17450939615567526, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 145, Training Loss: 0.17359747329065878, Validation Loss: 0.1737589011589686, Validation Accuracy: 0.5125\n",
      "Epoch 146, Training Loss: 0.17444283635385574, Validation Loss: 0.17405222753683727, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 147, Training Loss: 0.17359312599705112, Validation Loss: 0.17294328808784484, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 148, Training Loss: 0.17431132831881124, Validation Loss: 0.17488931914170583, Validation Accuracy: 0.48125\n",
      "Epoch 149, Training Loss: 0.17355231075517594, Validation Loss: 0.17388816873232524, Validation Accuracy: 0.50625\n",
      "Epoch 150, Training Loss: 0.17439471858163033, Validation Loss: 0.17523473997910818, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 151, Training Loss: 0.1737847948266614, Validation Loss: 0.17225070893764496, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 152, Training Loss: 0.17423530643986118, Validation Loss: 0.17572011649608613, Validation Accuracy: 0.475\n",
      "Epoch 153, Training Loss: 0.17379404796708015, Validation Loss: 0.1734835724035899, Validation Accuracy: 0.5125\n",
      "Epoch 154, Training Loss: 0.17398165214446284, Validation Loss: 0.1756644348303477, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 155, Training Loss: 0.17401637857960117, Validation Loss: 0.17265972991784415, Validation Accuracy: 0.5375\n",
      "Epoch 156, Training Loss: 0.17389404725643895, Validation Loss: 0.17579673926035563, Validation Accuracy: 0.4875\n",
      "Epoch 157, Training Loss: 0.17396363567921422, Validation Loss: 0.17415226101875306, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 158, Training Loss: 0.17398678919961375, Validation Loss: 0.17537590861320496, Validation Accuracy: 0.475\n",
      "Epoch 159, Training Loss: 0.1740770613954913, Validation Loss: 0.17182225485642752, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 160, Training Loss: 0.17376776808692562, Validation Loss: 0.1764826516310374, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 161, Training Loss: 0.17424008346373035, Validation Loss: 0.17397743761539458, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 162, Training Loss: 0.17369622665066872, Validation Loss: 0.1753317137559255, Validation Accuracy: 0.4875\n",
      "Epoch 163, Training Loss: 0.17441765867894696, Validation Loss: 0.17273398141066235, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 164, Training Loss: 0.17335690798298006, Validation Loss: 0.17578230599562328, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 165, Training Loss: 0.17467245603761367, Validation Loss: 0.17370080053806305, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 166, Training Loss: 0.1736418153009107, Validation Loss: 0.1748695433139801, Validation Accuracy: 0.49375\n",
      "Epoch 167, Training Loss: 0.17430349271143636, Validation Loss: 0.17360992829004923, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 168, Training Loss: 0.17362371279347327, Validation Loss: 0.17486042777697244, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 169, Training Loss: 0.17442357492062352, Validation Loss: 0.17389308114846547, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 170, Training Loss: 0.17378728620467648, Validation Loss: 0.17372337579727173, Validation Accuracy: 0.5125\n",
      "Epoch 171, Training Loss: 0.1742191905936887, Validation Loss: 0.17437333861986795, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 172, Training Loss: 0.1735940013201006, Validation Loss: 0.17324005564053854, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 173, Training Loss: 0.17433804273605347, Validation Loss: 0.17396635413169861, Validation Accuracy: 0.48125\n",
      "Epoch 174, Training Loss: 0.17370395122035856, Validation Loss: 0.17422389884789785, Validation Accuracy: 0.50625\n",
      "Epoch 175, Training Loss: 0.17427602169975157, Validation Loss: 0.17453709840774537, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 176, Training Loss: 0.17363387394335963, Validation Loss: 0.17208536763985952, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 177, Training Loss: 0.17442653592555754, Validation Loss: 0.17391953468322754, Validation Accuracy: 0.475\n",
      "Epoch 178, Training Loss: 0.17373913334261987, Validation Loss: 0.17370892564455667, Validation Accuracy: 0.5125\n",
      "Epoch 179, Training Loss: 0.1740580912559263, Validation Loss: 0.17481712301572164, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 180, Training Loss: 0.1736602961055694, Validation Loss: 0.1728167563676834, Validation Accuracy: 0.5375\n",
      "Epoch 181, Training Loss: 0.17429604020810896, Validation Loss: 0.1738168070713679, Validation Accuracy: 0.4875\n",
      "Epoch 182, Training Loss: 0.1737576497177924, Validation Loss: 0.1744041750828425, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 183, Training Loss: 0.17430025675604421, Validation Loss: 0.17392867803573608, Validation Accuracy: 0.475\n",
      "Epoch 184, Training Loss: 0.1737041756991417, Validation Loss: 0.17192159791787465, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 185, Training Loss: 0.17421984816751174, Validation Loss: 0.17417403658231098, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 186, Training Loss: 0.17394066337616212, Validation Loss: 0.1737595647573471, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 187, Training Loss: 0.17413205292917067, Validation Loss: 0.17384031017621357, Validation Accuracy: 0.4875\n",
      "Epoch 188, Training Loss: 0.17385852336883545, Validation Loss: 0.17286143104235333, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 189, Training Loss: 0.1742266724186559, Validation Loss: 0.17343632678190868, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 190, Training Loss: 0.1738685715583063, Validation Loss: 0.17347460488478342, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 191, Training Loss: 0.17413452700261148, Validation Loss: 0.17359021604061126, Validation Accuracy: 0.49375\n",
      "Epoch 192, Training Loss: 0.17384395003318787, Validation Loss: 0.1733156164487203, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 193, Training Loss: 0.17415846307431498, Validation Loss: 0.17327283521493275, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 194, Training Loss: 0.17394502028342215, Validation Loss: 0.17351778447628022, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 195, Training Loss: 0.17376567086865824, Validation Loss: 0.17343980073928833, Validation Accuracy: 0.5125\n",
      "Epoch 196, Training Loss: 0.1740825512716847, Validation Loss: 0.17357681194941202, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 197, Training Loss: 0.17407652783778407, Validation Loss: 0.17304030160109202, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 198, Training Loss: 0.17402817501175788, Validation Loss: 0.17355482081572216, Validation Accuracy: 0.48125\n",
      "Epoch 199, Training Loss: 0.1739591158205463, Validation Loss: 0.1733348419268926, Validation Accuracy: 0.50625\n",
      "Epoch 200, Training Loss: 0.17393778120317765, Validation Loss: 0.17362078527609506, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 201, Training Loss: 0.17414618740158697, Validation Loss: 0.17286405662695567, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 202, Training Loss: 0.17399499012577918, Validation Loss: 0.17369587620099386, Validation Accuracy: 0.475\n",
      "Epoch 203, Training Loss: 0.17395654080375547, Validation Loss: 0.17322982649008434, Validation Accuracy: 0.5125\n",
      "Epoch 204, Training Loss: 0.17387661818535097, Validation Loss: 0.17374917070070903, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 205, Training Loss: 0.17418110659045558, Validation Loss: 0.17300018966197966, Validation Accuracy: 0.5375\n",
      "Epoch 206, Training Loss: 0.17388192636351432, Validation Loss: 0.1736333668231964, Validation Accuracy: 0.4875\n",
      "Epoch 207, Training Loss: 0.1740277438394485, Validation Loss: 0.17354031503200532, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 208, Training Loss: 0.1738260801761381, Validation Loss: 0.17401549220085144, Validation Accuracy: 0.475\n",
      "Epoch 209, Training Loss: 0.17423605390133395, Validation Loss: 0.17289947271347045, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 210, Training Loss: 0.17391026885278763, Validation Loss: 0.17418626149495442, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 211, Training Loss: 0.17401975345227025, Validation Loss: 0.17352233529090882, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 212, Training Loss: 0.17379319331338328, Validation Loss: 0.1739274263381958, Validation Accuracy: 0.4875\n",
      "Epoch 213, Training Loss: 0.1742819211175365, Validation Loss: 0.1730769415696462, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 214, Training Loss: 0.17375465939121862, Validation Loss: 0.17364599307378134, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 215, Training Loss: 0.17427539921575977, Validation Loss: 0.17340410749117532, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 216, Training Loss: 0.17365721781407634, Validation Loss: 0.17374098896980286, Validation Accuracy: 0.49375\n",
      "Epoch 217, Training Loss: 0.17432274068555526, Validation Loss: 0.1732845256725947, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 218, Training Loss: 0.1737926842704896, Validation Loss: 0.17330669363339743, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 219, Training Loss: 0.17423897116414963, Validation Loss: 0.1734377423922221, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 220, Training Loss: 0.17377882330648362, Validation Loss: 0.17327333887418112, Validation Accuracy: 0.5125\n",
      "Epoch 221, Training Loss: 0.1742117702960968, Validation Loss: 0.17345665295918783, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 222, Training Loss: 0.1738617035650438, Validation Loss: 0.17290725509325663, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 223, Training Loss: 0.17412897800245591, Validation Loss: 0.17353565295537313, Validation Accuracy: 0.48125\n",
      "Epoch 224, Training Loss: 0.17363590002059937, Validation Loss: 0.17348201473553976, Validation Accuracy: 0.50625\n",
      "Epoch 225, Training Loss: 0.17440000272566272, Validation Loss: 0.17348788678646088, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 226, Training Loss: 0.173696615042225, Validation Loss: 0.17222646375497183, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 227, Training Loss: 0.17428297140905935, Validation Loss: 0.17355350454648336, Validation Accuracy: 0.475\n",
      "Epoch 228, Training Loss: 0.17370134640124538, Validation Loss: 0.17328292727470399, Validation Accuracy: 0.5125\n",
      "Epoch 229, Training Loss: 0.1743211231885418, Validation Loss: 0.17347202797730762, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 230, Training Loss: 0.17369646362719998, Validation Loss: 0.17269828617572786, Validation Accuracy: 0.5375\n",
      "Epoch 231, Training Loss: 0.17432336509227753, Validation Loss: 0.1734317014614741, Validation Accuracy: 0.4875\n",
      "Epoch 232, Training Loss: 0.173674437788225, Validation Loss: 0.1739696055650711, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 233, Training Loss: 0.1743749346463911, Validation Loss: 0.17344201803207399, Validation Accuracy: 0.475\n",
      "Epoch 234, Training Loss: 0.1736560324507375, Validation Loss: 0.17207840979099273, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 235, Training Loss: 0.17437539562102286, Validation Loss: 0.1735220432281494, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 236, Training Loss: 0.17363281067340605, Validation Loss: 0.17373419900735218, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 237, Training Loss: 0.17438627683347271, Validation Loss: 0.17335731883843739, Validation Accuracy: 0.4875\n",
      "Epoch 238, Training Loss: 0.17371931431754942, Validation Loss: 0.17272696991761524, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 239, Training Loss: 0.17431805595274893, Validation Loss: 0.1733546197414398, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 240, Training Loss: 0.17365335120308784, Validation Loss: 0.1738078643878301, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 241, Training Loss: 0.17438579615085356, Validation Loss: 0.17332307497660318, Validation Accuracy: 0.49375\n",
      "Epoch 242, Training Loss: 0.17372914908393736, Validation Loss: 0.17351646423339845, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 243, Training Loss: 0.17431769159532362, Validation Loss: 0.17325632174809774, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 244, Training Loss: 0.17357545225850998, Validation Loss: 0.17455168863137563, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 245, Training Loss: 0.17445479814083345, Validation Loss: 0.17323095202445984, Validation Accuracy: 0.5125\n",
      "Epoch 246, Training Loss: 0.17364573382562207, Validation Loss: 0.17467589775721232, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 247, Training Loss: 0.1743260670092798, Validation Loss: 0.17314275602499643, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 248, Training Loss: 0.1736442999493691, Validation Loss: 0.174985866745313, Validation Accuracy: 0.48125\n",
      "Epoch 249, Training Loss: 0.174380351939509, Validation Loss: 0.1732737253109614, Validation Accuracy: 0.50625\n",
      "Epoch 250, Training Loss: 0.1735524179474, Validation Loss: 0.17574711441993712, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 251, Training Loss: 0.17448476677940739, Validation Loss: 0.17287695904572806, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 252, Training Loss: 0.17348560690879822, Validation Loss: 0.17530174255371095, Validation Accuracy: 0.475\n",
      "Epoch 253, Training Loss: 0.1745258987911286, Validation Loss: 0.17321908275286357, Validation Accuracy: 0.5125\n",
      "Epoch 254, Training Loss: 0.17344737725873147, Validation Loss: 0.17543052633603415, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 255, Training Loss: 0.17454885234755854, Validation Loss: 0.17292322119077047, Validation Accuracy: 0.5375\n",
      "Epoch 256, Training Loss: 0.17343813853879128, Validation Loss: 0.1750822216272354, Validation Accuracy: 0.4875\n",
      "Epoch 257, Training Loss: 0.17455852752731693, Validation Loss: 0.17345785697301228, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 258, Training Loss: 0.17363961761997593, Validation Loss: 0.17545253535111746, Validation Accuracy: 0.475\n",
      "Epoch 259, Training Loss: 0.17404726772539078, Validation Loss: 0.17314282953739166, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 260, Training Loss: 0.1737185336889759, Validation Loss: 0.1745075712601344, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 261, Training Loss: 0.17445166360947392, Validation Loss: 0.1736689289410909, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 262, Training Loss: 0.17354368490557517, Validation Loss: 0.17506579558054605, Validation Accuracy: 0.4875\n",
      "Epoch 263, Training Loss: 0.17431734406178997, Validation Loss: 0.1727402518192927, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 264, Training Loss: 0.17359294574106893, Validation Loss: 0.17453668713569642, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 265, Training Loss: 0.17439003721360238, Validation Loss: 0.17387351095676423, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 266, Training Loss: 0.17356631736601552, Validation Loss: 0.17482304871082305, Validation Accuracy: 0.49375\n",
      "Epoch 267, Training Loss: 0.17442186369049933, Validation Loss: 0.17367267807324727, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 268, Training Loss: 0.1735381676304725, Validation Loss: 0.1740282118320465, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 269, Training Loss: 0.17429278310268156, Validation Loss: 0.17460642258326212, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 270, Training Loss: 0.1736260316064281, Validation Loss: 0.17379115124543507, Validation Accuracy: 0.5125\n",
      "Epoch 271, Training Loss: 0.17435089522792446, Validation Loss: 0.17475834786891936, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 272, Training Loss: 0.17375495356898155, Validation Loss: 0.17304007411003114, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 273, Training Loss: 0.17431097645913401, Validation Loss: 0.17495953838030498, Validation Accuracy: 0.48125\n",
      "Epoch 274, Training Loss: 0.1735899794486261, Validation Loss: 0.1738942265510559, Validation Accuracy: 0.50625\n",
      "Epoch 275, Training Loss: 0.17448031710040185, Validation Loss: 0.17556911408901216, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 276, Training Loss: 0.17366634501564887, Validation Loss: 0.17220490475495656, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 277, Training Loss: 0.17427096732201114, Validation Loss: 0.1758049766222636, Validation Accuracy: 0.475\n",
      "Epoch 278, Training Loss: 0.17384018821101035, Validation Loss: 0.17348047693570454, Validation Accuracy: 0.5125\n",
      "Epoch 279, Training Loss: 0.1739941801755659, Validation Loss: 0.1757987787326177, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 280, Training Loss: 0.1739991739872963, Validation Loss: 0.17265974283218383, Validation Accuracy: 0.5375\n",
      "Epoch 281, Training Loss: 0.1738667199688573, Validation Loss: 0.17545778354008992, Validation Accuracy: 0.4875\n",
      "Epoch 282, Training Loss: 0.1739933019684207, Validation Loss: 0.17428462306658427, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 283, Training Loss: 0.1739847323586864, Validation Loss: 0.17569364309310914, Validation Accuracy: 0.475\n",
      "Epoch 284, Training Loss: 0.1740562487994471, Validation Loss: 0.1719135344028473, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 285, Training Loss: 0.17373399196132536, Validation Loss: 0.17668451368808746, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 286, Training Loss: 0.1742156744003296, Validation Loss: 0.1738547017176946, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 287, Training Loss: 0.17375831161775895, Validation Loss: 0.17472406923770906, Validation Accuracy: 0.4875\n",
      "Epoch 288, Training Loss: 0.1743539018977073, Validation Loss: 0.17272751927375793, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 289, Training Loss: 0.1733997473793645, Validation Loss: 0.17546748419602712, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 290, Training Loss: 0.17464755667794135, Validation Loss: 0.1738078276316325, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 291, Training Loss: 0.17364040834288444, Validation Loss: 0.17476731936136883, Validation Accuracy: 0.49375\n",
      "Epoch 292, Training Loss: 0.17429570373027556, Validation Loss: 0.17362590332825978, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 293, Training Loss: 0.17362847924232483, Validation Loss: 0.17439446349938711, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 294, Training Loss: 0.17438828608682078, Validation Loss: 0.1739814470211665, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 295, Training Loss: 0.17372749072890128, Validation Loss: 0.1741118292013804, Validation Accuracy: 0.5125\n",
      "Epoch 296, Training Loss: 0.1742834520916785, Validation Loss: 0.17412197589874268, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 297, Training Loss: 0.17359016258870402, Validation Loss: 0.17331499656041463, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 298, Training Loss: 0.17417054214785177, Validation Loss: 0.17472254137198132, Validation Accuracy: 0.48125\n",
      "Epoch 299, Training Loss: 0.17374919547188666, Validation Loss: 0.17420340180397034, Validation Accuracy: 0.50625\n",
      "Epoch 300, Training Loss: 0.17429569844276674, Validation Loss: 0.17448995709419252, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 301, Training Loss: 0.17363200456865371, Validation Loss: 0.17209441165129344, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 302, Training Loss: 0.17440385443549003, Validation Loss: 0.17391834557056426, Validation Accuracy: 0.475\n",
      "Epoch 303, Training Loss: 0.1738175533471569, Validation Loss: 0.1736826797326406, Validation Accuracy: 0.5125\n",
      "Epoch 304, Training Loss: 0.17426929022035292, Validation Loss: 0.17430315613746644, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 305, Training Loss: 0.17360350008933775, Validation Loss: 0.1727361371119817, Validation Accuracy: 0.5375\n",
      "Epoch 306, Training Loss: 0.17440726007184676, Validation Loss: 0.17362615764141082, Validation Accuracy: 0.4875\n",
      "Epoch 307, Training Loss: 0.1737594215139266, Validation Loss: 0.1743929346402486, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 308, Training Loss: 0.17401720679575397, Validation Loss: 0.17510327100753784, Validation Accuracy: 0.475\n",
      "Epoch 309, Training Loss: 0.1737582923904542, Validation Loss: 0.17175156772136688, Validation Accuracy: 0.5604166666666667\n",
      "New best validation loss, checkpoint saved\n",
      "Epoch 310, Training Loss: 0.17424019065595442, Validation Loss: 0.1739815851052602, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 311, Training Loss: 0.1738321699442402, Validation Loss: 0.17407323618729909, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 312, Training Loss: 0.17406711751414883, Validation Loss: 0.1740473637978236, Validation Accuracy: 0.4875\n",
      "Epoch 313, Training Loss: 0.17384007476991223, Validation Loss: 0.17287760575612385, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 314, Training Loss: 0.1742506656915911, Validation Loss: 0.17338781754175822, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 315, Training Loss: 0.17395452482085075, Validation Loss: 0.1735647886991501, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 316, Training Loss: 0.17397253167244695, Validation Loss: 0.1738205373287201, Validation Accuracy: 0.49375\n",
      "Epoch 317, Training Loss: 0.17385424289011187, Validation Loss: 0.17330203652381898, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 318, Training Loss: 0.17417039457828767, Validation Loss: 0.17327066858609516, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 319, Training Loss: 0.17393335700035095, Validation Loss: 0.17350384692351023, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 320, Training Loss: 0.17390494048595428, Validation Loss: 0.17328608632087708, Validation Accuracy: 0.5125\n",
      "Epoch 321, Training Loss: 0.1739959438000956, Validation Loss: 0.17355439166227976, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 322, Training Loss: 0.1741067329722066, Validation Loss: 0.17305513123671215, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 323, Training Loss: 0.17403164265617246, Validation Loss: 0.17349344889322918, Validation Accuracy: 0.48125\n",
      "Epoch 324, Training Loss: 0.17396875927525182, Validation Loss: 0.17334759533405303, Validation Accuracy: 0.50625\n",
      "Epoch 325, Training Loss: 0.17393965971085332, Validation Loss: 0.17358390788237255, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 326, Training Loss: 0.17416875737328683, Validation Loss: 0.17283781866232553, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 327, Training Loss: 0.17390564901213493, Validation Loss: 0.17361885209878286, Validation Accuracy: 0.475\n",
      "Epoch 328, Training Loss: 0.17402208956979937, Validation Loss: 0.173221351703008, Validation Accuracy: 0.5125\n",
      "Epoch 329, Training Loss: 0.173899287658353, Validation Loss: 0.17374674876530966, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 330, Training Loss: 0.17419631202374736, Validation Loss: 0.17303673724333446, Validation Accuracy: 0.5375\n",
      "Epoch 331, Training Loss: 0.17387396097183228, Validation Loss: 0.17355797588825225, Validation Accuracy: 0.4875\n",
      "Epoch 332, Training Loss: 0.17412587567683188, Validation Loss: 0.1734493980805079, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 333, Training Loss: 0.17385545757509047, Validation Loss: 0.17376016676425934, Validation Accuracy: 0.475\n",
      "Epoch 334, Training Loss: 0.17419010496908618, Validation Loss: 0.17277366916338602, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 335, Training Loss: 0.17384419085518008, Validation Loss: 0.17397011717160543, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 336, Training Loss: 0.17417744475026284, Validation Loss: 0.17339442372322084, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 337, Training Loss: 0.17378452516371204, Validation Loss: 0.17367553114891052, Validation Accuracy: 0.4875\n",
      "Epoch 338, Training Loss: 0.17424155339117972, Validation Loss: 0.17307946781317393, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 339, Training Loss: 0.17377903817161436, Validation Loss: 0.17375560303529103, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 340, Training Loss: 0.17418397193954838, Validation Loss: 0.1735459089279175, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 341, Training Loss: 0.17370334075343224, Validation Loss: 0.17371589144070942, Validation Accuracy: 0.49375\n",
      "Epoch 342, Training Loss: 0.17435187774319802, Validation Loss: 0.17328111430009205, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 343, Training Loss: 0.17382774718346133, Validation Loss: 0.17336385647455851, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 344, Training Loss: 0.17409168856759225, Validation Loss: 0.17357274095217387, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 345, Training Loss: 0.1737952616906935, Validation Loss: 0.17326901654402416, Validation Accuracy: 0.5125\n",
      "Epoch 346, Training Loss: 0.17426281158001192, Validation Loss: 0.1734234611193339, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 347, Training Loss: 0.1738199976182753, Validation Loss: 0.17291077673435212, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 348, Training Loss: 0.17421606471461634, Validation Loss: 0.17346918682257334, Validation Accuracy: 0.48125\n",
      "Epoch 349, Training Loss: 0.1736309456248437, Validation Loss: 0.1734656701485316, Validation Accuracy: 0.50625\n",
      "Epoch 350, Training Loss: 0.17439632982976974, Validation Loss: 0.17347232004006705, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 351, Training Loss: 0.17369546909486094, Validation Loss: 0.17221585909525552, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 352, Training Loss: 0.17427880341006863, Validation Loss: 0.17356925308704377, Validation Accuracy: 0.475\n",
      "Epoch 353, Training Loss: 0.173663035515816, Validation Loss: 0.1732570658127467, Validation Accuracy: 0.5125\n",
      "Epoch 354, Training Loss: 0.1743708445179847, Validation Loss: 0.17348743478457132, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 355, Training Loss: 0.1736979474944453, Validation Loss: 0.17267341315746307, Validation Accuracy: 0.5375\n",
      "Epoch 356, Training Loss: 0.17425222406464239, Validation Loss: 0.17343930701414745, Validation Accuracy: 0.4875\n",
      "Epoch 357, Training Loss: 0.1736807842408457, Validation Loss: 0.17382502257823945, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 358, Training Loss: 0.1744132008283369, Validation Loss: 0.1733818213144938, Validation Accuracy: 0.475\n",
      "Epoch 359, Training Loss: 0.17367725458837324, Validation Loss: 0.1718823085228602, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 360, Training Loss: 0.17435740270922262, Validation Loss: 0.17351620197296141, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 361, Training Loss: 0.1736709802381454, Validation Loss: 0.1737468034029007, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 362, Training Loss: 0.17433417564438236, Validation Loss: 0.17336329718430837, Validation Accuracy: 0.4875\n",
      "Epoch 363, Training Loss: 0.1737264697590182, Validation Loss: 0.17274012863636018, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 364, Training Loss: 0.17431035493650743, Validation Loss: 0.17334894935290018, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 365, Training Loss: 0.1736520403815854, Validation Loss: 0.17380035122235615, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 366, Training Loss: 0.17439668120876436, Validation Loss: 0.17334666550159455, Validation Accuracy: 0.49375\n",
      "Epoch 367, Training Loss: 0.1737561845971692, Validation Loss: 0.17380343973636628, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 368, Training Loss: 0.1742433040372787, Validation Loss: 0.1732593576113383, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 369, Training Loss: 0.17360924665004976, Validation Loss: 0.174530624349912, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 370, Training Loss: 0.17443245024450363, Validation Loss: 0.1732267806927363, Validation Accuracy: 0.5125\n",
      "Epoch 371, Training Loss: 0.1736335095859343, Validation Loss: 0.17426774899164835, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 372, Training Loss: 0.17437863686392385, Validation Loss: 0.17310172120730083, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 373, Training Loss: 0.17360925337960642, Validation Loss: 0.1750996232032776, Validation Accuracy: 0.48125\n",
      "Epoch 374, Training Loss: 0.1743985145322738, Validation Loss: 0.17328004638353983, Validation Accuracy: 0.50625\n",
      "Epoch 375, Training Loss: 0.17355620332302585, Validation Loss: 0.17564803858598074, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 376, Training Loss: 0.17450513810880722, Validation Loss: 0.17279060979684194, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 377, Training Loss: 0.17347264578265528, Validation Loss: 0.1754346509774526, Validation Accuracy: 0.475\n",
      "Epoch 378, Training Loss: 0.17452539840052206, Validation Loss: 0.17321856419245402, Validation Accuracy: 0.5125\n",
      "Epoch 379, Training Loss: 0.17345084922928963, Validation Loss: 0.17553057074546813, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 380, Training Loss: 0.1745444175697142, Validation Loss: 0.1728232502937317, Validation Accuracy: 0.5375\n",
      "Epoch 381, Training Loss: 0.17344466620875942, Validation Loss: 0.17497436801592509, Validation Accuracy: 0.4875\n",
      "Epoch 382, Training Loss: 0.17458475981989213, Validation Loss: 0.1736667861541112, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 383, Training Loss: 0.17358823553208383, Validation Loss: 0.1754992405573527, Validation Accuracy: 0.475\n",
      "Epoch 384, Training Loss: 0.17440260898682378, Validation Loss: 0.17224006752173107, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 385, Training Loss: 0.1736098100100794, Validation Loss: 0.1754788895448049, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 386, Training Loss: 0.17438852162130417, Validation Loss: 0.17373403708140056, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 387, Training Loss: 0.17354965402233985, Validation Loss: 0.17504669229189554, Validation Accuracy: 0.4875\n",
      "Epoch 388, Training Loss: 0.1743192139171785, Validation Loss: 0.17287033398946125, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 389, Training Loss: 0.17354813266185024, Validation Loss: 0.1742786258459091, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 390, Training Loss: 0.1743840483888503, Validation Loss: 0.17392543057600657, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 391, Training Loss: 0.17356886113843611, Validation Loss: 0.1747351884841919, Validation Accuracy: 0.49375\n",
      "Epoch 392, Training Loss: 0.17437478803819226, Validation Loss: 0.17368816534678141, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 393, Training Loss: 0.173590182777374, Validation Loss: 0.17401650547981262, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 394, Training Loss: 0.1742950048177473, Validation Loss: 0.17454471290111542, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 395, Training Loss: 0.17360308718296788, Validation Loss: 0.17386319637298583, Validation Accuracy: 0.5125\n",
      "Epoch 396, Training Loss: 0.1744312345981598, Validation Loss: 0.174850931763649, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 397, Training Loss: 0.17369230812595737, Validation Loss: 0.17300931811332704, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 398, Training Loss: 0.1743254925935499, Validation Loss: 0.1749922235806783, Validation Accuracy: 0.48125\n",
      "Epoch 399, Training Loss: 0.17358032493822037, Validation Loss: 0.1738655835390091, Validation Accuracy: 0.50625\n",
      "Epoch 400, Training Loss: 0.17437104448195426, Validation Loss: 0.17395179470380148, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 401, Training Loss: 0.17366560091895442, Validation Loss: 0.17250055472056072, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 402, Training Loss: 0.17430306298117484, Validation Loss: 0.17585393687089285, Validation Accuracy: 0.475\n",
      "Epoch 403, Training Loss: 0.1736927835210677, Validation Loss: 0.17358953257401785, Validation Accuracy: 0.5125\n",
      "Epoch 404, Training Loss: 0.17395917061836488, Validation Loss: 0.17580295900503795, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 405, Training Loss: 0.17400902653894118, Validation Loss: 0.17266035079956055, Validation Accuracy: 0.5375\n",
      "Epoch 406, Training Loss: 0.17389257829035482, Validation Loss: 0.1757734626531601, Validation Accuracy: 0.4875\n",
      "Epoch 407, Training Loss: 0.17397235381987788, Validation Loss: 0.1740329772233963, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 408, Training Loss: 0.1739703041891898, Validation Loss: 0.17521437406539916, Validation Accuracy: 0.475\n",
      "Epoch 409, Training Loss: 0.17408732012394937, Validation Loss: 0.17200634082158406, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 410, Training Loss: 0.1737780152790008, Validation Loss: 0.17701212366422017, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 411, Training Loss: 0.17424726293933007, Validation Loss: 0.17389154235521953, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 412, Training Loss: 0.17370627868560054, Validation Loss: 0.1753771742184957, Validation Accuracy: 0.4875\n",
      "Epoch 413, Training Loss: 0.1744212407258249, Validation Loss: 0.17272907594839731, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 414, Training Loss: 0.1733820568169317, Validation Loss: 0.1753832459449768, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 415, Training Loss: 0.17467576505676394, Validation Loss: 0.17378787497679393, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 416, Training Loss: 0.17363131815387356, Validation Loss: 0.17483096917470295, Validation Accuracy: 0.49375\n",
      "Epoch 417, Training Loss: 0.17431699508620846, Validation Loss: 0.17363085150718688, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 418, Training Loss: 0.17363423060986302, Validation Loss: 0.17460102339585623, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 419, Training Loss: 0.17433284463420992, Validation Loss: 0.17403982679049174, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 420, Training Loss: 0.17379865194520644, Validation Loss: 0.17380101680755616, Validation Accuracy: 0.5125\n",
      "Epoch 421, Training Loss: 0.17424946302367794, Validation Loss: 0.1743028124173482, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 422, Training Loss: 0.17359421522386612, Validation Loss: 0.17335842450459799, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 423, Training Loss: 0.17429669489783625, Validation Loss: 0.17399308880170186, Validation Accuracy: 0.48125\n",
      "Epoch 424, Training Loss: 0.17380432832625606, Validation Loss: 0.17384923994541168, Validation Accuracy: 0.50625\n",
      "Epoch 425, Training Loss: 0.174123409294313, Validation Loss: 0.17548036177953083, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 426, Training Loss: 0.17369302866920347, Validation Loss: 0.17209610243638357, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 427, Training Loss: 0.1743076890707016, Validation Loss: 0.17406978011131286, Validation Accuracy: 0.475\n",
      "Epoch 428, Training Loss: 0.17383624709421588, Validation Loss: 0.17335914472738903, Validation Accuracy: 0.5125\n",
      "Epoch 429, Training Loss: 0.17412701681736978, Validation Loss: 0.17489480674266816, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 430, Training Loss: 0.1736313912176317, Validation Loss: 0.1727770298719406, Validation Accuracy: 0.5375\n",
      "Epoch 431, Training Loss: 0.17440437693749705, Validation Loss: 0.17365467647711436, Validation Accuracy: 0.4875\n",
      "Epoch 432, Training Loss: 0.17374884841903562, Validation Loss: 0.17444174389044445, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 433, Training Loss: 0.17429671941264982, Validation Loss: 0.17396127680937448, Validation Accuracy: 0.475\n",
      "Epoch 434, Training Loss: 0.17371850773211447, Validation Loss: 0.1719359387954076, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 435, Training Loss: 0.17421925452447706, Validation Loss: 0.1741175840298335, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 436, Training Loss: 0.17390372051346686, Validation Loss: 0.17384609977404278, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 437, Training Loss: 0.17416340449163992, Validation Loss: 0.1737733205159505, Validation Accuracy: 0.4875\n",
      "Epoch 438, Training Loss: 0.1738385130320826, Validation Loss: 0.17286744117736816, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 439, Training Loss: 0.17423682203215937, Validation Loss: 0.17343039214611053, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 440, Training Loss: 0.17385513888251397, Validation Loss: 0.17349253296852113, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 441, Training Loss: 0.17400014015936083, Validation Loss: 0.17406235933303832, Validation Accuracy: 0.49375\n",
      "Epoch 442, Training Loss: 0.1738988709065222, Validation Loss: 0.1733829398949941, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 443, Training Loss: 0.17415775166403863, Validation Loss: 0.17326530814170837, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 444, Training Loss: 0.17400262673054973, Validation Loss: 0.17349014083544415, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 445, Training Loss: 0.17388427786288724, Validation Loss: 0.1732630491256714, Validation Accuracy: 0.5125\n",
      "Epoch 446, Training Loss: 0.17396189608881552, Validation Loss: 0.17350472013155618, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 447, Training Loss: 0.17412156827988162, Validation Loss: 0.17303294936815897, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 448, Training Loss: 0.1739750720800892, Validation Loss: 0.17350078423817952, Validation Accuracy: 0.48125\n",
      "Epoch 449, Training Loss: 0.17407185608340847, Validation Loss: 0.17329999506473542, Validation Accuracy: 0.50625\n",
      "Epoch 450, Training Loss: 0.17388378083705902, Validation Loss: 0.1736259231964747, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 451, Training Loss: 0.17416910827159882, Validation Loss: 0.17290412187576293, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 452, Training Loss: 0.1739730868608721, Validation Loss: 0.1736876179774602, Validation Accuracy: 0.475\n",
      "Epoch 453, Training Loss: 0.1739671206282031, Validation Loss: 0.17322540879249573, Validation Accuracy: 0.5125\n",
      "Epoch 454, Training Loss: 0.17387685900734318, Validation Loss: 0.17371456225713094, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 455, Training Loss: 0.17417054214785177, Validation Loss: 0.17298999627431233, Validation Accuracy: 0.5375\n",
      "Epoch 456, Training Loss: 0.1738859838055026, Validation Loss: 0.17358564138412474, Validation Accuracy: 0.4875\n",
      "Epoch 457, Training Loss: 0.174119274462423, Validation Loss: 0.17345425387223562, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 458, Training Loss: 0.17380623567488887, Validation Loss: 0.17381521264712016, Validation Accuracy: 0.475\n",
      "Epoch 459, Training Loss: 0.17425340077569407, Validation Loss: 0.1728654036919276, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 460, Training Loss: 0.17390901427115163, Validation Loss: 0.17431660989920297, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 461, Training Loss: 0.174091431402391, Validation Loss: 0.17341885765393575, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 462, Training Loss: 0.1737929053844944, Validation Loss: 0.17367835839589438, Validation Accuracy: 0.4875\n",
      "Epoch 463, Training Loss: 0.17424220904227225, Validation Loss: 0.1730449378490448, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 464, Training Loss: 0.17371054234043246, Validation Loss: 0.1736782670021057, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 465, Training Loss: 0.17420851559408249, Validation Loss: 0.1734724203745524, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 466, Training Loss: 0.17366841147022863, Validation Loss: 0.1738928327957789, Validation Accuracy: 0.49375\n",
      "Epoch 467, Training Loss: 0.17433036383121245, Validation Loss: 0.17328799565633138, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 468, Training Loss: 0.17372681248572566, Validation Loss: 0.1733147641023, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 469, Training Loss: 0.1741650681341848, Validation Loss: 0.17355943024158477, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 470, Training Loss: 0.17384651495564368, Validation Loss: 0.17324975232283274, Validation Accuracy: 0.5125\n",
      "Epoch 471, Training Loss: 0.17421234663455717, Validation Loss: 0.17347280383110047, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 472, Training Loss: 0.17386740638363746, Validation Loss: 0.17290875613689421, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 473, Training Loss: 0.1740662739161522, Validation Loss: 0.17364616692066193, Validation Accuracy: 0.48125\n",
      "Epoch 474, Training Loss: 0.17371655952545903, Validation Loss: 0.17347722550233205, Validation Accuracy: 0.50625\n",
      "Epoch 475, Training Loss: 0.17439116297229643, Validation Loss: 0.1734668989976247, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 476, Training Loss: 0.17367974644707096, Validation Loss: 0.17229424218336742, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 477, Training Loss: 0.17435154222672986, Validation Loss: 0.17348530888557434, Validation Accuracy: 0.475\n",
      "Epoch 478, Training Loss: 0.1736726342670379, Validation Loss: 0.1732792278130849, Validation Accuracy: 0.5125\n",
      "Epoch 479, Training Loss: 0.17436587570175047, Validation Loss: 0.17342770099639893, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 480, Training Loss: 0.17365518885274087, Validation Loss: 0.17270783483982086, Validation Accuracy: 0.5375\n",
      "Epoch 481, Training Loss: 0.17429235433378526, Validation Loss: 0.17341508467992148, Validation Accuracy: 0.4875\n",
      "Epoch 482, Training Loss: 0.1736364580931202, Validation Loss: 0.17388152778148652, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 483, Training Loss: 0.1744220309680508, Validation Loss: 0.17346252302328746, Validation Accuracy: 0.475\n",
      "Epoch 484, Training Loss: 0.17363296689525728, Validation Loss: 0.17183238764603934, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 485, Training Loss: 0.17428027141478755, Validation Loss: 0.173668905099233, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 486, Training Loss: 0.17366548651649105, Validation Loss: 0.17363299230734508, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 487, Training Loss: 0.17438756314016157, Validation Loss: 0.17334376275539398, Validation Accuracy: 0.4875\n",
      "Epoch 488, Training Loss: 0.17371398018252465, Validation Loss: 0.17273516754309337, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 489, Training Loss: 0.17431517185703402, Validation Loss: 0.17333773573239644, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 490, Training Loss: 0.17364854966440507, Validation Loss: 0.17371761004130046, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 491, Training Loss: 0.17438872254663898, Validation Loss: 0.1733354240655899, Validation Accuracy: 0.49375\n",
      "Epoch 492, Training Loss: 0.17376412066721147, Validation Loss: 0.1738630751768748, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 493, Training Loss: 0.1742233859915887, Validation Loss: 0.17325662275155385, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 494, Training Loss: 0.17361366556536767, Validation Loss: 0.17435081005096437, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 495, Training Loss: 0.17444185335789958, Validation Loss: 0.17322597304979961, Validation Accuracy: 0.5125\n",
      "Epoch 496, Training Loss: 0.1736855439601406, Validation Loss: 0.17506072620550792, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 497, Training Loss: 0.17424948273166532, Validation Loss: 0.17300242682298025, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 498, Training Loss: 0.17363405275729396, Validation Loss: 0.17449180285135904, Validation Accuracy: 0.48125\n",
      "Epoch 499, Training Loss: 0.1744034093233847, Validation Loss: 0.17327715059121448, Validation Accuracy: 0.50625\n",
      "Epoch 500, Training Loss: 0.17354592969340663, Validation Loss: 0.17576825221379597, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 501, Training Loss: 0.1744869779194555, Validation Loss: 0.17281290491422016, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 502, Training Loss: 0.17349067378428676, Validation Loss: 0.17538355092207591, Validation Accuracy: 0.475\n",
      "Epoch 503, Training Loss: 0.17449204383357877, Validation Loss: 0.1732203076283137, Validation Accuracy: 0.5125\n",
      "Epoch 504, Training Loss: 0.17347925228457298, Validation Loss: 0.17574589153130848, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 505, Training Loss: 0.17445738950083334, Validation Loss: 0.172776593764623, Validation Accuracy: 0.5375\n",
      "Epoch 506, Training Loss: 0.17350274516690162, Validation Loss: 0.17480595807234448, Validation Accuracy: 0.4875\n",
      "Epoch 507, Training Loss: 0.17456592571350835, Validation Loss: 0.17360470493634542, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 508, Training Loss: 0.17359055194162554, Validation Loss: 0.17548611462116243, Validation Accuracy: 0.475\n",
      "Epoch 509, Training Loss: 0.17440470139826497, Validation Loss: 0.1724287152290344, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 510, Training Loss: 0.17361783885186718, Validation Loss: 0.17558749616146088, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 511, Training Loss: 0.17439524252568522, Validation Loss: 0.17370261152585348, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 512, Training Loss: 0.17352813914898904, Validation Loss: 0.1750214417775472, Validation Accuracy: 0.4875\n",
      "Epoch 513, Training Loss: 0.1743861734867096, Validation Loss: 0.17274379233519235, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 514, Training Loss: 0.17354250723315823, Validation Loss: 0.17461199462413787, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 515, Training Loss: 0.17439762815352408, Validation Loss: 0.173824679851532, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 516, Training Loss: 0.173593268759789, Validation Loss: 0.17488403022289276, Validation Accuracy: 0.49375\n",
      "Epoch 517, Training Loss: 0.17439433547758287, Validation Loss: 0.17367552121480306, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 518, Training Loss: 0.17356260986097397, Validation Loss: 0.173957763115565, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 519, Training Loss: 0.17429530187960593, Validation Loss: 0.17452206015586852, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 520, Training Loss: 0.1735988244895012, Validation Loss: 0.1737761398156484, Validation Accuracy: 0.5125\n",
      "Epoch 521, Training Loss: 0.17435431913022073, Validation Loss: 0.17475472489992777, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 522, Training Loss: 0.17375703684745297, Validation Loss: 0.1730340341726939, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 523, Training Loss: 0.17429623824934806, Validation Loss: 0.17495659589767457, Validation Accuracy: 0.48125\n",
      "Epoch 524, Training Loss: 0.17359271741682483, Validation Loss: 0.17387934426466625, Validation Accuracy: 0.50625\n",
      "Epoch 525, Training Loss: 0.1744802738389661, Validation Loss: 0.17474314371744792, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 526, Training Loss: 0.17361002631725803, Validation Loss: 0.17236903806527457, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 527, Training Loss: 0.1742858382002, Validation Loss: 0.17568956315517426, Validation Accuracy: 0.475\n",
      "Epoch 528, Training Loss: 0.1737831009011115, Validation Loss: 0.17349623342355092, Validation Accuracy: 0.5125\n",
      "Epoch 529, Training Loss: 0.1739559635039299, Validation Loss: 0.1754441261291504, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 530, Training Loss: 0.17402422860745462, Validation Loss: 0.17266365786393484, Validation Accuracy: 0.5375\n",
      "Epoch 531, Training Loss: 0.17387378167721532, Validation Loss: 0.17564938763777416, Validation Accuracy: 0.4875\n",
      "Epoch 532, Training Loss: 0.17397290083669847, Validation Loss: 0.1742151806751887, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 533, Training Loss: 0.17395587842310628, Validation Loss: 0.1753149688243866, Validation Accuracy: 0.475\n",
      "Epoch 534, Training Loss: 0.17392650342756702, Validation Loss: 0.17222383220990498, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 535, Training Loss: 0.17383254583804839, Validation Loss: 0.17596428990364074, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 536, Training Loss: 0.17395236174906453, Validation Loss: 0.1733242283264796, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 537, Training Loss: 0.17349852381214018, Validation Loss: 0.17459023495515189, Validation Accuracy: 0.4875\n",
      "Epoch 538, Training Loss: 0.18089788383053196, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.46458333333333335\n",
      "Epoch 539, Training Loss: 0.17505544424057007, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 540, Training Loss: 0.1736879555448409, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 541, Training Loss: 0.1733189263651448, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.50625\n",
      "Epoch 542, Training Loss: 0.17641820350000936, Validation Loss: 0.1734334131081899, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 543, Training Loss: 0.17371655519931548, Validation Loss: 0.17549689809481303, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 544, Training Loss: 0.1744508070330466, Validation Loss: 0.17503916919231416, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 545, Training Loss: 0.17369535180830187, Validation Loss: 0.17383227348327637, Validation Accuracy: 0.5125\n",
      "Epoch 546, Training Loss: 0.1742398637917734, Validation Loss: 0.17463098963101706, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 547, Training Loss: 0.173606316889486, Validation Loss: 0.17353219886620838, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 548, Training Loss: 0.1741927323802825, Validation Loss: 0.1744016230106354, Validation Accuracy: 0.48125\n",
      "Epoch 549, Training Loss: 0.17375697580076033, Validation Loss: 0.17409173846244813, Validation Accuracy: 0.50625\n",
      "Epoch 550, Training Loss: 0.17423377017821035, Validation Loss: 0.17488672335942587, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 551, Training Loss: 0.17365989665831288, Validation Loss: 0.1720750590165456, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 552, Training Loss: 0.17432013057893322, Validation Loss: 0.17418997784455617, Validation Accuracy: 0.475\n",
      "Epoch 553, Training Loss: 0.17379528716687234, Validation Loss: 0.17340421477953594, Validation Accuracy: 0.5125\n",
      "Epoch 554, Training Loss: 0.17420959809134084, Validation Loss: 0.17457740505536398, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 555, Training Loss: 0.17365176014361844, Validation Loss: 0.17269570926825206, Validation Accuracy: 0.5375\n",
      "Epoch 556, Training Loss: 0.17431954991432927, Validation Loss: 0.17372159262498219, Validation Accuracy: 0.4875\n",
      "Epoch 557, Training Loss: 0.17377677511784337, Validation Loss: 0.1740827391544978, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 558, Training Loss: 0.1742194689089252, Validation Loss: 0.17413938840230306, Validation Accuracy: 0.475\n",
      "Epoch 559, Training Loss: 0.1737511037818847, Validation Loss: 0.17207829852898915, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 560, Training Loss: 0.17421592868143512, Validation Loss: 0.17393367985884348, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 561, Training Loss: 0.17379826836047635, Validation Loss: 0.17384389638900757, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 562, Training Loss: 0.17418239722328802, Validation Loss: 0.17369897961616515, Validation Accuracy: 0.4875\n",
      "Epoch 563, Training Loss: 0.17384588478072996, Validation Loss: 0.17286987602710724, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 564, Training Loss: 0.17413353391232028, Validation Loss: 0.17349616686503092, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 565, Training Loss: 0.17384961007102842, Validation Loss: 0.1735985259215037, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 566, Training Loss: 0.1741030115273691, Validation Loss: 0.17354325950145721, Validation Accuracy: 0.49375\n",
      "Epoch 567, Training Loss: 0.1738298862211166, Validation Loss: 0.17332134246826172, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 568, Training Loss: 0.1740804732807221, Validation Loss: 0.17326548894246419, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 569, Training Loss: 0.1739625709672128, Validation Loss: 0.17359063824017842, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 570, Training Loss: 0.17391437244030736, Validation Loss: 0.17322753171126049, Validation Accuracy: 0.5125\n",
      "Epoch 571, Training Loss: 0.1739317947818387, Validation Loss: 0.17357640961805978, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 572, Training Loss: 0.17401045416632005, Validation Loss: 0.17304876049359638, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 573, Training Loss: 0.17402294470417884, Validation Loss: 0.17365160286426545, Validation Accuracy: 0.48125\n",
      "Epoch 574, Training Loss: 0.17362268172925518, Validation Loss: 0.17378716667493185, Validation Accuracy: 0.50625\n",
      "Epoch 575, Training Loss: 0.17401639011598402, Validation Loss: 0.17368081212043762, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 576, Training Loss: 0.1739165768507988, Validation Loss: 0.17281621197859445, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 577, Training Loss: 0.17394759866499132, Validation Loss: 0.17377708752950033, Validation Accuracy: 0.475\n",
      "Epoch 578, Training Loss: 0.17378670602075516, Validation Loss: 0.1732483446598053, Validation Accuracy: 0.5125\n",
      "Epoch 579, Training Loss: 0.17390792552501924, Validation Loss: 0.17391563852628072, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 580, Training Loss: 0.17391543859435665, Validation Loss: 0.17300015687942505, Validation Accuracy: 0.5375\n",
      "Epoch 581, Training Loss: 0.1739196955196319, Validation Loss: 0.17360777854919435, Validation Accuracy: 0.4875\n",
      "Epoch 582, Training Loss: 0.17391716809042038, Validation Loss: 0.17345289985338846, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 583, Training Loss: 0.17380759841011417, Validation Loss: 0.17413003941377003, Validation Accuracy: 0.475\n",
      "Epoch 584, Training Loss: 0.17408342611405156, Validation Loss: 0.17300144235293072, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 585, Training Loss: 0.17385694240370103, Validation Loss: 0.17395492494106293, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 586, Training Loss: 0.1739371495862161, Validation Loss: 0.17344087759653729, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 587, Training Loss: 0.17381174429770438, Validation Loss: 0.17376648485660554, Validation Accuracy: 0.4875\n",
      "Epoch 588, Training Loss: 0.17399345434481098, Validation Loss: 0.17303341726462046, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 589, Training Loss: 0.1738084396046977, Validation Loss: 0.17352860768636066, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 590, Training Loss: 0.1739909783486397, Validation Loss: 0.1735800047715505, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 591, Training Loss: 0.17367120663965901, Validation Loss: 0.17378653089205423, Validation Accuracy: 0.49375\n",
      "Epoch 592, Training Loss: 0.1741317827855387, Validation Loss: 0.1732797731955846, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 593, Training Loss: 0.17385976833681907, Validation Loss: 0.173360941807429, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 594, Training Loss: 0.17383149650789076, Validation Loss: 0.17370508114496866, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 595, Training Loss: 0.17379120905553141, Validation Loss: 0.17329360842704772, Validation Accuracy: 0.5125\n",
      "Epoch 596, Training Loss: 0.17403083559005492, Validation Loss: 0.1733806977669398, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 597, Training Loss: 0.17385942368738114, Validation Loss: 0.17292034824689229, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 598, Training Loss: 0.1737815257041685, Validation Loss: 0.1741238494714101, Validation Accuracy: 0.48125\n",
      "Epoch 599, Training Loss: 0.17370765007311298, Validation Loss: 0.17353276908397675, Validation Accuracy: 0.50625\n",
      "Epoch 600, Training Loss: 0.17407368796487008, Validation Loss: 0.1736200660467148, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 601, Training Loss: 0.1737543498316119, Validation Loss: 0.17239714761575062, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 602, Training Loss: 0.17389710535926203, Validation Loss: 0.1738453398148219, Validation Accuracy: 0.475\n",
      "Epoch 603, Training Loss: 0.17374731552216313, Validation Loss: 0.17333473165829977, Validation Accuracy: 0.5125\n",
      "Epoch 604, Training Loss: 0.17409862818256502, Validation Loss: 0.17344810763994853, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 605, Training Loss: 0.17376625345599267, Validation Loss: 0.17276610136032106, Validation Accuracy: 0.5375\n",
      "Epoch 606, Training Loss: 0.1738050820366029, Validation Loss: 0.1741229424873988, Validation Accuracy: 0.4875\n",
      "Epoch 607, Training Loss: 0.17369190435255727, Validation Loss: 0.17399035493532816, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 608, Training Loss: 0.17421484330008108, Validation Loss: 0.1733842670917511, Validation Accuracy: 0.475\n",
      "Epoch 609, Training Loss: 0.17372924714319168, Validation Loss: 0.17221673329671225, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 610, Training Loss: 0.17408863671364322, Validation Loss: 0.17348586320877074, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 611, Training Loss: 0.17366179775807164, Validation Loss: 0.17370043794314066, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 612, Training Loss: 0.17415948260215022, Validation Loss: 0.1733306497335434, Validation Accuracy: 0.4875\n",
      "Epoch 613, Training Loss: 0.17374867008578393, Validation Loss: 0.17285964488983155, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 614, Training Loss: 0.17397770045265074, Validation Loss: 0.17332006394863128, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 615, Training Loss: 0.17372308142723575, Validation Loss: 0.17390250662962595, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 616, Training Loss: 0.17409960252623405, Validation Loss: 0.17331501543521882, Validation Accuracy: 0.49375\n",
      "Epoch 617, Training Loss: 0.1738184618373071, Validation Loss: 0.17344021797180176, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 618, Training Loss: 0.17385211971498304, Validation Loss: 0.17325581808884938, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 619, Training Loss: 0.17366574704647064, Validation Loss: 0.17408247391382853, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 620, Training Loss: 0.17423951914233546, Validation Loss: 0.17326221664746602, Validation Accuracy: 0.5125\n",
      "Epoch 621, Training Loss: 0.1737644927155587, Validation Loss: 0.17452793021996815, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 622, Training Loss: 0.1740583618802409, Validation Loss: 0.17321677406628927, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 623, Training Loss: 0.17362267548038113, Validation Loss: 0.17417500813802084, Validation Accuracy: 0.48125\n",
      "Epoch 624, Training Loss: 0.1741738732784025, Validation Loss: 0.17327326635519663, Validation Accuracy: 0.50625\n",
      "Epoch 625, Training Loss: 0.1736366936276036, Validation Loss: 0.17519595523675283, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 626, Training Loss: 0.17419431430678214, Validation Loss: 0.1731784294048945, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 627, Training Loss: 0.1735741106733199, Validation Loss: 0.17518788774808247, Validation Accuracy: 0.475\n",
      "Epoch 628, Training Loss: 0.17425568882496126, Validation Loss: 0.17326003710428875, Validation Accuracy: 0.5125\n",
      "Epoch 629, Training Loss: 0.17356928798460192, Validation Loss: 0.17533295452594758, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 630, Training Loss: 0.17417526197048924, Validation Loss: 0.17321231961250305, Validation Accuracy: 0.5375\n",
      "Epoch 631, Training Loss: 0.17353626749207895, Validation Loss: 0.17470289766788483, Validation Accuracy: 0.4875\n",
      "Epoch 632, Training Loss: 0.17431198589263425, Validation Loss: 0.17336592574914297, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 633, Training Loss: 0.17368940912908123, Validation Loss: 0.17532158692677816, Validation Accuracy: 0.475\n",
      "Epoch 634, Training Loss: 0.17414490734377214, Validation Loss: 0.17302090922991434, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 635, Training Loss: 0.17364513297234813, Validation Loss: 0.17548578083515168, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 636, Training Loss: 0.1741784349564583, Validation Loss: 0.1735510806242625, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 637, Training Loss: 0.17359361677400528, Validation Loss: 0.17524162530899048, Validation Accuracy: 0.4875\n",
      "Epoch 638, Training Loss: 0.17420862759313277, Validation Loss: 0.17281654278437297, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 639, Training Loss: 0.17351725216834776, Validation Loss: 0.1748312493165334, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 640, Training Loss: 0.17426743142066464, Validation Loss: 0.17374144693215687, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 641, Training Loss: 0.1735631275561548, Validation Loss: 0.17509290874004363, Validation Accuracy: 0.49375\n",
      "Epoch 642, Training Loss: 0.17422151565551758, Validation Loss: 0.17333307166894277, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 643, Training Loss: 0.1734971437723406, Validation Loss: 0.17380632559458414, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 644, Training Loss: 0.17409406073631778, Validation Loss: 0.17423936029275258, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 645, Training Loss: 0.17356475130204232, Validation Loss: 0.1741412768761317, Validation Accuracy: 0.5125\n",
      "Epoch 646, Training Loss: 0.17426612925144933, Validation Loss: 0.17361101508140564, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 647, Training Loss: 0.17357902036559197, Validation Loss: 0.17290950417518616, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 648, Training Loss: 0.17405588876816533, Validation Loss: 0.1744681884845098, Validation Accuracy: 0.48125\n",
      "Epoch 649, Training Loss: 0.17351367348624813, Validation Loss: 0.17403781513373057, Validation Accuracy: 0.50625\n",
      "Epoch 650, Training Loss: 0.17433165686745797, Validation Loss: 0.17540944814682008, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 651, Training Loss: 0.17365596419380558, Validation Loss: 0.1721088449160258, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 652, Training Loss: 0.17415752093638143, Validation Loss: 0.1753706892331441, Validation Accuracy: 0.475\n",
      "Epoch 653, Training Loss: 0.17373607139433583, Validation Loss: 0.1735999216636022, Validation Accuracy: 0.5125\n",
      "Epoch 654, Training Loss: 0.17391400183400801, Validation Loss: 0.17577623724937438, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 655, Training Loss: 0.17390521976255602, Validation Loss: 0.17267879645029705, Validation Accuracy: 0.5375\n",
      "Epoch 656, Training Loss: 0.1737840473651886, Validation Loss: 0.17530800998210908, Validation Accuracy: 0.4875\n",
      "Epoch 657, Training Loss: 0.17388828531388315, Validation Loss: 0.1744111826022466, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 658, Training Loss: 0.17390925317041336, Validation Loss: 0.17566700875759125, Validation Accuracy: 0.475\n",
      "Epoch 659, Training Loss: 0.1739499016154197, Validation Loss: 0.17189273635546368, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 660, Training Loss: 0.17368319726759388, Validation Loss: 0.17632168332735698, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 661, Training Loss: 0.17407932541062754, Validation Loss: 0.17416763603687285, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 662, Training Loss: 0.17362736550069624, Validation Loss: 0.17540389895439149, Validation Accuracy: 0.4875\n",
      "Epoch 663, Training Loss: 0.174193833624163, Validation Loss: 0.17285930414994558, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 664, Training Loss: 0.17332459890073346, Validation Loss: 0.17545376221338907, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 665, Training Loss: 0.17450907682218858, Validation Loss: 0.1738192230463028, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 666, Training Loss: 0.1735684698627841, Validation Loss: 0.1744376222292582, Validation Accuracy: 0.49375\n",
      "Epoch 667, Training Loss: 0.17413628726236283, Validation Loss: 0.17363570829232533, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 668, Training Loss: 0.17360540215046175, Validation Loss: 0.17403662204742432, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 669, Training Loss: 0.1742093092010867, Validation Loss: 0.17417676051457723, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 670, Training Loss: 0.17374124882682676, Validation Loss: 0.17356611887613932, Validation Accuracy: 0.5125\n",
      "Epoch 671, Training Loss: 0.17403482573647652, Validation Loss: 0.17473443349202475, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 672, Training Loss: 0.17356766135461868, Validation Loss: 0.1729499210913976, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 673, Training Loss: 0.1740425858766802, Validation Loss: 0.17442412277062733, Validation Accuracy: 0.48125\n",
      "Epoch 674, Training Loss: 0.17372943989692197, Validation Loss: 0.17374715705712637, Validation Accuracy: 0.50625\n",
      "Epoch 675, Training Loss: 0.17399026165085454, Validation Loss: 0.1748920092980067, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 676, Training Loss: 0.1737087219953537, Validation Loss: 0.1722270131111145, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 677, Training Loss: 0.1739826625393283, Validation Loss: 0.17455615003903707, Validation Accuracy: 0.475\n",
      "Epoch 678, Training Loss: 0.17385393621460085, Validation Loss: 0.17374149362246197, Validation Accuracy: 0.5125\n",
      "Epoch 679, Training Loss: 0.17399434168492595, Validation Loss: 0.17495725750923158, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 680, Training Loss: 0.1735991479889039, Validation Loss: 0.1726616621017456, Validation Accuracy: 0.5375\n",
      "Epoch 681, Training Loss: 0.17410510538085813, Validation Loss: 0.17374744017918906, Validation Accuracy: 0.4875\n",
      "Epoch 682, Training Loss: 0.17378393873091666, Validation Loss: 0.1738786776860555, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 683, Training Loss: 0.17393738464001687, Validation Loss: 0.17483690579732258, Validation Accuracy: 0.475\n",
      "Epoch 684, Training Loss: 0.1737446342745135, Validation Loss: 0.1723415603240331, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 685, Training Loss: 0.174035549644501, Validation Loss: 0.17387136220932006, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 686, Training Loss: 0.17379464593625837, Validation Loss: 0.17365902066230773, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 687, Training Loss: 0.17401825852932468, Validation Loss: 0.17382508913675945, Validation Accuracy: 0.4875\n",
      "Epoch 688, Training Loss: 0.17382880083976254, Validation Loss: 0.17280371189117433, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 689, Training Loss: 0.17398970453969895, Validation Loss: 0.1734234670797984, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 690, Training Loss: 0.1739035580427416, Validation Loss: 0.17350493868192038, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 691, Training Loss: 0.17389638770011165, Validation Loss: 0.17366049885749818, Validation Accuracy: 0.49375\n",
      "Epoch 692, Training Loss: 0.17384795748418377, Validation Loss: 0.17336555818716684, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 693, Training Loss: 0.17396351166309848, Validation Loss: 0.17326216499010721, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 694, Training Loss: 0.17394648300063226, Validation Loss: 0.17355180978775026, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 695, Training Loss: 0.17382395315554836, Validation Loss: 0.17322884698708851, Validation Accuracy: 0.5125\n",
      "Epoch 696, Training Loss: 0.1739435527593859, Validation Loss: 0.1735929826895396, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 697, Training Loss: 0.17387817655840226, Validation Loss: 0.17303994397322336, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 698, Training Loss: 0.17402020048710606, Validation Loss: 0.17362935145696004, Validation Accuracy: 0.48125\n",
      "Epoch 699, Training Loss: 0.1737143926082119, Validation Loss: 0.17355261147022247, Validation Accuracy: 0.50625\n",
      "Epoch 700, Training Loss: 0.1740089044455559, Validation Loss: 0.1736481765906016, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 701, Training Loss: 0.17378537404921748, Validation Loss: 0.17244113584359486, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 702, Training Loss: 0.1739223676343118, Validation Loss: 0.17358486751715343, Validation Accuracy: 0.475\n",
      "Epoch 703, Training Loss: 0.1738680649188257, Validation Loss: 0.1732183039188385, Validation Accuracy: 0.5125\n",
      "Epoch 704, Training Loss: 0.1739014449619478, Validation Loss: 0.17398133476575214, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 705, Training Loss: 0.1738814317410992, Validation Loss: 0.1729458640019099, Validation Accuracy: 0.5375\n",
      "Epoch 706, Training Loss: 0.17396724752841458, Validation Loss: 0.1736009180545807, Validation Accuracy: 0.4875\n",
      "Epoch 707, Training Loss: 0.17387962821991212, Validation Loss: 0.1734949598709742, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 708, Training Loss: 0.17381635115992639, Validation Loss: 0.17410393456617992, Validation Accuracy: 0.475\n",
      "Epoch 709, Training Loss: 0.17391705464932225, Validation Loss: 0.1727267215649287, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 710, Training Loss: 0.17392590305497568, Validation Loss: 0.17388286391894023, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 711, Training Loss: 0.17380402261211025, Validation Loss: 0.17363034784793854, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 712, Training Loss: 0.17382785293363756, Validation Loss: 0.17381965219974518, Validation Accuracy: 0.4875\n",
      "Epoch 713, Training Loss: 0.17400963892859797, Validation Loss: 0.17308845619360605, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 714, Training Loss: 0.17372854919202865, Validation Loss: 0.17354728976885478, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 715, Training Loss: 0.1740514362050641, Validation Loss: 0.17337842384974161, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 716, Training Loss: 0.17372799688769924, Validation Loss: 0.1736357013384501, Validation Accuracy: 0.49375\n",
      "Epoch 717, Training Loss: 0.17405837774276733, Validation Loss: 0.17328314979871115, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 718, Training Loss: 0.17383591926866962, Validation Loss: 0.1733188529809316, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 719, Training Loss: 0.17389494036474534, Validation Loss: 0.17353439331054688, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 720, Training Loss: 0.17379494203675178, Validation Loss: 0.17328409651915233, Validation Accuracy: 0.5125\n",
      "Epoch 721, Training Loss: 0.17399649225896405, Validation Loss: 0.1734015514453252, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 722, Training Loss: 0.17384142741080252, Validation Loss: 0.17292800943056744, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 723, Training Loss: 0.17384005986875103, Validation Loss: 0.17363627354303995, Validation Accuracy: 0.48125\n",
      "Epoch 724, Training Loss: 0.17367883315009455, Validation Loss: 0.17350175082683564, Validation Accuracy: 0.50625\n",
      "Epoch 725, Training Loss: 0.17409664969290456, Validation Loss: 0.17347663442293804, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 726, Training Loss: 0.1737985385041083, Validation Loss: 0.17252006928126018, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 727, Training Loss: 0.17401939245962328, Validation Loss: 0.17348961432774862, Validation Accuracy: 0.475\n",
      "Epoch 728, Training Loss: 0.17372641928734317, Validation Loss: 0.1732712616523107, Validation Accuracy: 0.5125\n",
      "Epoch 729, Training Loss: 0.17406660847125516, Validation Loss: 0.17345655759175618, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 730, Training Loss: 0.1737811594240127, Validation Loss: 0.17275169889132183, Validation Accuracy: 0.5375\n",
      "Epoch 731, Training Loss: 0.1740391489959532, Validation Loss: 0.17340332567691802, Validation Accuracy: 0.4875\n",
      "Epoch 732, Training Loss: 0.17368780172640277, Validation Loss: 0.1736428439617157, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 733, Training Loss: 0.17386544567923393, Validation Loss: 0.17400879661242166, Validation Accuracy: 0.475\n",
      "Epoch 734, Training Loss: 0.17378475396863877, Validation Loss: 0.172150249282519, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 735, Training Loss: 0.17399599907859678, Validation Loss: 0.17362861831982931, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 736, Training Loss: 0.17372048622177494, Validation Loss: 0.17379213273525237, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 737, Training Loss: 0.17396092174514646, Validation Loss: 0.17336152295271556, Validation Accuracy: 0.4875\n",
      "Epoch 738, Training Loss: 0.17376663223389657, Validation Loss: 0.17287325163682302, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 739, Training Loss: 0.1736947528777584, Validation Loss: 0.17365762591362, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 740, Training Loss: 0.17381686452896364, Validation Loss: 0.1738622695207596, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 741, Training Loss: 0.1741143157405238, Validation Loss: 0.17331688006718954, Validation Accuracy: 0.49375\n",
      "Epoch 742, Training Loss: 0.17378749434025056, Validation Loss: 0.1733131210009257, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 743, Training Loss: 0.17396425191433199, Validation Loss: 0.17326281766096752, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 744, Training Loss: 0.17368165427638638, Validation Loss: 0.17423839966456095, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 745, Training Loss: 0.17413468514719316, Validation Loss: 0.17326350112756092, Validation Accuracy: 0.5125\n",
      "Epoch 746, Training Loss: 0.1737905538851215, Validation Loss: 0.17433647314707437, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 747, Training Loss: 0.17404181101629812, Validation Loss: 0.1732153981924057, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 748, Training Loss: 0.17364558577537537, Validation Loss: 0.17424590984980265, Validation Accuracy: 0.48125\n",
      "Epoch 749, Training Loss: 0.17410514095137197, Validation Loss: 0.17328144510587057, Validation Accuracy: 0.50625\n",
      "Epoch 750, Training Loss: 0.17368506568093453, Validation Loss: 0.17490544120470683, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 751, Training Loss: 0.17419243291501077, Validation Loss: 0.17320204476515452, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 752, Training Loss: 0.17355387249300558, Validation Loss: 0.17504593630631765, Validation Accuracy: 0.475\n",
      "Epoch 753, Training Loss: 0.17426848459628322, Validation Loss: 0.17325550615787505, Validation Accuracy: 0.5125\n",
      "Epoch 754, Training Loss: 0.17358245820768417, Validation Loss: 0.17529940803845723, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 755, Training Loss: 0.17424639434583725, Validation Loss: 0.17315898140271505, Validation Accuracy: 0.5375\n",
      "Epoch 756, Training Loss: 0.17351034235569737, Validation Loss: 0.1747280885775884, Validation Accuracy: 0.4875\n",
      "Epoch 757, Training Loss: 0.17432744512634893, Validation Loss: 0.17335614959398907, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 758, Training Loss: 0.17367217569581925, Validation Loss: 0.17512009739875795, Validation Accuracy: 0.475\n",
      "Epoch 759, Training Loss: 0.17385594402590104, Validation Loss: 0.17321439683437348, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 760, Training Loss: 0.17370784763366945, Validation Loss: 0.17469699581464132, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 761, Training Loss: 0.174218304214939, Validation Loss: 0.17346651156743367, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 762, Training Loss: 0.17359420657157898, Validation Loss: 0.17521400054295858, Validation Accuracy: 0.4875\n",
      "Epoch 763, Training Loss: 0.17421305083459424, Validation Loss: 0.17288196484247845, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 764, Training Loss: 0.1734878824603173, Validation Loss: 0.17469793955485027, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 765, Training Loss: 0.17424187400648672, Validation Loss: 0.1736380010843277, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 766, Training Loss: 0.17356345009419225, Validation Loss: 0.1750900387763977, Validation Accuracy: 0.49375\n",
      "Epoch 767, Training Loss: 0.17423486709594727, Validation Loss: 0.1733239233493805, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 768, Training Loss: 0.17346907911762113, Validation Loss: 0.17403548061847687, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 769, Training Loss: 0.1741419501842991, Validation Loss: 0.17419937650362652, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 770, Training Loss: 0.17352249353162705, Validation Loss: 0.17414307395617168, Validation Accuracy: 0.5125\n",
      "Epoch 771, Training Loss: 0.17431427922941023, Validation Loss: 0.1743722309668859, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 772, Training Loss: 0.17358042636225302, Validation Loss: 0.17311260203520457, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 773, Training Loss: 0.17422334897902705, Validation Loss: 0.17436812023321788, Validation Accuracy: 0.48125\n",
      "Epoch 774, Training Loss: 0.1734840461323338, Validation Loss: 0.1739983191092809, Validation Accuracy: 0.50625\n",
      "Epoch 775, Training Loss: 0.17430893788414617, Validation Loss: 0.1748792439699173, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 776, Training Loss: 0.17361089250733774, Validation Loss: 0.17218613922595977, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 777, Training Loss: 0.17408729032162698, Validation Loss: 0.17506635189056396, Validation Accuracy: 0.475\n",
      "Epoch 778, Training Loss: 0.17371081296474702, Validation Loss: 0.17327984968821208, Validation Accuracy: 0.5125\n",
      "Epoch 779, Training Loss: 0.17392174995714618, Validation Loss: 0.17487368086973826, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 780, Training Loss: 0.173707083348305, Validation Loss: 0.17271170417467754, Validation Accuracy: 0.5375\n",
      "Epoch 781, Training Loss: 0.1738189915495534, Validation Loss: 0.17539984583854676, Validation Accuracy: 0.4875\n",
      "Epoch 782, Training Loss: 0.1738521264445397, Validation Loss: 0.1745305190483729, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 783, Training Loss: 0.173907884186314, Validation Loss: 0.1757948060830434, Validation Accuracy: 0.475\n",
      "Epoch 784, Training Loss: 0.173981711268425, Validation Loss: 0.1720209946235021, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 785, Training Loss: 0.17365781289915885, Validation Loss: 0.17627674341201782, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 786, Training Loss: 0.1740968587898439, Validation Loss: 0.1738399585088094, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 787, Training Loss: 0.1736819710462324, Validation Loss: 0.17504702210426332, Validation Accuracy: 0.4875\n",
      "Epoch 788, Training Loss: 0.17423402830477683, Validation Loss: 0.1727432866891225, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 789, Training Loss: 0.1733784363154442, Validation Loss: 0.17506239414215088, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 790, Training Loss: 0.17449903824637014, Validation Loss: 0.17388734519481658, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 791, Training Loss: 0.17356979366271727, Validation Loss: 0.17450652420520782, Validation Accuracy: 0.49375\n",
      "Epoch 792, Training Loss: 0.1741344476899793, Validation Loss: 0.17362179160118102, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 793, Training Loss: 0.17355815345241177, Validation Loss: 0.17378892103830973, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 794, Training Loss: 0.174164580722009, Validation Loss: 0.17453802625338236, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 795, Training Loss: 0.17363852983520878, Validation Loss: 0.17371259828408558, Validation Accuracy: 0.5125\n",
      "Epoch 796, Training Loss: 0.17408575405997614, Validation Loss: 0.17461314896742502, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 797, Training Loss: 0.17363723727964586, Validation Loss: 0.17300691703955332, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 798, Training Loss: 0.17406689928423974, Validation Loss: 0.1742920676867167, Validation Accuracy: 0.48125\n",
      "Epoch 799, Training Loss: 0.17373318874066876, Validation Loss: 0.173775644103686, Validation Accuracy: 0.50625\n",
      "Epoch 800, Training Loss: 0.17400753594213916, Validation Loss: 0.175121342142423, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 801, Training Loss: 0.17365746728835568, Validation Loss: 0.17208694120248158, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 802, Training Loss: 0.17413644588762714, Validation Loss: 0.17415572305520374, Validation Accuracy: 0.475\n",
      "Epoch 803, Training Loss: 0.17382130843977775, Validation Loss: 0.1733769953250885, Validation Accuracy: 0.5125\n",
      "Epoch 804, Training Loss: 0.17398052590508614, Validation Loss: 0.17440720895926157, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 805, Training Loss: 0.17365200769516728, Validation Loss: 0.17269359529018402, Validation Accuracy: 0.5375\n",
      "Epoch 806, Training Loss: 0.17402141132662374, Validation Loss: 0.17417575418949127, Validation Accuracy: 0.4875\n",
      "Epoch 807, Training Loss: 0.17371095909226325, Validation Loss: 0.17406060496966044, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 808, Training Loss: 0.17409004415235213, Validation Loss: 0.1741588701804479, Validation Accuracy: 0.475\n",
      "Epoch 809, Training Loss: 0.173732848898057, Validation Loss: 0.17196790874004364, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 810, Training Loss: 0.17400586749276808, Validation Loss: 0.1739998032649358, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 811, Training Loss: 0.1738406986959519, Validation Loss: 0.17376455267270405, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 812, Training Loss: 0.17385682944328554, Validation Loss: 0.1744228998819987, Validation Accuracy: 0.4875\n",
      "Epoch 813, Training Loss: 0.1737949103116989, Validation Loss: 0.172841939330101, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 814, Training Loss: 0.17402076144372264, Validation Loss: 0.1734065184990565, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 815, Training Loss: 0.17388167833128282, Validation Loss: 0.17353639205296834, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 816, Training Loss: 0.17391306979040946, Validation Loss: 0.17374504307905833, Validation Accuracy: 0.49375\n",
      "Epoch 817, Training Loss: 0.1738593323576835, Validation Loss: 0.1733325868844986, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 818, Training Loss: 0.173917323831589, Validation Loss: 0.1732737272977829, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 819, Training Loss: 0.17396462155926612, Validation Loss: 0.1735258936882019, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 820, Training Loss: 0.1737750816729761, Validation Loss: 0.17326075534025828, Validation Accuracy: 0.5125\n",
      "Epoch 821, Training Loss: 0.17397945398284542, Validation Loss: 0.1736248274644216, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 822, Training Loss: 0.17388351694230111, Validation Loss: 0.173041170835495, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 823, Training Loss: 0.17401241583208885, Validation Loss: 0.17357186675071717, Validation Accuracy: 0.48125\n",
      "Epoch 824, Training Loss: 0.17383101438322374, Validation Loss: 0.17331861158212025, Validation Accuracy: 0.50625\n",
      "Epoch 825, Training Loss: 0.17396363856330996, Validation Loss: 0.17378247380256653, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 826, Training Loss: 0.17384570308269992, Validation Loss: 0.17266455193360647, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 827, Training Loss: 0.17393591903871106, Validation Loss: 0.173652184009552, Validation Accuracy: 0.475\n",
      "Epoch 828, Training Loss: 0.1738150268793106, Validation Loss: 0.1732351412375768, Validation Accuracy: 0.5125\n",
      "Epoch 829, Training Loss: 0.17391539148746, Validation Loss: 0.17390896280606588, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 830, Training Loss: 0.17392426825338794, Validation Loss: 0.1730366845925649, Validation Accuracy: 0.5375\n",
      "Epoch 831, Training Loss: 0.17396015553705155, Validation Loss: 0.1735651155312856, Validation Accuracy: 0.4875\n",
      "Epoch 832, Training Loss: 0.17384655725571416, Validation Loss: 0.17357414265473683, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 833, Training Loss: 0.17385438709489762, Validation Loss: 0.17408265272776285, Validation Accuracy: 0.475\n",
      "Epoch 834, Training Loss: 0.1739815228408383, Validation Loss: 0.17285381654898327, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 835, Training Loss: 0.17391610049432324, Validation Loss: 0.17385415037473043, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 836, Training Loss: 0.17397643818009284, Validation Loss: 0.17338143587112426, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 837, Training Loss: 0.1738015826671354, Validation Loss: 0.17396712104479473, Validation Accuracy: 0.4875\n",
      "Epoch 838, Training Loss: 0.17402694446425285, Validation Loss: 0.1730802983045578, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 839, Training Loss: 0.1737979938907008, Validation Loss: 0.17362032731374105, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 840, Training Loss: 0.17392778204333398, Validation Loss: 0.17367828985055286, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 841, Training Loss: 0.17368181434369856, Validation Loss: 0.17378919819990793, Validation Accuracy: 0.49375\n",
      "Epoch 842, Training Loss: 0.1740663936061244, Validation Loss: 0.17328096330165862, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 843, Training Loss: 0.17384751573685678, Validation Loss: 0.17327371935049693, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 844, Training Loss: 0.17386731505393982, Validation Loss: 0.17357798020044962, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 845, Training Loss: 0.17383925712877704, Validation Loss: 0.17325014273325604, Validation Accuracy: 0.5125\n",
      "Epoch 846, Training Loss: 0.17388923466205597, Validation Loss: 0.17356695234775543, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 847, Training Loss: 0.17394535387715987, Validation Loss: 0.17296893000602723, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 848, Training Loss: 0.17392020360116037, Validation Loss: 0.1735160748163859, Validation Accuracy: 0.48125\n",
      "Epoch 849, Training Loss: 0.17372953747549363, Validation Loss: 0.17341093520323436, Validation Accuracy: 0.50625\n",
      "Epoch 850, Training Loss: 0.1739894555461022, Validation Loss: 0.17362632552782695, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 851, Training Loss: 0.17409967751272262, Validation Loss: 0.17319426635901133, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 852, Training Loss: 0.17397976065835646, Validation Loss: 0.17329132556915283, Validation Accuracy: 0.475\n",
      "Epoch 853, Training Loss: 0.17354133292551963, Validation Loss: 0.17330319086710613, Validation Accuracy: 0.5125\n",
      "Epoch 854, Training Loss: 0.17438208816512937, Validation Loss: 0.17930435637633005, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 855, Training Loss: 0.1739864315717451, Validation Loss: 0.17306681275367736, Validation Accuracy: 0.5375\n",
      "Epoch 856, Training Loss: 0.1748259283842579, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5125\n",
      "Epoch 857, Training Loss: 0.1786116034753861, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5104166666666666\n",
      "Epoch 858, Training Loss: 0.17820721047539864, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.525\n",
      "Epoch 859, Training Loss: 0.1732867956161499, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.4395833333333333\n",
      "Epoch 860, Training Loss: 0.1732871537247012, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5270833333333333\n",
      "Epoch 861, Training Loss: 0.1765976317467228, Validation Loss: 0.17328926920890808, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 862, Training Loss: 0.1732865072065784, Validation Loss: 0.17328683733940126, Validation Accuracy: 0.4875\n",
      "Epoch 863, Training Loss: 0.17331217758117184, Validation Loss: 0.17318844199180602, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 864, Training Loss: 0.17354238369772512, Validation Loss: 0.17329845130443572, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 865, Training Loss: 0.17337040603160858, Validation Loss: 0.17336036662260693, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 866, Training Loss: 0.17367905618682986, Validation Loss: 0.17328709761301678, Validation Accuracy: 0.49375\n",
      "Epoch 867, Training Loss: 0.173475282807504, Validation Loss: 0.1732798546552658, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 868, Training Loss: 0.17355529291014518, Validation Loss: 0.17328014572461445, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 869, Training Loss: 0.17340358563007846, Validation Loss: 0.1734992225964864, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 870, Training Loss: 0.17365062861673294, Validation Loss: 0.17327886124451955, Validation Accuracy: 0.5125\n",
      "Epoch 871, Training Loss: 0.17346338543199724, Validation Loss: 0.1738362510999044, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 872, Training Loss: 0.1735225733249418, Validation Loss: 0.17320756912231444, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 873, Training Loss: 0.1734122585865759, Validation Loss: 0.1737474928299586, Validation Accuracy: 0.48125\n",
      "Epoch 874, Training Loss: 0.17369078484273726, Validation Loss: 0.17328275442123414, Validation Accuracy: 0.50625\n",
      "Epoch 875, Training Loss: 0.17346743133760267, Validation Loss: 0.17406914333502452, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 876, Training Loss: 0.17355357254705123, Validation Loss: 0.1732039878765742, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 877, Training Loss: 0.17339587644223245, Validation Loss: 0.17408611377080283, Validation Accuracy: 0.475\n",
      "Epoch 878, Training Loss: 0.17376111111333292, Validation Loss: 0.17325934171676635, Validation Accuracy: 0.5125\n",
      "Epoch 879, Training Loss: 0.17338522018924837, Validation Loss: 0.17462035914262136, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 880, Training Loss: 0.1737337444097765, Validation Loss: 0.1732267200946808, Validation Accuracy: 0.5375\n",
      "Epoch 881, Training Loss: 0.17341843007072325, Validation Loss: 0.17391896943251292, Validation Accuracy: 0.4875\n",
      "Epoch 882, Training Loss: 0.1739978809510508, Validation Loss: 0.17353858749071757, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 883, Training Loss: 0.17347248956080405, Validation Loss: 0.17434163490931193, Validation Accuracy: 0.475\n",
      "Epoch 884, Training Loss: 0.17376497868568666, Validation Loss: 0.1732144484917323, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 885, Training Loss: 0.17356826557267097, Validation Loss: 0.17434542775154113, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 886, Training Loss: 0.17399432486103428, Validation Loss: 0.17363655765851338, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 887, Training Loss: 0.17348008674959983, Validation Loss: 0.17449435591697693, Validation Accuracy: 0.4875\n",
      "Epoch 888, Training Loss: 0.17398415121339983, Validation Loss: 0.17300466398398082, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 889, Training Loss: 0.17346367384156874, Validation Loss: 0.17404947479565938, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 890, Training Loss: 0.17411197097070755, Validation Loss: 0.17382528285185497, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 891, Training Loss: 0.17352596550218521, Validation Loss: 0.1743498057126999, Validation Accuracy: 0.49375\n",
      "Epoch 892, Training Loss: 0.17415994549951247, Validation Loss: 0.1736056884129842, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 893, Training Loss: 0.17353361460470385, Validation Loss: 0.17379036049048105, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 894, Training Loss: 0.17394047302584495, Validation Loss: 0.1743588328361511, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 895, Training Loss: 0.17368309680492647, Validation Loss: 0.17366587320963542, Validation Accuracy: 0.5125\n",
      "Epoch 896, Training Loss: 0.17407505166146062, Validation Loss: 0.17457182208697, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 897, Training Loss: 0.17373186397937038, Validation Loss: 0.17298074464003246, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 898, Training Loss: 0.17401643626151547, Validation Loss: 0.17464396754900616, Validation Accuracy: 0.48125\n",
      "Epoch 899, Training Loss: 0.17364326936583366, Validation Loss: 0.1738762358824412, Validation Accuracy: 0.50625\n",
      "Epoch 900, Training Loss: 0.1742416081889983, Validation Loss: 0.17518317798773447, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 901, Training Loss: 0.1737638149530657, Validation Loss: 0.1721454312403997, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 902, Training Loss: 0.1740621631183932, Validation Loss: 0.1752436488866806, Validation Accuracy: 0.475\n",
      "Epoch 903, Training Loss: 0.17380566318188945, Validation Loss: 0.17348225712776183, Validation Accuracy: 0.5125\n",
      "Epoch 904, Training Loss: 0.17382534040558723, Validation Loss: 0.175117822488149, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 905, Training Loss: 0.17395468296543246, Validation Loss: 0.1726863831281662, Validation Accuracy: 0.5375\n",
      "Epoch 906, Training Loss: 0.17377457407213026, Validation Loss: 0.1749330500761668, Validation Accuracy: 0.4875\n",
      "Epoch 907, Training Loss: 0.1739593215527073, Validation Loss: 0.17429237763086955, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 908, Training Loss: 0.17387946815259994, Validation Loss: 0.17512744665145874, Validation Accuracy: 0.475\n",
      "Epoch 909, Training Loss: 0.1740404256889897, Validation Loss: 0.1718802809715271, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 910, Training Loss: 0.1737173411153978, Validation Loss: 0.17524192531903585, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 911, Training Loss: 0.17414767992111943, Validation Loss: 0.17410436968008677, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 912, Training Loss: 0.17364282329236308, Validation Loss: 0.17459546029567719, Validation Accuracy: 0.4875\n",
      "Epoch 913, Training Loss: 0.1743167350369115, Validation Loss: 0.1727270523707072, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 914, Training Loss: 0.17339624128034037, Validation Loss: 0.1745324492454529, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 915, Training Loss: 0.17455194121406925, Validation Loss: 0.17399118145306905, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 916, Training Loss: 0.17353808831784032, Validation Loss: 0.17430430948734282, Validation Accuracy: 0.49375\n",
      "Epoch 917, Training Loss: 0.17424618669094577, Validation Loss: 0.1737588773171107, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 918, Training Loss: 0.1736513727134274, Validation Loss: 0.17375941971937817, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 919, Training Loss: 0.17427601064405135, Validation Loss: 0.17423681020736695, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 920, Training Loss: 0.1736793888192023, Validation Loss: 0.17390670677026113, Validation Accuracy: 0.5125\n",
      "Epoch 921, Training Loss: 0.17424096022882768, Validation Loss: 0.17431060075759888, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 922, Training Loss: 0.1735678170957873, Validation Loss: 0.17332273026307424, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 923, Training Loss: 0.17429702080065204, Validation Loss: 0.1740206966797511, Validation Accuracy: 0.48125\n",
      "Epoch 924, Training Loss: 0.17375315581598588, Validation Loss: 0.1735865851243337, Validation Accuracy: 0.50625\n",
      "Epoch 925, Training Loss: 0.1741114652925922, Validation Loss: 0.17490486800670624, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 926, Training Loss: 0.17367020201298497, Validation Loss: 0.17207899590333303, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 927, Training Loss: 0.17427834916499355, Validation Loss: 0.17415779928366343, Validation Accuracy: 0.475\n",
      "Epoch 928, Training Loss: 0.17378144591085373, Validation Loss: 0.17336786290009817, Validation Accuracy: 0.5125\n",
      "Epoch 929, Training Loss: 0.17415395090656896, Validation Loss: 0.1746245563030243, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 930, Training Loss: 0.17372026751118322, Validation Loss: 0.17265948156515756, Validation Accuracy: 0.5375\n",
      "Epoch 931, Training Loss: 0.17417615267538256, Validation Loss: 0.17394407987594604, Validation Accuracy: 0.4875\n",
      "Epoch 932, Training Loss: 0.1737467026518237, Validation Loss: 0.17419962088267008, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 933, Training Loss: 0.17419795547762223, Validation Loss: 0.17427090108394622, Validation Accuracy: 0.475\n",
      "Epoch 934, Training Loss: 0.17372096017483743, Validation Loss: 0.1720247596502304, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 935, Training Loss: 0.17424085447865148, Validation Loss: 0.17402096887429555, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 936, Training Loss: 0.17382990208364302, Validation Loss: 0.17376375993092855, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 937, Training Loss: 0.1740200707027989, Validation Loss: 0.17400328417619068, Validation Accuracy: 0.4875\n",
      "Epoch 938, Training Loss: 0.17393046857849245, Validation Loss: 0.17277839283148447, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 939, Training Loss: 0.17400769168330776, Validation Loss: 0.17367542485396067, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 940, Training Loss: 0.17387845968046495, Validation Loss: 0.17372486293315886, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 941, Training Loss: 0.17396666446039755, Validation Loss: 0.17379819949467976, Validation Accuracy: 0.49375\n",
      "Epoch 942, Training Loss: 0.17384123129229392, Validation Loss: 0.17330456574757894, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 943, Training Loss: 0.17408583769875188, Validation Loss: 0.17330427865187328, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 944, Training Loss: 0.1739835681453828, Validation Loss: 0.173539400100708, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 945, Training Loss: 0.173734289023184, Validation Loss: 0.17339914441108703, Validation Accuracy: 0.5125\n",
      "Epoch 946, Training Loss: 0.17398665893462398, Validation Loss: 0.17357012629508972, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 947, Training Loss: 0.1740462597339384, Validation Loss: 0.1729955365260442, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 948, Training Loss: 0.1740907613308199, Validation Loss: 0.17390873829523723, Validation Accuracy: 0.48125\n",
      "Epoch 949, Training Loss: 0.1738087890609618, Validation Loss: 0.17342108090718586, Validation Accuracy: 0.50625\n",
      "Epoch 950, Training Loss: 0.17397236872103908, Validation Loss: 0.17358494699001312, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 951, Training Loss: 0.1740371358971442, Validation Loss: 0.17262658774852752, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 952, Training Loss: 0.17397892715469485, Validation Loss: 0.1738865117232005, Validation Accuracy: 0.475\n",
      "Epoch 953, Training Loss: 0.17387597070586297, Validation Loss: 0.17327454686164856, Validation Accuracy: 0.5125\n",
      "Epoch 954, Training Loss: 0.17387532755251853, Validation Loss: 0.1737860749165217, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 955, Training Loss: 0.17410854802977654, Validation Loss: 0.17294172048568726, Validation Accuracy: 0.5375\n",
      "Epoch 956, Training Loss: 0.17395805783810153, Validation Loss: 0.17375401357809703, Validation Accuracy: 0.4875\n",
      "Epoch 957, Training Loss: 0.1739403461256335, Validation Loss: 0.1736769030491511, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 958, Training Loss: 0.17381164623845008, Validation Loss: 0.1739028404156367, Validation Accuracy: 0.475\n",
      "Epoch 959, Training Loss: 0.17418179588933144, Validation Loss: 0.17264691690603892, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 960, Training Loss: 0.17381059210146627, Validation Loss: 0.1740427315235138, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 961, Training Loss: 0.17413701838062656, Validation Loss: 0.1734280327955882, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 962, Training Loss: 0.17384986627486446, Validation Loss: 0.17403087218602498, Validation Accuracy: 0.4875\n",
      "Epoch 963, Training Loss: 0.174062188594572, Validation Loss: 0.17285990118980407, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 964, Training Loss: 0.17374177421292952, Validation Loss: 0.17367328504721324, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 965, Training Loss: 0.17425535090508, Validation Loss: 0.1734514206647873, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 966, Training Loss: 0.17370654113831058, Validation Loss: 0.17397444248199462, Validation Accuracy: 0.49375\n",
      "Epoch 967, Training Loss: 0.17412906500601, Validation Loss: 0.1733590543270111, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 968, Training Loss: 0.173861397850898, Validation Loss: 0.17345780432224273, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 969, Training Loss: 0.17402672815707423, Validation Loss: 0.17368603547414144, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 970, Training Loss: 0.17378251831377706, Validation Loss: 0.17327904601891836, Validation Accuracy: 0.5125\n",
      "Epoch 971, Training Loss: 0.1741495603515256, Validation Loss: 0.17360833287239075, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 972, Training Loss: 0.17386352006466158, Validation Loss: 0.17290899256865183, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 973, Training Loss: 0.17395928261741514, Validation Loss: 0.17412074903647104, Validation Accuracy: 0.48125\n",
      "Epoch 974, Training Loss: 0.17368377793219783, Validation Loss: 0.17349423666795094, Validation Accuracy: 0.50625\n",
      "Epoch 975, Training Loss: 0.174337187601674, Validation Loss: 0.1736463079849879, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 976, Training Loss: 0.17370456024523703, Validation Loss: 0.17218614916006725, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 977, Training Loss: 0.17415832896386424, Validation Loss: 0.1741889774799347, Validation Accuracy: 0.475\n",
      "Epoch 978, Training Loss: 0.1737250469384655, Validation Loss: 0.17330875198046367, Validation Accuracy: 0.5125\n",
      "Epoch 979, Training Loss: 0.17430614800222458, Validation Loss: 0.1735514760017395, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 980, Training Loss: 0.17368016127617128, Validation Loss: 0.17266142169634502, Validation Accuracy: 0.5375\n",
      "Epoch 981, Training Loss: 0.17426180839538574, Validation Loss: 0.17353376944859822, Validation Accuracy: 0.4875\n",
      "Epoch 982, Training Loss: 0.17366253800930515, Validation Loss: 0.17389889458815258, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 983, Training Loss: 0.1742829603533591, Validation Loss: 0.17345127165317537, Validation Accuracy: 0.475\n",
      "Epoch 984, Training Loss: 0.17367613892401418, Validation Loss: 0.17198963661988576, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 985, Training Loss: 0.1742142568672857, Validation Loss: 0.17345365683237712, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 986, Training Loss: 0.17365303779802016, Validation Loss: 0.17364799082279206, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 987, Training Loss: 0.1743700542757588, Validation Loss: 0.17345266739527385, Validation Accuracy: 0.4875\n",
      "Epoch 988, Training Loss: 0.1736899282663099, Validation Loss: 0.17273617386817933, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 989, Training Loss: 0.17417894303798676, Validation Loss: 0.17338932851950328, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 990, Training Loss: 0.17369482209605555, Validation Loss: 0.1738074988126755, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 991, Training Loss: 0.17435728301925044, Validation Loss: 0.1733866035938263, Validation Accuracy: 0.49375\n",
      "Epoch 992, Training Loss: 0.17374644981276605, Validation Loss: 0.17379140456517536, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 993, Training Loss: 0.17420520224878866, Validation Loss: 0.17326871554056802, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 994, Training Loss: 0.1736030347885624, Validation Loss: 0.17465177377065022, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 995, Training Loss: 0.17437933048894327, Validation Loss: 0.17321771184603374, Validation Accuracy: 0.5125\n",
      "Epoch 996, Training Loss: 0.17367241411439835, Validation Loss: 0.1748539557059606, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 997, Training Loss: 0.17416411253713793, Validation Loss: 0.1730217864116033, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 998, Training Loss: 0.1736496691742251, Validation Loss: 0.17476454774538677, Validation Accuracy: 0.48125\n",
      "Epoch 999, Training Loss: 0.17429321619772142, Validation Loss: 0.17329692641894023, Validation Accuracy: 0.50625\n",
      "Epoch 1000, Training Loss: 0.17359183680626653, Validation Loss: 0.17557591398557026, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 1001, Training Loss: 0.1744080993436998, Validation Loss: 0.17258583803971608, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 1002, Training Loss: 0.17347587933463435, Validation Loss: 0.17520588636398315, Validation Accuracy: 0.475\n",
      "Epoch 1003, Training Loss: 0.17442390659163076, Validation Loss: 0.17321720321973164, Validation Accuracy: 0.5125\n",
      "Epoch 1004, Training Loss: 0.17349629152205684, Validation Loss: 0.17561416228612264, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 1005, Training Loss: 0.17419783194218913, Validation Loss: 0.173221621910731, Validation Accuracy: 0.5375\n",
      "Epoch 1006, Training Loss: 0.17362958673507936, Validation Loss: 0.17419688105583192, Validation Accuracy: 0.4875\n",
      "Epoch 1007, Training Loss: 0.17446294571122817, Validation Loss: 0.17347212135791779, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 1008, Training Loss: 0.17359746367700638, Validation Loss: 0.17543596625328065, Validation Accuracy: 0.475\n",
      "Epoch 1009, Training Loss: 0.17429423043804784, Validation Loss: 0.1721491704384486, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 1010, Training Loss: 0.17364298095626216, Validation Loss: 0.17535333534081776, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 1011, Training Loss: 0.17427901635246892, Validation Loss: 0.17388497392336527, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1012, Training Loss: 0.17359167721963698, Validation Loss: 0.17496837675571442, Validation Accuracy: 0.4875\n",
      "Epoch 1013, Training Loss: 0.1741598137924748, Validation Loss: 0.172901518146197, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 1014, Training Loss: 0.1736079555365347, Validation Loss: 0.1741616169611613, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 1015, Training Loss: 0.17431383892413108, Validation Loss: 0.17397024035453795, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1016, Training Loss: 0.17358946607958886, Validation Loss: 0.17472800413767497, Validation Accuracy: 0.49375\n",
      "Epoch 1017, Training Loss: 0.17420414042088292, Validation Loss: 0.17345985770225525, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 1018, Training Loss: 0.17363709211349487, Validation Loss: 0.17368961075941722, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 1019, Training Loss: 0.17414855860894726, Validation Loss: 0.1745545208454132, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 1020, Training Loss: 0.17362619071237503, Validation Loss: 0.17381176352500916, Validation Accuracy: 0.5125\n",
      "Epoch 1021, Training Loss: 0.174243166081367, Validation Loss: 0.17465567092100778, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 1022, Training Loss: 0.17375810252081964, Validation Loss: 0.17303143739700316, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 1023, Training Loss: 0.17426519672716817, Validation Loss: 0.17489205996195475, Validation Accuracy: 0.48125\n",
      "Epoch 1024, Training Loss: 0.17357706831347558, Validation Loss: 0.1739724487066269, Validation Accuracy: 0.50625\n",
      "Epoch 1025, Training Loss: 0.1743407787815217, Validation Loss: 0.17526735961437226, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 1026, Training Loss: 0.17382070133762975, Validation Loss: 0.17212818066279092, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 1027, Training Loss: 0.17415497283781728, Validation Loss: 0.17557305097579956, Validation Accuracy: 0.475\n",
      "Epoch 1028, Training Loss: 0.17386427858183462, Validation Loss: 0.1735323856274287, Validation Accuracy: 0.5125\n",
      "Epoch 1029, Training Loss: 0.17392082127832598, Validation Loss: 0.1755777378877004, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 1030, Training Loss: 0.17401639780690592, Validation Loss: 0.17266326745351154, Validation Accuracy: 0.5375\n",
      "Epoch 1031, Training Loss: 0.17383728248457755, Validation Loss: 0.17551697691281637, Validation Accuracy: 0.4875\n",
      "Epoch 1032, Training Loss: 0.17398095034783886, Validation Loss: 0.17426147361596425, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 1033, Training Loss: 0.1739497011707675, Validation Loss: 0.17583808799584708, Validation Accuracy: 0.475\n",
      "Epoch 1034, Training Loss: 0.1740904426382434, Validation Loss: 0.17187237739562988, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 1035, Training Loss: 0.1737694062532917, Validation Loss: 0.1768318831920624, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 1036, Training Loss: 0.17420140774019302, Validation Loss: 0.1741324285666148, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1037, Training Loss: 0.1736622779600082, Validation Loss: 0.17487212618192036, Validation Accuracy: 0.4875\n",
      "Epoch 1038, Training Loss: 0.1743335118216853, Validation Loss: 0.17273342311382295, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 1039, Training Loss: 0.17334693189590208, Validation Loss: 0.1754396786292394, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 1040, Training Loss: 0.17467111204901048, Validation Loss: 0.17385994692643483, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1041, Training Loss: 0.1736492980872431, Validation Loss: 0.17425405979156494, Validation Accuracy: 0.49375\n",
      "Epoch 1042, Training Loss: 0.1742237215080569, Validation Loss: 0.17380025287469228, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 1043, Training Loss: 0.1736681096015438, Validation Loss: 0.17439147035280864, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 1044, Training Loss: 0.17426709109737026, Validation Loss: 0.17450165152549743, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 1045, Training Loss: 0.17371365860585244, Validation Loss: 0.17347016235192617, Validation Accuracy: 0.5125\n",
      "Epoch 1046, Training Loss: 0.17417790620557724, Validation Loss: 0.1744730979204178, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 1047, Training Loss: 0.17360288818036357, Validation Loss: 0.17326936423778533, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 1048, Training Loss: 0.17430353789560257, Validation Loss: 0.1740035613377889, Validation Accuracy: 0.48125\n",
      "Epoch 1049, Training Loss: 0.17368012570565747, Validation Loss: 0.17432253956794738, Validation Accuracy: 0.50625\n",
      "Epoch 1050, Training Loss: 0.1741911115184907, Validation Loss: 0.17507146100203197, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 1051, Training Loss: 0.1736699741694235, Validation Loss: 0.17209020654360455, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 1052, Training Loss: 0.17437592196849086, Validation Loss: 0.17399565875530243, Validation Accuracy: 0.475\n",
      "Epoch 1053, Training Loss: 0.1738020638304372, Validation Loss: 0.17347314556439716, Validation Accuracy: 0.5125\n",
      "Epoch 1054, Training Loss: 0.1742107219273044, Validation Loss: 0.17446541885534922, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 1055, Training Loss: 0.1736264584525939, Validation Loss: 0.17273924748102823, Validation Accuracy: 0.5375\n",
      "Epoch 1056, Training Loss: 0.17439461283145413, Validation Loss: 0.17365645468235016, Validation Accuracy: 0.4875\n",
      "Epoch 1057, Training Loss: 0.17384102363740245, Validation Loss: 0.17388549149036409, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 1058, Training Loss: 0.17408155097115424, Validation Loss: 0.17446592052777607, Validation Accuracy: 0.475\n",
      "Epoch 1059, Training Loss: 0.1737400629828053, Validation Loss: 0.17170857886473337, Validation Accuracy: 0.5604166666666667\n",
      "New best validation loss, checkpoint saved\n",
      "Epoch 1060, Training Loss: 0.1743012628247661, Validation Loss: 0.17373479306697845, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 1061, Training Loss: 0.1738459386171833, Validation Loss: 0.17365076541900634, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1062, Training Loss: 0.17403584814840747, Validation Loss: 0.1740869661172231, Validation Accuracy: 0.4875\n",
      "Epoch 1063, Training Loss: 0.1738368676554772, Validation Loss: 0.17284500698248545, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 1064, Training Loss: 0.1742274530472294, Validation Loss: 0.17347018818060558, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 1065, Training Loss: 0.17391439647443832, Validation Loss: 0.17359443406263989, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1066, Training Loss: 0.1739735819639698, Validation Loss: 0.17382987836996713, Validation Accuracy: 0.49375\n",
      "Epoch 1067, Training Loss: 0.1738204792622597, Validation Loss: 0.17331446210543314, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 1068, Training Loss: 0.17419987195922482, Validation Loss: 0.173262753089269, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 1069, Training Loss: 0.17391914898349392, Validation Loss: 0.1734681119521459, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 1070, Training Loss: 0.17403146624565125, Validation Loss: 0.1732231557369232, Validation Accuracy: 0.5125\n",
      "Epoch 1071, Training Loss: 0.17388937213728506, Validation Loss: 0.1734963208436966, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 1072, Training Loss: 0.1741328239440918, Validation Loss: 0.1730359842379888, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 1073, Training Loss: 0.17396168843392404, Validation Loss: 0.17350547413031261, Validation Accuracy: 0.48125\n",
      "Epoch 1074, Training Loss: 0.174044422564968, Validation Loss: 0.17331311404705046, Validation Accuracy: 0.50625\n",
      "Epoch 1075, Training Loss: 0.17390330280027083, Validation Loss: 0.17354757885138195, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 1076, Training Loss: 0.17418455020073922, Validation Loss: 0.17283449272314708, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 1077, Training Loss: 0.1738827593864933, Validation Loss: 0.17356568773587544, Validation Accuracy: 0.475\n",
      "Epoch 1078, Training Loss: 0.1741079803436033, Validation Loss: 0.17321711778640747, Validation Accuracy: 0.5125\n",
      "Epoch 1079, Training Loss: 0.1738985450037064, Validation Loss: 0.17369049787521362, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 1080, Training Loss: 0.17405024218943813, Validation Loss: 0.17288055022557577, Validation Accuracy: 0.5375\n",
      "Epoch 1081, Training Loss: 0.17398270387803355, Validation Loss: 0.1737196058034897, Validation Accuracy: 0.4875\n",
      "Epoch 1082, Training Loss: 0.17398944689381507, Validation Loss: 0.17358877261479697, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 1083, Training Loss: 0.1737958433166627, Validation Loss: 0.17398594717184704, Validation Accuracy: 0.475\n",
      "Epoch 1084, Training Loss: 0.1742141890910364, Validation Loss: 0.17277605533599855, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 1085, Training Loss: 0.1738635287169487, Validation Loss: 0.1740336040655772, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 1086, Training Loss: 0.17406069895913523, Validation Loss: 0.1734852075576782, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1087, Training Loss: 0.17382531589077366, Validation Loss: 0.17373738487561544, Validation Accuracy: 0.4875\n",
      "Epoch 1088, Training Loss: 0.17417442366000144, Validation Loss: 0.17298920353253683, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 1089, Training Loss: 0.17379530783622496, Validation Loss: 0.17369084159533182, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 1090, Training Loss: 0.17418632488096913, Validation Loss: 0.17355719606081646, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1091, Training Loss: 0.17367383260880748, Validation Loss: 0.17383381128311157, Validation Accuracy: 0.49375\n",
      "Epoch 1092, Training Loss: 0.1743703099989122, Validation Loss: 0.17328336934248606, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 1093, Training Loss: 0.17383673306434386, Validation Loss: 0.1734407236178716, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 1094, Training Loss: 0.17404981245917658, Validation Loss: 0.1736487219731013, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 1095, Training Loss: 0.17372262189465185, Validation Loss: 0.1733012706041336, Validation Accuracy: 0.5125\n",
      "Epoch 1096, Training Loss: 0.1742887088368016, Validation Loss: 0.17347514629364014, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 1097, Training Loss: 0.17387412392324017, Validation Loss: 0.17291629711786907, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 1098, Training Loss: 0.17407652014686215, Validation Loss: 0.17360982795556387, Validation Accuracy: 0.48125\n",
      "Epoch 1099, Training Loss: 0.17364858138945796, Validation Loss: 0.1734978953997294, Validation Accuracy: 0.50625\n",
      "Epoch 1100, Training Loss: 0.17432898523346071, Validation Loss: 0.17357582449913025, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 1101, Training Loss: 0.17376250989975467, Validation Loss: 0.17223452925682067, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 1102, Training Loss: 0.17423262038538534, Validation Loss: 0.1736328810453415, Validation Accuracy: 0.475\n",
      "Epoch 1103, Training Loss: 0.17365875167231407, Validation Loss: 0.17327559689680735, Validation Accuracy: 0.5125\n",
      "Epoch 1104, Training Loss: 0.17438258855573593, Validation Loss: 0.17348284820715587, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 1105, Training Loss: 0.17367103936210757, Validation Loss: 0.1726624031861623, Validation Accuracy: 0.5375\n",
      "Epoch 1106, Training Loss: 0.17433793794724248, Validation Loss: 0.1734429895877838, Validation Accuracy: 0.4875\n",
      "Epoch 1107, Training Loss: 0.17363091534183872, Validation Loss: 0.17378919025262196, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 1108, Training Loss: 0.17440034160690923, Validation Loss: 0.17342547476291656, Validation Accuracy: 0.475\n",
      "Epoch 1109, Training Loss: 0.17362751403162557, Validation Loss: 0.1720887690782547, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 1110, Training Loss: 0.17422900565208926, Validation Loss: 0.1733776807785034, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 1111, Training Loss: 0.17363913405326106, Validation Loss: 0.1735906591018041, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1112, Training Loss: 0.1744027296381612, Validation Loss: 0.17339150110880533, Validation Accuracy: 0.4875\n",
      "Epoch 1113, Training Loss: 0.17368483254986425, Validation Loss: 0.17273947099844614, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 1114, Training Loss: 0.17424408658858268, Validation Loss: 0.1733982930580775, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 1115, Training Loss: 0.17368326504384318, Validation Loss: 0.17389446198940278, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1116, Training Loss: 0.1743746616186634, Validation Loss: 0.17334596812725067, Validation Accuracy: 0.49375\n",
      "Epoch 1117, Training Loss: 0.17369972265535785, Validation Loss: 0.17339048385620118, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 1118, Training Loss: 0.17432839735861747, Validation Loss: 0.1732564071814219, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 1119, Training Loss: 0.17356046217103158, Validation Loss: 0.1746377428372701, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 1120, Training Loss: 0.17446719638762936, Validation Loss: 0.17322379450003306, Validation Accuracy: 0.5125\n",
      "Epoch 1121, Training Loss: 0.17364653368150035, Validation Loss: 0.17462119460105896, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 1122, Training Loss: 0.17431784349103127, Validation Loss: 0.17299640476703643, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 1123, Training Loss: 0.17362709487638167, Validation Loss: 0.17460589011510214, Validation Accuracy: 0.48125\n",
      "Epoch 1124, Training Loss: 0.17437776923179626, Validation Loss: 0.17326967616875966, Validation Accuracy: 0.50625\n",
      "Epoch 1125, Training Loss: 0.17356376349925995, Validation Loss: 0.1757264991601308, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 1126, Training Loss: 0.17446248617864424, Validation Loss: 0.17293165822823842, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 1127, Training Loss: 0.1734921807242978, Validation Loss: 0.17519932389259338, Validation Accuracy: 0.475\n",
      "Epoch 1128, Training Loss: 0.1744274203815768, Validation Loss: 0.17325768868128458, Validation Accuracy: 0.5125\n",
      "Epoch 1129, Training Loss: 0.173538300779558, Validation Loss: 0.17565404574076335, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 1130, Training Loss: 0.17440693368834834, Validation Loss: 0.17277474304040272, Validation Accuracy: 0.5375\n",
      "Epoch 1131, Training Loss: 0.1735189220597667, Validation Loss: 0.17478885451952617, Validation Accuracy: 0.4875\n",
      "Epoch 1132, Training Loss: 0.17456152506412997, Validation Loss: 0.1736224929491679, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 1133, Training Loss: 0.17358734819196886, Validation Loss: 0.1753500501314799, Validation Accuracy: 0.475\n",
      "Epoch 1134, Training Loss: 0.1744449826017503, Validation Loss: 0.1724028209845225, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 1135, Training Loss: 0.17357513020115514, Validation Loss: 0.17545988460381826, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 1136, Training Loss: 0.1742629514586541, Validation Loss: 0.1733039438724518, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1137, Training Loss: 0.1735587639193381, Validation Loss: 0.17445881764094034, Validation Accuracy: 0.4875\n",
      "Epoch 1138, Training Loss: 0.17439679609191033, Validation Loss: 0.17276858389377595, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 1139, Training Loss: 0.17347098454352347, Validation Loss: 0.17455741465091706, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 1140, Training Loss: 0.17435289534830278, Validation Loss: 0.1740913232167562, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1141, Training Loss: 0.17365161305473698, Validation Loss: 0.17479737798372905, Validation Accuracy: 0.49375\n",
      "Epoch 1142, Training Loss: 0.17438179446804908, Validation Loss: 0.17357037464777628, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 1143, Training Loss: 0.1735150698692568, Validation Loss: 0.17390323877334596, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 1144, Training Loss: 0.1743210606998013, Validation Loss: 0.17449151972929636, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 1145, Training Loss: 0.1735836301119097, Validation Loss: 0.1737297733624776, Validation Accuracy: 0.5125\n",
      "Epoch 1146, Training Loss: 0.17435328422054167, Validation Loss: 0.1747351735830307, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 1147, Training Loss: 0.17375576976806886, Validation Loss: 0.17303913533687593, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 1148, Training Loss: 0.17428138323368564, Validation Loss: 0.1749820291996002, Validation Accuracy: 0.48125\n",
      "Epoch 1149, Training Loss: 0.17359630811598994, Validation Loss: 0.17386418282985688, Validation Accuracy: 0.50625\n",
      "Epoch 1150, Training Loss: 0.17444899870503333, Validation Loss: 0.17552503546078999, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 1151, Training Loss: 0.17377440775594405, Validation Loss: 0.17211272120475768, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 1152, Training Loss: 0.17418944354980223, Validation Loss: 0.17566259801387787, Validation Accuracy: 0.475\n",
      "Epoch 1153, Training Loss: 0.17385678473980196, Validation Loss: 0.17351035475730897, Validation Accuracy: 0.5125\n",
      "Epoch 1154, Training Loss: 0.1739919642286916, Validation Loss: 0.1761009822289149, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 1155, Training Loss: 0.17397088581515896, Validation Loss: 0.17265907526016236, Validation Accuracy: 0.5375\n",
      "Epoch 1156, Training Loss: 0.1738841918206984, Validation Loss: 0.17566654682159424, Validation Accuracy: 0.4875\n",
      "Epoch 1157, Training Loss: 0.17398987037520255, Validation Loss: 0.17407237291336058, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 1158, Training Loss: 0.1739745726508479, Validation Loss: 0.17563417553901672, Validation Accuracy: 0.475\n",
      "Epoch 1159, Training Loss: 0.1741096761918837, Validation Loss: 0.1718800276517868, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 1160, Training Loss: 0.173789031082584, Validation Loss: 0.17697029312451681, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 1161, Training Loss: 0.17419290734875587, Validation Loss: 0.17404693365097046, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1162, Training Loss: 0.17372404759930027, Validation Loss: 0.17498981058597565, Validation Accuracy: 0.4875\n",
      "Epoch 1163, Training Loss: 0.1743598614008196, Validation Loss: 0.17274572451909384, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 1164, Training Loss: 0.17330595274125377, Validation Loss: 0.17576282223065695, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 1165, Training Loss: 0.17467272666192823, Validation Loss: 0.17376263538996378, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1166, Training Loss: 0.17365708322294296, Validation Loss: 0.17433779835700988, Validation Accuracy: 0.49375\n",
      "Epoch 1167, Training Loss: 0.1742656495301954, Validation Loss: 0.17374470134576162, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 1168, Training Loss: 0.1736493927817191, Validation Loss: 0.17451987663904825, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 1169, Training Loss: 0.17436860597902729, Validation Loss: 0.17397115329901378, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 1170, Training Loss: 0.1737665880110956, Validation Loss: 0.17385532160600026, Validation Accuracy: 0.5125\n",
      "Epoch 1171, Training Loss: 0.17409714095054135, Validation Loss: 0.17468694845835367, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 1172, Training Loss: 0.17360916926014808, Validation Loss: 0.17327393392721813, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 1173, Training Loss: 0.1742748651773699, Validation Loss: 0.1740820904572805, Validation Accuracy: 0.48125\n",
      "Epoch 1174, Training Loss: 0.1738428016824107, Validation Loss: 0.1736586759487788, Validation Accuracy: 0.50625\n",
      "Epoch 1175, Training Loss: 0.17415387447803252, Validation Loss: 0.17487204174200693, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 1176, Training Loss: 0.17366381277961115, Validation Loss: 0.1720752110083898, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 1177, Training Loss: 0.17436717787096578, Validation Loss: 0.17397093772888184, Validation Accuracy: 0.475\n",
      "Epoch 1178, Training Loss: 0.17374892725098517, Validation Loss: 0.17367483973503112, Validation Accuracy: 0.5125\n",
      "Epoch 1179, Training Loss: 0.1741979742242444, Validation Loss: 0.1750114252169927, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 1180, Training Loss: 0.1735874645171627, Validation Loss: 0.17305139402548472, Validation Accuracy: 0.5375\n",
      "Epoch 1181, Training Loss: 0.17432900109598715, Validation Loss: 0.17382435202598573, Validation Accuracy: 0.4875\n",
      "Epoch 1182, Training Loss: 0.17370855087234127, Validation Loss: 0.17508818904558818, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 1183, Training Loss: 0.174150534214512, Validation Loss: 0.17454820573329927, Validation Accuracy: 0.475\n",
      "Epoch 1184, Training Loss: 0.17375228626112785, Validation Loss: 0.17168728212515513, Validation Accuracy: 0.5604166666666667\n",
      "New best validation loss, checkpoint saved\n",
      "Epoch 1185, Training Loss: 0.17433588350972823, Validation Loss: 0.17372083365917207, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 1186, Training Loss: 0.17387958928461997, Validation Loss: 0.17374366223812104, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1187, Training Loss: 0.17407742479155142, Validation Loss: 0.17388487458229065, Validation Accuracy: 0.4875\n",
      "Epoch 1188, Training Loss: 0.17383969214654738, Validation Loss: 0.17286463379859923, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 1189, Training Loss: 0.17419506993985945, Validation Loss: 0.17350709835688274, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 1190, Training Loss: 0.17395895671459935, Validation Loss: 0.1735001762708028, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1191, Training Loss: 0.17406423678321223, Validation Loss: 0.1736809859673182, Validation Accuracy: 0.49375\n",
      "Epoch 1192, Training Loss: 0.1738461491561705, Validation Loss: 0.17329729994138082, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 1193, Training Loss: 0.17409916318232013, Validation Loss: 0.17330161333084107, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 1194, Training Loss: 0.17401085265221133, Validation Loss: 0.17352857689062753, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 1195, Training Loss: 0.17400985860055493, Validation Loss: 0.17322575946648916, Validation Accuracy: 0.5125\n",
      "Epoch 1196, Training Loss: 0.17390714201235002, Validation Loss: 0.17350057363510132, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 1197, Training Loss: 0.17413413043945067, Validation Loss: 0.1730400542418162, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 1198, Training Loss: 0.17394775200274684, Validation Loss: 0.17353255649407703, Validation Accuracy: 0.48125\n",
      "Epoch 1199, Training Loss: 0.1738271814200186, Validation Loss: 0.17354459961255392, Validation Accuracy: 0.50625\n",
      "Epoch 1200, Training Loss: 0.17404067804736476, Validation Loss: 0.17358547846476238, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 1201, Training Loss: 0.17413909300681082, Validation Loss: 0.17285993397235871, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 1202, Training Loss: 0.17391754110013286, Validation Loss: 0.17363030811150867, Validation Accuracy: 0.475\n",
      "Epoch 1203, Training Loss: 0.17409511198920588, Validation Loss: 0.17321732739607493, Validation Accuracy: 0.5125\n",
      "Epoch 1204, Training Loss: 0.17386476647469304, Validation Loss: 0.17362683316071828, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 1205, Training Loss: 0.17416917124102194, Validation Loss: 0.1729794333378474, Validation Accuracy: 0.5375\n",
      "Epoch 1206, Training Loss: 0.1738756222109641, Validation Loss: 0.17359369695186616, Validation Accuracy: 0.4875\n",
      "Epoch 1207, Training Loss: 0.17417799657390964, Validation Loss: 0.1734049439430237, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 1208, Training Loss: 0.17377176640495176, Validation Loss: 0.17378623684247335, Validation Accuracy: 0.475\n",
      "Epoch 1209, Training Loss: 0.17425328445050023, Validation Loss: 0.17286577920118967, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 1210, Training Loss: 0.17383329954839521, Validation Loss: 0.17397322555383046, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 1211, Training Loss: 0.17418740689754486, Validation Loss: 0.1733831117550532, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1212, Training Loss: 0.17378205109027126, Validation Loss: 0.17365672091643017, Validation Accuracy: 0.4875\n",
      "Epoch 1213, Training Loss: 0.17418209487392056, Validation Loss: 0.17299970189730327, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 1214, Training Loss: 0.17375403834927466, Validation Loss: 0.17365731199582418, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 1215, Training Loss: 0.17418881193284066, Validation Loss: 0.1735044886668523, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1216, Training Loss: 0.17366698624626284, Validation Loss: 0.17391156852245332, Validation Accuracy: 0.49375\n",
      "Epoch 1217, Training Loss: 0.1743538769022111, Validation Loss: 0.17328393658002217, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 1218, Training Loss: 0.17378189775251573, Validation Loss: 0.17332464655240376, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 1219, Training Loss: 0.1742575365689493, Validation Loss: 0.1734407295783361, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 1220, Training Loss: 0.17374409062247123, Validation Loss: 0.17325174907843272, Validation Accuracy: 0.5125\n",
      "Epoch 1221, Training Loss: 0.1742710615358045, Validation Loss: 0.17342337171236674, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 1222, Training Loss: 0.17378791589890757, Validation Loss: 0.17291711668173473, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 1223, Training Loss: 0.1742569573463932, Validation Loss: 0.17343858480453492, Validation Accuracy: 0.48125\n",
      "Epoch 1224, Training Loss: 0.17363386961721605, Validation Loss: 0.17347062627474466, Validation Accuracy: 0.50625\n",
      "Epoch 1225, Training Loss: 0.17433421746377023, Validation Loss: 0.17350587944189708, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 1226, Training Loss: 0.17372138798236847, Validation Loss: 0.17234831353028615, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 1227, Training Loss: 0.1740135367839567, Validation Loss: 0.1740522116422653, Validation Accuracy: 0.475\n",
      "Epoch 1228, Training Loss: 0.17374138678273848, Validation Loss: 0.17338573733965557, Validation Accuracy: 0.5125\n",
      "Epoch 1229, Training Loss: 0.1744394629232345, Validation Loss: 0.17354389329751332, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 1230, Training Loss: 0.17370981506762967, Validation Loss: 0.17265923420588175, Validation Accuracy: 0.5375\n",
      "Epoch 1231, Training Loss: 0.17416479270304402, Validation Loss: 0.17340728441874187, Validation Accuracy: 0.4875\n",
      "Epoch 1232, Training Loss: 0.1736660849663519, Validation Loss: 0.17368600765864053, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 1233, Training Loss: 0.17445560280353792, Validation Loss: 0.1734645475943883, Validation Accuracy: 0.475\n",
      "Epoch 1234, Training Loss: 0.17363821114263228, Validation Loss: 0.17185674707094828, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 1235, Training Loss: 0.17430969303654087, Validation Loss: 0.173575430115064, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 1236, Training Loss: 0.17365833299775277, Validation Loss: 0.17372107406457266, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1237, Training Loss: 0.1743871492724265, Validation Loss: 0.17338113188743592, Validation Accuracy: 0.4875\n",
      "Epoch 1238, Training Loss: 0.17370434778351937, Validation Loss: 0.17272761066754658, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 1239, Training Loss: 0.17429485340272227, Validation Loss: 0.1733704755703608, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 1240, Training Loss: 0.1736709326505661, Validation Loss: 0.17387637098630268, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1241, Training Loss: 0.17438059997174046, Validation Loss: 0.1733267943064372, Validation Accuracy: 0.49375\n",
      "Epoch 1242, Training Loss: 0.1737421227078284, Validation Loss: 0.17358170946439108, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 1243, Training Loss: 0.17430989348119305, Validation Loss: 0.17325599789619445, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 1244, Training Loss: 0.17357247779446264, Validation Loss: 0.17448346714178722, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 1245, Training Loss: 0.17443540403919836, Validation Loss: 0.17324014902114868, Validation Accuracy: 0.5125\n",
      "Epoch 1246, Training Loss: 0.1736850599127431, Validation Loss: 0.1749058355887731, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 1247, Training Loss: 0.1743076818604623, Validation Loss: 0.1730344623327255, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 1248, Training Loss: 0.17362385267211544, Validation Loss: 0.17483677665392558, Validation Accuracy: 0.48125\n",
      "Epoch 1249, Training Loss: 0.17440174760357027, Validation Loss: 0.1732785363992055, Validation Accuracy: 0.50625\n",
      "Epoch 1250, Training Loss: 0.1735370337001739, Validation Loss: 0.17555349469184875, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 1251, Training Loss: 0.17454112921991655, Validation Loss: 0.17276597321033477, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 1252, Training Loss: 0.17344631254673004, Validation Loss: 0.17546251714229583, Validation Accuracy: 0.475\n",
      "Epoch 1253, Training Loss: 0.17450867929766256, Validation Loss: 0.1732240190108617, Validation Accuracy: 0.5125\n",
      "Epoch 1254, Training Loss: 0.17349191682953988, Validation Loss: 0.17575930058956146, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 1255, Training Loss: 0.1744441394844363, Validation Loss: 0.1727849433819453, Validation Accuracy: 0.5375\n",
      "Epoch 1256, Training Loss: 0.17351437384082424, Validation Loss: 0.17478423217932385, Validation Accuracy: 0.4875\n",
      "Epoch 1257, Training Loss: 0.17456233645639113, Validation Loss: 0.17358004848162334, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 1258, Training Loss: 0.17358846770178887, Validation Loss: 0.17548372944196064, Validation Accuracy: 0.475\n",
      "Epoch 1259, Training Loss: 0.17441218466528, Validation Loss: 0.17229539652665457, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 1260, Training Loss: 0.17360288529626786, Validation Loss: 0.1754138648509979, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 1261, Training Loss: 0.17440921500805887, Validation Loss: 0.17371075451374055, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1262, Training Loss: 0.17352105677127838, Validation Loss: 0.17502723932266234, Validation Accuracy: 0.4875\n",
      "Epoch 1263, Training Loss: 0.17435322701931, Validation Loss: 0.1727387438217799, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 1264, Training Loss: 0.17357306470794062, Validation Loss: 0.17458512981732685, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 1265, Training Loss: 0.17439927064603375, Validation Loss: 0.17396815319856007, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1266, Training Loss: 0.17358441506662675, Validation Loss: 0.17471754054228464, Validation Accuracy: 0.49375\n",
      "Epoch 1267, Training Loss: 0.17441469334786938, Validation Loss: 0.17365615367889403, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 1268, Training Loss: 0.17354250290701467, Validation Loss: 0.1740556279818217, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 1269, Training Loss: 0.17430036827441184, Validation Loss: 0.17460395097732545, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 1270, Training Loss: 0.17362728811079456, Validation Loss: 0.17377011875311535, Validation Accuracy: 0.5125\n",
      "Epoch 1271, Training Loss: 0.17436747397145919, Validation Loss: 0.1747880925734838, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 1272, Training Loss: 0.17374719967765193, Validation Loss: 0.17303086817264557, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 1273, Training Loss: 0.1743137240409851, Validation Loss: 0.17494940559069316, Validation Accuracy: 0.48125\n",
      "Epoch 1274, Training Loss: 0.17357943423332706, Validation Loss: 0.1738575448592504, Validation Accuracy: 0.50625\n",
      "Epoch 1275, Training Loss: 0.17446470741302736, Validation Loss: 0.1747276117404302, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 1276, Training Loss: 0.17363379270799698, Validation Loss: 0.1723645160595576, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 1277, Training Loss: 0.1742207585803924, Validation Loss: 0.17559947768847148, Validation Accuracy: 0.475\n",
      "Epoch 1278, Training Loss: 0.173812692684512, Validation Loss: 0.17350206275780997, Validation Accuracy: 0.5125\n",
      "Epoch 1279, Training Loss: 0.17398494914654763, Validation Loss: 0.17585800290107728, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 1280, Training Loss: 0.1740100585645245, Validation Loss: 0.17266158163547515, Validation Accuracy: 0.5375\n",
      "Epoch 1281, Training Loss: 0.17387597503200655, Validation Loss: 0.17576268215974172, Validation Accuracy: 0.4875\n",
      "Epoch 1282, Training Loss: 0.17399341396747098, Validation Loss: 0.1741539845863978, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 1283, Training Loss: 0.1739666178341835, Validation Loss: 0.1760551869869232, Validation Accuracy: 0.475\n",
      "Epoch 1284, Training Loss: 0.17411633893366782, Validation Loss: 0.17191476225852967, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 1285, Training Loss: 0.17376764839695347, Validation Loss: 0.17692140837510426, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 1286, Training Loss: 0.17425420976454212, Validation Loss: 0.1739131987094879, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1287, Training Loss: 0.17373698324926437, Validation Loss: 0.17556181053320566, Validation Accuracy: 0.4875\n",
      "Epoch 1288, Training Loss: 0.17439662593026314, Validation Loss: 0.17274256149927775, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 1289, Training Loss: 0.17335414694201562, Validation Loss: 0.17569661140441895, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 1290, Training Loss: 0.17469791010502847, Validation Loss: 0.17381998300552368, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1291, Training Loss: 0.1736222077761927, Validation Loss: 0.17485485275586446, Validation Accuracy: 0.49375\n",
      "Epoch 1292, Training Loss: 0.17421307919486875, Validation Loss: 0.1735050807396571, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 1293, Training Loss: 0.17362251925852992, Validation Loss: 0.17465355197588603, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 1294, Training Loss: 0.17440648617282992, Validation Loss: 0.17392108837763467, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 1295, Training Loss: 0.17378975258719537, Validation Loss: 0.1736446003119151, Validation Accuracy: 0.5125\n",
      "Epoch 1296, Training Loss: 0.17421722988928517, Validation Loss: 0.1744372606277466, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 1297, Training Loss: 0.17359656960733474, Validation Loss: 0.17322086195151012, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 1298, Training Loss: 0.17433216542966903, Validation Loss: 0.17397697865962983, Validation Accuracy: 0.48125\n",
      "Epoch 1299, Training Loss: 0.17372164370552187, Validation Loss: 0.1741390029589335, Validation Accuracy: 0.50625\n",
      "Epoch 1300, Training Loss: 0.17430402482709578, Validation Loss: 0.17444321115811665, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 1301, Training Loss: 0.17362966989317247, Validation Loss: 0.17207547525564829, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 1302, Training Loss: 0.17438495735968312, Validation Loss: 0.1739571044842402, Validation Accuracy: 0.475\n",
      "Epoch 1303, Training Loss: 0.17370965211622177, Validation Loss: 0.17386996746063232, Validation Accuracy: 0.5125\n",
      "Epoch 1304, Training Loss: 0.1743733969426924, Validation Loss: 0.17410573462645212, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 1305, Training Loss: 0.17358396610906046, Validation Loss: 0.17274521589279174, Validation Accuracy: 0.5375\n",
      "Epoch 1306, Training Loss: 0.17440224607144633, Validation Loss: 0.1736418793598811, Validation Accuracy: 0.4875\n",
      "Epoch 1307, Training Loss: 0.1737644806984932, Validation Loss: 0.1743597775697708, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 1308, Training Loss: 0.17415396532704752, Validation Loss: 0.17463412086168925, Validation Accuracy: 0.475\n",
      "Epoch 1309, Training Loss: 0.1737307906150818, Validation Loss: 0.17173965473969777, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 1310, Training Loss: 0.17431310492177163, Validation Loss: 0.17380428612232207, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 1311, Training Loss: 0.17390005675054365, Validation Loss: 0.1736259639263153, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1312, Training Loss: 0.17408080543241194, Validation Loss: 0.17387577891349792, Validation Accuracy: 0.4875\n",
      "Epoch 1313, Training Loss: 0.1738498927124085, Validation Loss: 0.17280872762203217, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 1314, Training Loss: 0.1741962702043595, Validation Loss: 0.17349782983462017, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 1315, Training Loss: 0.1739034681550918, Validation Loss: 0.1735104610522588, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1316, Training Loss: 0.1741380455993837, Validation Loss: 0.17357774476210278, Validation Accuracy: 0.49375\n",
      "Epoch 1317, Training Loss: 0.17384117120696652, Validation Loss: 0.17331153750419617, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 1318, Training Loss: 0.1739398226622612, Validation Loss: 0.17352854708830515, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 1319, Training Loss: 0.17403496273102298, Validation Loss: 0.1735759456952413, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 1320, Training Loss: 0.17399065100377606, Validation Loss: 0.1732251892487208, Validation Accuracy: 0.5125\n",
      "Epoch 1321, Training Loss: 0.17390823941076955, Validation Loss: 0.1734883040189743, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 1322, Training Loss: 0.17414440166565678, Validation Loss: 0.17305528422196706, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 1323, Training Loss: 0.17394710356189358, Validation Loss: 0.173513259490331, Validation Accuracy: 0.48125\n",
      "Epoch 1324, Training Loss: 0.17409603922597824, Validation Loss: 0.17328936755657195, Validation Accuracy: 0.50625\n",
      "Epoch 1325, Training Loss: 0.17388727636106552, Validation Loss: 0.17356127699216206, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 1326, Training Loss: 0.17416886264278042, Validation Loss: 0.1728482315937678, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 1327, Training Loss: 0.1739164461051264, Validation Loss: 0.17359745701154072, Validation Accuracy: 0.475\n",
      "Epoch 1328, Training Loss: 0.17407171091725748, Validation Loss: 0.17321732739607493, Validation Accuracy: 0.5125\n",
      "Epoch 1329, Training Loss: 0.1738483852917148, Validation Loss: 0.1737375557422638, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 1330, Training Loss: 0.1741924343570586, Validation Loss: 0.1730400453011195, Validation Accuracy: 0.5375\n",
      "Epoch 1331, Training Loss: 0.1739364444248138, Validation Loss: 0.17359667519728342, Validation Accuracy: 0.4875\n",
      "Epoch 1332, Training Loss: 0.17404419231799342, Validation Loss: 0.17352900604406993, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 1333, Training Loss: 0.17378793272279924, Validation Loss: 0.17402243316173555, Validation Accuracy: 0.475\n",
      "Epoch 1334, Training Loss: 0.1742648934164355, Validation Loss: 0.17292767465114595, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 1335, Training Loss: 0.1738566501486686, Validation Loss: 0.17397056420644125, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 1336, Training Loss: 0.17410708098642289, Validation Loss: 0.17343861957391102, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1337, Training Loss: 0.17381394918887846, Validation Loss: 0.17373751898606618, Validation Accuracy: 0.4875\n",
      "Epoch 1338, Training Loss: 0.17425806435846514, Validation Loss: 0.1730720986922582, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 1339, Training Loss: 0.1737596695461581, Validation Loss: 0.17370569109916686, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 1340, Training Loss: 0.17424513159259672, Validation Loss: 0.17343464195728303, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1341, Training Loss: 0.17365773022174835, Validation Loss: 0.1738026072581609, Validation Accuracy: 0.49375\n",
      "Epoch 1342, Training Loss: 0.17435869093864195, Validation Loss: 0.17328298290570576, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 1343, Training Loss: 0.1738208532333374, Validation Loss: 0.17335053384304047, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 1344, Training Loss: 0.17411623606758733, Validation Loss: 0.17353028655052186, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 1345, Training Loss: 0.17379655232352595, Validation Loss: 0.17326794266700746, Validation Accuracy: 0.5125\n",
      "Epoch 1346, Training Loss: 0.17426108352599606, Validation Loss: 0.17343588868776957, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 1347, Training Loss: 0.17386940121650696, Validation Loss: 0.17291243771711987, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 1348, Training Loss: 0.1739992186907799, Validation Loss: 0.1737875779469808, Validation Accuracy: 0.48125\n",
      "Epoch 1349, Training Loss: 0.17373906845046627, Validation Loss: 0.17351699074109395, Validation Accuracy: 0.50625\n",
      "Epoch 1350, Training Loss: 0.17439322077458905, Validation Loss: 0.1734772672255834, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 1351, Training Loss: 0.17366901424623304, Validation Loss: 0.17234702209631603, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 1352, Training Loss: 0.17412068815000595, Validation Loss: 0.1737652619679769, Validation Accuracy: 0.475\n",
      "Epoch 1353, Training Loss: 0.17370591865431878, Validation Loss: 0.1733796278635661, Validation Accuracy: 0.5125\n",
      "Epoch 1354, Training Loss: 0.17437731931286474, Validation Loss: 0.1734910289446513, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 1355, Training Loss: 0.1737110956061271, Validation Loss: 0.1726759781440099, Validation Accuracy: 0.5375\n",
      "Epoch 1356, Training Loss: 0.1742830007306991, Validation Loss: 0.1734794149796168, Validation Accuracy: 0.4875\n",
      "Epoch 1357, Training Loss: 0.17368464700637326, Validation Loss: 0.17385730544726055, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 1358, Training Loss: 0.17429776970417268, Validation Loss: 0.17344923615455626, Validation Accuracy: 0.475\n",
      "Epoch 1359, Training Loss: 0.17376767339244967, Validation Loss: 0.17192099491755167, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 1360, Training Loss: 0.17426863841472134, Validation Loss: 0.17352541188398998, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 1361, Training Loss: 0.17364123992381558, Validation Loss: 0.173585973183314, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1362, Training Loss: 0.17434434256246012, Validation Loss: 0.17336714466412861, Validation Accuracy: 0.4875\n",
      "Epoch 1363, Training Loss: 0.17376014205717272, Validation Loss: 0.17280297378698986, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 1364, Training Loss: 0.17431968017931906, Validation Loss: 0.17334770063559216, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 1365, Training Loss: 0.1736747771501541, Validation Loss: 0.1740833818912506, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1366, Training Loss: 0.17429616855036828, Validation Loss: 0.17330891688664754, Validation Accuracy: 0.49375\n",
      "Epoch 1367, Training Loss: 0.1737803182294292, Validation Loss: 0.17337119281291963, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 1368, Training Loss: 0.17411883607987436, Validation Loss: 0.17326273918151855, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 1369, Training Loss: 0.17363421282460612, Validation Loss: 0.17433708210786183, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 1370, Training Loss: 0.17447037321905937, Validation Loss: 0.17323162754376728, Validation Accuracy: 0.5125\n",
      "Epoch 1371, Training Loss: 0.17370103059276457, Validation Loss: 0.17506067951520285, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 1372, Training Loss: 0.1742604124930597, Validation Loss: 0.1730233629544576, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 1373, Training Loss: 0.1736216732571202, Validation Loss: 0.17429300546646118, Validation Accuracy: 0.48125\n",
      "Epoch 1374, Training Loss: 0.17442296493437984, Validation Loss: 0.1732790142297745, Validation Accuracy: 0.50625\n",
      "Epoch 1375, Training Loss: 0.17354079408030357, Validation Loss: 0.17571571866671246, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 1376, Training Loss: 0.17451788340845414, Validation Loss: 0.1727245678504308, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 1377, Training Loss: 0.1734613641615837, Validation Loss: 0.175324077407519, Validation Accuracy: 0.475\n",
      "Epoch 1378, Training Loss: 0.17452148468263687, Validation Loss: 0.17321840524673462, Validation Accuracy: 0.5125\n",
      "Epoch 1379, Training Loss: 0.17345315842859207, Validation Loss: 0.17562511165936787, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 1380, Training Loss: 0.17452992018192046, Validation Loss: 0.17286355495452882, Validation Accuracy: 0.5375\n",
      "Epoch 1381, Training Loss: 0.17346060372168018, Validation Loss: 0.1748326559861501, Validation Accuracy: 0.4875\n",
      "Epoch 1382, Training Loss: 0.17455173740463872, Validation Loss: 0.1734087566534678, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 1383, Training Loss: 0.17362514666972623, Validation Loss: 0.17559555768966675, Validation Accuracy: 0.475\n",
      "Epoch 1384, Training Loss: 0.17434920658988337, Validation Loss: 0.1722086658080419, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 1385, Training Loss: 0.1736350698817161, Validation Loss: 0.17520126203695932, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 1386, Training Loss: 0.17439834004448307, Validation Loss: 0.17374428113301596, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1387, Training Loss: 0.1735345692403855, Validation Loss: 0.17498138546943665, Validation Accuracy: 0.4875\n",
      "Epoch 1388, Training Loss: 0.17441970109939575, Validation Loss: 0.17275258799393972, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 1389, Training Loss: 0.1735096198897208, Validation Loss: 0.17461837728818258, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 1390, Training Loss: 0.17437844699428928, Validation Loss: 0.17402117649714152, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1391, Training Loss: 0.17360935912978265, Validation Loss: 0.17480363547801972, Validation Accuracy: 0.49375\n",
      "Epoch 1392, Training Loss: 0.1743397679059736, Validation Loss: 0.17373209396998088, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 1393, Training Loss: 0.17361965775489807, Validation Loss: 0.17400551438331605, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 1394, Training Loss: 0.1742438409597643, Validation Loss: 0.17459749579429626, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 1395, Training Loss: 0.1736496922469908, Validation Loss: 0.1738137573003769, Validation Accuracy: 0.5125\n",
      "Epoch 1396, Training Loss: 0.17437976646807887, Validation Loss: 0.17481846511363983, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 1397, Training Loss: 0.1737349461163244, Validation Loss: 0.17302656769752503, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 1398, Training Loss: 0.1743173719413819, Validation Loss: 0.1749320536851883, Validation Accuracy: 0.48125\n",
      "Epoch 1399, Training Loss: 0.17355705653467485, Validation Loss: 0.1739019105831782, Validation Accuracy: 0.50625\n",
      "Epoch 1400, Training Loss: 0.1744742532891612, Validation Loss: 0.1756357580423355, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 1401, Training Loss: 0.1737595945596695, Validation Loss: 0.1721283624569575, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 1402, Training Loss: 0.17422746698702535, Validation Loss: 0.17575509746869405, Validation Accuracy: 0.475\n",
      "Epoch 1403, Training Loss: 0.1738256812095642, Validation Loss: 0.1734815051158269, Validation Accuracy: 0.5125\n",
      "Epoch 1404, Training Loss: 0.17398250102996826, Validation Loss: 0.17562834322452545, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 1405, Training Loss: 0.17401066470530727, Validation Loss: 0.1726653387149175, Validation Accuracy: 0.5375\n",
      "Epoch 1406, Training Loss: 0.17386022162052892, Validation Loss: 0.1756840576728185, Validation Accuracy: 0.4875\n",
      "Epoch 1407, Training Loss: 0.1739905870729877, Validation Loss: 0.1741935819387436, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 1408, Training Loss: 0.17398107292190676, Validation Loss: 0.17564818561077117, Validation Accuracy: 0.475\n",
      "Epoch 1409, Training Loss: 0.17408809306160097, Validation Loss: 0.1719865341981252, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 1410, Training Loss: 0.17377723897657088, Validation Loss: 0.17686500549316406, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 1411, Training Loss: 0.1742049753665924, Validation Loss: 0.17390745282173156, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1412, Training Loss: 0.1737490858762495, Validation Loss: 0.1748318483432134, Validation Accuracy: 0.4875\n",
      "Epoch 1413, Training Loss: 0.17436703943437146, Validation Loss: 0.17272699077924092, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 1414, Training Loss: 0.17335848846743185, Validation Loss: 0.17580509483814238, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 1415, Training Loss: 0.174675811682978, Validation Loss: 0.17377092937628427, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1416, Training Loss: 0.17363062933568033, Validation Loss: 0.17487574418385823, Validation Accuracy: 0.49375\n",
      "Epoch 1417, Training Loss: 0.1743215197517026, Validation Loss: 0.1736158549785614, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 1418, Training Loss: 0.17361933377481276, Validation Loss: 0.17449819842974346, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 1419, Training Loss: 0.1743954280691762, Validation Loss: 0.17393550276756287, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 1420, Training Loss: 0.17376090874595027, Validation Loss: 0.17390104234218598, Validation Accuracy: 0.5125\n",
      "Epoch 1421, Training Loss: 0.17425801436747274, Validation Loss: 0.1742074320713679, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 1422, Training Loss: 0.17359138304187405, Validation Loss: 0.1735935499270757, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 1423, Training Loss: 0.17426365950415212, Validation Loss: 0.17404395639896392, Validation Accuracy: 0.48125\n",
      "Epoch 1424, Training Loss: 0.1737951434427692, Validation Loss: 0.1739753594001134, Validation Accuracy: 0.50625\n",
      "Epoch 1425, Training Loss: 0.17417715586000873, Validation Loss: 0.1751116434733073, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 1426, Training Loss: 0.1736657965567804, Validation Loss: 0.17212831377983093, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 1427, Training Loss: 0.17431155039418128, Validation Loss: 0.17405482828617097, Validation Accuracy: 0.475\n",
      "Epoch 1428, Training Loss: 0.17387171281922248, Validation Loss: 0.17335729002952577, Validation Accuracy: 0.5125\n",
      "Epoch 1429, Training Loss: 0.1741597887969786, Validation Loss: 0.17463549077510834, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 1430, Training Loss: 0.1736663680884146, Validation Loss: 0.17267067233721414, Validation Accuracy: 0.5375\n",
      "Epoch 1431, Training Loss: 0.1743476866714416, Validation Loss: 0.173712557554245, Validation Accuracy: 0.4875\n",
      "Epoch 1432, Training Loss: 0.1737749365068251, Validation Loss: 0.17436928649743397, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 1433, Training Loss: 0.1741518267700749, Validation Loss: 0.17466618617375693, Validation Accuracy: 0.475\n",
      "Epoch 1434, Training Loss: 0.17370352629692323, Validation Loss: 0.17175465126832326, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 1435, Training Loss: 0.17433445395961886, Validation Loss: 0.1738218088944753, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 1436, Training Loss: 0.17387362160990316, Validation Loss: 0.1736897309621175, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1437, Training Loss: 0.17409697992186393, Validation Loss: 0.17392299473285674, Validation Accuracy: 0.4875\n",
      "Epoch 1438, Training Loss: 0.17387101150328113, Validation Loss: 0.17277310093243917, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 1439, Training Loss: 0.17423509061336517, Validation Loss: 0.17344402273495993, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 1440, Training Loss: 0.17388377362681973, Validation Loss: 0.17348333398501078, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1441, Training Loss: 0.17405133045488788, Validation Loss: 0.17382802963256835, Validation Accuracy: 0.49375\n",
      "Epoch 1442, Training Loss: 0.17386166030360806, Validation Loss: 0.17333836158116658, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 1443, Training Loss: 0.17420829544144292, Validation Loss: 0.17326111992200216, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 1444, Training Loss: 0.17392290359543217, Validation Loss: 0.17346422076225282, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 1445, Training Loss: 0.17396725714206696, Validation Loss: 0.1732523461182912, Validation Accuracy: 0.5125\n",
      "Epoch 1446, Training Loss: 0.17398036824118707, Validation Loss: 0.17355392376581827, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 1447, Training Loss: 0.17413592290493748, Validation Loss: 0.17305034895737967, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 1448, Training Loss: 0.17394053984072902, Validation Loss: 0.17350984811782838, Validation Accuracy: 0.48125\n",
      "Epoch 1449, Training Loss: 0.1741259963281693, Validation Loss: 0.1732869952917099, Validation Accuracy: 0.50625\n",
      "Epoch 1450, Training Loss: 0.17387933884897538, Validation Loss: 0.17356904943784077, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 1451, Training Loss: 0.17418470930668614, Validation Loss: 0.17288593649864198, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 1452, Training Loss: 0.17390954638681105, Validation Loss: 0.17359403073787688, Validation Accuracy: 0.475\n",
      "Epoch 1453, Training Loss: 0.1740783957704421, Validation Loss: 0.17321712871392567, Validation Accuracy: 0.5125\n",
      "Epoch 1454, Training Loss: 0.17385823928540753, Validation Loss: 0.17369038462638856, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 1455, Training Loss: 0.17418378303127904, Validation Loss: 0.17301845252513887, Validation Accuracy: 0.5375\n",
      "Epoch 1456, Training Loss: 0.17393411503684136, Validation Loss: 0.17360169192155203, Validation Accuracy: 0.4875\n",
      "Epoch 1457, Training Loss: 0.17404306944339507, Validation Loss: 0.17351787984371186, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 1458, Training Loss: 0.17379765308672382, Validation Loss: 0.17399701178073884, Validation Accuracy: 0.475\n",
      "Epoch 1459, Training Loss: 0.17414842786327486, Validation Loss: 0.17276108165582021, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 1460, Training Loss: 0.17384890490962612, Validation Loss: 0.17405550877253215, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 1461, Training Loss: 0.173864544399323, Validation Loss: 0.17381703356901804, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1462, Training Loss: 0.1738354746372469, Validation Loss: 0.17382593750953673, Validation Accuracy: 0.4875\n",
      "Epoch 1463, Training Loss: 0.17427693691945845, Validation Loss: 0.17308326462904614, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 1464, Training Loss: 0.17368056697230186, Validation Loss: 0.17395957211653393, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 1465, Training Loss: 0.17434391187083337, Validation Loss: 0.17339134911696116, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1466, Training Loss: 0.17365151259206957, Validation Loss: 0.17372382879257203, Validation Accuracy: 0.49375\n",
      "Epoch 1467, Training Loss: 0.1743133423789855, Validation Loss: 0.17328315277894338, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 1468, Training Loss: 0.17391519969509495, Validation Loss: 0.17345967491467792, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 1469, Training Loss: 0.17403612357954826, Validation Loss: 0.17364258567492166, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 1470, Training Loss: 0.17380503108424525, Validation Loss: 0.17325655817985536, Validation Accuracy: 0.5125\n",
      "Epoch 1471, Training Loss: 0.1742588695018522, Validation Loss: 0.17343460520108542, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 1472, Training Loss: 0.17380978359330085, Validation Loss: 0.17291754086812336, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 1473, Training Loss: 0.17423133552074432, Validation Loss: 0.173445334037145, Validation Accuracy: 0.48125\n",
      "Epoch 1474, Training Loss: 0.1736391153066389, Validation Loss: 0.17346050937970478, Validation Accuracy: 0.50625\n",
      "Epoch 1475, Training Loss: 0.17437848785231191, Validation Loss: 0.17348605493704478, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 1476, Training Loss: 0.17371196948712872, Validation Loss: 0.17221334278583528, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 1477, Training Loss: 0.17411218535515569, Validation Loss: 0.17384291887283326, Validation Accuracy: 0.475\n",
      "Epoch 1478, Training Loss: 0.1737295317073022, Validation Loss: 0.1733910361925761, Validation Accuracy: 0.5125\n",
      "Epoch 1479, Training Loss: 0.17437227502945932, Validation Loss: 0.17350279688835143, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 1480, Training Loss: 0.17371109656749234, Validation Loss: 0.1726708471775055, Validation Accuracy: 0.5375\n",
      "Epoch 1481, Training Loss: 0.17431009008038428, Validation Loss: 0.17338992655277252, Validation Accuracy: 0.4875\n",
      "Epoch 1482, Training Loss: 0.1736010096726879, Validation Loss: 0.17366625964641572, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 1483, Training Loss: 0.17438962238450204, Validation Loss: 0.1734693149725596, Validation Accuracy: 0.475\n",
      "Epoch 1484, Training Loss: 0.17373616416608134, Validation Loss: 0.17192371785640717, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 1485, Training Loss: 0.17427565253550006, Validation Loss: 0.17361833254496256, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 1486, Training Loss: 0.17365517731635802, Validation Loss: 0.17363178431987764, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1487, Training Loss: 0.17439353225692625, Validation Loss: 0.17334211270014446, Validation Accuracy: 0.4875\n",
      "Epoch 1488, Training Loss: 0.17369251097402266, Validation Loss: 0.17282006442546843, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 1489, Training Loss: 0.1743204689794971, Validation Loss: 0.17332092622915904, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 1490, Training Loss: 0.17368190471203096, Validation Loss: 0.173893004655838, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1491, Training Loss: 0.1743961803374752, Validation Loss: 0.17332637906074524, Validation Accuracy: 0.49375\n",
      "Epoch 1492, Training Loss: 0.1737280579343919, Validation Loss: 0.17360636393229167, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 1493, Training Loss: 0.17427782377889078, Validation Loss: 0.1732578307390213, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 1494, Training Loss: 0.17361360451867502, Validation Loss: 0.17459349830945334, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 1495, Training Loss: 0.17445051189391844, Validation Loss: 0.17322735885779064, Validation Accuracy: 0.5125\n",
      "Epoch 1496, Training Loss: 0.17367948783982184, Validation Loss: 0.1749568462371826, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 1497, Training Loss: 0.1742723564947805, Validation Loss: 0.17307850619157156, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 1498, Training Loss: 0.17366113778083556, Validation Loss: 0.1747534841299057, Validation Accuracy: 0.48125\n",
      "Epoch 1499, Training Loss: 0.17438872879551304, Validation Loss: 0.17327513992786409, Validation Accuracy: 0.50625\n",
      "Epoch 1500, Training Loss: 0.17354657717289462, Validation Loss: 0.1757640729347865, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 1501, Training Loss: 0.17438859372369706, Validation Loss: 0.17309426565965016, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 1502, Training Loss: 0.1735325042278536, Validation Loss: 0.17519172430038452, Validation Accuracy: 0.475\n",
      "Epoch 1503, Training Loss: 0.17446120419809896, Validation Loss: 0.17324680387973784, Validation Accuracy: 0.5125\n",
      "Epoch 1504, Training Loss: 0.1735381753213944, Validation Loss: 0.1755609651406606, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 1505, Training Loss: 0.17448557961371639, Validation Loss: 0.17282159626483917, Validation Accuracy: 0.5375\n",
      "Epoch 1506, Training Loss: 0.17346146174015536, Validation Loss: 0.17500920196374256, Validation Accuracy: 0.4875\n",
      "Epoch 1507, Training Loss: 0.17454223575130587, Validation Loss: 0.17365915675957996, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 1508, Training Loss: 0.17363962146543688, Validation Loss: 0.17546464800834655, Validation Accuracy: 0.475\n",
      "Epoch 1509, Training Loss: 0.17434870908337255, Validation Loss: 0.1723226338624954, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 1510, Training Loss: 0.17362035810947418, Validation Loss: 0.1754573365052541, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 1511, Training Loss: 0.174424113285157, Validation Loss: 0.17372786899407705, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1512, Training Loss: 0.1735279699487071, Validation Loss: 0.17503606180349987, Validation Accuracy: 0.4875\n",
      "Epoch 1513, Training Loss: 0.17436304448112364, Validation Loss: 0.1727397084236145, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 1514, Training Loss: 0.17356939133136504, Validation Loss: 0.17460905909538268, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 1515, Training Loss: 0.1743928857388035, Validation Loss: 0.17396750450134277, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1516, Training Loss: 0.1735875601730039, Validation Loss: 0.17471903264522554, Validation Accuracy: 0.49375\n",
      "Epoch 1517, Training Loss: 0.17442424931833822, Validation Loss: 0.17370479106903075, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 1518, Training Loss: 0.1735623219320851, Validation Loss: 0.17397054533163706, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 1519, Training Loss: 0.17429119540799048, Validation Loss: 0.17446470856666565, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 1520, Training Loss: 0.17358315087133838, Validation Loss: 0.1738572726647059, Validation Accuracy: 0.5125\n",
      "Epoch 1521, Training Loss: 0.17435709747575945, Validation Loss: 0.17479955554008483, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 1522, Training Loss: 0.17375909368838033, Validation Loss: 0.17300969858964285, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 1523, Training Loss: 0.17432080930279148, Validation Loss: 0.17491797010103863, Validation Accuracy: 0.48125\n",
      "Epoch 1524, Training Loss: 0.1735784791169628, Validation Loss: 0.17387085060278576, Validation Accuracy: 0.50625\n",
      "Epoch 1525, Training Loss: 0.1744834098123735, Validation Loss: 0.17561210691928864, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 1526, Training Loss: 0.17374656517659465, Validation Loss: 0.17213556269804636, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 1527, Training Loss: 0.1742434496841123, Validation Loss: 0.17576340635617574, Validation Accuracy: 0.475\n",
      "Epoch 1528, Training Loss: 0.17381925544431132, Validation Loss: 0.17348493734995524, Validation Accuracy: 0.5125\n",
      "Epoch 1529, Training Loss: 0.17397144292631456, Validation Loss: 0.17535732487837474, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 1530, Training Loss: 0.17398258082328305, Validation Loss: 0.17266866167386372, Validation Accuracy: 0.5375\n",
      "Epoch 1531, Training Loss: 0.17383267658372079, Validation Loss: 0.17546480298042297, Validation Accuracy: 0.4875\n",
      "Epoch 1532, Training Loss: 0.17396143751759682, Validation Loss: 0.17426155805587767, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 1533, Training Loss: 0.17397457793835672, Validation Loss: 0.17623904943466187, Validation Accuracy: 0.475\n",
      "Epoch 1534, Training Loss: 0.17405090889623087, Validation Loss: 0.17198898593584697, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 1535, Training Loss: 0.17381894396197412, Validation Loss: 0.17705424924691518, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 1536, Training Loss: 0.17417947755705926, Validation Loss: 0.1739030063152313, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1537, Training Loss: 0.17364111398496934, Validation Loss: 0.17622974912325542, Validation Accuracy: 0.4875\n",
      "Epoch 1538, Training Loss: 0.17436370541972498, Validation Loss: 0.1727625439564387, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 1539, Training Loss: 0.17337860984186973, Validation Loss: 0.1762036015590032, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 1540, Training Loss: 0.17454863267560158, Validation Loss: 0.17349894146124523, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1541, Training Loss: 0.173680083405587, Validation Loss: 0.1751236766576767, Validation Accuracy: 0.49375\n",
      "Epoch 1542, Training Loss: 0.174285281569727, Validation Loss: 0.17356965641180674, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 1543, Training Loss: 0.17367240834620692, Validation Loss: 0.17489996949831646, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 1544, Training Loss: 0.17429539801612978, Validation Loss: 0.17418989837169646, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 1545, Training Loss: 0.173749735278468, Validation Loss: 0.17432080705960593, Validation Accuracy: 0.5125\n",
      "Epoch 1546, Training Loss: 0.17427964700806525, Validation Loss: 0.1741072138150533, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 1547, Training Loss: 0.1735986860529069, Validation Loss: 0.1734066476424535, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 1548, Training Loss: 0.17429764568805695, Validation Loss: 0.17409269014994302, Validation Accuracy: 0.48125\n",
      "Epoch 1549, Training Loss: 0.1737213432788849, Validation Loss: 0.1743847241004308, Validation Accuracy: 0.50625\n",
      "Epoch 1550, Training Loss: 0.17436073624318646, Validation Loss: 0.1743295172850291, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 1551, Training Loss: 0.17361463606357574, Validation Loss: 0.17210299372673035, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 1552, Training Loss: 0.17442103595502914, Validation Loss: 0.17388813495635985, Validation Accuracy: 0.475\n",
      "Epoch 1553, Training Loss: 0.17370608064436144, Validation Loss: 0.17385429441928862, Validation Accuracy: 0.5125\n",
      "Epoch 1554, Training Loss: 0.17436751771357753, Validation Loss: 0.174101784825325, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 1555, Training Loss: 0.17360360103268777, Validation Loss: 0.17271527647972107, Validation Accuracy: 0.5375\n",
      "Epoch 1556, Training Loss: 0.17439835494564426, Validation Loss: 0.17363500694433848, Validation Accuracy: 0.4875\n",
      "Epoch 1557, Training Loss: 0.1737135470874848, Validation Loss: 0.17464161316553753, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 1558, Training Loss: 0.17413032295242434, Validation Loss: 0.1748820682366689, Validation Accuracy: 0.475\n",
      "Epoch 1559, Training Loss: 0.17375607115607108, Validation Loss: 0.17178334097067516, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 1560, Training Loss: 0.17417636802119593, Validation Loss: 0.17415331999460856, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 1561, Training Loss: 0.17375783718401386, Validation Loss: 0.1739408294359843, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1562, Training Loss: 0.1742784736617919, Validation Loss: 0.17359800537427267, Validation Accuracy: 0.4875\n",
      "Epoch 1563, Training Loss: 0.1738005535256478, Validation Loss: 0.17278676132361095, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 1564, Training Loss: 0.17425988374217863, Validation Loss: 0.17343198557694753, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 1565, Training Loss: 0.17385458705886717, Validation Loss: 0.17350973188877106, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1566, Training Loss: 0.1741668548314802, Validation Loss: 0.17353386183579764, Validation Accuracy: 0.49375\n",
      "Epoch 1567, Training Loss: 0.1738500609513252, Validation Loss: 0.17330250839392344, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 1568, Training Loss: 0.17414509769408934, Validation Loss: 0.17327982385953267, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 1569, Training Loss: 0.174002397925623, Validation Loss: 0.1734738330046336, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 1570, Training Loss: 0.17390333548668893, Validation Loss: 0.17326044340928395, Validation Accuracy: 0.5125\n",
      "Epoch 1571, Training Loss: 0.1739646508809059, Validation Loss: 0.1734952578941981, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 1572, Training Loss: 0.17413097860351687, Validation Loss: 0.17304520606994628, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 1573, Training Loss: 0.17395431091708521, Validation Loss: 0.1735064407189687, Validation Accuracy: 0.48125\n",
      "Epoch 1574, Training Loss: 0.17404928755375645, Validation Loss: 0.17331307530403137, Validation Accuracy: 0.50625\n",
      "Epoch 1575, Training Loss: 0.1739302489065355, Validation Loss: 0.1735331455866496, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 1576, Training Loss: 0.17393966740177524, Validation Loss: 0.17244352598985035, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 1577, Training Loss: 0.17402779286907566, Validation Loss: 0.17370527982711792, Validation Accuracy: 0.475\n",
      "Epoch 1578, Training Loss: 0.1740815822155245, Validation Loss: 0.173217111825943, Validation Accuracy: 0.5125\n",
      "Epoch 1579, Training Loss: 0.17383612163605228, Validation Loss: 0.17367753287156423, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 1580, Training Loss: 0.17414624556418387, Validation Loss: 0.17298507789770762, Validation Accuracy: 0.5375\n",
      "Epoch 1581, Training Loss: 0.17398436031033915, Validation Loss: 0.1736820658047994, Validation Accuracy: 0.4875\n",
      "Epoch 1582, Training Loss: 0.1740217396328526, Validation Loss: 0.17351937393347422, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 1583, Training Loss: 0.17385103865977256, Validation Loss: 0.17386428713798524, Validation Accuracy: 0.475\n",
      "Epoch 1584, Training Loss: 0.17418283752856717, Validation Loss: 0.1727342297633489, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 1585, Training Loss: 0.17384193981847457, Validation Loss: 0.17402034103870392, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 1586, Training Loss: 0.17416434951366916, Validation Loss: 0.17340391675631206, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1587, Training Loss: 0.1737831143602248, Validation Loss: 0.17366129060586294, Validation Accuracy: 0.4875\n",
      "Epoch 1588, Training Loss: 0.1742542318759426, Validation Loss: 0.17306326528390248, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 1589, Training Loss: 0.17374727466414053, Validation Loss: 0.17363461554050447, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 1590, Training Loss: 0.17411462049330434, Validation Loss: 0.17362042665481567, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1591, Training Loss: 0.17371261937002982, Validation Loss: 0.1738096594810486, Validation Accuracy: 0.49375\n",
      "Epoch 1592, Training Loss: 0.17434509771485482, Validation Loss: 0.17328251898288727, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 1593, Training Loss: 0.17384371930553066, Validation Loss: 0.17335671583811443, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 1594, Training Loss: 0.17415748632723285, Validation Loss: 0.17348562280337015, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 1595, Training Loss: 0.17375975510766428, Validation Loss: 0.1732586443424225, Validation Accuracy: 0.5125\n",
      "Epoch 1596, Training Loss: 0.17426104651343438, Validation Loss: 0.17343620657920839, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 1597, Training Loss: 0.17379459209980502, Validation Loss: 0.17292050818602245, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 1598, Training Loss: 0.17425300325116805, Validation Loss: 0.17343401511510212, Validation Accuracy: 0.48125\n",
      "Epoch 1599, Training Loss: 0.17362697903187044, Validation Loss: 0.17346052527427674, Validation Accuracy: 0.50625\n",
      "Epoch 1600, Training Loss: 0.17438816735821386, Validation Loss: 0.17345785399278005, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 1601, Training Loss: 0.1736494658454772, Validation Loss: 0.1723673572142919, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 1602, Training Loss: 0.17438544429117633, Validation Loss: 0.17344874143600464, Validation Accuracy: 0.475\n",
      "Epoch 1603, Training Loss: 0.1736647275186354, Validation Loss: 0.17336748838424682, Validation Accuracy: 0.5125\n",
      "Epoch 1604, Training Loss: 0.1743340766237628, Validation Loss: 0.17346614599227905, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 1605, Training Loss: 0.17369084108260371, Validation Loss: 0.17269292175769807, Validation Accuracy: 0.5375\n",
      "Epoch 1606, Training Loss: 0.17435076880839565, Validation Loss: 0.17341858446598052, Validation Accuracy: 0.4875\n",
      "Epoch 1607, Training Loss: 0.17363249246151216, Validation Loss: 0.17380673388640086, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 1608, Training Loss: 0.17438836299603985, Validation Loss: 0.1734261800845464, Validation Accuracy: 0.475\n",
      "Epoch 1609, Training Loss: 0.17363790110234292, Validation Loss: 0.1721454362074534, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 1610, Training Loss: 0.1743388541283146, Validation Loss: 0.17350891828536988, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 1611, Training Loss: 0.17365458799946693, Validation Loss: 0.17380840182304383, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1612, Training Loss: 0.17441756879129716, Validation Loss: 0.17336455980936685, Validation Accuracy: 0.4875\n",
      "Epoch 1613, Training Loss: 0.1736661474550924, Validation Loss: 0.1727364460627238, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 1614, Training Loss: 0.17422705792611645, Validation Loss: 0.17332201699415842, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 1615, Training Loss: 0.1736636680941428, Validation Loss: 0.1738064706325531, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1616, Training Loss: 0.17439156338091819, Validation Loss: 0.17330667674541472, Validation Accuracy: 0.49375\n",
      "Epoch 1617, Training Loss: 0.17374761883289583, Validation Loss: 0.17338122030099232, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 1618, Training Loss: 0.17374093878653743, Validation Loss: 0.1732635686794917, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 1619, Training Loss: 0.17382969250602107, Validation Loss: 0.17343002458413442, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 1620, Training Loss: 0.18196653598739254, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.4875\n",
      "Epoch 1621, Training Loss: 0.17334628970392288, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5208333333333334\n",
      "Epoch 1622, Training Loss: 0.17376001035013505, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 1623, Training Loss: 0.17406599127477215, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.51875\n",
      "Epoch 1624, Training Loss: 0.1732868105173111, Validation Loss: 0.17328432500362395, Validation Accuracy: 0.50625\n",
      "Epoch 1625, Training Loss: 0.1735736583509753, Validation Loss: 0.17402669191360473, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 1626, Training Loss: 0.1735722686975233, Validation Loss: 0.17320603827635447, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 1627, Training Loss: 0.17352246661340037, Validation Loss: 0.17350627581278483, Validation Accuracy: 0.475\n",
      "Epoch 1628, Training Loss: 0.17372796612401162, Validation Loss: 0.17328670819600422, Validation Accuracy: 0.5125\n",
      "Epoch 1629, Training Loss: 0.17350607629745238, Validation Loss: 0.173704265554746, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 1630, Training Loss: 0.17366125843217295, Validation Loss: 0.1732282171646754, Validation Accuracy: 0.5375\n",
      "Epoch 1631, Training Loss: 0.17339697384065197, Validation Loss: 0.17363557517528533, Validation Accuracy: 0.4875\n",
      "Epoch 1632, Training Loss: 0.17376779308242182, Validation Loss: 0.17329841752847036, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 1633, Training Loss: 0.17356570065021515, Validation Loss: 0.17395893931388856, Validation Accuracy: 0.475\n",
      "Epoch 1634, Training Loss: 0.1737672056882612, Validation Loss: 0.17322332163651785, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 1635, Training Loss: 0.17350092674455336, Validation Loss: 0.17426171799500784, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 1636, Training Loss: 0.1738617319253183, Validation Loss: 0.17329060832659404, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1637, Training Loss: 0.17352215320833267, Validation Loss: 0.17428483466307323, Validation Accuracy: 0.4875\n",
      "Epoch 1638, Training Loss: 0.1737408181352, Validation Loss: 0.17327843308448793, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 1639, Training Loss: 0.17343363646538026, Validation Loss: 0.17358891665935516, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 1640, Training Loss: 0.17384672164916992, Validation Loss: 0.17328944603602092, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1641, Training Loss: 0.17352512767238001, Validation Loss: 0.17356566886107128, Validation Accuracy: 0.49375\n",
      "Epoch 1642, Training Loss: 0.17375354420754216, Validation Loss: 0.17328472236792247, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 1643, Training Loss: 0.17342357625884394, Validation Loss: 0.1734116663535436, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 1644, Training Loss: 0.17387230165543094, Validation Loss: 0.17332013845443725, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 1645, Training Loss: 0.17343846348024183, Validation Loss: 0.17323593596617382, Validation Accuracy: 0.5125\n",
      "Epoch 1646, Training Loss: 0.1737590302382746, Validation Loss: 0.1733517388502757, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 1647, Training Loss: 0.1734696174821546, Validation Loss: 0.1729208638270696, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 1648, Training Loss: 0.17381452120119525, Validation Loss: 0.17333797017733257, Validation Accuracy: 0.48125\n",
      "Epoch 1649, Training Loss: 0.17353194134850655, Validation Loss: 0.17330137491226197, Validation Accuracy: 0.50625\n",
      "Epoch 1650, Training Loss: 0.173731533750411, Validation Loss: 0.1733326643705368, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 1651, Training Loss: 0.17349063388762936, Validation Loss: 0.17262847522894542, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 1652, Training Loss: 0.17394607586245384, Validation Loss: 0.1736082504192988, Validation Accuracy: 0.475\n",
      "Epoch 1653, Training Loss: 0.17360542858800582, Validation Loss: 0.17323710123697916, Validation Accuracy: 0.5125\n",
      "Epoch 1654, Training Loss: 0.1736557536548184, Validation Loss: 0.17377995749314626, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 1655, Training Loss: 0.17356848620599316, Validation Loss: 0.1728882263104121, Validation Accuracy: 0.5375\n",
      "Epoch 1656, Training Loss: 0.1736747598455798, Validation Loss: 0.1743399033943812, Validation Accuracy: 0.4875\n",
      "Epoch 1657, Training Loss: 0.17369033588517097, Validation Loss: 0.17376583615938823, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 1658, Training Loss: 0.1736507656112794, Validation Loss: 0.17486125826835633, Validation Accuracy: 0.475\n",
      "Epoch 1659, Training Loss: 0.17362813122810855, Validation Loss: 0.172453240553538, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 1660, Training Loss: 0.17359229537748522, Validation Loss: 0.17601730028788248, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 1661, Training Loss: 0.1738969520215065, Validation Loss: 0.17366565863291422, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1662, Training Loss: 0.17341973896949522, Validation Loss: 0.17572872042655946, Validation Accuracy: 0.4875\n",
      "Epoch 1663, Training Loss: 0.17396989080213732, Validation Loss: 0.1729806751012802, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 1664, Training Loss: 0.17330143576668156, Validation Loss: 0.1750255803267161, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 1665, Training Loss: 0.1742996371561481, Validation Loss: 0.17354847192764283, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1666, Training Loss: 0.17342529566057266, Validation Loss: 0.17515024443467458, Validation Accuracy: 0.49375\n",
      "Epoch 1667, Training Loss: 0.1740164920206993, Validation Loss: 0.17352247337500254, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 1668, Training Loss: 0.1735094473246605, Validation Loss: 0.17416254083315533, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 1669, Training Loss: 0.1741147276855284, Validation Loss: 0.17438068389892578, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 1670, Training Loss: 0.17360912167256878, Validation Loss: 0.1736468623081843, Validation Accuracy: 0.5125\n",
      "Epoch 1671, Training Loss: 0.17387142585169885, Validation Loss: 0.174092502395312, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 1672, Training Loss: 0.17349390060670913, Validation Loss: 0.1730139414469401, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 1673, Training Loss: 0.17391188683048373, Validation Loss: 0.17485291659832, Validation Accuracy: 0.48125\n",
      "Epoch 1674, Training Loss: 0.17362323835972818, Validation Loss: 0.17395848135153452, Validation Accuracy: 0.50625\n",
      "Epoch 1675, Training Loss: 0.1739377619758729, Validation Loss: 0.17488184968630474, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 1676, Training Loss: 0.17361819696041844, Validation Loss: 0.17212160329023998, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 1677, Training Loss: 0.17401935352433112, Validation Loss: 0.1745140592257182, Validation Accuracy: 0.475\n",
      "Epoch 1678, Training Loss: 0.1736809318104098, Validation Loss: 0.17347187797228494, Validation Accuracy: 0.5125\n",
      "Epoch 1679, Training Loss: 0.17397796627013914, Validation Loss: 0.17504572570323945, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 1680, Training Loss: 0.17353804697913508, Validation Loss: 0.17266608277956644, Validation Accuracy: 0.5375\n",
      "Epoch 1681, Training Loss: 0.1740485386502358, Validation Loss: 0.17388683557510376, Validation Accuracy: 0.4875\n",
      "Epoch 1682, Training Loss: 0.17369820946647274, Validation Loss: 0.17390645146369935, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 1683, Training Loss: 0.17394473139316804, Validation Loss: 0.17495448291301727, Validation Accuracy: 0.475\n",
      "Epoch 1684, Training Loss: 0.17367601827267679, Validation Loss: 0.17214037676652272, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 1685, Training Loss: 0.17403232955163525, Validation Loss: 0.17390175660451254, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 1686, Training Loss: 0.17376931924973765, Validation Loss: 0.17361119985580445, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1687, Training Loss: 0.17387312698748805, Validation Loss: 0.17439902524153392, Validation Accuracy: 0.4875\n",
      "Epoch 1688, Training Loss: 0.1738197688133486, Validation Loss: 0.1728409230709076, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 1689, Training Loss: 0.17393413282209827, Validation Loss: 0.17350538969039916, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 1690, Training Loss: 0.17380107650833745, Validation Loss: 0.1735433618227641, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1691, Training Loss: 0.173834532979996, Validation Loss: 0.1740498592456182, Validation Accuracy: 0.49375\n",
      "Epoch 1692, Training Loss: 0.17381245090115455, Validation Loss: 0.1733340620994568, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 1693, Training Loss: 0.17392891068612376, Validation Loss: 0.17326413492361706, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 1694, Training Loss: 0.17390402286283432, Validation Loss: 0.17362292607625326, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 1695, Training Loss: 0.17369823974947776, Validation Loss: 0.17328886886437733, Validation Accuracy: 0.5125\n",
      "Epoch 1696, Training Loss: 0.17394938440092148, Validation Loss: 0.17369165420532226, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 1697, Training Loss: 0.17381767495985953, Validation Loss: 0.17301409045855204, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 1698, Training Loss: 0.17394746215112747, Validation Loss: 0.17361597617467245, Validation Accuracy: 0.48125\n",
      "Epoch 1699, Training Loss: 0.17364673652956564, Validation Loss: 0.17362134953339894, Validation Accuracy: 0.50625\n",
      "Epoch 1700, Training Loss: 0.1739797015343943, Validation Loss: 0.17368030846118926, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 1701, Training Loss: 0.17387206804367802, Validation Loss: 0.17283327877521515, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 1702, Training Loss: 0.17389780571383814, Validation Loss: 0.17372254927953085, Validation Accuracy: 0.475\n",
      "Epoch 1703, Training Loss: 0.17378696510868688, Validation Loss: 0.1732264329989751, Validation Accuracy: 0.5125\n",
      "Epoch 1704, Training Loss: 0.17388016370034987, Validation Loss: 0.17398647864659628, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 1705, Training Loss: 0.1738851954860072, Validation Loss: 0.1730231742064158, Validation Accuracy: 0.5375\n",
      "Epoch 1706, Training Loss: 0.17387671095709648, Validation Loss: 0.1735796203215917, Validation Accuracy: 0.4875\n",
      "Epoch 1707, Training Loss: 0.1738509742483016, Validation Loss: 0.17350357671578726, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 1708, Training Loss: 0.1737957385278517, Validation Loss: 0.17393534084161122, Validation Accuracy: 0.475\n",
      "Epoch 1709, Training Loss: 0.1739532567801014, Validation Loss: 0.1729368249575297, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 1710, Training Loss: 0.17383416141233138, Validation Loss: 0.1738431433836619, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 1711, Training Loss: 0.17387958543915902, Validation Loss: 0.17344384789466857, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1712, Training Loss: 0.17378975931675203, Validation Loss: 0.17373961210250854, Validation Accuracy: 0.4875\n",
      "Epoch 1713, Training Loss: 0.17395120090053928, Validation Loss: 0.1730266084273656, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 1714, Training Loss: 0.17375147198477098, Validation Loss: 0.17353151539961498, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 1715, Training Loss: 0.173931943312768, Validation Loss: 0.1735589881738027, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1716, Training Loss: 0.17370754432293675, Validation Loss: 0.17367072105407716, Validation Accuracy: 0.49375\n",
      "Epoch 1717, Training Loss: 0.17395781172860053, Validation Loss: 0.1733183075984319, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 1718, Training Loss: 0.1737983298878516, Validation Loss: 0.1733095169067383, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 1719, Training Loss: 0.17398714442406932, Validation Loss: 0.17341057856877645, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 1720, Training Loss: 0.1737398495597224, Validation Loss: 0.17325916190942128, Validation Accuracy: 0.5125\n",
      "Epoch 1721, Training Loss: 0.17397700971172703, Validation Loss: 0.17342961033185322, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 1722, Training Loss: 0.17381340169137524, Validation Loss: 0.17294644117355346, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 1723, Training Loss: 0.17398182519020572, Validation Loss: 0.17342773179213206, Validation Accuracy: 0.48125\n",
      "Epoch 1724, Training Loss: 0.17362873352343036, Validation Loss: 0.17343569695949554, Validation Accuracy: 0.50625\n",
      "Epoch 1725, Training Loss: 0.17406719778814622, Validation Loss: 0.173505899310112, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 1726, Training Loss: 0.1737461349656505, Validation Loss: 0.17245552241802214, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 1727, Training Loss: 0.1739925915195096, Validation Loss: 0.1735367089509964, Validation Accuracy: 0.475\n",
      "Epoch 1728, Training Loss: 0.17367675035230576, Validation Loss: 0.17327160239219666, Validation Accuracy: 0.5125\n",
      "Epoch 1729, Training Loss: 0.1741088455723178, Validation Loss: 0.1734263390302658, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 1730, Training Loss: 0.1736849296477533, Validation Loss: 0.17275183101495106, Validation Accuracy: 0.5375\n",
      "Epoch 1731, Training Loss: 0.17386977182280633, Validation Loss: 0.17365195055802662, Validation Accuracy: 0.4875\n",
      "Epoch 1732, Training Loss: 0.17365899009089317, Validation Loss: 0.17398359378178915, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 1733, Training Loss: 0.17411285927218775, Validation Loss: 0.17342839737733204, Validation Accuracy: 0.475\n",
      "Epoch 1734, Training Loss: 0.1737042578958696, Validation Loss: 0.17234636048475901, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 1735, Training Loss: 0.17388488640708308, Validation Loss: 0.17390795151392618, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 1736, Training Loss: 0.17369044596149075, Validation Loss: 0.17381670872370403, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1737, Training Loss: 0.17400670724530373, Validation Loss: 0.17339193522930146, Validation Accuracy: 0.4875\n",
      "Epoch 1738, Training Loss: 0.17380735518470888, Validation Loss: 0.1727863808472951, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 1739, Training Loss: 0.17386005914980365, Validation Loss: 0.17337235112984975, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 1740, Training Loss: 0.17370048982481803, Validation Loss: 0.17361966768900552, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1741, Training Loss: 0.17404277238153643, Validation Loss: 0.1733231633901596, Validation Accuracy: 0.49375\n",
      "Epoch 1742, Training Loss: 0.17380652360377774, Validation Loss: 0.17340036034584044, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 1743, Training Loss: 0.1738470518781293, Validation Loss: 0.17326341768105824, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 1744, Training Loss: 0.17362391468017332, Validation Loss: 0.17429924209912617, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 1745, Training Loss: 0.17408184562959977, Validation Loss: 0.17326648831367492, Validation Accuracy: 0.5125\n",
      "Epoch 1746, Training Loss: 0.17374653200949391, Validation Loss: 0.17427000204722087, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 1747, Training Loss: 0.17391551598425833, Validation Loss: 0.17319395740826923, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 1748, Training Loss: 0.17366614553236193, Validation Loss: 0.17434698939323426, Validation Accuracy: 0.48125\n",
      "Epoch 1749, Training Loss: 0.17406762271158158, Validation Loss: 0.17327874402205148, Validation Accuracy: 0.50625\n",
      "Epoch 1750, Training Loss: 0.17362177564251807, Validation Loss: 0.17504197160402934, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 1751, Training Loss: 0.17403793527233985, Validation Loss: 0.17322418789068858, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 1752, Training Loss: 0.1735601867398908, Validation Loss: 0.17498855888843537, Validation Accuracy: 0.475\n",
      "Epoch 1753, Training Loss: 0.1742065962283842, Validation Loss: 0.17324776450792947, Validation Accuracy: 0.5125\n",
      "Epoch 1754, Training Loss: 0.17353193365758465, Validation Loss: 0.17525037129720053, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 1755, Training Loss: 0.17411583758169605, Validation Loss: 0.17322419583797455, Validation Accuracy: 0.5375\n",
      "Epoch 1756, Training Loss: 0.1734997913722069, Validation Loss: 0.17484604716300964, Validation Accuracy: 0.4875\n",
      "Epoch 1757, Training Loss: 0.17423903942108154, Validation Loss: 0.17343717614809673, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 1758, Training Loss: 0.1736534579146293, Validation Loss: 0.17517227530479432, Validation Accuracy: 0.475\n",
      "Epoch 1759, Training Loss: 0.17405997697384126, Validation Loss: 0.1731145352125168, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 1760, Training Loss: 0.17362101664466242, Validation Loss: 0.1752210944890976, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 1761, Training Loss: 0.174096375223129, Validation Loss: 0.17347607811292012, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1762, Training Loss: 0.1735526717478229, Validation Loss: 0.17453972299893697, Validation Accuracy: 0.4875\n",
      "Epoch 1763, Training Loss: 0.17406396663958026, Validation Loss: 0.17292494277159373, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 1764, Training Loss: 0.17351003568018636, Validation Loss: 0.17452267209688824, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 1765, Training Loss: 0.1741357748546908, Validation Loss: 0.17375919421513875, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1766, Training Loss: 0.17356177635731235, Validation Loss: 0.17485288679599761, Validation Accuracy: 0.49375\n",
      "Epoch 1767, Training Loss: 0.17417722459762328, Validation Loss: 0.17328529755274455, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 1768, Training Loss: 0.1734141255578687, Validation Loss: 0.17383656203746795, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 1769, Training Loss: 0.17409283787973465, Validation Loss: 0.1740767906109492, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 1770, Training Loss: 0.1734812456753946, Validation Loss: 0.1739849398533503, Validation Accuracy: 0.5125\n",
      "Epoch 1771, Training Loss: 0.17422252893447876, Validation Loss: 0.173944757382075, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 1772, Training Loss: 0.1735755604120993, Validation Loss: 0.17291127542654675, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 1773, Training Loss: 0.17400578241194448, Validation Loss: 0.1744506706794103, Validation Accuracy: 0.48125\n",
      "Epoch 1774, Training Loss: 0.17353685007941339, Validation Loss: 0.17404493888219197, Validation Accuracy: 0.50625\n",
      "Epoch 1775, Training Loss: 0.17429822827539138, Validation Loss: 0.17503429253896077, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 1776, Training Loss: 0.17358412906046836, Validation Loss: 0.17213022212187448, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 1777, Training Loss: 0.17404323672094651, Validation Loss: 0.17515732645988463, Validation Accuracy: 0.475\n",
      "Epoch 1778, Training Loss: 0.1737546262241179, Validation Loss: 0.17354823847611744, Validation Accuracy: 0.5125\n",
      "Epoch 1779, Training Loss: 0.1738297535527137, Validation Loss: 0.17553995052973428, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 1780, Training Loss: 0.1738617718219757, Validation Loss: 0.1726599872112274, Validation Accuracy: 0.5375\n",
      "Epoch 1781, Training Loss: 0.1737550482634575, Validation Loss: 0.17516445219516755, Validation Accuracy: 0.4875\n",
      "Epoch 1782, Training Loss: 0.1738304058390279, Validation Loss: 0.17433194021383921, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 1783, Training Loss: 0.17386619698616765, Validation Loss: 0.17582706809043885, Validation Accuracy: 0.475\n",
      "Epoch 1784, Training Loss: 0.1738809698051022, Validation Loss: 0.1719687243302663, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 1785, Training Loss: 0.1737012550715477, Validation Loss: 0.1759924829006195, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 1786, Training Loss: 0.17403461615885457, Validation Loss: 0.17397361795107524, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1787, Training Loss: 0.17361039403946169, Validation Loss: 0.17506138881047567, Validation Accuracy: 0.4875\n",
      "Epoch 1788, Training Loss: 0.17421420014673664, Validation Loss: 0.17273131708304088, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 1789, Training Loss: 0.17335739683720372, Validation Loss: 0.17482175529003144, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 1790, Training Loss: 0.17441910889840895, Validation Loss: 0.17375586330890655, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1791, Training Loss: 0.17356067895889282, Validation Loss: 0.17435132066408793, Validation Accuracy: 0.49375\n",
      "Epoch 1792, Training Loss: 0.17407194356764516, Validation Loss: 0.17367064952850342, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 1793, Training Loss: 0.1735452591411529, Validation Loss: 0.17381693522135416, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 1794, Training Loss: 0.17413969962827622, Validation Loss: 0.1741394579410553, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 1795, Training Loss: 0.17366319606381078, Validation Loss: 0.17354126075903575, Validation Accuracy: 0.5125\n",
      "Epoch 1796, Training Loss: 0.1740520264833204, Validation Loss: 0.1743543565273285, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 1797, Training Loss: 0.17354608158911428, Validation Loss: 0.17297868728637694, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 1798, Training Loss: 0.17405982892359456, Validation Loss: 0.17406728367010751, Validation Accuracy: 0.48125\n",
      "Epoch 1799, Training Loss: 0.17366629838943481, Validation Loss: 0.17382361193497975, Validation Accuracy: 0.50625\n",
      "Epoch 1800, Training Loss: 0.1739286482334137, Validation Loss: 0.174726336201032, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 1801, Training Loss: 0.17372175426252426, Validation Loss: 0.17227735022703808, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 1802, Training Loss: 0.17391189836686657, Validation Loss: 0.17484751343727112, Validation Accuracy: 0.475\n",
      "Epoch 1803, Training Loss: 0.17364044439408086, Validation Loss: 0.17367759545644124, Validation Accuracy: 0.5125\n",
      "Epoch 1804, Training Loss: 0.17399436860315262, Validation Loss: 0.17450866401195525, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 1805, Training Loss: 0.17360528630595054, Validation Loss: 0.1727112183968226, Validation Accuracy: 0.5375\n",
      "Epoch 1806, Training Loss: 0.1740526407957077, Validation Loss: 0.17371022701263428, Validation Accuracy: 0.4875\n",
      "Epoch 1807, Training Loss: 0.17373776531988575, Validation Loss: 0.1738619307676951, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 1808, Training Loss: 0.17400922217676718, Validation Loss: 0.17416047652562458, Validation Accuracy: 0.475\n",
      "Epoch 1809, Training Loss: 0.17369638864071138, Validation Loss: 0.17229356070359547, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 1810, Training Loss: 0.17400909383450786, Validation Loss: 0.17388344605763753, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 1811, Training Loss: 0.17368183981987736, Validation Loss: 0.1738788346449534, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1812, Training Loss: 0.17397463225549267, Validation Loss: 0.17365687092145285, Validation Accuracy: 0.4875\n",
      "Epoch 1813, Training Loss: 0.1738374713928469, Validation Loss: 0.17284477452437083, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 1814, Training Loss: 0.1738621986681415, Validation Loss: 0.17386749188105266, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 1815, Training Loss: 0.17382400891473215, Validation Loss: 0.17362696131070454, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1816, Training Loss: 0.1737995272682559, Validation Loss: 0.1740486999352773, Validation Accuracy: 0.49375\n",
      "Epoch 1817, Training Loss: 0.17381122371842783, Validation Loss: 0.17334080239137015, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 1818, Training Loss: 0.17395108265261497, Validation Loss: 0.17326067090034486, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 1819, Training Loss: 0.1739376615132055, Validation Loss: 0.17351622978846232, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 1820, Training Loss: 0.17361183849073225, Validation Loss: 0.17341872056325278, Validation Accuracy: 0.5125\n",
      "Epoch 1821, Training Loss: 0.17399996471020482, Validation Loss: 0.17359355390071868, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 1822, Training Loss: 0.17378334316515154, Validation Loss: 0.17297932902971905, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 1823, Training Loss: 0.1739723144039031, Validation Loss: 0.1735834449529648, Validation Accuracy: 0.48125\n",
      "Epoch 1824, Training Loss: 0.1737078485950347, Validation Loss: 0.17343202233314514, Validation Accuracy: 0.50625\n",
      "Epoch 1825, Training Loss: 0.17396342802432277, Validation Loss: 0.17375190754731495, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 1826, Training Loss: 0.17387171137717464, Validation Loss: 0.1728498379389445, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 1827, Training Loss: 0.17390992901017588, Validation Loss: 0.17362211942672728, Validation Accuracy: 0.475\n",
      "Epoch 1828, Training Loss: 0.1738000041054141, Validation Loss: 0.17322699626286825, Validation Accuracy: 0.5125\n",
      "Epoch 1829, Training Loss: 0.1738893106099098, Validation Loss: 0.17388190527757008, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 1830, Training Loss: 0.17379947775794613, Validation Loss: 0.17285339931646984, Validation Accuracy: 0.5375\n",
      "Epoch 1831, Training Loss: 0.17393889302207577, Validation Loss: 0.1735918511946996, Validation Accuracy: 0.4875\n",
      "Epoch 1832, Training Loss: 0.17378822113237075, Validation Loss: 0.17361011604468027, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 1833, Training Loss: 0.17382884842734184, Validation Loss: 0.17393837769826254, Validation Accuracy: 0.475\n",
      "Epoch 1834, Training Loss: 0.17397997648485244, Validation Loss: 0.17290764649709064, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 1835, Training Loss: 0.1738484199008634, Validation Loss: 0.1738467186689377, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 1836, Training Loss: 0.17380843720128458, Validation Loss: 0.17355239689350127, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1837, Training Loss: 0.1737905461941996, Validation Loss: 0.17387239933013915, Validation Accuracy: 0.4875\n",
      "Epoch 1838, Training Loss: 0.1739724696643891, Validation Loss: 0.17306613624095918, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 1839, Training Loss: 0.17377769850915478, Validation Loss: 0.17353107432524364, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 1840, Training Loss: 0.17388702832883404, Validation Loss: 0.17374058961868286, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1841, Training Loss: 0.17367108214286067, Validation Loss: 0.17375541826089222, Validation Accuracy: 0.49375\n",
      "Epoch 1842, Training Loss: 0.17390082968819526, Validation Loss: 0.1733579307794571, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 1843, Training Loss: 0.17387027846228692, Validation Loss: 0.1732866923014323, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 1844, Training Loss: 0.20889501321700313, Validation Loss: 0.3735833744208018, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 1845, Training Loss: 0.23523430333983514, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.4875\n",
      "Epoch 1846, Training Loss: 0.17371578706849006, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5208333333333334\n",
      "Epoch 1847, Training Loss: 0.1732955704773626, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 1848, Training Loss: 0.17331484969585173, Validation Loss: 0.1733195940653483, Validation Accuracy: 0.48125\n",
      "Epoch 1849, Training Loss: 0.17514023713527188, Validation Loss: 0.17358467380205791, Validation Accuracy: 0.50625\n",
      "Epoch 1850, Training Loss: 0.17421865463256836, Validation Loss: 0.1739198019107183, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 1851, Training Loss: 0.17371880287124264, Validation Loss: 0.17236516376336417, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 1852, Training Loss: 0.17382118874980557, Validation Loss: 0.17410673201084137, Validation Accuracy: 0.475\n",
      "Epoch 1853, Training Loss: 0.17376264737498376, Validation Loss: 0.17330762147903442, Validation Accuracy: 0.5125\n",
      "Epoch 1854, Training Loss: 0.1738326496654941, Validation Loss: 0.1740569680929184, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 1855, Training Loss: 0.17378116086606057, Validation Loss: 0.1726988842089971, Validation Accuracy: 0.5375\n",
      "Epoch 1856, Training Loss: 0.1740461039927698, Validation Loss: 0.17344641387462617, Validation Accuracy: 0.4875\n",
      "Epoch 1857, Training Loss: 0.17365066226451628, Validation Loss: 0.17384668191274008, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 1858, Training Loss: 0.17414568220415422, Validation Loss: 0.17344944874445598, Validation Accuracy: 0.475\n",
      "Epoch 1859, Training Loss: 0.17365050700403029, Validation Loss: 0.17222625414530437, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 1860, Training Loss: 0.17385453562582692, Validation Loss: 0.17383899986743928, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 1861, Training Loss: 0.1736601985269977, Validation Loss: 0.17387554049491882, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1862, Training Loss: 0.17414380273511332, Validation Loss: 0.17337416609128317, Validation Accuracy: 0.4875\n",
      "Epoch 1863, Training Loss: 0.17373201154893445, Validation Loss: 0.17275605003039043, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 1864, Training Loss: 0.17403565683672506, Validation Loss: 0.17335324585437775, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 1865, Training Loss: 0.1736450522176681, Validation Loss: 0.17382563551266988, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1866, Training Loss: 0.17387268331743055, Validation Loss: 0.1733151227235794, Validation Accuracy: 0.49375\n",
      "Epoch 1867, Training Loss: 0.17376977878232155, Validation Loss: 0.17335820595423382, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 1868, Training Loss: 0.174045923256105, Validation Loss: 0.173264875014623, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 1869, Training Loss: 0.1736131901702573, Validation Loss: 0.1744653324286143, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 1870, Training Loss: 0.17416769218060277, Validation Loss: 0.17324329415957132, Validation Accuracy: 0.5125\n",
      "Epoch 1871, Training Loss: 0.1736996178665469, Validation Loss: 0.17444167137145997, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 1872, Training Loss: 0.173956889779337, Validation Loss: 0.17322098215421042, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 1873, Training Loss: 0.17361452262247762, Validation Loss: 0.174243567387263, Validation Accuracy: 0.48125\n",
      "Epoch 1874, Training Loss: 0.17418495301277406, Validation Loss: 0.17326990862687427, Validation Accuracy: 0.50625\n",
      "Epoch 1875, Training Loss: 0.17356555500338156, Validation Loss: 0.17544011473655702, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 1876, Training Loss: 0.17400646690399416, Validation Loss: 0.1732095052798589, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 1877, Training Loss: 0.17355331970799354, Validation Loss: 0.1745791991551717, Validation Accuracy: 0.475\n",
      "Epoch 1878, Training Loss: 0.1742520990871614, Validation Loss: 0.17322094440460206, Validation Accuracy: 0.5125\n",
      "Epoch 1879, Training Loss: 0.1735107990041856, Validation Loss: 0.17534925838311513, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 1880, Training Loss: 0.17420693895509165, Validation Loss: 0.17288179695606232, Validation Accuracy: 0.5375\n",
      "Epoch 1881, Training Loss: 0.17346772936082655, Validation Loss: 0.1747335652510325, Validation Accuracy: 0.4875\n",
      "Epoch 1882, Training Loss: 0.17429477841623367, Validation Loss: 0.17352909644444783, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 1883, Training Loss: 0.17362726071188528, Validation Loss: 0.17529481252034504, Validation Accuracy: 0.475\n",
      "Epoch 1884, Training Loss: 0.17415987435848482, Validation Loss: 0.17251685559749602, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 1885, Training Loss: 0.17358574944157754, Validation Loss: 0.1754674901564916, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 1886, Training Loss: 0.1741479221851595, Validation Loss: 0.1736515909433365, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1887, Training Loss: 0.17357329351286735, Validation Loss: 0.17505854964256287, Validation Accuracy: 0.4875\n",
      "Epoch 1888, Training Loss: 0.17414239337367396, Validation Loss: 0.17278026044368744, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 1889, Training Loss: 0.17351339324828116, Validation Loss: 0.17461976408958435, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 1890, Training Loss: 0.17420141783452803, Validation Loss: 0.17380643685658773, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1891, Training Loss: 0.1735558884759103, Validation Loss: 0.1749274253845215, Validation Accuracy: 0.49375\n",
      "Epoch 1892, Training Loss: 0.17422309181382578, Validation Loss: 0.17334893345832825, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 1893, Training Loss: 0.17342657043087867, Validation Loss: 0.17427253623803457, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 1894, Training Loss: 0.174076410551225, Validation Loss: 0.17436049381891885, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 1895, Training Loss: 0.1735800547945884, Validation Loss: 0.17401108741760254, Validation Accuracy: 0.5125\n",
      "Epoch 1896, Training Loss: 0.17424734705878842, Validation Loss: 0.17458663781483968, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 1897, Training Loss: 0.1736409750676924, Validation Loss: 0.1730326940615972, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 1898, Training Loss: 0.17420081553920622, Validation Loss: 0.17457713981469472, Validation Accuracy: 0.48125\n",
      "Epoch 1899, Training Loss: 0.17347194158261822, Validation Loss: 0.17400851746400198, Validation Accuracy: 0.50625\n",
      "Epoch 1900, Training Loss: 0.17440431973626536, Validation Loss: 0.17509634395440418, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 1901, Training Loss: 0.17358220152316556, Validation Loss: 0.17215238908926647, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 1902, Training Loss: 0.17409754472394143, Validation Loss: 0.17532348036766052, Validation Accuracy: 0.475\n",
      "Epoch 1903, Training Loss: 0.1737309665449204, Validation Loss: 0.17352799971898397, Validation Accuracy: 0.5125\n",
      "Epoch 1904, Training Loss: 0.1738688479508123, Validation Loss: 0.1754554659128189, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 1905, Training Loss: 0.17388335447157582, Validation Loss: 0.17267448504765828, Validation Accuracy: 0.5375\n",
      "Epoch 1906, Training Loss: 0.17380175811629142, Validation Loss: 0.17536938488483428, Validation Accuracy: 0.4875\n",
      "Epoch 1907, Training Loss: 0.1737878615817716, Validation Loss: 0.17456800242265066, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 1908, Training Loss: 0.1738458559397728, Validation Loss: 0.17570462822914124, Validation Accuracy: 0.475\n",
      "Epoch 1909, Training Loss: 0.17391492570600203, Validation Loss: 0.17189964552720388, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 1910, Training Loss: 0.17371491174544057, Validation Loss: 0.17573428551356, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 1911, Training Loss: 0.17406594801333644, Validation Loss: 0.17410484353701275, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1912, Training Loss: 0.17362539614400557, Validation Loss: 0.1749258647362391, Validation Accuracy: 0.4875\n",
      "Epoch 1913, Training Loss: 0.17426715887361957, Validation Loss: 0.17272712687651318, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 1914, Training Loss: 0.17329388808819554, Validation Loss: 0.17550712426503498, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 1915, Training Loss: 0.1745057024302021, Validation Loss: 0.17375173767407734, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1916, Training Loss: 0.17357618193472585, Validation Loss: 0.1748177081346512, Validation Accuracy: 0.49375\n",
      "Epoch 1917, Training Loss: 0.1741087431869199, Validation Loss: 0.17369730869928995, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 1918, Training Loss: 0.17357057573333864, Validation Loss: 0.1737521509329478, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 1919, Training Loss: 0.17411830348353233, Validation Loss: 0.17417457401752473, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 1920, Training Loss: 0.17371331299504927, Validation Loss: 0.17353475689888, Validation Accuracy: 0.5125\n",
      "Epoch 1921, Training Loss: 0.17409511150852328, Validation Loss: 0.17439317603905996, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 1922, Training Loss: 0.17356844054114434, Validation Loss: 0.17303438782691954, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 1923, Training Loss: 0.17414082538697026, Validation Loss: 0.17399145464102428, Validation Accuracy: 0.48125\n",
      "Epoch 1924, Training Loss: 0.1737276666587399, Validation Loss: 0.17367027203241983, Validation Accuracy: 0.50625\n",
      "Epoch 1925, Training Loss: 0.17393167172708818, Validation Loss: 0.1752031127611796, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 1926, Training Loss: 0.17361640978244045, Validation Loss: 0.17216860949993135, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 1927, Training Loss: 0.17408399572295527, Validation Loss: 0.17407992482185364, Validation Accuracy: 0.475\n",
      "Epoch 1928, Training Loss: 0.17377175390720367, Validation Loss: 0.17342582146326702, Validation Accuracy: 0.5125\n",
      "Epoch 1929, Training Loss: 0.17405255427283625, Validation Loss: 0.17437818149725595, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 1930, Training Loss: 0.1736693617797667, Validation Loss: 0.17269287606080372, Validation Accuracy: 0.5375\n",
      "Epoch 1931, Training Loss: 0.17408222152340797, Validation Loss: 0.17377061545848846, Validation Accuracy: 0.4875\n",
      "Epoch 1932, Training Loss: 0.1738059453425869, Validation Loss: 0.17387604514757793, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 1933, Training Loss: 0.1740347295999527, Validation Loss: 0.1742335230112076, Validation Accuracy: 0.475\n",
      "Epoch 1934, Training Loss: 0.1736969909360332, Validation Loss: 0.17208407421906788, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 1935, Training Loss: 0.17410048602088804, Validation Loss: 0.17374616662661235, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 1936, Training Loss: 0.17376724991106218, Validation Loss: 0.1737444500128428, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1937, Training Loss: 0.1740526662718865, Validation Loss: 0.17360728085041047, Validation Accuracy: 0.4875\n",
      "Epoch 1938, Training Loss: 0.1738071629116612, Validation Loss: 0.1728308876355489, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 1939, Training Loss: 0.17392124764380917, Validation Loss: 0.17386110226313273, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 1940, Training Loss: 0.17379546838421975, Validation Loss: 0.17364262640476227, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1941, Training Loss: 0.173888151684115, Validation Loss: 0.1740030199289322, Validation Accuracy: 0.49375\n",
      "Epoch 1942, Training Loss: 0.17383296162851394, Validation Loss: 0.17334956626097361, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 1943, Training Loss: 0.17391121099072118, Validation Loss: 0.1732757270336151, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 1944, Training Loss: 0.1739972084760666, Validation Loss: 0.1736016720533371, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 1945, Training Loss: 0.17370105558826077, Validation Loss: 0.17328461805979412, Validation Accuracy: 0.5125\n",
      "Epoch 1946, Training Loss: 0.17396897029492162, Validation Loss: 0.1736705074707667, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 1947, Training Loss: 0.17366554948591417, Validation Loss: 0.1729086806376775, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 1948, Training Loss: 0.17412849587778892, Validation Loss: 0.1736331860224406, Validation Accuracy: 0.48125\n",
      "Epoch 1949, Training Loss: 0.1735852817373891, Validation Loss: 0.17358863254388174, Validation Accuracy: 0.50625\n",
      "Epoch 1950, Training Loss: 0.1739795236818252, Validation Loss: 0.17369492053985597, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 1951, Training Loss: 0.17386494961477095, Validation Loss: 0.1728253811597824, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 1952, Training Loss: 0.1739662342494534, Validation Loss: 0.1737129032611847, Validation Accuracy: 0.475\n",
      "Epoch 1953, Training Loss: 0.1739204833584447, Validation Loss: 0.17322587768236797, Validation Accuracy: 0.5125\n",
      "Epoch 1954, Training Loss: 0.17383422678516758, Validation Loss: 0.17379212578137715, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 1955, Training Loss: 0.17399647447370714, Validation Loss: 0.1731058677037557, Validation Accuracy: 0.5375\n",
      "Epoch 1956, Training Loss: 0.17389600315401632, Validation Loss: 0.1736419806877772, Validation Accuracy: 0.4875\n",
      "Epoch 1957, Training Loss: 0.17387614375160587, Validation Loss: 0.17346031467119852, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 1958, Training Loss: 0.17380777385927015, Validation Loss: 0.17393508156140644, Validation Accuracy: 0.475\n",
      "Epoch 1959, Training Loss: 0.17400723695755005, Validation Loss: 0.17295390764872234, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 1960, Training Loss: 0.17385724090760754, Validation Loss: 0.17396327257156372, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 1961, Training Loss: 0.17375799244449985, Validation Loss: 0.17364152570565541, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1962, Training Loss: 0.17383669941656052, Validation Loss: 0.17374475598335265, Validation Accuracy: 0.4875\n",
      "Epoch 1963, Training Loss: 0.17400212297516485, Validation Loss: 0.17309756179650623, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 1964, Training Loss: 0.17375936575474277, Validation Loss: 0.17353059848149618, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 1965, Training Loss: 0.17400122025320608, Validation Loss: 0.1734371503194173, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1966, Training Loss: 0.1736671131464743, Validation Loss: 0.17373165289560955, Validation Accuracy: 0.49375\n",
      "Epoch 1967, Training Loss: 0.1741296043319087, Validation Loss: 0.17327914734681446, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 1968, Training Loss: 0.17380632315912553, Validation Loss: 0.17335272928078968, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 1969, Training Loss: 0.1737783791557435, Validation Loss: 0.1740693747997284, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 1970, Training Loss: 0.1737977477811998, Validation Loss: 0.173342697819074, Validation Accuracy: 0.5125\n",
      "Epoch 1971, Training Loss: 0.1740772892390528, Validation Loss: 0.17337820132573445, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 1972, Training Loss: 0.17385500140728488, Validation Loss: 0.17293604115645092, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 1973, Training Loss: 0.17400576414600497, Validation Loss: 0.17342251340548198, Validation Accuracy: 0.48125\n",
      "Epoch 1974, Training Loss: 0.1736235733955137, Validation Loss: 0.173469673593839, Validation Accuracy: 0.50625\n",
      "Epoch 1975, Training Loss: 0.17417817202306562, Validation Loss: 0.17341896295547485, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 1976, Training Loss: 0.1737366270634436, Validation Loss: 0.17255874474843344, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 1977, Training Loss: 0.17402378301466664, Validation Loss: 0.17349261442820232, Validation Accuracy: 0.475\n",
      "Epoch 1978, Training Loss: 0.17371584186630865, Validation Loss: 0.1732737511396408, Validation Accuracy: 0.5125\n",
      "Epoch 1979, Training Loss: 0.17412220662639988, Validation Loss: 0.1734189103047053, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 1980, Training Loss: 0.17373430584707567, Validation Loss: 0.17278676033020018, Validation Accuracy: 0.5375\n",
      "Epoch 1981, Training Loss: 0.17388082896509477, Validation Loss: 0.17362196147441863, Validation Accuracy: 0.4875\n",
      "Epoch 1982, Training Loss: 0.17369368528166124, Validation Loss: 0.17393396099408467, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 1983, Training Loss: 0.17414671711383328, Validation Loss: 0.17342667977015178, Validation Accuracy: 0.475\n",
      "Epoch 1984, Training Loss: 0.17375178538983868, Validation Loss: 0.17224282423655193, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 1985, Training Loss: 0.17407144942591268, Validation Loss: 0.17345810532569886, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 1986, Training Loss: 0.17366564321902492, Validation Loss: 0.17353811462720234, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1987, Training Loss: 0.1741628420929755, Validation Loss: 0.17332374453544616, Validation Accuracy: 0.4875\n",
      "Epoch 1988, Training Loss: 0.1737699628837647, Validation Loss: 0.17285270392894744, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 1989, Training Loss: 0.17398130172683346, Validation Loss: 0.1733684500058492, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 1990, Training Loss: 0.17372830837003647, Validation Loss: 0.17378064393997192, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 1991, Training Loss: 0.173991558532561, Validation Loss: 0.17330653766791027, Validation Accuracy: 0.49375\n",
      "Epoch 1992, Training Loss: 0.17386584608785569, Validation Loss: 0.17344611287117004, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 1993, Training Loss: 0.17399249682503362, Validation Loss: 0.17327344516913096, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 1994, Training Loss: 0.17364966580944677, Validation Loss: 0.17411550283432006, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 1995, Training Loss: 0.17408244504082587, Validation Loss: 0.17327369848887125, Validation Accuracy: 0.5125\n",
      "Epoch 1996, Training Loss: 0.1737751749254042, Validation Loss: 0.17434213956197103, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 1997, Training Loss: 0.1740528239357856, Validation Loss: 0.17320301135381064, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 1998, Training Loss: 0.17365854882424878, Validation Loss: 0.17454927464326223, Validation Accuracy: 0.48125\n",
      "Epoch 1999, Training Loss: 0.17413696358280797, Validation Loss: 0.173273961742719, Validation Accuracy: 0.50625\n",
      "Epoch 2000, Training Loss: 0.17363401670609752, Validation Loss: 0.17511670887470246, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 2001, Training Loss: 0.17425924203088206, Validation Loss: 0.1730672687292099, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 2002, Training Loss: 0.17350543843161675, Validation Loss: 0.17511643866697948, Validation Accuracy: 0.475\n",
      "Epoch 2003, Training Loss: 0.17428788013996616, Validation Loss: 0.17325529356797537, Validation Accuracy: 0.5125\n",
      "Epoch 2004, Training Loss: 0.17355364416876146, Validation Loss: 0.17521110375722249, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 2005, Training Loss: 0.1741733661582393, Validation Loss: 0.17322025895118714, Validation Accuracy: 0.5375\n",
      "Epoch 2006, Training Loss: 0.1735301584966721, Validation Loss: 0.17463669081528982, Validation Accuracy: 0.4875\n",
      "Epoch 2007, Training Loss: 0.17423007324818643, Validation Loss: 0.17331585089365642, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 2008, Training Loss: 0.17363635090089613, Validation Loss: 0.17425475418567657, Validation Accuracy: 0.475\n",
      "Epoch 2009, Training Loss: 0.17409183469510847, Validation Loss: 0.17319874266783397, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 2010, Training Loss: 0.17361427939707233, Validation Loss: 0.17479412158330282, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 2011, Training Loss: 0.17413778074326053, Validation Loss: 0.17337202231089274, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2012, Training Loss: 0.17361329928521188, Validation Loss: 0.1750667691230774, Validation Accuracy: 0.4875\n",
      "Epoch 2013, Training Loss: 0.17413310850820235, Validation Loss: 0.172991144657135, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 2014, Training Loss: 0.17350763082504272, Validation Loss: 0.17481643358866375, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 2015, Training Loss: 0.1741942888306033, Validation Loss: 0.17367828289667767, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2016, Training Loss: 0.17360441386699677, Validation Loss: 0.17502621710300445, Validation Accuracy: 0.49375\n",
      "Epoch 2017, Training Loss: 0.17422495686238812, Validation Loss: 0.17348660031954447, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 2018, Training Loss: 0.1734829891112543, Validation Loss: 0.17425541182359058, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 2019, Training Loss: 0.17416351072249875, Validation Loss: 0.17424590984980265, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 2020, Training Loss: 0.17353106506409183, Validation Loss: 0.17411874135335287, Validation Accuracy: 0.5125\n",
      "Epoch 2021, Training Loss: 0.17432385202377074, Validation Loss: 0.17447870075702668, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 2022, Training Loss: 0.17360233347262105, Validation Loss: 0.17306755085786182, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 2023, Training Loss: 0.17418242269946682, Validation Loss: 0.17448312838872274, Validation Accuracy: 0.48125\n",
      "Epoch 2024, Training Loss: 0.17350783319242538, Validation Loss: 0.1739686091740926, Validation Accuracy: 0.50625\n",
      "Epoch 2025, Training Loss: 0.17430150076266257, Validation Loss: 0.17474997242291768, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 2026, Training Loss: 0.1735608241250438, Validation Loss: 0.17219126721223196, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 2027, Training Loss: 0.17407057506422843, Validation Loss: 0.1752678334712982, Validation Accuracy: 0.475\n",
      "Epoch 2028, Training Loss: 0.17379166906879795, Validation Loss: 0.17356024980545043, Validation Accuracy: 0.5125\n",
      "Epoch 2029, Training Loss: 0.17389677176552434, Validation Loss: 0.1752094119787216, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 2030, Training Loss: 0.17380239357871394, Validation Loss: 0.17273241380850474, Validation Accuracy: 0.5375\n",
      "Epoch 2031, Training Loss: 0.1737263870816077, Validation Loss: 0.17529519895712534, Validation Accuracy: 0.4875\n",
      "Epoch 2032, Training Loss: 0.17385755527404048, Validation Loss: 0.17402511537075044, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 2033, Training Loss: 0.17392873764038086, Validation Loss: 0.17597660521666209, Validation Accuracy: 0.475\n",
      "Epoch 2034, Training Loss: 0.17387221080641593, Validation Loss: 0.1719942977031072, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 2035, Training Loss: 0.173684760928154, Validation Loss: 0.17656524777412413, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 2036, Training Loss: 0.17407501416821633, Validation Loss: 0.1740241954723994, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2037, Training Loss: 0.17364013867993508, Validation Loss: 0.17508786022663117, Validation Accuracy: 0.4875\n",
      "Epoch 2038, Training Loss: 0.1741704474533758, Validation Loss: 0.17285000185171764, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 2039, Training Loss: 0.17341294452067343, Validation Loss: 0.1746682693560918, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 2040, Training Loss: 0.17440360351916281, Validation Loss: 0.17355771561463673, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2041, Training Loss: 0.1735812045874134, Validation Loss: 0.17496494054794312, Validation Accuracy: 0.49375\n",
      "Epoch 2042, Training Loss: 0.1739862205520753, Validation Loss: 0.17338500122229258, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 2043, Training Loss: 0.17361892279117339, Validation Loss: 0.1739918718735377, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 2044, Training Loss: 0.17417184720116277, Validation Loss: 0.1746327817440033, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 2045, Training Loss: 0.17365153662620053, Validation Loss: 0.17368298172950744, Validation Accuracy: 0.5125\n",
      "Epoch 2046, Training Loss: 0.1740036001128535, Validation Loss: 0.17431468566258748, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 2047, Training Loss: 0.17357848296242376, Validation Loss: 0.17293659051259358, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 2048, Training Loss: 0.1740454618007906, Validation Loss: 0.17436195214589437, Validation Accuracy: 0.48125\n",
      "Epoch 2049, Training Loss: 0.1737940114352011, Validation Loss: 0.17370131313800813, Validation Accuracy: 0.50625\n",
      "Epoch 2050, Training Loss: 0.1738869269048014, Validation Loss: 0.17465440332889556, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 2051, Training Loss: 0.17357282388594844, Validation Loss: 0.17210571964581808, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 2052, Training Loss: 0.17413121461868286, Validation Loss: 0.17405424614747364, Validation Accuracy: 0.475\n",
      "Epoch 2053, Training Loss: 0.17372922455110856, Validation Loss: 0.17395194371541342, Validation Accuracy: 0.5125\n",
      "Epoch 2054, Training Loss: 0.17408148896309636, Validation Loss: 0.1743172268072764, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 2055, Training Loss: 0.1736748973208089, Validation Loss: 0.1726601541042328, Validation Accuracy: 0.5375\n",
      "Epoch 2056, Training Loss: 0.1740732870755657, Validation Loss: 0.17384838263193766, Validation Accuracy: 0.4875\n",
      "Epoch 2057, Training Loss: 0.17379341683080118, Validation Loss: 0.17391884624958037, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 2058, Training Loss: 0.17404992253549637, Validation Loss: 0.17417303721110025, Validation Accuracy: 0.475\n",
      "Epoch 2059, Training Loss: 0.1737167666996679, Validation Loss: 0.17208505968252819, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 2060, Training Loss: 0.17407098124104162, Validation Loss: 0.17396898667017618, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 2061, Training Loss: 0.1737214913291316, Validation Loss: 0.17410374184449515, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2062, Training Loss: 0.17383364612056362, Validation Loss: 0.17423890034357706, Validation Accuracy: 0.4875\n",
      "Epoch 2063, Training Loss: 0.17381933331489563, Validation Loss: 0.17283256749312084, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 2064, Training Loss: 0.17401523936179378, Validation Loss: 0.17340807616710663, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 2065, Training Loss: 0.17388463356802542, Validation Loss: 0.1735519488652547, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2066, Training Loss: 0.17387790449203983, Validation Loss: 0.17390441099802653, Validation Accuracy: 0.49375\n",
      "Epoch 2067, Training Loss: 0.17381997406482697, Validation Loss: 0.1733448714017868, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 2068, Training Loss: 0.1739793900520571, Validation Loss: 0.17326137920220694, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 2069, Training Loss: 0.17394621477973077, Validation Loss: 0.17356325685977936, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 2070, Training Loss: 0.1737924886326636, Validation Loss: 0.1732329845428467, Validation Accuracy: 0.5125\n",
      "Epoch 2071, Training Loss: 0.17399217909382236, Validation Loss: 0.1735886683066686, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 2072, Training Loss: 0.17383183250504156, Validation Loss: 0.1730078677336375, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 2073, Training Loss: 0.17405408524697827, Validation Loss: 0.1735818346341451, Validation Accuracy: 0.48125\n",
      "Epoch 2074, Training Loss: 0.17380082126586668, Validation Loss: 0.17333164711793264, Validation Accuracy: 0.50625\n",
      "Epoch 2075, Training Loss: 0.173955746235386, Validation Loss: 0.17387573023637135, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 2076, Training Loss: 0.17390879748329038, Validation Loss: 0.17288741171360017, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 2077, Training Loss: 0.1739806446336931, Validation Loss: 0.1737185130516688, Validation Accuracy: 0.475\n",
      "Epoch 2078, Training Loss: 0.1739202170602737, Validation Loss: 0.17322073479493458, Validation Accuracy: 0.5125\n",
      "Epoch 2079, Training Loss: 0.17385956500807115, Validation Loss: 0.17394052545229594, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 2080, Training Loss: 0.17397284267410154, Validation Loss: 0.17308428585529329, Validation Accuracy: 0.5375\n",
      "Epoch 2081, Training Loss: 0.17392015072607225, Validation Loss: 0.17362878918647767, Validation Accuracy: 0.4875\n",
      "Epoch 2082, Training Loss: 0.17382196120677457, Validation Loss: 0.17362180352210999, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 2083, Training Loss: 0.17382867922705988, Validation Loss: 0.17391855518023172, Validation Accuracy: 0.475\n",
      "Epoch 2084, Training Loss: 0.1739477712300516, Validation Loss: 0.17279998064041138, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 2085, Training Loss: 0.17389759229075524, Validation Loss: 0.17384603420893352, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 2086, Training Loss: 0.17379383454399724, Validation Loss: 0.17371245821317036, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2087, Training Loss: 0.17382797070087924, Validation Loss: 0.17381564577420552, Validation Accuracy: 0.4875\n",
      "Epoch 2088, Training Loss: 0.17400610302725145, Validation Loss: 0.17309395869572958, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 2089, Training Loss: 0.17371731996536255, Validation Loss: 0.1739290952682495, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 2090, Training Loss: 0.17402935364554006, Validation Loss: 0.17357957164446514, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2091, Training Loss: 0.17373285034010488, Validation Loss: 0.17360173165798187, Validation Accuracy: 0.49375\n",
      "Epoch 2092, Training Loss: 0.1740734322417167, Validation Loss: 0.17328076362609862, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 2093, Training Loss: 0.17383248959818193, Validation Loss: 0.1732900301615397, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 2094, Training Loss: 0.17397145734679315, Validation Loss: 0.17344067494074503, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 2095, Training Loss: 0.17374534616547246, Validation Loss: 0.17331770161787668, Validation Accuracy: 0.5125\n",
      "Epoch 2096, Training Loss: 0.17405512592484873, Validation Loss: 0.17339601119359335, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 2097, Training Loss: 0.1738141563630873, Validation Loss: 0.17296140988667805, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 2098, Training Loss: 0.17387605338327347, Validation Loss: 0.17356766760349274, Validation Accuracy: 0.48125\n",
      "Epoch 2099, Training Loss: 0.17370853164503652, Validation Loss: 0.17343540489673615, Validation Accuracy: 0.50625\n",
      "Epoch 2100, Training Loss: 0.17405527205236496, Validation Loss: 0.17353928685188294, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 2101, Training Loss: 0.17380477920655282, Validation Loss: 0.17252413133780162, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 2102, Training Loss: 0.17409309312220542, Validation Loss: 0.1734162618716558, Validation Accuracy: 0.475\n",
      "Epoch 2103, Training Loss: 0.1736882410703167, Validation Loss: 0.17327340145905812, Validation Accuracy: 0.5125\n",
      "Epoch 2104, Training Loss: 0.17414023510871396, Validation Loss: 0.1734265387058258, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 2105, Training Loss: 0.17375482282330912, Validation Loss: 0.17273741066455842, Validation Accuracy: 0.5375\n",
      "Epoch 2106, Training Loss: 0.1740130017842016, Validation Loss: 0.17343659400939943, Validation Accuracy: 0.4875\n",
      "Epoch 2107, Training Loss: 0.17364919185638428, Validation Loss: 0.1736393262942632, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 2108, Training Loss: 0.17421684822728556, Validation Loss: 0.17336659431457518, Validation Accuracy: 0.475\n",
      "Epoch 2109, Training Loss: 0.1737276719462487, Validation Loss: 0.17225225865840912, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 2110, Training Loss: 0.17398225684319774, Validation Loss: 0.17363298535346985, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 2111, Training Loss: 0.17374588549137115, Validation Loss: 0.17365592817465464, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2112, Training Loss: 0.17408854874872393, Validation Loss: 0.17335045337677002, Validation Accuracy: 0.4875\n",
      "Epoch 2113, Training Loss: 0.17374517311972956, Validation Loss: 0.17304366330305734, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 2114, Training Loss: 0.17399480169819248, Validation Loss: 0.17335209548473357, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 2115, Training Loss: 0.17371204158952158, Validation Loss: 0.17352603673934935, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2116, Training Loss: 0.17405490577220917, Validation Loss: 0.17332957983016967, Validation Accuracy: 0.49375\n",
      "Epoch 2117, Training Loss: 0.1738471350362224, Validation Loss: 0.17330301304658255, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 2118, Training Loss: 0.17378270529931591, Validation Loss: 0.1733004738887151, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 2119, Training Loss: 0.17370201310803812, Validation Loss: 0.17429638504981995, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 2120, Training Loss: 0.1741995051983864, Validation Loss: 0.17326405545075735, Validation Accuracy: 0.5125\n",
      "Epoch 2121, Training Loss: 0.17374625129084434, Validation Loss: 0.1740387280782064, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 2122, Training Loss: 0.17408065594011737, Validation Loss: 0.17322279612223307, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 2123, Training Loss: 0.1736621424075096, Validation Loss: 0.174381755789121, Validation Accuracy: 0.48125\n",
      "Epoch 2124, Training Loss: 0.17416984708078445, Validation Loss: 0.17327561477820078, Validation Accuracy: 0.50625\n",
      "Epoch 2125, Training Loss: 0.17365738893708876, Validation Loss: 0.17536166707674664, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 2126, Training Loss: 0.17425548020870454, Validation Loss: 0.17302663624286652, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 2127, Training Loss: 0.17350919544696808, Validation Loss: 0.17493030428886414, Validation Accuracy: 0.475\n",
      "Epoch 2128, Training Loss: 0.1742987507773984, Validation Loss: 0.1732534060875575, Validation Accuracy: 0.5125\n",
      "Epoch 2129, Training Loss: 0.17356965618748818, Validation Loss: 0.17513648172219595, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 2130, Training Loss: 0.17418065763288929, Validation Loss: 0.17323380211989084, Validation Accuracy: 0.5375\n",
      "Epoch 2131, Training Loss: 0.17354238129431201, Validation Loss: 0.1745398998260498, Validation Accuracy: 0.4875\n",
      "Epoch 2132, Training Loss: 0.17421775575607054, Validation Loss: 0.17329307893911997, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 2133, Training Loss: 0.17370779716199444, Validation Loss: 0.17418798406918842, Validation Accuracy: 0.475\n",
      "Epoch 2134, Training Loss: 0.17382597827142285, Validation Loss: 0.17324565251668295, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 2135, Training Loss: 0.1736930719306392, Validation Loss: 0.17465890049934388, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 2136, Training Loss: 0.1741629901432222, Validation Loss: 0.17337744335333508, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2137, Training Loss: 0.17363945755266375, Validation Loss: 0.1750258505344391, Validation Accuracy: 0.4875\n",
      "Epoch 2138, Training Loss: 0.17412428557872772, Validation Loss: 0.1730667899052302, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 2139, Training Loss: 0.17350072774194902, Validation Loss: 0.17491818368434905, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 2140, Training Loss: 0.17419365529091127, Validation Loss: 0.17374082605044047, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2141, Training Loss: 0.17359829381588968, Validation Loss: 0.17509249349435171, Validation Accuracy: 0.49375\n",
      "Epoch 2142, Training Loss: 0.1742157176617653, Validation Loss: 0.17346317867438, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 2143, Training Loss: 0.1734837875250847, Validation Loss: 0.1742180496454239, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 2144, Training Loss: 0.1742019465854091, Validation Loss: 0.17416181365648906, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 2145, Training Loss: 0.17352948217622696, Validation Loss: 0.17417277197043102, Validation Accuracy: 0.5125\n",
      "Epoch 2146, Training Loss: 0.17435984938375412, Validation Loss: 0.17431084116299947, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 2147, Training Loss: 0.17358662332257918, Validation Loss: 0.17300574084122974, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 2148, Training Loss: 0.17423162056553748, Validation Loss: 0.17433051864306132, Validation Accuracy: 0.48125\n",
      "Epoch 2149, Training Loss: 0.1734658008621585, Validation Loss: 0.17414828936258953, Validation Accuracy: 0.50625\n",
      "Epoch 2150, Training Loss: 0.17433032633796816, Validation Loss: 0.17420494159062702, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 2151, Training Loss: 0.17356499837290856, Validation Loss: 0.172189990679423, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 2152, Training Loss: 0.174118987975582, Validation Loss: 0.17517201900482177, Validation Accuracy: 0.475\n",
      "Epoch 2153, Training Loss: 0.1737484835809277, Validation Loss: 0.17368929386138915, Validation Accuracy: 0.5125\n",
      "Epoch 2154, Training Loss: 0.17387617932211968, Validation Loss: 0.17564979692300162, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 2155, Training Loss: 0.1737796010509614, Validation Loss: 0.1726592868566513, Validation Accuracy: 0.5375\n",
      "Epoch 2156, Training Loss: 0.17382975932090514, Validation Loss: 0.17544344067573547, Validation Accuracy: 0.4875\n",
      "Epoch 2157, Training Loss: 0.17387067214135202, Validation Loss: 0.17443183660507203, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 2158, Training Loss: 0.17386674929049709, Validation Loss: 0.1760249465703964, Validation Accuracy: 0.475\n",
      "Epoch 2159, Training Loss: 0.17391515018478518, Validation Loss: 0.17187131146589915, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 2160, Training Loss: 0.17371468534392695, Validation Loss: 0.17618672748406727, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 2161, Training Loss: 0.17408118324895058, Validation Loss: 0.173550350467364, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2162, Training Loss: 0.1734655499458313, Validation Loss: 0.17577674587567646, Validation Accuracy: 0.4875\n",
      "Epoch 2163, Training Loss: 0.17419286024185918, Validation Loss: 0.17273444334665936, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 2164, Training Loss: 0.1733167483921974, Validation Loss: 0.17568192183971404, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 2165, Training Loss: 0.17449356903952937, Validation Loss: 0.17366513311862947, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2166, Training Loss: 0.17361697987202676, Validation Loss: 0.17449679374694824, Validation Accuracy: 0.49375\n",
      "Epoch 2167, Training Loss: 0.1741009989092427, Validation Loss: 0.17354157865047454, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 2168, Training Loss: 0.1735608717126231, Validation Loss: 0.17399532596270242, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 2169, Training Loss: 0.17419906777720298, Validation Loss: 0.17411771217981975, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 2170, Training Loss: 0.17370816776829381, Validation Loss: 0.17363128860791524, Validation Accuracy: 0.5125\n",
      "Epoch 2171, Training Loss: 0.17413121750277857, Validation Loss: 0.17427245179812115, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 2172, Training Loss: 0.17361215381853043, Validation Loss: 0.1730583926041921, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 2173, Training Loss: 0.17413718950363896, Validation Loss: 0.17404756247997283, Validation Accuracy: 0.48125\n",
      "Epoch 2174, Training Loss: 0.17373585797125293, Validation Loss: 0.17385190625985464, Validation Accuracy: 0.50625\n",
      "Epoch 2175, Training Loss: 0.17409556719564623, Validation Loss: 0.17488383253415427, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 2176, Training Loss: 0.1736577816547886, Validation Loss: 0.17207713226477306, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 2177, Training Loss: 0.17414222753817035, Validation Loss: 0.17410264909267426, Validation Accuracy: 0.475\n",
      "Epoch 2178, Training Loss: 0.1737758973913808, Validation Loss: 0.17335939904054007, Validation Accuracy: 0.5125\n",
      "Epoch 2179, Training Loss: 0.1741355662384341, Validation Loss: 0.17431698342164356, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 2180, Training Loss: 0.1736755842162717, Validation Loss: 0.17265948553880056, Validation Accuracy: 0.5375\n",
      "Epoch 2181, Training Loss: 0.17417044120450173, Validation Loss: 0.17363451719284057, Validation Accuracy: 0.4875\n",
      "Epoch 2182, Training Loss: 0.17372299538504693, Validation Loss: 0.17412092983722688, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 2183, Training Loss: 0.17399749304017714, Validation Loss: 0.17416616479555766, Validation Accuracy: 0.475\n",
      "Epoch 2184, Training Loss: 0.17373638287667306, Validation Loss: 0.17208302319049834, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 2185, Training Loss: 0.17405526868758664, Validation Loss: 0.1737689177195231, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 2186, Training Loss: 0.17379824192293228, Validation Loss: 0.1737610270579656, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2187, Training Loss: 0.1739293961755691, Validation Loss: 0.1743279258410136, Validation Accuracy: 0.4875\n",
      "Epoch 2188, Training Loss: 0.1738317382912482, Validation Loss: 0.17280873258908588, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 2189, Training Loss: 0.17398996747309162, Validation Loss: 0.17340101798375449, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 2190, Training Loss: 0.17392420768737793, Validation Loss: 0.1735195517539978, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2191, Training Loss: 0.1738444350419506, Validation Loss: 0.17435055871804556, Validation Accuracy: 0.49375\n",
      "Epoch 2192, Training Loss: 0.17380342704634513, Validation Loss: 0.17332994937896729, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 2193, Training Loss: 0.17394768999468896, Validation Loss: 0.17327329516410828, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 2194, Training Loss: 0.17395861783335287, Validation Loss: 0.17354999979337057, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 2195, Training Loss: 0.17370570234714017, Validation Loss: 0.1733063906431198, Validation Accuracy: 0.5125\n",
      "Epoch 2196, Training Loss: 0.17398539570070082, Validation Loss: 0.17368245720863343, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 2197, Training Loss: 0.1739214365520785, Validation Loss: 0.17307426333427428, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 2198, Training Loss: 0.17398444346843228, Validation Loss: 0.1736251523097356, Validation Accuracy: 0.48125\n",
      "Epoch 2199, Training Loss: 0.17374031149571942, Validation Loss: 0.1734151264031728, Validation Accuracy: 0.50625\n",
      "Epoch 2200, Training Loss: 0.1740013163897299, Validation Loss: 0.17376390794912974, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 2201, Training Loss: 0.17390778949183802, Validation Loss: 0.17288602689901988, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 2202, Training Loss: 0.17394248516328872, Validation Loss: 0.17368809779485067, Validation Accuracy: 0.475\n",
      "Epoch 2203, Training Loss: 0.17382978575844918, Validation Loss: 0.17322206894556683, Validation Accuracy: 0.5125\n",
      "Epoch 2204, Training Loss: 0.17389070747360105, Validation Loss: 0.1739802340666453, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 2205, Training Loss: 0.17396815169242122, Validation Loss: 0.17309356331825257, Validation Accuracy: 0.5375\n",
      "Epoch 2206, Training Loss: 0.17393839695761282, Validation Loss: 0.17381423711776733, Validation Accuracy: 0.4875\n",
      "Epoch 2207, Training Loss: 0.17389098723088542, Validation Loss: 0.17344541152318318, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 2208, Training Loss: 0.17382503709485453, Validation Loss: 0.1741628259420395, Validation Accuracy: 0.475\n",
      "Epoch 2209, Training Loss: 0.17399070676295988, Validation Loss: 0.17265688280264538, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 2210, Training Loss: 0.17391607597950967, Validation Loss: 0.17403795917828876, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 2211, Training Loss: 0.173740376387873, Validation Loss: 0.17398898005485536, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2212, Training Loss: 0.17385656987467119, Validation Loss: 0.17375089526176452, Validation Accuracy: 0.4875\n",
      "Epoch 2213, Training Loss: 0.17411340436627787, Validation Loss: 0.17304127415021262, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 2214, Training Loss: 0.17377180149478297, Validation Loss: 0.17358399828275045, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 2215, Training Loss: 0.174045336342627, Validation Loss: 0.17346009612083435, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2216, Training Loss: 0.17369629202350492, Validation Loss: 0.1737655301888784, Validation Accuracy: 0.49375\n",
      "Epoch 2217, Training Loss: 0.17406687621147401, Validation Loss: 0.1732911338408788, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 2218, Training Loss: 0.17382209579790792, Validation Loss: 0.17329940100510915, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 2219, Training Loss: 0.17384119283768437, Validation Loss: 0.17371055881182354, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 2220, Training Loss: 0.1738172971433209, Validation Loss: 0.17324305872122447, Validation Accuracy: 0.5125\n",
      "Epoch 2221, Training Loss: 0.17401359590791887, Validation Loss: 0.1734112759431203, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 2222, Training Loss: 0.17387398500596324, Validation Loss: 0.17293857236703236, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 2223, Training Loss: 0.17399148066197673, Validation Loss: 0.17344445983568826, Validation Accuracy: 0.48125\n",
      "Epoch 2224, Training Loss: 0.17367921192799846, Validation Loss: 0.17342399954795837, Validation Accuracy: 0.50625\n",
      "Epoch 2225, Training Loss: 0.1741303974582303, Validation Loss: 0.17346640229225158, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 2226, Training Loss: 0.17371506989002228, Validation Loss: 0.17230293552080791, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 2227, Training Loss: 0.17419016120895262, Validation Loss: 0.17341077327728271, Validation Accuracy: 0.475\n",
      "Epoch 2228, Training Loss: 0.1736557786503146, Validation Loss: 0.1732503036657969, Validation Accuracy: 0.5125\n",
      "Epoch 2229, Training Loss: 0.17403320343263687, Validation Loss: 0.17354174554347992, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 2230, Training Loss: 0.1737968123728229, Validation Loss: 0.17274223764737448, Validation Accuracy: 0.5375\n",
      "Epoch 2231, Training Loss: 0.17398858022305272, Validation Loss: 0.1734261244535446, Validation Accuracy: 0.4875\n",
      "Epoch 2232, Training Loss: 0.17369326228095638, Validation Loss: 0.17384867370128632, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 2233, Training Loss: 0.17419109325255117, Validation Loss: 0.17336880067984264, Validation Accuracy: 0.475\n",
      "Epoch 2234, Training Loss: 0.17373567963800124, Validation Loss: 0.172321417927742, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 2235, Training Loss: 0.17410348259633587, Validation Loss: 0.17347112993399302, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 2236, Training Loss: 0.17366605179925118, Validation Loss: 0.17361010412375133, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2237, Training Loss: 0.1741280488429531, Validation Loss: 0.17334387004375457, Validation Accuracy: 0.4875\n",
      "Epoch 2238, Training Loss: 0.17378537212648698, Validation Loss: 0.1728351761897405, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 2239, Training Loss: 0.17397513601087755, Validation Loss: 0.173347274462382, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 2240, Training Loss: 0.1737358171132303, Validation Loss: 0.17372285723686218, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2241, Training Loss: 0.17411654851128977, Validation Loss: 0.1732988715171814, Validation Accuracy: 0.49375\n",
      "Epoch 2242, Training Loss: 0.17385010084798258, Validation Loss: 0.17345954378445944, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 2243, Training Loss: 0.17391183780085656, Validation Loss: 0.17325850824515024, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 2244, Training Loss: 0.1736852507437429, Validation Loss: 0.17434104482332866, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 2245, Training Loss: 0.17411613800833303, Validation Loss: 0.17326546510060628, Validation Accuracy: 0.5125\n",
      "Epoch 2246, Training Loss: 0.17379698878334415, Validation Loss: 0.17407664159933725, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 2247, Training Loss: 0.17393771823375456, Validation Loss: 0.17322805523872375, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 2248, Training Loss: 0.17370395122035856, Validation Loss: 0.17452381253242494, Validation Accuracy: 0.48125\n",
      "Epoch 2249, Training Loss: 0.17413590944582416, Validation Loss: 0.17327378690242767, Validation Accuracy: 0.50625\n",
      "Epoch 2250, Training Loss: 0.17365029742640833, Validation Loss: 0.17504815061887105, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 2251, Training Loss: 0.17415114852689928, Validation Loss: 0.17321542799472808, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 2252, Training Loss: 0.17356673652125942, Validation Loss: 0.1746193140745163, Validation Accuracy: 0.475\n",
      "Epoch 2253, Training Loss: 0.1742067687934445, Validation Loss: 0.17327664295832315, Validation Accuracy: 0.5125\n",
      "Epoch 2254, Training Loss: 0.17365478604070603, Validation Loss: 0.1750694344441096, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 2255, Training Loss: 0.17412147598881875, Validation Loss: 0.17322056889533996, Validation Accuracy: 0.5375\n",
      "Epoch 2256, Training Loss: 0.17353468893035764, Validation Loss: 0.17488512694835662, Validation Accuracy: 0.4875\n",
      "Epoch 2257, Training Loss: 0.17419883608818054, Validation Loss: 0.17330489953358968, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 2258, Training Loss: 0.1737079413667802, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.525\n",
      "Epoch 2259, Training Loss: 0.17541885904727444, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.4395833333333333\n",
      "Epoch 2260, Training Loss: 0.17538965950089117, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5270833333333333\n",
      "Epoch 2261, Training Loss: 0.17328338709569746, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 2262, Training Loss: 0.17327710793864343, Validation Loss: 0.17328920662403108, Validation Accuracy: 0.4875\n",
      "Epoch 2263, Training Loss: 0.17425122376411192, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.46458333333333335\n",
      "Epoch 2264, Training Loss: 0.1732867956161499, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 2265, Training Loss: 0.1732880199147809, Validation Loss: 0.1732889175415039, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2266, Training Loss: 0.1733125731829674, Validation Loss: 0.17348238527774812, Validation Accuracy: 0.49375\n",
      "Epoch 2267, Training Loss: 0.1736096946462508, Validation Loss: 0.17327975233395895, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 2268, Training Loss: 0.17337776720523834, Validation Loss: 0.17340263028939565, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 2269, Training Loss: 0.17347914605371414, Validation Loss: 0.17333502074082693, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 2270, Training Loss: 0.1737763737478564, Validation Loss: 0.1732195516427358, Validation Accuracy: 0.5125\n",
      "Epoch 2271, Training Loss: 0.17388146538888255, Validation Loss: 0.1736807366212209, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 2272, Training Loss: 0.17358929447589383, Validation Loss: 0.17290977438290914, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 2273, Training Loss: 0.17397828207861993, Validation Loss: 0.17350763082504272, Validation Accuracy: 0.48125\n",
      "Epoch 2274, Training Loss: 0.17354294080888072, Validation Loss: 0.17348958055178323, Validation Accuracy: 0.50625\n",
      "Epoch 2275, Training Loss: 0.17385127659766905, Validation Loss: 0.17328954835732777, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 2276, Training Loss: 0.17355828996627562, Validation Loss: 0.17227055728435517, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 2277, Training Loss: 0.17402220541431057, Validation Loss: 0.17459164261817933, Validation Accuracy: 0.475\n",
      "Epoch 2278, Training Loss: 0.17365967169884713, Validation Loss: 0.1734432538350423, Validation Accuracy: 0.5125\n",
      "Epoch 2279, Training Loss: 0.17365737163251446, Validation Loss: 0.17402315537134808, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 2280, Training Loss: 0.17361420152648802, Validation Loss: 0.17276687820752462, Validation Accuracy: 0.5375\n",
      "Epoch 2281, Training Loss: 0.17368075684193643, Validation Loss: 0.17498679459095, Validation Accuracy: 0.4875\n",
      "Epoch 2282, Training Loss: 0.17377884782129718, Validation Loss: 0.17439976533253987, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 2283, Training Loss: 0.17374853357192008, Validation Loss: 0.17559426426887512, Validation Accuracy: 0.475\n",
      "Epoch 2284, Training Loss: 0.17386154782387517, Validation Loss: 0.17197707990805308, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 2285, Training Loss: 0.17363419792344492, Validation Loss: 0.17576894064744314, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 2286, Training Loss: 0.17400677021472685, Validation Loss: 0.17401856581370037, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2287, Training Loss: 0.1735484104964041, Validation Loss: 0.17458905975023906, Validation Accuracy: 0.4875\n",
      "Epoch 2288, Training Loss: 0.1740787322482755, Validation Loss: 0.17278606990973155, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 2289, Training Loss: 0.17329540031571541, Validation Loss: 0.1746384451786677, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 2290, Training Loss: 0.17437589889572513, Validation Loss: 0.17378725210825602, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2291, Training Loss: 0.1734750174706982, Validation Loss: 0.17421462535858154, Validation Accuracy: 0.49375\n",
      "Epoch 2292, Training Loss: 0.17405575369634935, Validation Loss: 0.17354882856210072, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 2293, Training Loss: 0.17353862860510427, Validation Loss: 0.17382514278093975, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 2294, Training Loss: 0.1741232934498018, Validation Loss: 0.17396199703216553, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 2295, Training Loss: 0.17359938160065683, Validation Loss: 0.17354572415351868, Validation Accuracy: 0.5125\n",
      "Epoch 2296, Training Loss: 0.17400431440722558, Validation Loss: 0.17415429453055065, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 2297, Training Loss: 0.17355160415172577, Validation Loss: 0.1729158341884613, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 2298, Training Loss: 0.17399980944971885, Validation Loss: 0.17406432926654816, Validation Accuracy: 0.48125\n",
      "Epoch 2299, Training Loss: 0.17368568143536967, Validation Loss: 0.17351355453332265, Validation Accuracy: 0.50625\n",
      "Epoch 2300, Training Loss: 0.17387969936093978, Validation Loss: 0.17473169565200805, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 2301, Training Loss: 0.17366248705694753, Validation Loss: 0.17234093348185223, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 2302, Training Loss: 0.17393438806456904, Validation Loss: 0.1743334174156189, Validation Accuracy: 0.475\n",
      "Epoch 2303, Training Loss: 0.17369127946515237, Validation Loss: 0.17334505518277485, Validation Accuracy: 0.5125\n",
      "Epoch 2304, Training Loss: 0.1739463436026727, Validation Loss: 0.1748869736989339, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 2305, Training Loss: 0.17358644402796222, Validation Loss: 0.17266855239868165, Validation Accuracy: 0.5375\n",
      "Epoch 2306, Training Loss: 0.17395798092888248, Validation Loss: 0.17403046588102977, Validation Accuracy: 0.4875\n",
      "Epoch 2307, Training Loss: 0.17373809699089296, Validation Loss: 0.17387508153915404, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 2308, Training Loss: 0.17389905404660008, Validation Loss: 0.17459853986899057, Validation Accuracy: 0.475\n",
      "Epoch 2309, Training Loss: 0.17367721661444632, Validation Loss: 0.17211813032627105, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 2310, Training Loss: 0.17392053142670663, Validation Loss: 0.17411074340343474, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 2311, Training Loss: 0.1737748682498932, Validation Loss: 0.17368220090866088, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2312, Training Loss: 0.1739844790389461, Validation Loss: 0.17364381849765778, Validation Accuracy: 0.4875\n",
      "Epoch 2313, Training Loss: 0.1737630501870186, Validation Loss: 0.1728410542011261, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 2314, Training Loss: 0.17394319128605626, Validation Loss: 0.1734637270371119, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 2315, Training Loss: 0.17377252684485528, Validation Loss: 0.1735630472501119, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2316, Training Loss: 0.1738488414595204, Validation Loss: 0.17366473078727723, Validation Accuracy: 0.49375\n",
      "Epoch 2317, Training Loss: 0.17381962701197592, Validation Loss: 0.17335362235705057, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 2318, Training Loss: 0.17382171750068665, Validation Loss: 0.17329288323720296, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 2319, Training Loss: 0.17391567076406172, Validation Loss: 0.17366903920968374, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 2320, Training Loss: 0.17347014767508354, Validation Loss: 0.1734810769557953, Validation Accuracy: 0.5125\n",
      "Epoch 2321, Training Loss: 0.17398338067916133, Validation Loss: 0.17354535758495332, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 2322, Training Loss: 0.17381964720064594, Validation Loss: 0.17303302387396494, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 2323, Training Loss: 0.17395055822787747, Validation Loss: 0.17352454066276551, Validation Accuracy: 0.48125\n",
      "Epoch 2324, Training Loss: 0.17356709895595426, Validation Loss: 0.17364296019077302, Validation Accuracy: 0.50625\n",
      "Epoch 2325, Training Loss: 0.17398038602644397, Validation Loss: 0.17378740509351095, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 2326, Training Loss: 0.17385748749779117, Validation Loss: 0.17282014389832814, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 2327, Training Loss: 0.17386138631451514, Validation Loss: 0.17373714645703633, Validation Accuracy: 0.475\n",
      "Epoch 2328, Training Loss: 0.17379356055490433, Validation Loss: 0.1732188512881597, Validation Accuracy: 0.5125\n",
      "Epoch 2329, Training Loss: 0.17384250413986943, Validation Loss: 0.1738429437081019, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 2330, Training Loss: 0.17388022042089893, Validation Loss: 0.1730003535747528, Validation Accuracy: 0.5375\n",
      "Epoch 2331, Training Loss: 0.17385435536984475, Validation Loss: 0.17368329068024954, Validation Accuracy: 0.4875\n",
      "Epoch 2332, Training Loss: 0.17365759947607595, Validation Loss: 0.17395707269509633, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 2333, Training Loss: 0.17380391541988618, Validation Loss: 0.17386813660462697, Validation Accuracy: 0.475\n",
      "Epoch 2334, Training Loss: 0.17395694601920345, Validation Loss: 0.17285276353359222, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 2335, Training Loss: 0.17380471671781234, Validation Loss: 0.17399171392122906, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 2336, Training Loss: 0.17366761161435035, Validation Loss: 0.17392634153366088, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2337, Training Loss: 0.17379972915495595, Validation Loss: 0.17375363210837047, Validation Accuracy: 0.4875\n",
      "Epoch 2338, Training Loss: 0.17399894422100437, Validation Loss: 0.17308744291464487, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 2339, Training Loss: 0.17372512432836718, Validation Loss: 0.17364167173703512, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 2340, Training Loss: 0.17390675217874588, Validation Loss: 0.1736762285232544, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2341, Training Loss: 0.17363799579681888, Validation Loss: 0.17373929222424825, Validation Accuracy: 0.49375\n",
      "Epoch 2342, Training Loss: 0.17399637977923116, Validation Loss: 0.17329137325286864, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 2343, Training Loss: 0.1738010221912015, Validation Loss: 0.1733018676439921, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 2344, Training Loss: 0.1737500092675609, Validation Loss: 0.1738464524348577, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 2345, Training Loss: 0.1738447215287916, Validation Loss: 0.17324745655059814, Validation Accuracy: 0.5125\n",
      "Epoch 2346, Training Loss: 0.17397244226547978, Validation Loss: 0.17344368000825247, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 2347, Training Loss: 0.17378398103098716, Validation Loss: 0.17294408877690634, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 2348, Training Loss: 0.17395345722475358, Validation Loss: 0.17346041202545165, Validation Accuracy: 0.48125\n",
      "Epoch 2349, Training Loss: 0.17362328210184652, Validation Loss: 0.17343379060427347, Validation Accuracy: 0.50625\n",
      "Epoch 2350, Training Loss: 0.17412335209308133, Validation Loss: 0.17346002161502838, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 2351, Training Loss: 0.17366879361291085, Validation Loss: 0.17238365610440573, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 2352, Training Loss: 0.17387508144301753, Validation Loss: 0.17376811504364015, Validation Accuracy: 0.475\n",
      "Epoch 2353, Training Loss: 0.17372317900580744, Validation Loss: 0.17330841819445292, Validation Accuracy: 0.5125\n",
      "Epoch 2354, Training Loss: 0.17404442641042894, Validation Loss: 0.17349118292331694, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 2355, Training Loss: 0.17369046086265194, Validation Loss: 0.17273677388827005, Validation Accuracy: 0.5375\n",
      "Epoch 2356, Training Loss: 0.17403672587487004, Validation Loss: 0.1734051485856374, Validation Accuracy: 0.4875\n",
      "Epoch 2357, Training Loss: 0.17361853103483876, Validation Loss: 0.1737628012895584, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 2358, Training Loss: 0.17413852099449403, Validation Loss: 0.17340547740459442, Validation Accuracy: 0.475\n",
      "Epoch 2359, Training Loss: 0.1736498124176456, Validation Loss: 0.17218574682871501, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 2360, Training Loss: 0.17401114442656118, Validation Loss: 0.1735782821973165, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 2361, Training Loss: 0.17367603413520322, Validation Loss: 0.173736509680748, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2362, Training Loss: 0.1740469995044893, Validation Loss: 0.17337048351764678, Validation Accuracy: 0.4875\n",
      "Epoch 2363, Training Loss: 0.17370261299994685, Validation Loss: 0.17288637657960257, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 2364, Training Loss: 0.17402057782296212, Validation Loss: 0.17331709961096445, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 2365, Training Loss: 0.17367799580097198, Validation Loss: 0.17390809456507364, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2366, Training Loss: 0.17393350360854978, Validation Loss: 0.17330337166786194, Validation Accuracy: 0.49375\n",
      "Epoch 2367, Training Loss: 0.17369068630280032, Validation Loss: 0.1733092168966929, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 2368, Training Loss: 0.1738292844064774, Validation Loss: 0.1732596566279729, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 2369, Training Loss: 0.1736289378135435, Validation Loss: 0.1741099973519643, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 2370, Training Loss: 0.17409301284820802, Validation Loss: 0.17326332330703736, Validation Accuracy: 0.5125\n",
      "Epoch 2371, Training Loss: 0.17375205601415328, Validation Loss: 0.17344216307004293, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 2372, Training Loss: 0.17380074772142595, Validation Loss: 0.17315680285294852, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 2373, Training Loss: 0.17365914342864866, Validation Loss: 0.17419868806997935, Validation Accuracy: 0.48125\n",
      "Epoch 2374, Training Loss: 0.1741091661876248, Validation Loss: 0.17327910661697388, Validation Accuracy: 0.50625\n",
      "Epoch 2375, Training Loss: 0.17362568936040323, Validation Loss: 0.17504912813504536, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 2376, Training Loss: 0.1741542931525938, Validation Loss: 0.1731633186340332, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 2377, Training Loss: 0.17350875466100632, Validation Loss: 0.1750819742679596, Validation Accuracy: 0.475\n",
      "Epoch 2378, Training Loss: 0.17421138046249265, Validation Loss: 0.1732399473587672, Validation Accuracy: 0.5125\n",
      "Epoch 2379, Training Loss: 0.1735290216822778, Validation Loss: 0.17517778674761456, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 2380, Training Loss: 0.17405896802102366, Validation Loss: 0.17322465280691782, Validation Accuracy: 0.5375\n",
      "Epoch 2381, Training Loss: 0.17350432324794032, Validation Loss: 0.1744474232196808, Validation Accuracy: 0.4875\n",
      "Epoch 2382, Training Loss: 0.17427930620408827, Validation Loss: 0.17339963515599568, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 2383, Training Loss: 0.17362620897831454, Validation Loss: 0.17528652052084606, Validation Accuracy: 0.475\n",
      "Epoch 2384, Training Loss: 0.174095862815457, Validation Loss: 0.1728590299685796, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 2385, Training Loss: 0.17360354863828228, Validation Loss: 0.17521028319994608, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 2386, Training Loss: 0.17412690674104997, Validation Loss: 0.17347593307495118, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2387, Training Loss: 0.17355494585729414, Validation Loss: 0.1750148594379425, Validation Accuracy: 0.4875\n",
      "Epoch 2388, Training Loss: 0.1741232463429051, Validation Loss: 0.1729823132356008, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 2389, Training Loss: 0.17347237852311903, Validation Loss: 0.17477334141731263, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 2390, Training Loss: 0.17414464104560115, Validation Loss: 0.17378437320391338, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2391, Training Loss: 0.1735972858244373, Validation Loss: 0.17492652237415313, Validation Accuracy: 0.49375\n",
      "Epoch 2392, Training Loss: 0.17415962776830118, Validation Loss: 0.1733397384484609, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 2393, Training Loss: 0.17346488371972116, Validation Loss: 0.17393390238285064, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 2394, Training Loss: 0.17412645970621415, Validation Loss: 0.17413307825724283, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 2395, Training Loss: 0.17350965401818674, Validation Loss: 0.17402975956598918, Validation Accuracy: 0.5125\n",
      "Epoch 2396, Training Loss: 0.17424894773191021, Validation Loss: 0.17453787724177042, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 2397, Training Loss: 0.173606236134806, Validation Loss: 0.17308315833409627, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 2398, Training Loss: 0.17418560770250135, Validation Loss: 0.17459250489870706, Validation Accuracy: 0.48125\n",
      "Epoch 2399, Training Loss: 0.1734830217976724, Validation Loss: 0.1740351269642512, Validation Accuracy: 0.50625\n",
      "Epoch 2400, Training Loss: 0.17430816734990767, Validation Loss: 0.17446007331212363, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 2401, Training Loss: 0.17359865144375833, Validation Loss: 0.17242088814576467, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 2402, Training Loss: 0.1740094269475629, Validation Loss: 0.17505308588345844, Validation Accuracy: 0.475\n",
      "Epoch 2403, Training Loss: 0.17372273485506734, Validation Loss: 0.17347191373507181, Validation Accuracy: 0.5125\n",
      "Epoch 2404, Training Loss: 0.17381799221038818, Validation Loss: 0.1754126876592636, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 2405, Training Loss: 0.17379660952475764, Validation Loss: 0.17273943026860555, Validation Accuracy: 0.5375\n",
      "Epoch 2406, Training Loss: 0.17371682101680386, Validation Loss: 0.17508304516474407, Validation Accuracy: 0.4875\n",
      "Epoch 2407, Training Loss: 0.17385222306174616, Validation Loss: 0.17428568502267203, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 2408, Training Loss: 0.17385910499480464, Validation Loss: 0.17587435146172842, Validation Accuracy: 0.475\n",
      "Epoch 2409, Training Loss: 0.17393536721506425, Validation Loss: 0.17193688154220582, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 2410, Training Loss: 0.17374080996359548, Validation Loss: 0.17648530304431914, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 2411, Training Loss: 0.174005183481401, Validation Loss: 0.1740041156609853, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2412, Training Loss: 0.17358253992372943, Validation Loss: 0.1755037764708201, Validation Accuracy: 0.4875\n",
      "Epoch 2413, Training Loss: 0.17413759952591312, Validation Loss: 0.1728221426407496, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 2414, Training Loss: 0.17340076210037356, Validation Loss: 0.17459663252035776, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 2415, Training Loss: 0.1743698908436683, Validation Loss: 0.1736370285352071, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2416, Training Loss: 0.17354484046659163, Validation Loss: 0.17463872234026592, Validation Accuracy: 0.49375\n",
      "Epoch 2417, Training Loss: 0.1740350982835216, Validation Loss: 0.17340011596679689, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 2418, Training Loss: 0.17356686438283614, Validation Loss: 0.1741865833600362, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 2419, Training Loss: 0.1741853226577082, Validation Loss: 0.1739325980345408, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 2420, Training Loss: 0.1737352023201604, Validation Loss: 0.1734896183013916, Validation Accuracy: 0.5125\n",
      "Epoch 2421, Training Loss: 0.17394278655129095, Validation Loss: 0.17411908904711407, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 2422, Training Loss: 0.17354770485431917, Validation Loss: 0.17294646004835765, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 2423, Training Loss: 0.1740286249306894, Validation Loss: 0.17431710561116537, Validation Accuracy: 0.48125\n",
      "Epoch 2424, Training Loss: 0.1736784601403821, Validation Loss: 0.17396737734476725, Validation Accuracy: 0.50625\n",
      "Epoch 2425, Training Loss: 0.17416615543826933, Validation Loss: 0.17425803740819296, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 2426, Training Loss: 0.1736405126510128, Validation Loss: 0.17213997840881348, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 2427, Training Loss: 0.17410745447681797, Validation Loss: 0.17405797640482584, Validation Accuracy: 0.475\n",
      "Epoch 2428, Training Loss: 0.1738054862906856, Validation Loss: 0.17348352173964182, Validation Accuracy: 0.5125\n",
      "Epoch 2429, Training Loss: 0.17403099517668447, Validation Loss: 0.17439561287562053, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 2430, Training Loss: 0.17363953782666114, Validation Loss: 0.1726633906364441, Validation Accuracy: 0.5375\n",
      "Epoch 2431, Training Loss: 0.17410841343864317, Validation Loss: 0.17374879419803618, Validation Accuracy: 0.4875\n",
      "Epoch 2432, Training Loss: 0.1737883581269172, Validation Loss: 0.17384548683961232, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 2433, Training Loss: 0.17403571163454362, Validation Loss: 0.17435940305391948, Validation Accuracy: 0.475\n",
      "Epoch 2434, Training Loss: 0.1737015305026885, Validation Loss: 0.17212966084480286, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 2435, Training Loss: 0.17401829121574278, Validation Loss: 0.1741359144449234, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 2436, Training Loss: 0.17370687184795255, Validation Loss: 0.1739280790090561, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2437, Training Loss: 0.17396767341321515, Validation Loss: 0.1738097647825877, Validation Accuracy: 0.4875\n",
      "Epoch 2438, Training Loss: 0.17384679759702376, Validation Loss: 0.1728410989046097, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 2439, Training Loss: 0.17400370922780806, Validation Loss: 0.17340512573719025, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 2440, Training Loss: 0.1738438505318857, Validation Loss: 0.17354851762453716, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2441, Training Loss: 0.1739672254170141, Validation Loss: 0.17352788746356965, Validation Accuracy: 0.49375\n",
      "Epoch 2442, Training Loss: 0.17384019830534536, Validation Loss: 0.17334188024202982, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 2443, Training Loss: 0.17389013978742784, Validation Loss: 0.17328545153141023, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 2444, Training Loss: 0.17393839359283447, Validation Loss: 0.17361508707205456, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 2445, Training Loss: 0.17351785830913052, Validation Loss: 0.17359585265318553, Validation Accuracy: 0.5125\n",
      "Epoch 2446, Training Loss: 0.17402402624007193, Validation Loss: 0.17363769312699637, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 2447, Training Loss: 0.17382871864303465, Validation Loss: 0.173014897108078, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 2448, Training Loss: 0.1739852572641065, Validation Loss: 0.17358584801355997, Validation Accuracy: 0.48125\n",
      "Epoch 2449, Training Loss: 0.17373545612058333, Validation Loss: 0.1733506977558136, Validation Accuracy: 0.50625\n",
      "Epoch 2450, Training Loss: 0.17399682392997126, Validation Loss: 0.1737927387158076, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 2451, Training Loss: 0.17385499852318917, Validation Loss: 0.17280198136965433, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 2452, Training Loss: 0.1739242567170051, Validation Loss: 0.173635596036911, Validation Accuracy: 0.475\n",
      "Epoch 2453, Training Loss: 0.17391602839193038, Validation Loss: 0.17322084804375967, Validation Accuracy: 0.5125\n",
      "Epoch 2454, Training Loss: 0.17385311761210043, Validation Loss: 0.17394284904003143, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 2455, Training Loss: 0.1739465700041863, Validation Loss: 0.1730777661005656, Validation Accuracy: 0.5375\n",
      "Epoch 2456, Training Loss: 0.17387667298316956, Validation Loss: 0.17364078760147095, Validation Accuracy: 0.4875\n",
      "Epoch 2457, Training Loss: 0.17379352786848623, Validation Loss: 0.1736044853925705, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 2458, Training Loss: 0.17384161487702401, Validation Loss: 0.1738453209400177, Validation Accuracy: 0.475\n",
      "Epoch 2459, Training Loss: 0.17399512423622993, Validation Loss: 0.17292800744374592, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 2460, Training Loss: 0.17385040560076315, Validation Loss: 0.17383188406626385, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 2461, Training Loss: 0.17387270302541794, Validation Loss: 0.17345507840315502, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2462, Training Loss: 0.1738010798731158, Validation Loss: 0.17374290227890016, Validation Accuracy: 0.4875\n",
      "Epoch 2463, Training Loss: 0.17402753378114394, Validation Loss: 0.17311270932356518, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 2464, Training Loss: 0.17378632195534244, Validation Loss: 0.17353672583897908, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 2465, Training Loss: 0.17390968386204012, Validation Loss: 0.17379290362199148, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2466, Training Loss: 0.17366987466812134, Validation Loss: 0.17379823128382366, Validation Accuracy: 0.49375\n",
      "Epoch 2467, Training Loss: 0.17410292548518028, Validation Loss: 0.1732804834842682, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 2468, Training Loss: 0.17386685455999068, Validation Loss: 0.1732899874448776, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 2469, Training Loss: 0.17396752728569892, Validation Loss: 0.17344363927841186, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 2470, Training Loss: 0.17373175101895486, Validation Loss: 0.1732899785041809, Validation Accuracy: 0.5125\n",
      "Epoch 2471, Training Loss: 0.17402140171297134, Validation Loss: 0.1734128733476003, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 2472, Training Loss: 0.17382703433113714, Validation Loss: 0.17291658818721772, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 2473, Training Loss: 0.1738614680305604, Validation Loss: 0.17369026243686675, Validation Accuracy: 0.48125\n",
      "Epoch 2474, Training Loss: 0.17365756198283164, Validation Loss: 0.17348990539709727, Validation Accuracy: 0.50625\n",
      "Epoch 2475, Training Loss: 0.17403687344443414, Validation Loss: 0.1736132025718689, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 2476, Training Loss: 0.17382659018039703, Validation Loss: 0.1732853978872299, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 2477, Training Loss: 0.18058427254999837, Validation Loss: 0.3792434632778168, Validation Accuracy: 0.475\n",
      "Epoch 2478, Training Loss: 0.1985586218295559, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.4875\n",
      "Epoch 2479, Training Loss: 0.18817149679506978, Validation Loss: 0.18063255846500398, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 2480, Training Loss: 0.1888316898576675, Validation Loss: 0.33679282466570537, Validation Accuracy: 0.5375\n",
      "Epoch 2481, Training Loss: 0.20173854068402322, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5125\n",
      "Epoch 2482, Training Loss: 0.1762150449137534, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5104166666666666\n",
      "Epoch 2483, Training Loss: 0.1732867956161499, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.525\n",
      "Epoch 2484, Training Loss: 0.17328791031914373, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.4395833333333333\n",
      "Epoch 2485, Training Loss: 0.1732867956161499, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5270833333333333\n",
      "Epoch 2486, Training Loss: 0.1732867956161499, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 2487, Training Loss: 0.17328682301505918, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5125\n",
      "Epoch 2488, Training Loss: 0.17328684801055538, Validation Loss: 0.17327747841676075, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 2489, Training Loss: 0.1750245233697276, Validation Loss: 0.17328677078088126, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 2490, Training Loss: 0.1732906747248865, Validation Loss: 0.17328904469807943, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2491, Training Loss: 0.17328538913880626, Validation Loss: 0.17328681349754332, Validation Accuracy: 0.49375\n",
      "Epoch 2492, Training Loss: 0.17352473014785397, Validation Loss: 0.17328677773475648, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 2493, Training Loss: 0.17328679417410203, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2494, Training Loss: 0.17329234221289236, Validation Loss: 0.17328678170839945, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 2495, Training Loss: 0.17331708919617436, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.4875\n",
      "Epoch 2496, Training Loss: 0.17328802087614614, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5208333333333334\n",
      "Epoch 2497, Training Loss: 0.17328709796551736, Validation Loss: 0.17328663070996603, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 2498, Training Loss: 0.17328778293824965, Validation Loss: 0.17328734894593556, Validation Accuracy: 0.48125\n",
      "Epoch 2499, Training Loss: 0.1760771039032167, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.49375\n",
      "Epoch 2500, Training Loss: 0.1732867956161499, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5333333333333333\n",
      "Epoch 2501, Training Loss: 0.1732867956161499, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.4479166666666667\n",
      "Epoch 2502, Training Loss: 0.1732867956161499, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.525\n",
      "Epoch 2503, Training Loss: 0.1732867956161499, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.4875\n",
      "Epoch 2504, Training Loss: 0.17328679417410203, Validation Loss: 0.17328679859638213, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 2505, Training Loss: 0.17328679898092825, Validation Loss: 0.17328671018282574, Validation Accuracy: 0.5375\n",
      "Epoch 2506, Training Loss: 0.1732867076512306, Validation Loss: 0.17328702906767526, Validation Accuracy: 0.4875\n",
      "Epoch 2507, Training Loss: 0.17328801655000256, Validation Loss: 0.17328812181949615, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 2508, Training Loss: 0.17328650384180008, Validation Loss: 0.17329564690589905, Validation Accuracy: 0.475\n",
      "Epoch 2509, Training Loss: 0.17330004034503813, Validation Loss: 0.17326376835505167, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 2510, Training Loss: 0.17329252054614405, Validation Loss: 0.17335463364919027, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 2511, Training Loss: 0.17337697167550364, Validation Loss: 0.17328693668047587, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2512, Training Loss: 0.1733022245668596, Validation Loss: 0.17330674330393472, Validation Accuracy: 0.4875\n",
      "Epoch 2513, Training Loss: 0.17338115697906864, Validation Loss: 0.1731732984383901, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 2514, Training Loss: 0.17331452090894023, Validation Loss: 0.17333244085311889, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 2515, Training Loss: 0.17343982237000619, Validation Loss: 0.17334202925364176, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2516, Training Loss: 0.17357479564605222, Validation Loss: 0.1732868432998657, Validation Accuracy: 0.49375\n",
      "Epoch 2517, Training Loss: 0.1733279901166116, Validation Loss: 0.17327954173088073, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 2518, Training Loss: 0.17333062281531672, Validation Loss: 0.17326919138431549, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 2519, Training Loss: 0.17395288088629324, Validation Loss: 0.1733040819565455, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 2520, Training Loss: 0.17329321032570255, Validation Loss: 0.1732811431090037, Validation Accuracy: 0.5125\n",
      "Epoch 2521, Training Loss: 0.17331126284214757, Validation Loss: 0.17334815859794617, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 2522, Training Loss: 0.17340210608897672, Validation Loss: 0.17312847077846527, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 2523, Training Loss: 0.17339474443466432, Validation Loss: 0.17328702211380004, Validation Accuracy: 0.48125\n",
      "Epoch 2524, Training Loss: 0.17337092276542418, Validation Loss: 0.17327781021595, Validation Accuracy: 0.50625\n",
      "Epoch 2525, Training Loss: 0.17330323496172506, Validation Loss: 0.17330213487148285, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 2526, Training Loss: 0.173390947041973, Validation Loss: 0.17305073142051697, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 2527, Training Loss: 0.1734098090279487, Validation Loss: 0.173486328125, Validation Accuracy: 0.475\n",
      "Epoch 2528, Training Loss: 0.17340681004908778, Validation Loss: 0.17326093117396038, Validation Accuracy: 0.5125\n",
      "Epoch 2529, Training Loss: 0.1733967488811862, Validation Loss: 0.1736333062251409, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 2530, Training Loss: 0.17336865009800081, Validation Loss: 0.1731368839740753, Validation Accuracy: 0.5375\n",
      "Epoch 2531, Training Loss: 0.1734211180479296, Validation Loss: 0.17341541945934297, Validation Accuracy: 0.4875\n",
      "Epoch 2532, Training Loss: 0.17345328292539042, Validation Loss: 0.1733038951953252, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 2533, Training Loss: 0.17322542302070126, Validation Loss: 0.17333583235740663, Validation Accuracy: 0.475\n",
      "Epoch 2534, Training Loss: 0.1734810726296517, Validation Loss: 0.17295444111029307, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 2535, Training Loss: 0.17337150919821956, Validation Loss: 0.17468668818473815, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 2536, Training Loss: 0.17351614900173679, Validation Loss: 0.17345583240191143, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2537, Training Loss: 0.17334168476443138, Validation Loss: 0.17368975977102916, Validation Accuracy: 0.4875\n",
      "Epoch 2538, Training Loss: 0.17356935383812075, Validation Loss: 0.1729323258002599, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 2539, Training Loss: 0.17320984842315798, Validation Loss: 0.17375955482323965, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 2540, Training Loss: 0.17369716542382393, Validation Loss: 0.17341988384723664, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2541, Training Loss: 0.17330849411026125, Validation Loss: 0.17363080978393555, Validation Accuracy: 0.49375\n",
      "Epoch 2542, Training Loss: 0.17356753301235936, Validation Loss: 0.17331583698590597, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 2543, Training Loss: 0.17334351664589298, Validation Loss: 0.1733062009016673, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 2544, Training Loss: 0.17361031472682953, Validation Loss: 0.1735288232564926, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 2545, Training Loss: 0.17337180529871293, Validation Loss: 0.17322945197423298, Validation Accuracy: 0.5125\n",
      "Epoch 2546, Training Loss: 0.17357926839782345, Validation Loss: 0.1736335059007009, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 2547, Training Loss: 0.1733515570240636, Validation Loss: 0.172992941737175, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 2548, Training Loss: 0.1735523275790676, Validation Loss: 0.173631622393926, Validation Accuracy: 0.48125\n",
      "Epoch 2549, Training Loss: 0.17339392006397247, Validation Loss: 0.17332257330417633, Validation Accuracy: 0.50625\n",
      "Epoch 2550, Training Loss: 0.17361017821296568, Validation Loss: 0.17368699312210084, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 2551, Training Loss: 0.17338991741980275, Validation Loss: 0.17271405160427095, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 2552, Training Loss: 0.1735403614659463, Validation Loss: 0.17373282909393312, Validation Accuracy: 0.475\n",
      "Epoch 2553, Training Loss: 0.1734183055739249, Validation Loss: 0.17323232889175416, Validation Accuracy: 0.5125\n",
      "Epoch 2554, Training Loss: 0.1735959288574034, Validation Loss: 0.1737660437822342, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 2555, Training Loss: 0.17339121430150925, Validation Loss: 0.17292087773482004, Validation Accuracy: 0.5375\n",
      "Epoch 2556, Training Loss: 0.17362711362300381, Validation Loss: 0.17344142198562623, Validation Accuracy: 0.4875\n",
      "Epoch 2557, Training Loss: 0.17344223683880222, Validation Loss: 0.17351040840148926, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 2558, Training Loss: 0.1735586211566002, Validation Loss: 0.1737547367811203, Validation Accuracy: 0.475\n",
      "Epoch 2559, Training Loss: 0.1734493475767874, Validation Loss: 0.17263057231903076, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 2560, Training Loss: 0.17360539157544413, Validation Loss: 0.1736145277818044, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 2561, Training Loss: 0.17346053834884398, Validation Loss: 0.1734540899594625, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2562, Training Loss: 0.17355769247778, Validation Loss: 0.17350666920344035, Validation Accuracy: 0.4875\n",
      "Epoch 2563, Training Loss: 0.17350252501426205, Validation Loss: 0.1729797214269638, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 2564, Training Loss: 0.17357353721895524, Validation Loss: 0.1733604699373245, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 2565, Training Loss: 0.17349593485555342, Validation Loss: 0.17342001100381216, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2566, Training Loss: 0.1735589600378467, Validation Loss: 0.17339525322119395, Validation Accuracy: 0.49375\n",
      "Epoch 2567, Training Loss: 0.1735196344314083, Validation Loss: 0.17328453063964844, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 2568, Training Loss: 0.1735422452611308, Validation Loss: 0.17325728138287863, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 2569, Training Loss: 0.17358089646985453, Validation Loss: 0.17339232563972473, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 2570, Training Loss: 0.17350839174562885, Validation Loss: 0.17321841220060985, Validation Accuracy: 0.5125\n",
      "Epoch 2571, Training Loss: 0.1735702964567369, Validation Loss: 0.17341811954975128, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 2572, Training Loss: 0.17353817099525082, Validation Loss: 0.1730978528658549, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 2573, Training Loss: 0.17362128150078557, Validation Loss: 0.17349583009878794, Validation Accuracy: 0.48125\n",
      "Epoch 2574, Training Loss: 0.17346528989653434, Validation Loss: 0.17329088350137076, Validation Accuracy: 0.50625\n",
      "Epoch 2575, Training Loss: 0.173579448173123, Validation Loss: 0.1736008882522583, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 2576, Training Loss: 0.1735852538577972, Validation Loss: 0.17302639186382293, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 2577, Training Loss: 0.17358572733017705, Validation Loss: 0.17370130916436513, Validation Accuracy: 0.475\n",
      "Epoch 2578, Training Loss: 0.17350032156513584, Validation Loss: 0.1732196440299352, Validation Accuracy: 0.5125\n",
      "Epoch 2579, Training Loss: 0.173588520576877, Validation Loss: 0.17381625572840373, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 2580, Training Loss: 0.17349179762025033, Validation Loss: 0.17293375929196675, Validation Accuracy: 0.5375\n",
      "Epoch 2581, Training Loss: 0.1735821303821379, Validation Loss: 0.1735226809978485, Validation Accuracy: 0.4875\n",
      "Epoch 2582, Training Loss: 0.17354740106290387, Validation Loss: 0.173432923356692, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 2583, Training Loss: 0.17352709895180118, Validation Loss: 0.17382160325845084, Validation Accuracy: 0.475\n",
      "Epoch 2584, Training Loss: 0.17360103370681887, Validation Loss: 0.17279380261898042, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 2585, Training Loss: 0.17354713620678072, Validation Loss: 0.17378657261530558, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 2586, Training Loss: 0.17358426749706268, Validation Loss: 0.17340906262397765, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2587, Training Loss: 0.17351627926672658, Validation Loss: 0.17361513276894888, Validation Accuracy: 0.4875\n",
      "Epoch 2588, Training Loss: 0.17366105462274245, Validation Loss: 0.17305514216423035, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 2589, Training Loss: 0.17348585638307756, Validation Loss: 0.17347679138183594, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 2590, Training Loss: 0.17374040715156064, Validation Loss: 0.17337527473767597, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2591, Training Loss: 0.1734230008817488, Validation Loss: 0.1735673129558563, Validation Accuracy: 0.49375\n",
      "Epoch 2592, Training Loss: 0.17372302614873456, Validation Loss: 0.1732859601577123, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 2593, Training Loss: 0.17355318271344708, Validation Loss: 0.17328794598579406, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 2594, Training Loss: 0.17364865685662917, Validation Loss: 0.17345417042573294, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 2595, Training Loss: 0.17350486209315638, Validation Loss: 0.17324125568072002, Validation Accuracy: 0.5125\n",
      "Epoch 2596, Training Loss: 0.17361455915435667, Validation Loss: 0.17351967394351958, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 2597, Training Loss: 0.17357120927303069, Validation Loss: 0.1729941924413045, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 2598, Training Loss: 0.17356799735176948, Validation Loss: 0.17366158763567607, Validation Accuracy: 0.48125\n",
      "Epoch 2599, Training Loss: 0.17346578499963206, Validation Loss: 0.17336952984333037, Validation Accuracy: 0.50625\n",
      "Epoch 2600, Training Loss: 0.17377689240440244, Validation Loss: 0.1735427995522817, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 2601, Training Loss: 0.17346580470761946, Validation Loss: 0.17244739631811778, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 2602, Training Loss: 0.1736246039790492, Validation Loss: 0.17375675439834595, Validation Accuracy: 0.475\n",
      "Epoch 2603, Training Loss: 0.17350924928342143, Validation Loss: 0.173259699344635, Validation Accuracy: 0.5125\n",
      "Epoch 2604, Training Loss: 0.17369936695021967, Validation Loss: 0.17362838884194692, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 2605, Training Loss: 0.17353079011363368, Validation Loss: 0.1728182057539622, Validation Accuracy: 0.5375\n",
      "Epoch 2606, Training Loss: 0.17370665602145657, Validation Loss: 0.17349228064219158, Validation Accuracy: 0.4875\n",
      "Epoch 2607, Training Loss: 0.17347335238610545, Validation Loss: 0.17378060917059582, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 2608, Training Loss: 0.17374158290124708, Validation Loss: 0.1735861122608185, Validation Accuracy: 0.475\n",
      "Epoch 2609, Training Loss: 0.17348478253810637, Validation Loss: 0.17226784825325012, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 2610, Training Loss: 0.1737832167456227, Validation Loss: 0.17356999814510346, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 2611, Training Loss: 0.17346443428147224, Validation Loss: 0.17377937038739522, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2612, Training Loss: 0.17373758314117307, Validation Loss: 0.17348323961098988, Validation Accuracy: 0.4875\n",
      "Epoch 2613, Training Loss: 0.17352584581221303, Validation Loss: 0.1728030244509379, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 2614, Training Loss: 0.17366281584385904, Validation Loss: 0.1734170486529668, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 2615, Training Loss: 0.17352443885418675, Validation Loss: 0.17372947533925373, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2616, Training Loss: 0.1738297982561973, Validation Loss: 0.17334669530391694, Validation Accuracy: 0.49375\n",
      "Epoch 2617, Training Loss: 0.17351928930128774, Validation Loss: 0.17342716455459595, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 2618, Training Loss: 0.17378768517125037, Validation Loss: 0.17325730323791505, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 2619, Training Loss: 0.17342925888876762, Validation Loss: 0.17419185241063437, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 2620, Training Loss: 0.17384536275940557, Validation Loss: 0.17323588331540427, Validation Accuracy: 0.5125\n",
      "Epoch 2621, Training Loss: 0.17351937245938084, Validation Loss: 0.17416467368602753, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 2622, Training Loss: 0.17371169213325746, Validation Loss: 0.1731734464565913, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 2623, Training Loss: 0.17349273591272293, Validation Loss: 0.1742269923289617, Validation Accuracy: 0.48125\n",
      "Epoch 2624, Training Loss: 0.1738413437720268, Validation Loss: 0.17326972484588624, Validation Accuracy: 0.50625\n",
      "Epoch 2625, Training Loss: 0.17343503813589772, Validation Loss: 0.17473663588364918, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 2626, Training Loss: 0.17391963879908284, Validation Loss: 0.17308010359605153, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 2627, Training Loss: 0.17336873421745916, Validation Loss: 0.17465847531954448, Validation Accuracy: 0.475\n",
      "Epoch 2628, Training Loss: 0.17397214328089067, Validation Loss: 0.17321719924608867, Validation Accuracy: 0.5125\n",
      "Epoch 2629, Training Loss: 0.17336744358462672, Validation Loss: 0.1747059871753057, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 2630, Training Loss: 0.17385935831454494, Validation Loss: 0.17318233251571655, Validation Accuracy: 0.5375\n",
      "Epoch 2631, Training Loss: 0.17340321310104861, Validation Loss: 0.17430953284104664, Validation Accuracy: 0.4875\n",
      "Epoch 2632, Training Loss: 0.17394418677976053, Validation Loss: 0.17334182957808178, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 2633, Training Loss: 0.1735004484653473, Validation Loss: 0.1745764881372452, Validation Accuracy: 0.475\n",
      "Epoch 2634, Training Loss: 0.1737798726366412, Validation Loss: 0.17312139372030894, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 2635, Training Loss: 0.17351691280641862, Validation Loss: 0.1748767117659251, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 2636, Training Loss: 0.17387215648927995, Validation Loss: 0.17357841432094573, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2637, Training Loss: 0.17346339312291914, Validation Loss: 0.17430717945098878, Validation Accuracy: 0.4875\n",
      "Epoch 2638, Training Loss: 0.17387240211809835, Validation Loss: 0.1730968862771988, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 2639, Training Loss: 0.17339272508698125, Validation Loss: 0.17425151268641154, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 2640, Training Loss: 0.17388801420888594, Validation Loss: 0.17375851571559905, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2641, Training Loss: 0.173535259019944, Validation Loss: 0.17417358954747517, Validation Accuracy: 0.49375\n",
      "Epoch 2642, Training Loss: 0.17389623820781708, Validation Loss: 0.17331769863764446, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 2643, Training Loss: 0.173427632739467, Validation Loss: 0.17361976106961569, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 2644, Training Loss: 0.17381440103054047, Validation Loss: 0.174075781305631, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 2645, Training Loss: 0.1735106562414477, Validation Loss: 0.17353939910729727, Validation Accuracy: 0.5125\n",
      "Epoch 2646, Training Loss: 0.1739642749870977, Validation Loss: 0.17425214250882468, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 2647, Training Loss: 0.17352965954811342, Validation Loss: 0.1729457050561905, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 2648, Training Loss: 0.17387997094661958, Validation Loss: 0.17427151004473368, Validation Accuracy: 0.48125\n",
      "Epoch 2649, Training Loss: 0.17348619814841978, Validation Loss: 0.1736203610897064, Validation Accuracy: 0.50625\n",
      "Epoch 2650, Training Loss: 0.17399005639937618, Validation Loss: 0.174581249554952, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 2651, Training Loss: 0.1735620253509091, Validation Loss: 0.17231022715568542, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 2652, Training Loss: 0.17383359132274503, Validation Loss: 0.17461703817049662, Validation Accuracy: 0.475\n",
      "Epoch 2653, Training Loss: 0.17372255075362422, Validation Loss: 0.173374476035436, Validation Accuracy: 0.5125\n",
      "Epoch 2654, Training Loss: 0.17369361077585527, Validation Loss: 0.17485493222872417, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 2655, Training Loss: 0.17374357773411658, Validation Loss: 0.17272500097751617, Validation Accuracy: 0.5375\n",
      "Epoch 2656, Training Loss: 0.17362240677879703, Validation Loss: 0.17436772386233013, Validation Accuracy: 0.4875\n",
      "Epoch 2657, Training Loss: 0.1737517839477908, Validation Loss: 0.17407160798708599, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 2658, Training Loss: 0.17370374308478448, Validation Loss: 0.17490309874216717, Validation Accuracy: 0.475\n",
      "Epoch 2659, Training Loss: 0.17386910271260045, Validation Loss: 0.17207449873288472, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 2660, Training Loss: 0.1735946314950143, Validation Loss: 0.1751613736152649, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 2661, Training Loss: 0.17394917338125168, Validation Loss: 0.1738074352343877, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2662, Training Loss: 0.17353782730717812, Validation Loss: 0.1743645191192627, Validation Accuracy: 0.4875\n",
      "Epoch 2663, Training Loss: 0.17397344064327977, Validation Loss: 0.17282167176405588, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 2664, Training Loss: 0.17336425713954434, Validation Loss: 0.17412664294242858, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 2665, Training Loss: 0.17425273791436227, Validation Loss: 0.17379440267880758, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2666, Training Loss: 0.17345920541594106, Validation Loss: 0.1740579128265381, Validation Accuracy: 0.49375\n",
      "Epoch 2667, Training Loss: 0.17395669846765457, Validation Loss: 0.17349249124526978, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 2668, Training Loss: 0.1735364487094264, Validation Loss: 0.1735918571551641, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 2669, Training Loss: 0.1740213728720142, Validation Loss: 0.17396608491738638, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 2670, Training Loss: 0.17359992813679478, Validation Loss: 0.17342400848865508, Validation Accuracy: 0.5125\n",
      "Epoch 2671, Training Loss: 0.173956076945028, Validation Loss: 0.17411912679672242, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 2672, Training Loss: 0.1735284213096865, Validation Loss: 0.17291646897792817, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 2673, Training Loss: 0.17393467743550578, Validation Loss: 0.1740707298119863, Validation Accuracy: 0.48125\n",
      "Epoch 2674, Training Loss: 0.17361939049536182, Validation Loss: 0.17359483738740286, Validation Accuracy: 0.50625\n",
      "Epoch 2675, Training Loss: 0.17389363819553005, Validation Loss: 0.17450220088164012, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 2676, Training Loss: 0.17362345178281108, Validation Loss: 0.1722978711128235, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 2677, Training Loss: 0.17389644297861284, Validation Loss: 0.1742745856444041, Validation Accuracy: 0.475\n",
      "Epoch 2678, Training Loss: 0.17367308370528683, Validation Loss: 0.1734063466389974, Validation Accuracy: 0.5125\n",
      "Epoch 2679, Training Loss: 0.1738891053584314, Validation Loss: 0.17408985296885174, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 2680, Training Loss: 0.17360820837559238, Validation Loss: 0.17272727588812511, Validation Accuracy: 0.5375\n",
      "Epoch 2681, Training Loss: 0.17394659548036515, Validation Loss: 0.17374474704265594, Validation Accuracy: 0.4875\n",
      "Epoch 2682, Training Loss: 0.1736658984614957, Validation Loss: 0.17402140100797017, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 2683, Training Loss: 0.17388498783111572, Validation Loss: 0.17420736253261565, Validation Accuracy: 0.475\n",
      "Epoch 2684, Training Loss: 0.17368208400664792, Validation Loss: 0.17230957051118215, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 2685, Training Loss: 0.1739100025546166, Validation Loss: 0.17405718068281809, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 2686, Training Loss: 0.1737060373829257, Validation Loss: 0.17370138863722484, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2687, Training Loss: 0.17391457192359433, Validation Loss: 0.1736710011959076, Validation Accuracy: 0.4875\n",
      "Epoch 2688, Training Loss: 0.17375785208517505, Validation Loss: 0.17283629775047302, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 2689, Training Loss: 0.17392805314833118, Validation Loss: 0.1734877030054728, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 2690, Training Loss: 0.17376176724510808, Validation Loss: 0.17353791097799937, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2691, Training Loss: 0.1738565275746007, Validation Loss: 0.17384733458360035, Validation Accuracy: 0.49375\n",
      "Epoch 2692, Training Loss: 0.17372129184584464, Validation Loss: 0.17334137658278148, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 2693, Training Loss: 0.17381461926044955, Validation Loss: 0.1733303775389989, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 2694, Training Loss: 0.17387612115952275, Validation Loss: 0.17357789476712546, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 2695, Training Loss: 0.17368352076699656, Validation Loss: 0.17324588497479756, Validation Accuracy: 0.5125\n",
      "Epoch 2696, Training Loss: 0.17394115319175105, Validation Loss: 0.17364157537619274, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 2697, Training Loss: 0.17365681355999363, Validation Loss: 0.17292953232924144, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 2698, Training Loss: 0.17400828869112075, Validation Loss: 0.1736497014760971, Validation Accuracy: 0.48125\n",
      "Epoch 2699, Training Loss: 0.1736677010213175, Validation Loss: 0.17340560456116993, Validation Accuracy: 0.50625\n",
      "Epoch 2700, Training Loss: 0.17392849729907128, Validation Loss: 0.1737219750881195, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 2701, Training Loss: 0.17372885442549182, Validation Loss: 0.17253665924072265, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 2702, Training Loss: 0.17396539738101344, Validation Loss: 0.1738841821750005, Validation Accuracy: 0.475\n",
      "Epoch 2703, Training Loss: 0.17373038732236432, Validation Loss: 0.17323244313398997, Validation Accuracy: 0.5125\n",
      "Epoch 2704, Training Loss: 0.17382071239333, Validation Loss: 0.17378828823566436, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 2705, Training Loss: 0.17386785293779067, Validation Loss: 0.1729188193877538, Validation Accuracy: 0.5375\n",
      "Epoch 2706, Training Loss: 0.1738435895212235, Validation Loss: 0.1736234664916992, Validation Accuracy: 0.4875\n",
      "Epoch 2707, Training Loss: 0.17373990676095408, Validation Loss: 0.17367657721042634, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 2708, Training Loss: 0.17378619265171788, Validation Loss: 0.17400700449943543, Validation Accuracy: 0.475\n",
      "Epoch 2709, Training Loss: 0.17388440139832034, Validation Loss: 0.1725991815328598, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 2710, Training Loss: 0.17379726517585017, Validation Loss: 0.17394887606302897, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 2711, Training Loss: 0.17375644897260972, Validation Loss: 0.17359769145647685, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2712, Training Loss: 0.17378029419529822, Validation Loss: 0.1737048516670863, Validation Accuracy: 0.4875\n",
      "Epoch 2713, Training Loss: 0.17394362966860494, Validation Loss: 0.17298883895079295, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 2714, Training Loss: 0.17369188656730036, Validation Loss: 0.17357583343982697, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 2715, Training Loss: 0.17396453167161635, Validation Loss: 0.17351592481136321, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2716, Training Loss: 0.17364238827459275, Validation Loss: 0.1736999958753586, Validation Accuracy: 0.49375\n",
      "Epoch 2717, Training Loss: 0.17398260822219233, Validation Loss: 0.17331080436706542, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 2718, Training Loss: 0.173805391115527, Validation Loss: 0.17334788640340168, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 2719, Training Loss: 0.17378977277586538, Validation Loss: 0.17374925116697948, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 2720, Training Loss: 0.17377760717945714, Validation Loss: 0.17327958544095357, Validation Accuracy: 0.5125\n",
      "Epoch 2721, Training Loss: 0.1738574937466652, Validation Loss: 0.1736121873060862, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 2722, Training Loss: 0.17381642037822354, Validation Loss: 0.17292063931624094, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 2723, Training Loss: 0.17377105355262756, Validation Loss: 0.17381622393925986, Validation Accuracy: 0.48125\n",
      "Epoch 2724, Training Loss: 0.17366852539200936, Validation Loss: 0.17349099814891816, Validation Accuracy: 0.50625\n",
      "Epoch 2725, Training Loss: 0.17399018858709642, Validation Loss: 0.17372385362784068, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 2726, Training Loss: 0.17368638611608936, Validation Loss: 0.17235887547334036, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 2727, Training Loss: 0.17391597263274655, Validation Loss: 0.1737336426973343, Validation Accuracy: 0.475\n",
      "Epoch 2728, Training Loss: 0.1736375824097664, Validation Loss: 0.17331677079200744, Validation Accuracy: 0.5125\n",
      "Epoch 2729, Training Loss: 0.17407695131917153, Validation Loss: 0.17353713909784954, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 2730, Training Loss: 0.17366043550352897, Validation Loss: 0.17267398536205292, Validation Accuracy: 0.5375\n",
      "Epoch 2731, Training Loss: 0.17395248864927598, Validation Loss: 0.17354404131571452, Validation Accuracy: 0.4875\n",
      "Epoch 2732, Training Loss: 0.17365371219573483, Validation Loss: 0.17386153042316438, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 2733, Training Loss: 0.17407266507225652, Validation Loss: 0.17346907953421276, Validation Accuracy: 0.475\n",
      "Epoch 2734, Training Loss: 0.17365176927658818, Validation Loss: 0.17215895851453145, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 2735, Training Loss: 0.17405042581019864, Validation Loss: 0.1735686590274175, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 2736, Training Loss: 0.17362016151028295, Validation Loss: 0.17379502654075624, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2737, Training Loss: 0.1739909485463173, Validation Loss: 0.17339419424533845, Validation Accuracy: 0.4875\n",
      "Epoch 2738, Training Loss: 0.1736816191865552, Validation Loss: 0.17287664810816447, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 2739, Training Loss: 0.17392338379736869, Validation Loss: 0.1733551601568858, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 2740, Training Loss: 0.1736829425058057, Validation Loss: 0.17379373908042908, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2741, Training Loss: 0.174007190331336, Validation Loss: 0.1733173906803131, Validation Accuracy: 0.49375\n",
      "Epoch 2742, Training Loss: 0.17378097051574337, Validation Loss: 0.17343315879503887, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 2743, Training Loss: 0.1738667194881747, Validation Loss: 0.1732644816239675, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 2744, Training Loss: 0.17362323835972818, Validation Loss: 0.1743191401163737, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 2745, Training Loss: 0.17404495804540573, Validation Loss: 0.17327026029427847, Validation Accuracy: 0.5125\n",
      "Epoch 2746, Training Loss: 0.1737342135560128, Validation Loss: 0.17422935068607331, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 2747, Training Loss: 0.17386534089042294, Validation Loss: 0.17310688992341358, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 2748, Training Loss: 0.1736757678370322, Validation Loss: 0.17440569599469502, Validation Accuracy: 0.48125\n",
      "Epoch 2749, Training Loss: 0.17400452638826064, Validation Loss: 0.17327760060628256, Validation Accuracy: 0.50625\n",
      "Epoch 2750, Training Loss: 0.1736169385333215, Validation Loss: 0.17500222822030384, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 2751, Training Loss: 0.17408991917487113, Validation Loss: 0.17320801516373951, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 2752, Training Loss: 0.1735277598904025, Validation Loss: 0.17485803961753846, Validation Accuracy: 0.475\n",
      "Epoch 2753, Training Loss: 0.17420416589706175, Validation Loss: 0.17326178749402363, Validation Accuracy: 0.5125\n",
      "Epoch 2754, Training Loss: 0.17349511433032253, Validation Loss: 0.17532909711201985, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 2755, Training Loss: 0.17412633713214629, Validation Loss: 0.17321552634239196, Validation Accuracy: 0.5375\n",
      "Epoch 2756, Training Loss: 0.1734797353706052, Validation Loss: 0.17456424733002981, Validation Accuracy: 0.4875\n",
      "Epoch 2757, Training Loss: 0.17425697320891964, Validation Loss: 0.1733682245016098, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 2758, Training Loss: 0.1736064351374103, Validation Loss: 0.1751504917939504, Validation Accuracy: 0.475\n",
      "Epoch 2759, Training Loss: 0.17406143728763826, Validation Loss: 0.1728869318962097, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 2760, Training Loss: 0.1735867896387654, Validation Loss: 0.17508014043172201, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 2761, Training Loss: 0.17411107738171855, Validation Loss: 0.17360338767369587, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2762, Training Loss: 0.17354739337198197, Validation Loss: 0.1748396098613739, Validation Accuracy: 0.4875\n",
      "Epoch 2763, Training Loss: 0.17409308158582257, Validation Loss: 0.17286055584748586, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 2764, Training Loss: 0.17348426724633864, Validation Loss: 0.17467403709888457, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 2765, Training Loss: 0.17412036705401637, Validation Loss: 0.173805965979894, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2766, Training Loss: 0.17358550910026796, Validation Loss: 0.17472812334696453, Validation Accuracy: 0.49375\n",
      "Epoch 2767, Training Loss: 0.17411438543950358, Validation Loss: 0.17340870102246603, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 2768, Training Loss: 0.173476483072004, Validation Loss: 0.17380065619945526, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 2769, Training Loss: 0.1740329433833399, Validation Loss: 0.1742848773797353, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 2770, Training Loss: 0.17356157302856445, Validation Loss: 0.17382550736268362, Validation Accuracy: 0.5125\n",
      "Epoch 2771, Training Loss: 0.1742072812011165, Validation Loss: 0.17401322722434998, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 2772, Training Loss: 0.173488030510564, Validation Loss: 0.1730516066153844, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 2773, Training Loss: 0.1741350850751323, Validation Loss: 0.174396018187205, Validation Accuracy: 0.48125\n",
      "Epoch 2774, Training Loss: 0.17354643008401316, Validation Loss: 0.17357427179813384, Validation Accuracy: 0.50625\n",
      "Epoch 2775, Training Loss: 0.17421282058761967, Validation Loss: 0.17427200178305308, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 2776, Training Loss: 0.17352709318360976, Validation Loss: 0.17213190197944642, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 2777, Training Loss: 0.17399166764751559, Validation Loss: 0.175151855746905, Validation Accuracy: 0.475\n",
      "Epoch 2778, Training Loss: 0.17380121013810557, Validation Loss: 0.1735527276992798, Validation Accuracy: 0.5125\n",
      "Epoch 2779, Training Loss: 0.17379144747411052, Validation Loss: 0.17541860143343607, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 2780, Training Loss: 0.173856419901694, Validation Loss: 0.17266069153944652, Validation Accuracy: 0.5375\n",
      "Epoch 2781, Training Loss: 0.1737365141030281, Validation Loss: 0.17497188846270242, Validation Accuracy: 0.4875\n",
      "Epoch 2782, Training Loss: 0.17386805963131688, Validation Loss: 0.17407962083816528, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 2783, Training Loss: 0.1738403775999623, Validation Loss: 0.17540947198867798, Validation Accuracy: 0.475\n",
      "Epoch 2784, Training Loss: 0.17388963122521678, Validation Loss: 0.17212286988894146, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 2785, Training Loss: 0.17366534663784888, Validation Loss: 0.17555677791436514, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 2786, Training Loss: 0.17405074258004466, Validation Loss: 0.17403943141301473, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2787, Training Loss: 0.17360481523698376, Validation Loss: 0.1746445228656133, Validation Accuracy: 0.4875\n",
      "Epoch 2788, Training Loss: 0.17413127758810598, Validation Loss: 0.17280436257521312, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 2789, Training Loss: 0.1734013124819725, Validation Loss: 0.17441789706548055, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 2790, Training Loss: 0.17438080954936244, Validation Loss: 0.17366795043150585, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2791, Training Loss: 0.173532429241365, Validation Loss: 0.17432666420936585, Validation Accuracy: 0.49375\n",
      "Epoch 2792, Training Loss: 0.17412518541659078, Validation Loss: 0.17355289657910664, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 2793, Training Loss: 0.17357200576413062, Validation Loss: 0.17402511537075044, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 2794, Training Loss: 0.17417503364624515, Validation Loss: 0.17395177483558655, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 2795, Training Loss: 0.17365189377338655, Validation Loss: 0.17362780769666036, Validation Accuracy: 0.5125\n",
      "Epoch 2796, Training Loss: 0.17409056473162868, Validation Loss: 0.17423207263151805, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 2797, Training Loss: 0.17356604145419213, Validation Loss: 0.1729641745487849, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 2798, Training Loss: 0.1739588226041486, Validation Loss: 0.17479308048884074, Validation Accuracy: 0.48125\n",
      "Epoch 2799, Training Loss: 0.1736641997291196, Validation Loss: 0.1736640900373459, Validation Accuracy: 0.50625\n",
      "Epoch 2800, Training Loss: 0.17395541216096572, Validation Loss: 0.17477996448675792, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 2801, Training Loss: 0.1736838356141121, Validation Loss: 0.17229296763737997, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 2802, Training Loss: 0.17402347201301205, Validation Loss: 0.17417404552300772, Validation Accuracy: 0.475\n",
      "Epoch 2803, Training Loss: 0.17372612270616716, Validation Loss: 0.17339179317156475, Validation Accuracy: 0.5125\n",
      "Epoch 2804, Training Loss: 0.17395459932665672, Validation Loss: 0.17461016277472177, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 2805, Training Loss: 0.17359096629004325, Validation Loss: 0.1726591388384501, Validation Accuracy: 0.5375\n",
      "Epoch 2806, Training Loss: 0.174092439874526, Validation Loss: 0.1736703266700109, Validation Accuracy: 0.4875\n",
      "Epoch 2807, Training Loss: 0.17371768912961405, Validation Loss: 0.1738355298837026, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 2808, Training Loss: 0.17400892223081282, Validation Loss: 0.17406780322392781, Validation Accuracy: 0.475\n",
      "Epoch 2809, Training Loss: 0.17371951139742328, Validation Loss: 0.17227071126302082, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 2810, Training Loss: 0.1740067139748604, Validation Loss: 0.1739189475774765, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 2811, Training Loss: 0.17377921602418345, Validation Loss: 0.17375150521596272, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2812, Training Loss: 0.17382942668853268, Validation Loss: 0.17412398457527162, Validation Accuracy: 0.4875\n",
      "Epoch 2813, Training Loss: 0.17382688964566878, Validation Loss: 0.17283745209376017, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 2814, Training Loss: 0.17396895491307782, Validation Loss: 0.17347972393035888, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 2815, Training Loss: 0.17380774838309135, Validation Loss: 0.17357367078463237, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2816, Training Loss: 0.17385153039809195, Validation Loss: 0.1736182043949763, Validation Accuracy: 0.49375\n",
      "Epoch 2817, Training Loss: 0.1738182412039849, Validation Loss: 0.17335064013799031, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 2818, Training Loss: 0.1738904570379565, Validation Loss: 0.173274294535319, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 2819, Training Loss: 0.17394215108886843, Validation Loss: 0.17359129389127095, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 2820, Training Loss: 0.17367270108192198, Validation Loss: 0.17326735655466716, Validation Accuracy: 0.5125\n",
      "Epoch 2821, Training Loss: 0.1739451721791298, Validation Loss: 0.17361708482106528, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 2822, Training Loss: 0.1737529880577518, Validation Loss: 0.1729595442612966, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 2823, Training Loss: 0.17401152080105198, Validation Loss: 0.17361352145671843, Validation Accuracy: 0.48125\n",
      "Epoch 2824, Training Loss: 0.17372108322958793, Validation Loss: 0.17340308328469595, Validation Accuracy: 0.50625\n",
      "Epoch 2825, Training Loss: 0.17391636390839854, Validation Loss: 0.17372886339823404, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 2826, Training Loss: 0.17392091405007146, Validation Loss: 0.17290040453275043, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 2827, Training Loss: 0.17390849561460556, Validation Loss: 0.17363842129707335, Validation Accuracy: 0.475\n",
      "Epoch 2828, Training Loss: 0.17370881332505134, Validation Loss: 0.17328649858633677, Validation Accuracy: 0.5125\n",
      "Epoch 2829, Training Loss: 0.17388872417711443, Validation Loss: 0.1737185686826706, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 2830, Training Loss: 0.1738984440603564, Validation Loss: 0.17293875614802043, Validation Accuracy: 0.5375\n",
      "Epoch 2831, Training Loss: 0.17388601408850762, Validation Loss: 0.17372527420520784, Validation Accuracy: 0.4875\n",
      "Epoch 2832, Training Loss: 0.1738150345702325, Validation Loss: 0.1735933115084966, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 2833, Training Loss: 0.1737710468230709, Validation Loss: 0.17403732140858968, Validation Accuracy: 0.475\n",
      "Epoch 2834, Training Loss: 0.17404030311492183, Validation Loss: 0.17294033964474995, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 2835, Training Loss: 0.17381803306841082, Validation Loss: 0.17397209405899047, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 2836, Training Loss: 0.17382791686442592, Validation Loss: 0.1735210637251536, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2837, Training Loss: 0.17380880732690135, Validation Loss: 0.1737085739771525, Validation Accuracy: 0.4875\n",
      "Epoch 2838, Training Loss: 0.17391666769981384, Validation Loss: 0.17294872899850208, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 2839, Training Loss: 0.17379537513179164, Validation Loss: 0.1735551138718923, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 2840, Training Loss: 0.1739133144578626, Validation Loss: 0.173693444331487, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2841, Training Loss: 0.17369125302760832, Validation Loss: 0.1736784319082896, Validation Accuracy: 0.49375\n",
      "Epoch 2842, Training Loss: 0.17404162355007663, Validation Loss: 0.173289688428243, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 2843, Training Loss: 0.17381823687784134, Validation Loss: 0.17327750225861868, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 2844, Training Loss: 0.1737488503417661, Validation Loss: 0.17390577594439188, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 2845, Training Loss: 0.17384244886136824, Validation Loss: 0.17325121760368348, Validation Accuracy: 0.5125\n",
      "Epoch 2846, Training Loss: 0.1739075078118232, Validation Loss: 0.17353387673695883, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 2847, Training Loss: 0.17385717889954966, Validation Loss: 0.1729437510172526, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 2848, Training Loss: 0.173784087261846, Validation Loss: 0.17380844056606293, Validation Accuracy: 0.48125\n",
      "Epoch 2849, Training Loss: 0.17372416055971576, Validation Loss: 0.1734137495358785, Validation Accuracy: 0.50625\n",
      "Epoch 2850, Training Loss: 0.1740307274364656, Validation Loss: 0.17359579602877298, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 2851, Training Loss: 0.17375322407291782, Validation Loss: 0.172447873155276, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 2852, Training Loss: 0.1738999875322465, Validation Loss: 0.17378039956092833, Validation Accuracy: 0.475\n",
      "Epoch 2853, Training Loss: 0.17373604255337868, Validation Loss: 0.17328758239746095, Validation Accuracy: 0.5125\n",
      "Epoch 2854, Training Loss: 0.17407586786054796, Validation Loss: 0.17348527908325195, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 2855, Training Loss: 0.17370890128997066, Validation Loss: 0.1727161516745885, Validation Accuracy: 0.5375\n",
      "Epoch 2856, Training Loss: 0.1740093005280341, Validation Loss: 0.1734584261973699, Validation Accuracy: 0.4875\n",
      "Epoch 2857, Training Loss: 0.17366268846296495, Validation Loss: 0.17371268967787426, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 2858, Training Loss: 0.1741492094532136, Validation Loss: 0.17341087460517884, Validation Accuracy: 0.475\n",
      "Epoch 2859, Training Loss: 0.1736773612999147, Validation Loss: 0.1721447229385376, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 2860, Training Loss: 0.17409482598304749, Validation Loss: 0.1734851082166036, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 2861, Training Loss: 0.17364083086290666, Validation Loss: 0.17363620201746624, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2862, Training Loss: 0.17406754195690155, Validation Loss: 0.17336525718371074, Validation Accuracy: 0.4875\n",
      "Epoch 2863, Training Loss: 0.17377130975646357, Validation Loss: 0.17286698122819263, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 2864, Training Loss: 0.1737889911859266, Validation Loss: 0.17356571853160857, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 2865, Training Loss: 0.17374833745341148, Validation Loss: 0.17365901271502177, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2866, Training Loss: 0.17409567534923553, Validation Loss: 0.17331180969874063, Validation Accuracy: 0.49375\n",
      "Epoch 2867, Training Loss: 0.17386011154420913, Validation Loss: 0.17334899803002676, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 2868, Training Loss: 0.1738685412753013, Validation Loss: 0.1732558290163676, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 2869, Training Loss: 0.17366920219313714, Validation Loss: 0.17434351940949758, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 2870, Training Loss: 0.1741035633510159, Validation Loss: 0.1732615162928899, Validation Accuracy: 0.5125\n",
      "Epoch 2871, Training Loss: 0.17374992514810256, Validation Loss: 0.174050772190094, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 2872, Training Loss: 0.17392131686210632, Validation Loss: 0.17318521440029144, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 2873, Training Loss: 0.17366300523281097, Validation Loss: 0.1741110384464264, Validation Accuracy: 0.48125\n",
      "Epoch 2874, Training Loss: 0.1740260446263898, Validation Loss: 0.17327560385068258, Validation Accuracy: 0.50625\n",
      "Epoch 2875, Training Loss: 0.1737084787699484, Validation Loss: 0.17468390266100567, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 2876, Training Loss: 0.1740697838606373, Validation Loss: 0.173187455534935, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 2877, Training Loss: 0.17356292518877214, Validation Loss: 0.1749239484469096, Validation Accuracy: 0.475\n",
      "Epoch 2878, Training Loss: 0.17422512606267007, Validation Loss: 0.1732456425825755, Validation Accuracy: 0.5125\n",
      "Epoch 2879, Training Loss: 0.17356741188033933, Validation Loss: 0.1752636690934499, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 2880, Training Loss: 0.17407937540161994, Validation Loss: 0.17323693931102752, Validation Accuracy: 0.5375\n",
      "Epoch 2881, Training Loss: 0.1735199531239848, Validation Loss: 0.1748030424118042, Validation Accuracy: 0.4875\n",
      "Epoch 2882, Training Loss: 0.1742488366942252, Validation Loss: 0.17332329054673512, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 2883, Training Loss: 0.17367268858417387, Validation Loss: 0.17521194219589234, Validation Accuracy: 0.475\n",
      "Epoch 2884, Training Loss: 0.1740087035202211, Validation Loss: 0.17321762243906658, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 2885, Training Loss: 0.17364181145544974, Validation Loss: 0.17494117816289265, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 2886, Training Loss: 0.17408374961345427, Validation Loss: 0.17333175440629323, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2887, Training Loss: 0.1736210003014534, Validation Loss: 0.1748510797818502, Validation Accuracy: 0.4875\n",
      "Epoch 2888, Training Loss: 0.17410181030150382, Validation Loss: 0.1731586088736852, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 2889, Training Loss: 0.1734770171103939, Validation Loss: 0.17478452622890472, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 2890, Training Loss: 0.17429086565971375, Validation Loss: 0.1736828456322352, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2891, Training Loss: 0.17351892782795814, Validation Loss: 0.17495940128962198, Validation Accuracy: 0.49375\n",
      "Epoch 2892, Training Loss: 0.17423286024601228, Validation Loss: 0.17357234557469686, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 2893, Training Loss: 0.17353437552528997, Validation Loss: 0.1740873336791992, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 2894, Training Loss: 0.17414709252695884, Validation Loss: 0.17366100549697877, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 2895, Training Loss: 0.1735009781775936, Validation Loss: 0.17364120682080586, Validation Accuracy: 0.5125\n",
      "Epoch 2896, Training Loss: 0.17418778471408353, Validation Loss: 0.17427762647469838, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 2897, Training Loss: 0.1735632933916584, Validation Loss: 0.17294836541016897, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 2898, Training Loss: 0.17417644589178025, Validation Loss: 0.17370793024698894, Validation Accuracy: 0.48125\n",
      "Epoch 2899, Training Loss: 0.1733988537903755, Validation Loss: 0.17403765519460043, Validation Accuracy: 0.50625\n",
      "Epoch 2900, Training Loss: 0.17427618465115946, Validation Loss: 0.17496692339579265, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 2901, Training Loss: 0.17357378092504316, Validation Loss: 0.17215350965658824, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 2902, Training Loss: 0.17405327385471714, Validation Loss: 0.1751543790102005, Validation Accuracy: 0.475\n",
      "Epoch 2903, Training Loss: 0.17382801300094974, Validation Loss: 0.17360438108444215, Validation Accuracy: 0.5125\n",
      "Epoch 2904, Training Loss: 0.17384130002990847, Validation Loss: 0.17578140397866568, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 2905, Training Loss: 0.1738746238331641, Validation Loss: 0.17266204059123993, Validation Accuracy: 0.5375\n",
      "Epoch 2906, Training Loss: 0.17384207537097315, Validation Loss: 0.17532875537872314, Validation Accuracy: 0.4875\n",
      "Epoch 2907, Training Loss: 0.17377832243519445, Validation Loss: 0.1745098998149236, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 2908, Training Loss: 0.17391364709023507, Validation Loss: 0.1756909042596817, Validation Accuracy: 0.475\n",
      "Epoch 2909, Training Loss: 0.17394110368144128, Validation Loss: 0.17225916385650636, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 2910, Training Loss: 0.17371453681299764, Validation Loss: 0.17685956557591756, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 2911, Training Loss: 0.17398571775805566, Validation Loss: 0.1741737385590871, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2912, Training Loss: 0.17369484709155175, Validation Loss: 0.17486168444156647, Validation Accuracy: 0.4875\n",
      "Epoch 2913, Training Loss: 0.17416395391187361, Validation Loss: 0.17285624543825787, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 2914, Training Loss: 0.1733942041474004, Validation Loss: 0.1750660628080368, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 2915, Training Loss: 0.17449989626484533, Validation Loss: 0.17377341787020364, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2916, Training Loss: 0.17349698418571102, Validation Loss: 0.17457764148712157, Validation Accuracy: 0.49375\n",
      "Epoch 2917, Training Loss: 0.1741710247532014, Validation Loss: 0.1737111469109853, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 2918, Training Loss: 0.17361079637081392, Validation Loss: 0.17403208712736765, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 2919, Training Loss: 0.1742040495718679, Validation Loss: 0.17402832607428234, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 2920, Training Loss: 0.17369194040375371, Validation Loss: 0.1738248477379481, Validation Accuracy: 0.5125\n",
      "Epoch 2921, Training Loss: 0.17403767906850384, Validation Loss: 0.17460685273011525, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 2922, Training Loss: 0.1735422851577882, Validation Loss: 0.17300749222437542, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 2923, Training Loss: 0.1741135653949553, Validation Loss: 0.17412043114503226, Validation Accuracy: 0.48125\n",
      "Epoch 2924, Training Loss: 0.1737225382558761, Validation Loss: 0.1737017124891281, Validation Accuracy: 0.50625\n",
      "Epoch 2925, Training Loss: 0.174071668617187, Validation Loss: 0.17469152410825092, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 2926, Training Loss: 0.17370393776124524, Validation Loss: 0.1721274475256602, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 2927, Training Loss: 0.17409226779014833, Validation Loss: 0.17433335781097412, Validation Accuracy: 0.475\n",
      "Epoch 2928, Training Loss: 0.17375969742574998, Validation Loss: 0.17342764139175415, Validation Accuracy: 0.5125\n",
      "Epoch 2929, Training Loss: 0.17404564686359897, Validation Loss: 0.1747692932685216, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 2930, Training Loss: 0.17365843057632446, Validation Loss: 0.17268613080183665, Validation Accuracy: 0.5375\n",
      "Epoch 2931, Training Loss: 0.17412088907534076, Validation Loss: 0.17366629838943481, Validation Accuracy: 0.4875\n",
      "Epoch 2932, Training Loss: 0.1737782834999023, Validation Loss: 0.17378537555535634, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 2933, Training Loss: 0.17395853082979879, Validation Loss: 0.17455371022224425, Validation Accuracy: 0.475\n",
      "Epoch 2934, Training Loss: 0.17372300596006454, Validation Loss: 0.17198660870393118, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 2935, Training Loss: 0.1740120356121371, Validation Loss: 0.17399070262908936, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 2936, Training Loss: 0.17417860944424907, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 2937, Training Loss: 0.17407915428761514, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5125\n",
      "Epoch 2938, Training Loss: 0.1732867956161499, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.46458333333333335\n",
      "Epoch 2939, Training Loss: 0.17337975434718594, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 2940, Training Loss: 0.17327544141200282, Validation Loss: 0.2116487552722295, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2941, Training Loss: 0.17492377469616552, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.50625\n",
      "Epoch 2942, Training Loss: 0.1735411108501496, Validation Loss: 0.17621731162071227, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 2943, Training Loss: 0.17296720079837308, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2944, Training Loss: 0.17401740003016689, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5166666666666667\n",
      "Epoch 2945, Training Loss: 0.1734842787827215, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.4875\n",
      "Epoch 2946, Training Loss: 0.17338864553359248, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5208333333333334\n",
      "Epoch 2947, Training Loss: 0.19338019336423568, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 2948, Training Loss: 0.1732939222166615, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.51875\n",
      "Epoch 2949, Training Loss: 0.17323583652896266, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.49375\n",
      "Epoch 2950, Training Loss: 0.1732828559414033, Validation Loss: 0.1733400285243988, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 2951, Training Loss: 0.17380384716295427, Validation Loss: 0.17316957811514536, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 2952, Training Loss: 0.17372139807670348, Validation Loss: 0.1733673632144928, Validation Accuracy: 0.475\n",
      "Epoch 2953, Training Loss: 0.1735906918202677, Validation Loss: 0.17321865359942118, Validation Accuracy: 0.5125\n",
      "Epoch 2954, Training Loss: 0.17372231281572773, Validation Loss: 0.17381959060827892, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 2955, Training Loss: 0.17369866563427833, Validation Loss: 0.1729421983162562, Validation Accuracy: 0.5375\n",
      "Epoch 2956, Training Loss: 0.17382395123281785, Validation Loss: 0.17365854481856027, Validation Accuracy: 0.4875\n",
      "Epoch 2957, Training Loss: 0.17368897218858043, Validation Loss: 0.17349931299686433, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 2958, Training Loss: 0.1736817648333888, Validation Loss: 0.17391420801480612, Validation Accuracy: 0.475\n",
      "Epoch 2959, Training Loss: 0.1737134120156688, Validation Loss: 0.172720135251681, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 2960, Training Loss: 0.17373292388454561, Validation Loss: 0.17364082435766856, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 2961, Training Loss: 0.1733069400633535, Validation Loss: 0.17401488721370698, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2962, Training Loss: 0.17373325122940925, Validation Loss: 0.17381791869799296, Validation Accuracy: 0.4875\n",
      "Epoch 2963, Training Loss: 0.1738321574464921, Validation Loss: 0.17298652132352194, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 2964, Training Loss: 0.17368883711676444, Validation Loss: 0.17363236943880717, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 2965, Training Loss: 0.17388458021225467, Validation Loss: 0.17351649105548858, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2966, Training Loss: 0.17369161305889005, Validation Loss: 0.17376315891742705, Validation Accuracy: 0.49375\n",
      "Epoch 2967, Training Loss: 0.17386425791248197, Validation Loss: 0.17339325249195098, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 2968, Training Loss: 0.173791409019501, Validation Loss: 0.17333000004291535, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 2969, Training Loss: 0.173659909156061, Validation Loss: 0.1742188185453415, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 2970, Training Loss: 0.1737890781894807, Validation Loss: 0.17335828840732576, Validation Accuracy: 0.5125\n",
      "Epoch 2971, Training Loss: 0.17389297245010252, Validation Loss: 0.17352344791094462, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 2972, Training Loss: 0.17383952775309164, Validation Loss: 0.17294202148914337, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 2973, Training Loss: 0.17392184801640048, Validation Loss: 0.17346680064996084, Validation Accuracy: 0.48125\n",
      "Epoch 2974, Training Loss: 0.17363961906202377, Validation Loss: 0.17346788148085276, Validation Accuracy: 0.50625\n",
      "Epoch 2975, Training Loss: 0.17408522723182554, Validation Loss: 0.1734820346037547, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 2976, Training Loss: 0.173729054870144, Validation Loss: 0.17258494993050894, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 2977, Training Loss: 0.17403252567014388, Validation Loss: 0.1734696865081787, Validation Accuracy: 0.475\n",
      "Epoch 2978, Training Loss: 0.1736436019982061, Validation Loss: 0.17327487369378408, Validation Accuracy: 0.5125\n",
      "Epoch 2979, Training Loss: 0.17408068045493094, Validation Loss: 0.173446586728096, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 2980, Training Loss: 0.17373008401163162, Validation Loss: 0.17280715703964233, Validation Accuracy: 0.5375\n",
      "Epoch 2981, Training Loss: 0.17397466734532388, Validation Loss: 0.1734429955482483, Validation Accuracy: 0.4875\n",
      "Epoch 2982, Training Loss: 0.17364474217737874, Validation Loss: 0.17382200757662455, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 2983, Training Loss: 0.17406819520458097, Validation Loss: 0.1734335720539093, Validation Accuracy: 0.475\n",
      "Epoch 2984, Training Loss: 0.17369039789322885, Validation Loss: 0.17235566278298695, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 2985, Training Loss: 0.17392608715641883, Validation Loss: 0.1739377001921336, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 2986, Training Loss: 0.17363318752857945, Validation Loss: 0.1737147351106008, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2987, Training Loss: 0.1741368107257351, Validation Loss: 0.17335601846377055, Validation Accuracy: 0.4875\n",
      "Epoch 2988, Training Loss: 0.17372804159118282, Validation Loss: 0.17279800275961557, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 2989, Training Loss: 0.1740220905311646, Validation Loss: 0.1733312408129374, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 2990, Training Loss: 0.17367418687189778, Validation Loss: 0.17386363844076794, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 2991, Training Loss: 0.17405438134747167, Validation Loss: 0.1733318656682968, Validation Accuracy: 0.49375\n",
      "Epoch 2992, Training Loss: 0.17376125531811867, Validation Loss: 0.17342552940050762, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 2993, Training Loss: 0.17402015289952677, Validation Loss: 0.17325786352157593, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 2994, Training Loss: 0.17358377287464757, Validation Loss: 0.17420770327250162, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 2995, Training Loss: 0.17414517123853007, Validation Loss: 0.173235026995341, Validation Accuracy: 0.5125\n",
      "Epoch 2996, Training Loss: 0.17370743809207792, Validation Loss: 0.1742942084868749, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 2997, Training Loss: 0.1738925576210022, Validation Loss: 0.1731827308734258, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 2998, Training Loss: 0.17362236976623535, Validation Loss: 0.17425474325815837, Validation Accuracy: 0.48125\n",
      "Epoch 2999, Training Loss: 0.17412022909810465, Validation Loss: 0.173271174232165, Validation Accuracy: 0.50625\n",
      "Epoch 3000, Training Loss: 0.17360638226232222, Validation Loss: 0.1750657836596171, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 3001, Training Loss: 0.17409574600958055, Validation Loss: 0.17315637369950612, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 3002, Training Loss: 0.17353413278056729, Validation Loss: 0.17479543288548788, Validation Accuracy: 0.475\n",
      "Epoch 3003, Training Loss: 0.17417594213639537, Validation Loss: 0.17323787709077199, Validation Accuracy: 0.5125\n",
      "Epoch 3004, Training Loss: 0.1735529971699561, Validation Loss: 0.17501072188218433, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 3005, Training Loss: 0.17400881551927136, Validation Loss: 0.1732112169265747, Validation Accuracy: 0.5375\n",
      "Epoch 3006, Training Loss: 0.17349836807097158, Validation Loss: 0.17415516475836437, Validation Accuracy: 0.4875\n",
      "Epoch 3007, Training Loss: 0.17415583758584915, Validation Loss: 0.17334363063176472, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 3008, Training Loss: 0.17365074013510057, Validation Loss: 0.17452987432479858, Validation Accuracy: 0.475\n",
      "Epoch 3009, Training Loss: 0.17406472659880115, Validation Loss: 0.1731162240107854, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 3010, Training Loss: 0.1735872587850017, Validation Loss: 0.1745717316865921, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 3011, Training Loss: 0.17410209678834485, Validation Loss: 0.17349751591682433, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3012, Training Loss: 0.17363555873593978, Validation Loss: 0.17486809690793356, Validation Accuracy: 0.4875\n",
      "Epoch 3013, Training Loss: 0.17391361151972123, Validation Loss: 0.17320298949877422, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 3014, Training Loss: 0.17353793594145006, Validation Loss: 0.17380806803703308, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 3015, Training Loss: 0.17409383721889987, Validation Loss: 0.1735544264316559, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3016, Training Loss: 0.1735783613497211, Validation Loss: 0.17468265493710836, Validation Accuracy: 0.49375\n",
      "Epoch 3017, Training Loss: 0.17414473429802926, Validation Loss: 0.17350284655888876, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 3018, Training Loss: 0.17350186984385213, Validation Loss: 0.17397933304309846, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 3019, Training Loss: 0.17406237942557182, Validation Loss: 0.17360773583253225, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 3020, Training Loss: 0.17352300257452072, Validation Loss: 0.17348983784516653, Validation Accuracy: 0.5125\n",
      "Epoch 3021, Training Loss: 0.17408951395942318, Validation Loss: 0.1737692465384801, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 3022, Training Loss: 0.1735483383940112, Validation Loss: 0.17292317152023315, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 3023, Training Loss: 0.17404692836346164, Validation Loss: 0.17452632486820222, Validation Accuracy: 0.48125\n",
      "Epoch 3024, Training Loss: 0.17347922007883748, Validation Loss: 0.17411472300688427, Validation Accuracy: 0.50625\n",
      "Epoch 3025, Training Loss: 0.17431402542898733, Validation Loss: 0.17519897321859995, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 3026, Training Loss: 0.17365056180184887, Validation Loss: 0.17216057082017264, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 3027, Training Loss: 0.17401524032315902, Validation Loss: 0.17510477006435393, Validation Accuracy: 0.475\n",
      "Epoch 3028, Training Loss: 0.1737956726743329, Validation Loss: 0.17359803716341654, Validation Accuracy: 0.5125\n",
      "Epoch 3029, Training Loss: 0.17380921590712764, Validation Loss: 0.17564186056454975, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 3030, Training Loss: 0.1738501739117407, Validation Loss: 0.1726617068052292, Validation Accuracy: 0.5375\n",
      "Epoch 3031, Training Loss: 0.17372815022545476, Validation Loss: 0.17515058020750682, Validation Accuracy: 0.4875\n",
      "Epoch 3032, Training Loss: 0.1738581003681306, Validation Loss: 0.17437185049057008, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 3033, Training Loss: 0.17382756212065298, Validation Loss: 0.17555274665355683, Validation Accuracy: 0.475\n",
      "Epoch 3034, Training Loss: 0.17395057985859533, Validation Loss: 0.17185625831286114, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 3035, Training Loss: 0.17366022929068534, Validation Loss: 0.17602751950422924, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 3036, Training Loss: 0.1740509925350066, Validation Loss: 0.1740641434987386, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3037, Training Loss: 0.17361414528662159, Validation Loss: 0.17513851821422577, Validation Accuracy: 0.4875\n",
      "Epoch 3038, Training Loss: 0.17410073934062834, Validation Loss: 0.17297220826148987, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 3039, Training Loss: 0.17334651754748437, Validation Loss: 0.17518244783083597, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 3040, Training Loss: 0.17438939886708413, Validation Loss: 0.17366015017032624, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3041, Training Loss: 0.17357787730232363, Validation Loss: 0.17448949615160625, Validation Accuracy: 0.49375\n",
      "Epoch 3042, Training Loss: 0.17408412262316672, Validation Loss: 0.17357724606990815, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 3043, Training Loss: 0.17355374318938102, Validation Loss: 0.17386789321899415, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 3044, Training Loss: 0.1741597710117217, Validation Loss: 0.17410226960976918, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 3045, Training Loss: 0.17367775065283622, Validation Loss: 0.1736338257789612, Validation Accuracy: 0.5125\n",
      "Epoch 3046, Training Loss: 0.17406007262968248, Validation Loss: 0.1745215614636739, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 3047, Training Loss: 0.17358570954492014, Validation Loss: 0.1731205701828003, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 3048, Training Loss: 0.17405351708012243, Validation Loss: 0.17415175040562947, Validation Accuracy: 0.48125\n",
      "Epoch 3049, Training Loss: 0.1736685984557675, Validation Loss: 0.1739038238922755, Validation Accuracy: 0.50625\n",
      "Epoch 3050, Training Loss: 0.17401555132481358, Validation Loss: 0.17494184970855714, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 3051, Training Loss: 0.17366867488430393, Validation Loss: 0.1721186916033427, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 3052, Training Loss: 0.17411146673464006, Validation Loss: 0.17399498323599497, Validation Accuracy: 0.475\n",
      "Epoch 3053, Training Loss: 0.17376940144646552, Validation Loss: 0.1733612249294917, Validation Accuracy: 0.5125\n",
      "Epoch 3054, Training Loss: 0.1740020239545453, Validation Loss: 0.1750291109085083, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 3055, Training Loss: 0.17360394760485617, Validation Loss: 0.17266387740770975, Validation Accuracy: 0.5375\n",
      "Epoch 3056, Training Loss: 0.17417249900679435, Validation Loss: 0.17356250683466592, Validation Accuracy: 0.4875\n",
      "Epoch 3057, Training Loss: 0.17374263799959613, Validation Loss: 0.17393500407536824, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 3058, Training Loss: 0.1739023164395363, Validation Loss: 0.1748054067293803, Validation Accuracy: 0.475\n",
      "Epoch 3059, Training Loss: 0.17369988656813098, Validation Loss: 0.1721872458855311, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 3060, Training Loss: 0.17403696669686225, Validation Loss: 0.17378500600655875, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 3061, Training Loss: 0.1737909581392042, Validation Loss: 0.17365442315737406, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3062, Training Loss: 0.17394333597152464, Validation Loss: 0.17373476922512054, Validation Accuracy: 0.4875\n",
      "Epoch 3063, Training Loss: 0.17381099827827945, Validation Loss: 0.17282651166121166, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 3064, Training Loss: 0.1740050253368193, Validation Loss: 0.1734365830818812, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 3065, Training Loss: 0.1738281225965869, Validation Loss: 0.1735485424598058, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3066, Training Loss: 0.17392470519388875, Validation Loss: 0.17356491684913636, Validation Accuracy: 0.49375\n",
      "Epoch 3067, Training Loss: 0.17382623928208504, Validation Loss: 0.17334411640961964, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 3068, Training Loss: 0.17394909743339784, Validation Loss: 0.17325878938039144, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 3069, Training Loss: 0.17396299348723504, Validation Loss: 0.17358953456083934, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 3070, Training Loss: 0.17349034019054904, Validation Loss: 0.17358386913935345, Validation Accuracy: 0.5125\n",
      "Epoch 3071, Training Loss: 0.17402393539105693, Validation Loss: 0.17356852789719898, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 3072, Training Loss: 0.1737022452777432, Validation Loss: 0.1729298194249471, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 3073, Training Loss: 0.17404465425399043, Validation Loss: 0.17361354033152263, Validation Accuracy: 0.48125\n",
      "Epoch 3074, Training Loss: 0.17364984606542894, Validation Loss: 0.17357349693775176, Validation Accuracy: 0.50625\n",
      "Epoch 3075, Training Loss: 0.17396661158530943, Validation Loss: 0.17370108465353648, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 3076, Training Loss: 0.17388850402447484, Validation Loss: 0.17290378312269847, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 3077, Training Loss: 0.1739434700819754, Validation Loss: 0.1737109879652659, Validation Accuracy: 0.475\n",
      "Epoch 3078, Training Loss: 0.17365212930786994, Validation Loss: 0.1734216590722402, Validation Accuracy: 0.5125\n",
      "Epoch 3079, Training Loss: 0.1739278305922785, Validation Loss: 0.17394225498040516, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 3080, Training Loss: 0.17389059980069438, Validation Loss: 0.17301775217056276, Validation Accuracy: 0.5375\n",
      "Epoch 3081, Training Loss: 0.17390152235184947, Validation Loss: 0.1736391137043635, Validation Accuracy: 0.4875\n",
      "Epoch 3082, Training Loss: 0.17391855149499832, Validation Loss: 0.17341234385967255, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 3083, Training Loss: 0.17378171989994665, Validation Loss: 0.17392605741818745, Validation Accuracy: 0.475\n",
      "Epoch 3084, Training Loss: 0.1739947973720489, Validation Loss: 0.17292840977509816, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 3085, Training Loss: 0.17385589403490867, Validation Loss: 0.17403826316197712, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 3086, Training Loss: 0.17367669218970883, Validation Loss: 0.17388280431429545, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3087, Training Loss: 0.1738326789871339, Validation Loss: 0.17375825345516205, Validation Accuracy: 0.4875\n",
      "Epoch 3088, Training Loss: 0.1739874602325501, Validation Loss: 0.17310674687226613, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 3089, Training Loss: 0.17374942139271768, Validation Loss: 0.173547692100207, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 3090, Training Loss: 0.173893345459815, Validation Loss: 0.1737203260262807, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3091, Training Loss: 0.1736703731359974, Validation Loss: 0.17376195192337035, Validation Accuracy: 0.49375\n",
      "Epoch 3092, Training Loss: 0.17404442929452466, Validation Loss: 0.17328348457813264, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 3093, Training Loss: 0.17383169166503415, Validation Loss: 0.1732964426279068, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 3094, Training Loss: 0.17390469677986636, Validation Loss: 0.1734945595264435, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 3095, Training Loss: 0.17379726517585017, Validation Loss: 0.1732513576745987, Validation Accuracy: 0.5125\n",
      "Epoch 3096, Training Loss: 0.1739847655257871, Validation Loss: 0.17343358794848124, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 3097, Training Loss: 0.17385478750351938, Validation Loss: 0.17292701800664265, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 3098, Training Loss: 0.17372816993344214, Validation Loss: 0.17398391366004945, Validation Accuracy: 0.48125\n",
      "Epoch 3099, Training Loss: 0.17371381530838628, Validation Loss: 0.17345735530058543, Validation Accuracy: 0.50625\n",
      "Epoch 3100, Training Loss: 0.1740458833594476, Validation Loss: 0.17351860801378885, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 3101, Training Loss: 0.1737626834261802, Validation Loss: 0.17251998682816824, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 3102, Training Loss: 0.1739814281463623, Validation Loss: 0.1735270897547404, Validation Accuracy: 0.475\n",
      "Epoch 3103, Training Loss: 0.17372489215866213, Validation Loss: 0.17327036162217457, Validation Accuracy: 0.5125\n",
      "Epoch 3104, Training Loss: 0.17403424747528567, Validation Loss: 0.17348214983940125, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 3105, Training Loss: 0.173798109735212, Validation Loss: 0.1727711707353592, Validation Accuracy: 0.5375\n",
      "Epoch 3106, Training Loss: 0.17401929391968635, Validation Loss: 0.17341396808624268, Validation Accuracy: 0.4875\n",
      "Epoch 3107, Training Loss: 0.17363871826279548, Validation Loss: 0.17365576128164928, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 3108, Training Loss: 0.174038992774102, Validation Loss: 0.17351099848747253, Validation Accuracy: 0.475\n",
      "Epoch 3109, Training Loss: 0.1737498256468004, Validation Loss: 0.17228015760580698, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 3110, Training Loss: 0.1739450789267017, Validation Loss: 0.17374620834986368, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 3111, Training Loss: 0.17374289131933643, Validation Loss: 0.17381699681282042, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3112, Training Loss: 0.17398735063691292, Validation Loss: 0.17336806356906892, Validation Accuracy: 0.4875\n",
      "Epoch 3113, Training Loss: 0.17377313346632065, Validation Loss: 0.17283930679162343, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 3114, Training Loss: 0.17396488401197618, Validation Loss: 0.1733258306980133, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 3115, Training Loss: 0.17374112288798055, Validation Loss: 0.1738283266623815, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3116, Training Loss: 0.17408097751678958, Validation Loss: 0.17332005500793457, Validation Accuracy: 0.49375\n",
      "Epoch 3117, Training Loss: 0.17376798920093045, Validation Loss: 0.1733462373415629, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 3118, Training Loss: 0.17388486045022164, Validation Loss: 0.17325612604618074, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 3119, Training Loss: 0.17366452563193538, Validation Loss: 0.17419232825438183, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 3120, Training Loss: 0.1741967720370139, Validation Loss: 0.1732558200756709, Validation Accuracy: 0.5125\n",
      "Epoch 3121, Training Loss: 0.17371983345477812, Validation Loss: 0.17409764925638835, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 3122, Training Loss: 0.17395079087826512, Validation Loss: 0.1732240190108617, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 3123, Training Loss: 0.17370228373235272, Validation Loss: 0.17436659435431162, Validation Accuracy: 0.48125\n",
      "Epoch 3124, Training Loss: 0.17402008368122962, Validation Loss: 0.17328213055928549, Validation Accuracy: 0.50625\n",
      "Epoch 3125, Training Loss: 0.17367702049593772, Validation Loss: 0.17470998068650564, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 3126, Training Loss: 0.17389828735782253, Validation Loss: 0.17316308319568635, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 3127, Training Loss: 0.1736123912757443, Validation Loss: 0.17445910175641377, Validation Accuracy: 0.475\n",
      "Epoch 3128, Training Loss: 0.17426168053380905, Validation Loss: 0.17325619359811148, Validation Accuracy: 0.5125\n",
      "Epoch 3129, Training Loss: 0.17358634404597745, Validation Loss: 0.1752753148476283, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 3130, Training Loss: 0.17413833593168565, Validation Loss: 0.17324176728725432, Validation Accuracy: 0.5375\n",
      "Epoch 3131, Training Loss: 0.17352680044789467, Validation Loss: 0.17481305996576946, Validation Accuracy: 0.4875\n",
      "Epoch 3132, Training Loss: 0.1742691267882624, Validation Loss: 0.1733456164598465, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 3133, Training Loss: 0.17369000950167257, Validation Loss: 0.17471098899841309, Validation Accuracy: 0.475\n",
      "Epoch 3134, Training Loss: 0.17387951670154447, Validation Loss: 0.1732270916302999, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 3135, Training Loss: 0.1736683124496091, Validation Loss: 0.1746756116549174, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 3136, Training Loss: 0.174133556985086, Validation Loss: 0.1733760933081309, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3137, Training Loss: 0.17363088265542062, Validation Loss: 0.1748451958100001, Validation Accuracy: 0.4875\n",
      "Epoch 3138, Training Loss: 0.17388122985439916, Validation Loss: 0.17320938408374786, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 3139, Training Loss: 0.17359645087872783, Validation Loss: 0.17385516166687012, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 3140, Training Loss: 0.17414383013402263, Validation Loss: 0.17370044390360515, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3141, Training Loss: 0.1735837964280959, Validation Loss: 0.1751112808783849, Validation Accuracy: 0.49375\n",
      "Epoch 3142, Training Loss: 0.17414558029943897, Validation Loss: 0.1733022928237915, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 3143, Training Loss: 0.17350828359203954, Validation Loss: 0.1736046959956487, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 3144, Training Loss: 0.1740516621258951, Validation Loss: 0.17411864697933196, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 3145, Training Loss: 0.1735478466556918, Validation Loss: 0.17399415572484334, Validation Accuracy: 0.5125\n",
      "Epoch 3146, Training Loss: 0.17425708953411348, Validation Loss: 0.17392351826032001, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 3147, Training Loss: 0.17353425583531779, Validation Loss: 0.17292897601922352, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 3148, Training Loss: 0.17420407360599888, Validation Loss: 0.1744188368320465, Validation Accuracy: 0.48125\n",
      "Epoch 3149, Training Loss: 0.1734229979976531, Validation Loss: 0.17415829598903657, Validation Accuracy: 0.50625\n",
      "Epoch 3150, Training Loss: 0.17441690592996537, Validation Loss: 0.1753615806500117, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 3151, Training Loss: 0.17362887820889872, Validation Loss: 0.17209913035233815, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 3152, Training Loss: 0.17408383902042143, Validation Loss: 0.17514927784601847, Validation Accuracy: 0.475\n",
      "Epoch 3153, Training Loss: 0.17377084349432298, Validation Loss: 0.17354167302449544, Validation Accuracy: 0.5125\n",
      "Epoch 3154, Training Loss: 0.17385376605295366, Validation Loss: 0.17571919361750285, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 3155, Training Loss: 0.1738322127249933, Validation Loss: 0.17265933056672414, Validation Accuracy: 0.5375\n",
      "Epoch 3156, Training Loss: 0.17376149758215872, Validation Loss: 0.17514462967713673, Validation Accuracy: 0.4875\n",
      "Epoch 3157, Training Loss: 0.17386080276581548, Validation Loss: 0.174520539244016, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 3158, Training Loss: 0.17388824109108217, Validation Loss: 0.17575366497039796, Validation Accuracy: 0.475\n",
      "Epoch 3159, Training Loss: 0.17395108505602805, Validation Loss: 0.17207539081573486, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 3160, Training Loss: 0.1736803098071006, Validation Loss: 0.17611526151498158, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 3161, Training Loss: 0.17405826574371708, Validation Loss: 0.17406712869803112, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3162, Training Loss: 0.17364933654185263, Validation Loss: 0.17512070536613464, Validation Accuracy: 0.4875\n",
      "Epoch 3163, Training Loss: 0.17418399357026623, Validation Loss: 0.17276354730129242, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 3164, Training Loss: 0.17338857006642125, Validation Loss: 0.1749967336654663, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 3165, Training Loss: 0.17443209934619167, Validation Loss: 0.17358694473902384, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3166, Training Loss: 0.17409165588117415, Validation Loss: 0.1732868254184723, Validation Accuracy: 0.49375\n",
      "Epoch 3167, Training Loss: 0.1754672339847011, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 3168, Training Loss: 0.17321184854353627, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3169, Training Loss: 0.1779344932686898, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5166666666666667\n",
      "Epoch 3170, Training Loss: 0.17806170640453214, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.4875\n",
      "Epoch 3171, Training Loss: 0.18484971696330654, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5208333333333334\n",
      "Epoch 3172, Training Loss: 0.1732867956161499, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 3173, Training Loss: 0.1732867956161499, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.51875\n",
      "Epoch 3174, Training Loss: 0.17328679850024561, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.49375\n",
      "Epoch 3175, Training Loss: 0.1732867956161499, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5333333333333333\n",
      "Epoch 3176, Training Loss: 0.1733232400109691, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.4479166666666667\n",
      "Epoch 3177, Training Loss: 0.1732867956161499, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.525\n",
      "Epoch 3178, Training Loss: 0.1732867956161499, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.4875\n",
      "Epoch 3179, Training Loss: 0.1732867956161499, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 3180, Training Loss: 0.1732867956161499, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.4625\n",
      "Epoch 3181, Training Loss: 0.1732867956161499, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5125\n",
      "Epoch 3182, Training Loss: 0.1732867956161499, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5104166666666666\n",
      "Epoch 3183, Training Loss: 0.1732867956161499, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.525\n",
      "Epoch 3184, Training Loss: 0.1732867956161499, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.4395833333333333\n",
      "Epoch 3185, Training Loss: 0.1732867956161499, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5270833333333333\n",
      "Epoch 3186, Training Loss: 0.1732867956161499, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 3187, Training Loss: 0.1732867956161499, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5125\n",
      "Epoch 3188, Training Loss: 0.1732867956161499, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.46458333333333335\n",
      "Epoch 3189, Training Loss: 0.1732867956161499, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 3190, Training Loss: 0.1732867956161499, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 3191, Training Loss: 0.1732867956161499, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.50625\n",
      "Epoch 3192, Training Loss: 0.1732867956161499, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 3193, Training Loss: 0.1732867956161499, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3194, Training Loss: 0.1732867956161499, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5166666666666667\n",
      "Epoch 3195, Training Loss: 0.17328673937628347, Validation Loss: 0.17328665951887767, Validation Accuracy: 0.5125\n",
      "Epoch 3196, Training Loss: 0.17328829726865214, Validation Loss: 0.17328884899616243, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 3197, Training Loss: 0.17329043486425955, Validation Loss: 0.17328588167826334, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 3198, Training Loss: 0.17329228164688235, Validation Loss: 0.1732890635728836, Validation Accuracy: 0.48125\n",
      "Epoch 3199, Training Loss: 0.17330265045166016, Validation Loss: 0.1732866624991099, Validation Accuracy: 0.50625\n",
      "Epoch 3200, Training Loss: 0.17330186020943425, Validation Loss: 0.17329221566518146, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 3201, Training Loss: 0.17331193435576656, Validation Loss: 0.17327897648016613, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 3202, Training Loss: 0.17331355329482787, Validation Loss: 0.1732875406742096, Validation Accuracy: 0.475\n",
      "Epoch 3203, Training Loss: 0.17330838451462408, Validation Loss: 0.17325618068377177, Validation Accuracy: 0.5125\n",
      "Epoch 3204, Training Loss: 0.17340239161445248, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 3205, Training Loss: 0.17329004166587705, Validation Loss: 0.17320419947306315, Validation Accuracy: 0.5375\n",
      "Epoch 3206, Training Loss: 0.17339434642945567, Validation Loss: 0.17331123451391856, Validation Accuracy: 0.4875\n",
      "Epoch 3207, Training Loss: 0.17330830183721357, Validation Loss: 0.17337529559930165, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 3208, Training Loss: 0.1734034736310282, Validation Loss: 0.17336997985839844, Validation Accuracy: 0.475\n",
      "Epoch 3209, Training Loss: 0.17340898754135256, Validation Loss: 0.1732687036196391, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 3210, Training Loss: 0.17337202160589157, Validation Loss: 0.17334152162075042, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 3211, Training Loss: 0.1741526828658196, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 3212, Training Loss: 0.17328739406601076, Validation Loss: 0.17329113682111105, Validation Accuracy: 0.4875\n",
      "Epoch 3213, Training Loss: 0.17348345441202964, Validation Loss: 0.17323560019334158, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 3214, Training Loss: 0.17336975951348582, Validation Loss: 0.17330399056275686, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 3215, Training Loss: 0.1732231609282955, Validation Loss: 0.1732967734336853, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3216, Training Loss: 0.17337545608320543, Validation Loss: 0.17333452502886454, Validation Accuracy: 0.49375\n",
      "Epoch 3217, Training Loss: 0.17391469834312315, Validation Loss: 0.17328040500481923, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 3218, Training Loss: 0.1734907583844277, Validation Loss: 0.17326575020949045, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 3219, Training Loss: 0.17359108165387185, Validation Loss: 0.17334822913010914, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 3220, Training Loss: 0.17345297528851417, Validation Loss: 0.1732190469900767, Validation Accuracy: 0.5125\n",
      "Epoch 3221, Training Loss: 0.17348081690649833, Validation Loss: 0.1733670969804128, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 3222, Training Loss: 0.1734963963108678, Validation Loss: 0.17309860686461132, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 3223, Training Loss: 0.1734864543522558, Validation Loss: 0.1735647310813268, Validation Accuracy: 0.48125\n",
      "Epoch 3224, Training Loss: 0.1734878343920554, Validation Loss: 0.1732763757308324, Validation Accuracy: 0.50625\n",
      "Epoch 3225, Training Loss: 0.17343278036963555, Validation Loss: 0.17371971706549327, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 3226, Training Loss: 0.17349106986676494, Validation Loss: 0.17278338372707366, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 3227, Training Loss: 0.17344460035524062, Validation Loss: 0.17368246714274088, Validation Accuracy: 0.475\n",
      "Epoch 3228, Training Loss: 0.17344431002293864, Validation Loss: 0.17321819464365643, Validation Accuracy: 0.5125\n",
      "Epoch 3229, Training Loss: 0.1734260589845719, Validation Loss: 0.17370601991812387, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 3230, Training Loss: 0.1734902637620126, Validation Loss: 0.1729291319847107, Validation Accuracy: 0.5375\n",
      "Epoch 3231, Training Loss: 0.17348116636276245, Validation Loss: 0.17340648969014485, Validation Accuracy: 0.4875\n",
      "Epoch 3232, Training Loss: 0.17342500580895331, Validation Loss: 0.1734667440255483, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 3233, Training Loss: 0.1735726171924222, Validation Loss: 0.1733778238296509, Validation Accuracy: 0.475\n",
      "Epoch 3234, Training Loss: 0.17346512502239597, Validation Loss: 0.17282740771770477, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 3235, Training Loss: 0.17356077028859046, Validation Loss: 0.17340541879336038, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 3236, Training Loss: 0.17343561255162762, Validation Loss: 0.1734595477581024, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3237, Training Loss: 0.17355887063087955, Validation Loss: 0.17336474657058715, Validation Accuracy: 0.4875\n",
      "Epoch 3238, Training Loss: 0.17348881450391584, Validation Loss: 0.17291894157727558, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 3239, Training Loss: 0.17361323583510616, Validation Loss: 0.17331021130084992, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 3240, Training Loss: 0.17345130828119093, Validation Loss: 0.17350658774375916, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3241, Training Loss: 0.1736584238467678, Validation Loss: 0.17330173055330914, Validation Accuracy: 0.49375\n",
      "Epoch 3242, Training Loss: 0.17352223300164746, Validation Loss: 0.1733046293258667, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 3243, Training Loss: 0.17349973705507094, Validation Loss: 0.1732563684384028, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 3244, Training Loss: 0.1734418474858807, Validation Loss: 0.17361083229382832, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 3245, Training Loss: 0.1736601831451539, Validation Loss: 0.1732650468746821, Validation Accuracy: 0.5125\n",
      "Epoch 3246, Training Loss: 0.173540348006833, Validation Loss: 0.17364659508069355, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 3247, Training Loss: 0.17360842516345362, Validation Loss: 0.17320846319198607, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 3248, Training Loss: 0.17348195708567096, Validation Loss: 0.17393914461135865, Validation Accuracy: 0.48125\n",
      "Epoch 3249, Training Loss: 0.173554229159509, Validation Loss: 0.17327574789524078, Validation Accuracy: 0.50625\n",
      "Epoch 3250, Training Loss: 0.17352355824362847, Validation Loss: 0.17378357748190562, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 3251, Training Loss: 0.17358643201089674, Validation Loss: 0.17312421003977457, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 3252, Training Loss: 0.17348201428690263, Validation Loss: 0.1741596281528473, Validation Accuracy: 0.475\n",
      "Epoch 3253, Training Loss: 0.1737319572317985, Validation Loss: 0.17327371935049693, Validation Accuracy: 0.5125\n",
      "Epoch 3254, Training Loss: 0.1734636329835461, Validation Loss: 0.17394006252288818, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 3255, Training Loss: 0.1737249849304076, Validation Loss: 0.17309779425462088, Validation Accuracy: 0.5375\n",
      "Epoch 3256, Training Loss: 0.17341441540948807, Validation Loss: 0.1739037185907364, Validation Accuracy: 0.4875\n",
      "Epoch 3257, Training Loss: 0.17367565920276026, Validation Loss: 0.173342435558637, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 3258, Training Loss: 0.17354067775510973, Validation Loss: 0.17385360995928448, Validation Accuracy: 0.475\n",
      "Epoch 3259, Training Loss: 0.17360206284830648, Validation Loss: 0.17312252620855967, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 3260, Training Loss: 0.17351314185127134, Validation Loss: 0.1738858421643575, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 3261, Training Loss: 0.1737801658530389, Validation Loss: 0.17330475250879923, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3262, Training Loss: 0.17350043164145562, Validation Loss: 0.173972420891126, Validation Accuracy: 0.4875\n",
      "Epoch 3263, Training Loss: 0.17367613748196634, Validation Loss: 0.1732380231221517, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 3264, Training Loss: 0.17343453870665643, Validation Loss: 0.17367667555809022, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 3265, Training Loss: 0.17383031691274337, Validation Loss: 0.1733931342760722, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3266, Training Loss: 0.1734559218729696, Validation Loss: 0.17432291905085245, Validation Accuracy: 0.49375\n",
      "Epoch 3267, Training Loss: 0.173764580680478, Validation Loss: 0.17328336934248606, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 3268, Training Loss: 0.17339946041184087, Validation Loss: 0.17351416647434234, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 3269, Training Loss: 0.17379945035903685, Validation Loss: 0.17335484425226846, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 3270, Training Loss: 0.1733625175491456, Validation Loss: 0.17341339588165283, Validation Accuracy: 0.5125\n",
      "Epoch 3271, Training Loss: 0.1737702589842581, Validation Loss: 0.17335266669591268, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 3272, Training Loss: 0.17349221244935067, Validation Loss: 0.17292348742485047, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 3273, Training Loss: 0.17380252432438634, Validation Loss: 0.17375390430291493, Validation Accuracy: 0.48125\n",
      "Epoch 3274, Training Loss: 0.17348407978011715, Validation Loss: 0.1734900712966919, Validation Accuracy: 0.50625\n",
      "Epoch 3275, Training Loss: 0.17382542452504557, Validation Loss: 0.17368944585323334, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 3276, Training Loss: 0.17348951245507888, Validation Loss: 0.17231418192386627, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 3277, Training Loss: 0.17386058934273257, Validation Loss: 0.17440777122974396, Validation Accuracy: 0.475\n",
      "Epoch 3278, Training Loss: 0.1735240480592174, Validation Loss: 0.17344008485476176, Validation Accuracy: 0.5125\n",
      "Epoch 3279, Training Loss: 0.17368998114139803, Validation Loss: 0.17505883773167927, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 3280, Training Loss: 0.17364681824561087, Validation Loss: 0.17266693512598674, Validation Accuracy: 0.5375\n",
      "Epoch 3281, Training Loss: 0.1735870410357752, Validation Loss: 0.17466657261053722, Validation Accuracy: 0.4875\n",
      "Epoch 3282, Training Loss: 0.17364572805743064, Validation Loss: 0.17418015201886494, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 3283, Training Loss: 0.1737214865223054, Validation Loss: 0.17527693013350168, Validation Accuracy: 0.475\n",
      "Epoch 3284, Training Loss: 0.1737244374329044, Validation Loss: 0.17196267147858937, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 3285, Training Loss: 0.173562484883493, Validation Loss: 0.1755311131477356, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 3286, Training Loss: 0.1738467711594797, Validation Loss: 0.17396349708239237, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3287, Training Loss: 0.17349338195016306, Validation Loss: 0.17471483548482258, Validation Accuracy: 0.4875\n",
      "Epoch 3288, Training Loss: 0.17398053311532544, Validation Loss: 0.17276384433110556, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 3289, Training Loss: 0.17326534803836577, Validation Loss: 0.1744131882985433, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 3290, Training Loss: 0.1741301095293414, Validation Loss: 0.17354768613974253, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3291, Training Loss: 0.17342051286851207, Validation Loss: 0.1742719054222107, Validation Accuracy: 0.49375\n",
      "Epoch 3292, Training Loss: 0.17388708072323952, Validation Loss: 0.173525869846344, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 3293, Training Loss: 0.17344374858563946, Validation Loss: 0.17369819482167562, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 3294, Training Loss: 0.17393677946059935, Validation Loss: 0.1742359459400177, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 3295, Training Loss: 0.17353562289668667, Validation Loss: 0.17350744207700095, Validation Accuracy: 0.5125\n",
      "Epoch 3296, Training Loss: 0.1737943705051176, Validation Loss: 0.17451865474383035, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 3297, Training Loss: 0.17343657487823116, Validation Loss: 0.17294566134611766, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 3298, Training Loss: 0.17388703025156452, Validation Loss: 0.17414711912473044, Validation Accuracy: 0.48125\n",
      "Epoch 3299, Training Loss: 0.17362163143773232, Validation Loss: 0.1735788643360138, Validation Accuracy: 0.50625\n",
      "Epoch 3300, Training Loss: 0.1738446032808673, Validation Loss: 0.17492387493451436, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 3301, Training Loss: 0.17357735335826874, Validation Loss: 0.17226847112178803, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 3302, Training Loss: 0.17389880361095553, Validation Loss: 0.17413951754570006, Validation Accuracy: 0.475\n",
      "Epoch 3303, Training Loss: 0.17364980136194536, Validation Loss: 0.17331630388895672, Validation Accuracy: 0.5125\n",
      "Epoch 3304, Training Loss: 0.17383373648889602, Validation Loss: 0.17484164039293926, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 3305, Training Loss: 0.17353563539443478, Validation Loss: 0.1727251221736272, Validation Accuracy: 0.5375\n",
      "Epoch 3306, Training Loss: 0.17387282608016844, Validation Loss: 0.17384612460931143, Validation Accuracy: 0.4875\n",
      "Epoch 3307, Training Loss: 0.17362854797993937, Validation Loss: 0.17387378017107646, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 3308, Training Loss: 0.173785763402139, Validation Loss: 0.1741284151871999, Validation Accuracy: 0.475\n",
      "Epoch 3309, Training Loss: 0.17364698840725806, Validation Loss: 0.1723463863134384, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 3310, Training Loss: 0.1738697660546149, Validation Loss: 0.17413373788197836, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 3311, Training Loss: 0.17371886584066576, Validation Loss: 0.17369330922762552, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3312, Training Loss: 0.17373096846765088, Validation Loss: 0.17408552765846252, Validation Accuracy: 0.4875\n",
      "Epoch 3313, Training Loss: 0.1737382883025754, Validation Loss: 0.1728537251551946, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 3314, Training Loss: 0.1738851204995186, Validation Loss: 0.17342975338300068, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 3315, Training Loss: 0.1737430086058955, Validation Loss: 0.1735140174627304, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3316, Training Loss: 0.17379030200742906, Validation Loss: 0.1735981931289037, Validation Accuracy: 0.49375\n",
      "Epoch 3317, Training Loss: 0.17377127947345858, Validation Loss: 0.17333745658397676, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 3318, Training Loss: 0.17380792960043875, Validation Loss: 0.17327639361222585, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 3319, Training Loss: 0.17384253874901803, Validation Loss: 0.17359219392140707, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 3320, Training Loss: 0.1736491904143364, Validation Loss: 0.17326191266377766, Validation Accuracy: 0.5125\n",
      "Epoch 3321, Training Loss: 0.1738628754692693, Validation Loss: 0.17369318803151448, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 3322, Training Loss: 0.17372351356091037, Validation Loss: 0.17301063239574432, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 3323, Training Loss: 0.17389707555693965, Validation Loss: 0.17367029786109925, Validation Accuracy: 0.48125\n",
      "Epoch 3324, Training Loss: 0.17362214913291316, Validation Loss: 0.17339793145656585, Validation Accuracy: 0.50625\n",
      "Epoch 3325, Training Loss: 0.17390309274196625, Validation Loss: 0.17375262876351674, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 3326, Training Loss: 0.17374346717711417, Validation Loss: 0.17271428604920705, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 3327, Training Loss: 0.17387289049163943, Validation Loss: 0.1736623118321101, Validation Accuracy: 0.475\n",
      "Epoch 3328, Training Loss: 0.17367735360899278, Validation Loss: 0.17324903110663095, Validation Accuracy: 0.5125\n",
      "Epoch 3329, Training Loss: 0.17382749482508628, Validation Loss: 0.17385777831077576, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 3330, Training Loss: 0.173837153180953, Validation Loss: 0.17300041218598683, Validation Accuracy: 0.5375\n",
      "Epoch 3331, Training Loss: 0.17382474580118734, Validation Loss: 0.17361223498980205, Validation Accuracy: 0.4875\n",
      "Epoch 3332, Training Loss: 0.17368325927565176, Validation Loss: 0.17375086843967438, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 3333, Training Loss: 0.17377943185067946, Validation Loss: 0.17388334671656291, Validation Accuracy: 0.475\n",
      "Epoch 3334, Training Loss: 0.17389505813198705, Validation Loss: 0.17278200884660086, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 3335, Training Loss: 0.1737762035862092, Validation Loss: 0.17389452954133353, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 3336, Training Loss: 0.1737576146279612, Validation Loss: 0.17354641954104105, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3337, Training Loss: 0.17374028553885798, Validation Loss: 0.17369495034217836, Validation Accuracy: 0.4875\n",
      "Epoch 3338, Training Loss: 0.17396809401050692, Validation Loss: 0.17311329742272694, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 3339, Training Loss: 0.17368551271577035, Validation Loss: 0.1735877146323522, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 3340, Training Loss: 0.17391192720782372, Validation Loss: 0.17352721492449444, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3341, Training Loss: 0.17364901304244995, Validation Loss: 0.1736590474843979, Validation Accuracy: 0.49375\n",
      "Epoch 3342, Training Loss: 0.17392101931956508, Validation Loss: 0.17332124908765156, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 3343, Training Loss: 0.17384085539848573, Validation Loss: 0.17329384883244833, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 3344, Training Loss: 0.173810574796892, Validation Loss: 0.1736664245525996, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 3345, Training Loss: 0.17375257226728624, Validation Loss: 0.17329911291599273, Validation Accuracy: 0.5125\n",
      "Epoch 3346, Training Loss: 0.17390965982790915, Validation Loss: 0.1735361913839976, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 3347, Training Loss: 0.17376893854910327, Validation Loss: 0.1729133576154709, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 3348, Training Loss: 0.17370512745072764, Validation Loss: 0.17407048145929974, Validation Accuracy: 0.48125\n",
      "Epoch 3349, Training Loss: 0.17369052142866195, Validation Loss: 0.17352241575717925, Validation Accuracy: 0.50625\n",
      "Epoch 3350, Training Loss: 0.17405305033729923, Validation Loss: 0.17358215848604838, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 3351, Training Loss: 0.17361640257220115, Validation Loss: 0.1722233941157659, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 3352, Training Loss: 0.17389082283742965, Validation Loss: 0.1739175299803416, Validation Accuracy: 0.475\n",
      "Epoch 3353, Training Loss: 0.17369544938687356, Validation Loss: 0.17334715723991395, Validation Accuracy: 0.5125\n",
      "Epoch 3354, Training Loss: 0.17403153306053532, Validation Loss: 0.17355799973011016, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 3355, Training Loss: 0.1736882088645812, Validation Loss: 0.17276636362075806, Validation Accuracy: 0.5375\n",
      "Epoch 3356, Training Loss: 0.17383830345446064, Validation Loss: 0.17367834448814393, Validation Accuracy: 0.4875\n",
      "Epoch 3357, Training Loss: 0.17371485742830461, Validation Loss: 0.17377140720685322, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 3358, Training Loss: 0.1740488462871121, Validation Loss: 0.17348928650220236, Validation Accuracy: 0.475\n",
      "Epoch 3359, Training Loss: 0.17363776843394002, Validation Loss: 0.172260382771492, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 3360, Training Loss: 0.17390514958289363, Validation Loss: 0.17386800050735474, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 3361, Training Loss: 0.17366057970831472, Validation Loss: 0.17387441794077554, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3362, Training Loss: 0.1739985265078083, Validation Loss: 0.17340293725331624, Validation Accuracy: 0.4875\n",
      "Epoch 3363, Training Loss: 0.17375421572116115, Validation Loss: 0.17275279362996418, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 3364, Training Loss: 0.1739178857495708, Validation Loss: 0.17339766025543213, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 3365, Training Loss: 0.17367964358099044, Validation Loss: 0.17391140560309093, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3366, Training Loss: 0.1740548961585568, Validation Loss: 0.17332320511341096, Validation Accuracy: 0.49375\n",
      "Epoch 3367, Training Loss: 0.17373386602247914, Validation Loss: 0.17337499062220255, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 3368, Training Loss: 0.17384311172270006, Validation Loss: 0.17326221565405528, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 3369, Training Loss: 0.17359790686638124, Validation Loss: 0.17423576911290486, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 3370, Training Loss: 0.17408515897489363, Validation Loss: 0.17326053182284037, Validation Accuracy: 0.5125\n",
      "Epoch 3371, Training Loss: 0.17375214157565946, Validation Loss: 0.1737924923499425, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 3372, Training Loss: 0.17392794547542448, Validation Loss: 0.17316801051298777, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 3373, Training Loss: 0.1736418201077369, Validation Loss: 0.17453096409638721, Validation Accuracy: 0.48125\n",
      "Epoch 3374, Training Loss: 0.17406667865091754, Validation Loss: 0.17327090601126352, Validation Accuracy: 0.50625\n",
      "Epoch 3375, Training Loss: 0.17358338111831295, Validation Loss: 0.17500424285729727, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 3376, Training Loss: 0.17389187601304823, Validation Loss: 0.17316354314486185, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 3377, Training Loss: 0.1735860042033657, Validation Loss: 0.1746523857116699, Validation Accuracy: 0.475\n",
      "Epoch 3378, Training Loss: 0.1742178326652896, Validation Loss: 0.1732423553864161, Validation Accuracy: 0.5125\n",
      "Epoch 3379, Training Loss: 0.17349596081241483, Validation Loss: 0.17534238696098328, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 3380, Training Loss: 0.17403292463671777, Validation Loss: 0.1732015828291575, Validation Accuracy: 0.5375\n",
      "Epoch 3381, Training Loss: 0.17353247106075287, Validation Loss: 0.17473279138406117, Validation Accuracy: 0.4875\n",
      "Epoch 3382, Training Loss: 0.17421747167264262, Validation Loss: 0.17340887089570364, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 3383, Training Loss: 0.17364427735728602, Validation Loss: 0.17513922850290933, Validation Accuracy: 0.475\n",
      "Epoch 3384, Training Loss: 0.17412919959714335, Validation Loss: 0.17266504963239035, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 3385, Training Loss: 0.17356751234300674, Validation Loss: 0.17527303795019786, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 3386, Training Loss: 0.17414709252695884, Validation Loss: 0.1734399676322937, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3387, Training Loss: 0.1735366794370836, Validation Loss: 0.17498439848423003, Validation Accuracy: 0.4875\n",
      "Epoch 3388, Training Loss: 0.17407799103567678, Validation Loss: 0.172958238919576, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 3389, Training Loss: 0.17347558611823666, Validation Loss: 0.17465559442838033, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 3390, Training Loss: 0.17408223209842558, Validation Loss: 0.1735697994629542, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3391, Training Loss: 0.17362312780272576, Validation Loss: 0.17426010966300964, Validation Accuracy: 0.49375\n",
      "Epoch 3392, Training Loss: 0.17410828701911435, Validation Loss: 0.17329877118269602, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 3393, Training Loss: 0.17339921862848343, Validation Loss: 0.17422980864842733, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 3394, Training Loss: 0.1741475583084168, Validation Loss: 0.17424471179644266, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 3395, Training Loss: 0.17352560691295132, Validation Loss: 0.17385997672875722, Validation Accuracy: 0.5125\n",
      "Epoch 3396, Training Loss: 0.1742020191684846, Validation Loss: 0.17449823021888733, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 3397, Training Loss: 0.1736455112695694, Validation Loss: 0.17302660544713339, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 3398, Training Loss: 0.1741372760265104, Validation Loss: 0.17457109491030376, Validation Accuracy: 0.48125\n",
      "Epoch 3399, Training Loss: 0.1734808313269769, Validation Loss: 0.17400371730327607, Validation Accuracy: 0.50625\n",
      "Epoch 3400, Training Loss: 0.17430830818991508, Validation Loss: 0.17491423587004343, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 3401, Training Loss: 0.17357064158685745, Validation Loss: 0.172272856036822, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 3402, Training Loss: 0.17401013547374355, Validation Loss: 0.175040864944458, Validation Accuracy: 0.475\n",
      "Epoch 3403, Training Loss: 0.17377511628212466, Validation Loss: 0.17341499924659728, Validation Accuracy: 0.5125\n",
      "Epoch 3404, Training Loss: 0.1738170438235806, Validation Loss: 0.17543548047542573, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 3405, Training Loss: 0.1738159204682996, Validation Loss: 0.17270274460315704, Validation Accuracy: 0.5375\n",
      "Epoch 3406, Training Loss: 0.17377929581749824, Validation Loss: 0.1754177858432134, Validation Accuracy: 0.4875\n",
      "Epoch 3407, Training Loss: 0.1737966893180724, Validation Loss: 0.17437819838523866, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 3408, Training Loss: 0.1738671713298367, Validation Loss: 0.17545258204142253, Validation Accuracy: 0.475\n",
      "Epoch 3409, Training Loss: 0.17395086105792754, Validation Loss: 0.17205793857574464, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 3410, Training Loss: 0.1736889592101497, Validation Loss: 0.1757194419701894, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 3411, Training Loss: 0.1740625870804633, Validation Loss: 0.17392492492993672, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3412, Training Loss: 0.17360088036906335, Validation Loss: 0.17501921157042186, Validation Accuracy: 0.4875\n",
      "Epoch 3413, Training Loss: 0.17419796509127464, Validation Loss: 0.17274798254172008, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 3414, Training Loss: 0.17335961326476065, Validation Loss: 0.17482220629851022, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 3415, Training Loss: 0.17443739935275046, Validation Loss: 0.17380958994229634, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3416, Training Loss: 0.17353551041695378, Validation Loss: 0.17436585923035938, Validation Accuracy: 0.49375\n",
      "Epoch 3417, Training Loss: 0.17411805352857035, Validation Loss: 0.17371563216050465, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 3418, Training Loss: 0.1735628766398276, Validation Loss: 0.17395781874656677, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 3419, Training Loss: 0.17418996076430043, Validation Loss: 0.17399574716885885, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 3420, Training Loss: 0.17367530397830472, Validation Loss: 0.1736866980791092, Validation Accuracy: 0.5125\n",
      "Epoch 3421, Training Loss: 0.17396872322405538, Validation Loss: 0.17405609786510468, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 3422, Training Loss: 0.17359783716740146, Validation Loss: 0.17296390334765116, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 3423, Training Loss: 0.1740704510481127, Validation Loss: 0.17409475843111674, Validation Accuracy: 0.48125\n",
      "Epoch 3424, Training Loss: 0.17371105763220018, Validation Loss: 0.1736570547024409, Validation Accuracy: 0.50625\n",
      "Epoch 3425, Training Loss: 0.17391602310442156, Validation Loss: 0.17500884532928468, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 3426, Training Loss: 0.173695309988914, Validation Loss: 0.1722825268904368, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 3427, Training Loss: 0.17403130137151288, Validation Loss: 0.17422822912534078, Validation Accuracy: 0.475\n",
      "Epoch 3428, Training Loss: 0.17374852443895034, Validation Loss: 0.17336302995681763, Validation Accuracy: 0.5125\n",
      "Epoch 3429, Training Loss: 0.17398485493275426, Validation Loss: 0.17497513095537823, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 3430, Training Loss: 0.17363980220210168, Validation Loss: 0.17269731958707174, Validation Accuracy: 0.5375\n",
      "Epoch 3431, Training Loss: 0.17403108073819068, Validation Loss: 0.17373509605725607, Validation Accuracy: 0.4875\n",
      "Epoch 3432, Training Loss: 0.1737411142356934, Validation Loss: 0.17392082313696544, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 3433, Training Loss: 0.17394377243134282, Validation Loss: 0.17447630564371744, Validation Accuracy: 0.475\n",
      "Epoch 3434, Training Loss: 0.17373236821543786, Validation Loss: 0.17231827278931935, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 3435, Training Loss: 0.17404000797579366, Validation Loss: 0.17387968003749849, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 3436, Training Loss: 0.1737621998594653, Validation Loss: 0.17363187571366628, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3437, Training Loss: 0.1738492961852781, Validation Loss: 0.1742845912774404, Validation Accuracy: 0.4875\n",
      "Epoch 3438, Training Loss: 0.17384079339042788, Validation Loss: 0.1728639781475067, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 3439, Training Loss: 0.173922001354156, Validation Loss: 0.17351941466331483, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 3440, Training Loss: 0.17382115558270486, Validation Loss: 0.17359405755996704, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3441, Training Loss: 0.17393859932499547, Validation Loss: 0.1735239267349243, Validation Accuracy: 0.49375\n",
      "Epoch 3442, Training Loss: 0.1738209003402341, Validation Loss: 0.17334816654523214, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 3443, Training Loss: 0.1739534774134236, Validation Loss: 0.17325867215792337, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 3444, Training Loss: 0.17396924332264932, Validation Loss: 0.17356671194235485, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 3445, Training Loss: 0.1735317135049451, Validation Loss: 0.17347702185312908, Validation Accuracy: 0.5125\n",
      "Epoch 3446, Training Loss: 0.1740140102563366, Validation Loss: 0.17358207007249196, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 3447, Training Loss: 0.17382761163096275, Validation Loss: 0.1730250597000122, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 3448, Training Loss: 0.17399086634958943, Validation Loss: 0.1735902339220047, Validation Accuracy: 0.48125\n",
      "Epoch 3449, Training Loss: 0.1738167203241779, Validation Loss: 0.17332309782505034, Validation Accuracy: 0.50625\n",
      "Epoch 3450, Training Loss: 0.17392300405809957, Validation Loss: 0.17371458311875662, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 3451, Training Loss: 0.1738406155378588, Validation Loss: 0.17283007502555847, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 3452, Training Loss: 0.17396624722788412, Validation Loss: 0.1737564225991567, Validation Accuracy: 0.475\n",
      "Epoch 3453, Training Loss: 0.17369630019510945, Validation Loss: 0.17331332663695018, Validation Accuracy: 0.5125\n",
      "Epoch 3454, Training Loss: 0.17388638613685484, Validation Loss: 0.17387538452943166, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 3455, Training Loss: 0.17381957509825308, Validation Loss: 0.17290658950805665, Validation Accuracy: 0.5375\n",
      "Epoch 3456, Training Loss: 0.17397054453049937, Validation Loss: 0.17328742146492004, Validation Accuracy: 0.4875\n",
      "Epoch 3457, Training Loss: 0.17428124768118705, Validation Loss: 0.17537296215693157, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 3458, Training Loss: 0.17376199701140005, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.525\n",
      "Epoch 3459, Training Loss: 0.23462530441822543, Validation Loss: 0.32122758626937864, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 3460, Training Loss: 0.18503315794852473, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5270833333333333\n",
      "Epoch 3461, Training Loss: 0.18664283521713748, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 3462, Training Loss: 0.17415022369354002, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5125\n",
      "Epoch 3463, Training Loss: 0.1736985618068326, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.46458333333333335\n",
      "Epoch 3464, Training Loss: 0.17332804635647805, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 3465, Training Loss: 0.17523537335857267, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 3466, Training Loss: 0.17329880162592856, Validation Loss: 0.17330679297447205, Validation Accuracy: 0.49375\n",
      "Epoch 3467, Training Loss: 0.17318384926165303, Validation Loss: 0.17328144311904908, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 3468, Training Loss: 0.17354061863114756, Validation Loss: 0.17325743039449057, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 3469, Training Loss: 0.17340163357796207, Validation Loss: 0.17363598545392353, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 3470, Training Loss: 0.17394616959556455, Validation Loss: 0.17322120567162833, Validation Accuracy: 0.5125\n",
      "Epoch 3471, Training Loss: 0.1735393573199549, Validation Loss: 0.17430592974026998, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 3472, Training Loss: 0.17389117854256783, Validation Loss: 0.17299046317736308, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 3473, Training Loss: 0.17369216440185423, Validation Loss: 0.17396993239720662, Validation Accuracy: 0.48125\n",
      "Epoch 3474, Training Loss: 0.17365116650058376, Validation Loss: 0.17346773346265157, Validation Accuracy: 0.50625\n",
      "Epoch 3475, Training Loss: 0.17389383623676916, Validation Loss: 0.17398284673690795, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 3476, Training Loss: 0.17370369405515731, Validation Loss: 0.17235739628473917, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 3477, Training Loss: 0.17375932681945064, Validation Loss: 0.1738959699869156, Validation Accuracy: 0.475\n",
      "Epoch 3478, Training Loss: 0.17370449294967036, Validation Loss: 0.17334090769290925, Validation Accuracy: 0.5125\n",
      "Epoch 3479, Training Loss: 0.1740667507533104, Validation Loss: 0.17362567484378816, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 3480, Training Loss: 0.17369004122672543, Validation Loss: 0.1726867824792862, Validation Accuracy: 0.5375\n",
      "Epoch 3481, Training Loss: 0.17388847662556556, Validation Loss: 0.1740097165107727, Validation Accuracy: 0.4875\n",
      "Epoch 3482, Training Loss: 0.17362364405585873, Validation Loss: 0.17376575072606404, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 3483, Training Loss: 0.17415665522698434, Validation Loss: 0.17351430157820383, Validation Accuracy: 0.475\n",
      "Epoch 3484, Training Loss: 0.17360714126017787, Validation Loss: 0.17206612527370452, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 3485, Training Loss: 0.1739285400798244, Validation Loss: 0.17389263113339742, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 3486, Training Loss: 0.1736371151862606, Validation Loss: 0.17379913727442423, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3487, Training Loss: 0.1741087600108116, Validation Loss: 0.17340956330299379, Validation Accuracy: 0.4875\n",
      "Epoch 3488, Training Loss: 0.17366307541247336, Validation Loss: 0.1727412909269333, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 3489, Training Loss: 0.17401817440986633, Validation Loss: 0.17337374091148378, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 3490, Training Loss: 0.1736339388355132, Validation Loss: 0.17405011653900146, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3491, Training Loss: 0.1739338223011263, Validation Loss: 0.17331094443798065, Validation Accuracy: 0.49375\n",
      "Epoch 3492, Training Loss: 0.17376410816946336, Validation Loss: 0.1735520402590434, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 3493, Training Loss: 0.17395241462415265, Validation Loss: 0.17325689295927685, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 3494, Training Loss: 0.1735783459678773, Validation Loss: 0.1744665523370107, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 3495, Training Loss: 0.17412212875581556, Validation Loss: 0.17321926256020864, Validation Accuracy: 0.5125\n",
      "Epoch 3496, Training Loss: 0.17362790963342112, Validation Loss: 0.17425249616305033, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 3497, Training Loss: 0.1740565405737969, Validation Loss: 0.1731059322754542, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 3498, Training Loss: 0.17356974222967703, Validation Loss: 0.17469125588734943, Validation Accuracy: 0.48125\n",
      "Epoch 3499, Training Loss: 0.17407850776949235, Validation Loss: 0.17326996922492982, Validation Accuracy: 0.50625\n",
      "Epoch 3500, Training Loss: 0.17354367433055753, Validation Loss: 0.17508288820584614, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 3501, Training Loss: 0.17410472996773257, Validation Loss: 0.17311505675315858, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 3502, Training Loss: 0.17348163310558565, Validation Loss: 0.17493352194627126, Validation Accuracy: 0.475\n",
      "Epoch 3503, Training Loss: 0.174143533072164, Validation Loss: 0.17325510283311207, Validation Accuracy: 0.5125\n",
      "Epoch 3504, Training Loss: 0.1735375461078459, Validation Loss: 0.17518235047658284, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 3505, Training Loss: 0.17415436189020833, Validation Loss: 0.17304287354151407, Validation Accuracy: 0.5375\n",
      "Epoch 3506, Training Loss: 0.17345959188476687, Validation Loss: 0.17463883757591248, Validation Accuracy: 0.4875\n",
      "Epoch 3507, Training Loss: 0.17407682586100795, Validation Loss: 0.173319011926651, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 3508, Training Loss: 0.17363104368409804, Validation Loss: 0.17453241149584453, Validation Accuracy: 0.475\n",
      "Epoch 3509, Training Loss: 0.1741329719943385, Validation Loss: 0.172509237130483, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 3510, Training Loss: 0.1735408152303388, Validation Loss: 0.17524558504422505, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 3511, Training Loss: 0.1741351975548652, Validation Loss: 0.17359038492043813, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3512, Training Loss: 0.17351931718087965, Validation Loss: 0.1747799237569173, Validation Accuracy: 0.4875\n",
      "Epoch 3513, Training Loss: 0.17414418199369985, Validation Loss: 0.17281010150909423, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 3514, Training Loss: 0.17345943950837658, Validation Loss: 0.17446300387382507, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 3515, Training Loss: 0.17404569973868708, Validation Loss: 0.17365426023801167, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3516, Training Loss: 0.17362538220420962, Validation Loss: 0.1743241637945175, Validation Accuracy: 0.49375\n",
      "Epoch 3517, Training Loss: 0.17404091117843504, Validation Loss: 0.17339869737625122, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 3518, Training Loss: 0.17350974102174083, Validation Loss: 0.1737599273522695, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 3519, Training Loss: 0.1739455158672025, Validation Loss: 0.1743156502644221, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 3520, Training Loss: 0.17358043741795323, Validation Loss: 0.17380061944325764, Validation Accuracy: 0.5125\n",
      "Epoch 3521, Training Loss: 0.17411597265351203, Validation Loss: 0.17446546157201132, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 3522, Training Loss: 0.17360573045669064, Validation Loss: 0.17301059067249297, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 3523, Training Loss: 0.17401957367697068, Validation Loss: 0.17454036076863608, Validation Accuracy: 0.48125\n",
      "Epoch 3524, Training Loss: 0.17355454737140286, Validation Loss: 0.1739028404156367, Validation Accuracy: 0.50625\n",
      "Epoch 3525, Training Loss: 0.17419631394647783, Validation Loss: 0.17502884864807128, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 3526, Training Loss: 0.17366518224439315, Validation Loss: 0.1722177396217982, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 3527, Training Loss: 0.17396968026315013, Validation Loss: 0.17500927448272705, Validation Accuracy: 0.475\n",
      "Epoch 3528, Training Loss: 0.17377479422476985, Validation Loss: 0.17349473933378856, Validation Accuracy: 0.5125\n",
      "Epoch 3529, Training Loss: 0.17379942536354065, Validation Loss: 0.17506648500760397, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 3530, Training Loss: 0.1738179648114789, Validation Loss: 0.17265927890936533, Validation Accuracy: 0.5375\n",
      "Epoch 3531, Training Loss: 0.17369466106737813, Validation Loss: 0.1749178171157837, Validation Accuracy: 0.4875\n",
      "Epoch 3532, Training Loss: 0.17380189895629883, Validation Loss: 0.1745647112528483, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 3533, Training Loss: 0.1738144274680845, Validation Loss: 0.17557175755500792, Validation Accuracy: 0.475\n",
      "Epoch 3534, Training Loss: 0.17392793345835902, Validation Loss: 0.17189773122469584, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 3535, Training Loss: 0.17365373526850053, Validation Loss: 0.17549998064835867, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 3536, Training Loss: 0.17400257529750948, Validation Loss: 0.17387578189373015, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3537, Training Loss: 0.17363438875444473, Validation Loss: 0.17462507784366607, Validation Accuracy: 0.4875\n",
      "Epoch 3538, Training Loss: 0.17413020037835644, Validation Loss: 0.172736856341362, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 3539, Training Loss: 0.17329884584872954, Validation Loss: 0.1745418647925059, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 3540, Training Loss: 0.1743291102109417, Validation Loss: 0.17363576094309488, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3541, Training Loss: 0.1735763410406728, Validation Loss: 0.17418778240680693, Validation Accuracy: 0.49375\n",
      "Epoch 3542, Training Loss: 0.17405823449934682, Validation Loss: 0.1735671023527781, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 3543, Training Loss: 0.17359140803737025, Validation Loss: 0.1736168831586838, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 3544, Training Loss: 0.174100419206004, Validation Loss: 0.17417322993278503, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 3545, Training Loss: 0.17365359827395407, Validation Loss: 0.17348234256108602, Validation Accuracy: 0.5125\n",
      "Epoch 3546, Training Loss: 0.17402102678052842, Validation Loss: 0.17453565796216328, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 3547, Training Loss: 0.17354709198397975, Validation Loss: 0.17298120458920796, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 3548, Training Loss: 0.1740348026637108, Validation Loss: 0.1740513801574707, Validation Accuracy: 0.48125\n",
      "Epoch 3549, Training Loss: 0.17369924389546917, Validation Loss: 0.17371470232804617, Validation Accuracy: 0.50625\n",
      "Epoch 3550, Training Loss: 0.17407094855462352, Validation Loss: 0.17443789740403493, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 3551, Training Loss: 0.17366279180972807, Validation Loss: 0.17229081789652506, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 3552, Training Loss: 0.17404005844746867, Validation Loss: 0.17408612072467805, Validation Accuracy: 0.475\n",
      "Epoch 3553, Training Loss: 0.1737064709586482, Validation Loss: 0.17334175904591878, Validation Accuracy: 0.5125\n",
      "Epoch 3554, Training Loss: 0.17394894169222924, Validation Loss: 0.1746609648068746, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 3555, Training Loss: 0.1736454862740732, Validation Loss: 0.17270781497160595, Validation Accuracy: 0.5375\n",
      "Epoch 3556, Training Loss: 0.17402384069658094, Validation Loss: 0.17375428676605226, Validation Accuracy: 0.4875\n",
      "Epoch 3557, Training Loss: 0.1737595344743421, Validation Loss: 0.1738200565179189, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 3558, Training Loss: 0.17399081395518395, Validation Loss: 0.17400703529516856, Validation Accuracy: 0.475\n",
      "Epoch 3559, Training Loss: 0.17367869711691333, Validation Loss: 0.17217844327290852, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 3560, Training Loss: 0.17397914298119083, Validation Loss: 0.1741135984659195, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 3561, Training Loss: 0.17380520461067075, Validation Loss: 0.1737169881661733, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3562, Training Loss: 0.1739712030656876, Validation Loss: 0.17367616295814514, Validation Accuracy: 0.4875\n",
      "Epoch 3563, Training Loss: 0.17380489745447714, Validation Loss: 0.17284467021624247, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 3564, Training Loss: 0.17394145746384898, Validation Loss: 0.17350346048672993, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 3565, Training Loss: 0.17382299803918408, Validation Loss: 0.1735503266255061, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3566, Training Loss: 0.17390440981234273, Validation Loss: 0.17356446584065754, Validation Accuracy: 0.49375\n",
      "Epoch 3567, Training Loss: 0.17380443119233654, Validation Loss: 0.17333265046278637, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 3568, Training Loss: 0.17393332719802856, Validation Loss: 0.1732590635617574, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 3569, Training Loss: 0.1739081903811424, Validation Loss: 0.1736184279123942, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 3570, Training Loss: 0.17356431820700247, Validation Loss: 0.1734534442424774, Validation Accuracy: 0.5125\n",
      "Epoch 3571, Training Loss: 0.17399416142894375, Validation Loss: 0.1736202379067739, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 3572, Training Loss: 0.17373825465479203, Validation Loss: 0.17295715709527335, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 3573, Training Loss: 0.17404271710303523, Validation Loss: 0.1736445943514506, Validation Accuracy: 0.48125\n",
      "Epoch 3574, Training Loss: 0.17360048620931565, Validation Loss: 0.17364156742890677, Validation Accuracy: 0.50625\n",
      "Epoch 3575, Training Loss: 0.17397239131312217, Validation Loss: 0.1737053096294403, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 3576, Training Loss: 0.1738606451019164, Validation Loss: 0.1728737821181615, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 3577, Training Loss: 0.173929403866491, Validation Loss: 0.17380809187889099, Validation Accuracy: 0.475\n",
      "Epoch 3578, Training Loss: 0.17364821030247596, Validation Loss: 0.17333092192808788, Validation Accuracy: 0.5125\n",
      "Epoch 3579, Training Loss: 0.17390899888930783, Validation Loss: 0.17378334204355875, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 3580, Training Loss: 0.17383074760437012, Validation Loss: 0.17300061186154683, Validation Accuracy: 0.5375\n",
      "Epoch 3581, Training Loss: 0.17387593513534916, Validation Loss: 0.17359696726004284, Validation Accuracy: 0.4875\n",
      "Epoch 3582, Training Loss: 0.17366540095498484, Validation Loss: 0.1740026036898295, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 3583, Training Loss: 0.1737894569673846, Validation Loss: 0.17403095662593843, Validation Accuracy: 0.475\n",
      "Epoch 3584, Training Loss: 0.17402390703078238, Validation Loss: 0.17298344075679778, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 3585, Training Loss: 0.17385054403735745, Validation Loss: 0.1741534988085429, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 3586, Training Loss: 0.17369685105739102, Validation Loss: 0.17379759152730306, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3587, Training Loss: 0.17381982601458026, Validation Loss: 0.17374553978443147, Validation Accuracy: 0.4875\n",
      "Epoch 3588, Training Loss: 0.17395075002024252, Validation Loss: 0.17304813961187998, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 3589, Training Loss: 0.17376034442455537, Validation Loss: 0.17355449199676515, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 3590, Training Loss: 0.1738750357781687, Validation Loss: 0.17383568088213602, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3591, Training Loss: 0.17366852394996152, Validation Loss: 0.17368920147418976, Validation Accuracy: 0.49375\n",
      "Epoch 3592, Training Loss: 0.17393320318191283, Validation Loss: 0.17335005402565, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 3593, Training Loss: 0.17385169046540414, Validation Loss: 0.1733077883720398, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 3594, Training Loss: 0.17385798596566723, Validation Loss: 0.17360474467277526, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 3595, Training Loss: 0.17374778274566896, Validation Loss: 0.1732977996269862, Validation Accuracy: 0.5125\n",
      "Epoch 3596, Training Loss: 0.17398691417709475, Validation Loss: 0.1734295924504598, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 3597, Training Loss: 0.17384771570082633, Validation Loss: 0.1729406048854192, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 3598, Training Loss: 0.17376111880425485, Validation Loss: 0.173828720053037, Validation Accuracy: 0.48125\n",
      "Epoch 3599, Training Loss: 0.17369062765952079, Validation Loss: 0.17348281840483348, Validation Accuracy: 0.50625\n",
      "Epoch 3600, Training Loss: 0.17411681673219126, Validation Loss: 0.17345103720823923, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 3601, Training Loss: 0.17372453212738037, Validation Loss: 0.1724492887655894, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 3602, Training Loss: 0.17394526398951007, Validation Loss: 0.1736101597547531, Validation Accuracy: 0.475\n",
      "Epoch 3603, Training Loss: 0.17371072019300154, Validation Loss: 0.17323078413804371, Validation Accuracy: 0.5125\n",
      "Epoch 3604, Training Loss: 0.17409313926773687, Validation Loss: 0.17343245446681976, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 3605, Training Loss: 0.1736048810905026, Validation Loss: 0.17267553011576334, Validation Accuracy: 0.5375\n",
      "Epoch 3606, Training Loss: 0.17395327841081926, Validation Loss: 0.17371165255705515, Validation Accuracy: 0.4875\n",
      "Epoch 3607, Training Loss: 0.17375515161022062, Validation Loss: 0.17365656594435375, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 3608, Training Loss: 0.17412463695772232, Validation Loss: 0.17340852717558544, Validation Accuracy: 0.475\n",
      "Epoch 3609, Training Loss: 0.1737049678640981, Validation Loss: 0.1722475508848826, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 3610, Training Loss: 0.17390977038491157, Validation Loss: 0.17380682130654654, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 3611, Training Loss: 0.1737238404250914, Validation Loss: 0.17384575208028158, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3612, Training Loss: 0.1740615637071671, Validation Loss: 0.17335981428623198, Validation Accuracy: 0.4875\n",
      "Epoch 3613, Training Loss: 0.17376830068326765, Validation Loss: 0.1728386849164963, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 3614, Training Loss: 0.1739648143129964, Validation Loss: 0.17333136002222696, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 3615, Training Loss: 0.17373423470604804, Validation Loss: 0.1739314446846644, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3616, Training Loss: 0.1740326222873503, Validation Loss: 0.1733104705810547, Validation Accuracy: 0.49375\n",
      "Epoch 3617, Training Loss: 0.173817420678754, Validation Loss: 0.17340787947177888, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 3618, Training Loss: 0.17397626513434994, Validation Loss: 0.17326569060484567, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 3619, Training Loss: 0.173623088386751, Validation Loss: 0.17382788161436716, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 3620, Training Loss: 0.17413815567570348, Validation Loss: 0.17326497336228688, Validation Accuracy: 0.5125\n",
      "Epoch 3621, Training Loss: 0.17373622713550443, Validation Loss: 0.1740828255812327, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 3622, Training Loss: 0.17402047832165995, Validation Loss: 0.17322803338368734, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 3623, Training Loss: 0.17365996779934054, Validation Loss: 0.17451875706513723, Validation Accuracy: 0.48125\n",
      "Epoch 3624, Training Loss: 0.17416650922067703, Validation Loss: 0.17326938311258952, Validation Accuracy: 0.50625\n",
      "Epoch 3625, Training Loss: 0.1735951631299911, Validation Loss: 0.17518806159496308, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 3626, Training Loss: 0.17402108734653843, Validation Loss: 0.17313690781593322, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 3627, Training Loss: 0.17361131118189904, Validation Loss: 0.17515111168225606, Validation Accuracy: 0.475\n",
      "Epoch 3628, Training Loss: 0.17420305503952888, Validation Loss: 0.1732535531123479, Validation Accuracy: 0.5125\n",
      "Epoch 3629, Training Loss: 0.1735768024959872, Validation Loss: 0.17480429907639822, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 3630, Training Loss: 0.1740717815776025, Validation Loss: 0.17322345077991486, Validation Accuracy: 0.5375\n",
      "Epoch 3631, Training Loss: 0.1735366895314186, Validation Loss: 0.17464706897735596, Validation Accuracy: 0.4875\n",
      "Epoch 3632, Training Loss: 0.17423137061057553, Validation Loss: 0.17330696086088818, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 3633, Training Loss: 0.17373752978540236, Validation Loss: 0.17507593631744384, Validation Accuracy: 0.475\n",
      "Epoch 3634, Training Loss: 0.17405303351340756, Validation Loss: 0.17321284313996632, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 3635, Training Loss: 0.1736383673644835, Validation Loss: 0.1749810884396235, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 3636, Training Loss: 0.174156621579201, Validation Loss: 0.1733860691388448, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3637, Training Loss: 0.17359157627628696, Validation Loss: 0.1750680536031723, Validation Accuracy: 0.4875\n",
      "Epoch 3638, Training Loss: 0.1741393554595209, Validation Loss: 0.17292257050673168, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 3639, Training Loss: 0.17350178428234592, Validation Loss: 0.17470827102661132, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 3640, Training Loss: 0.17415356203433005, Validation Loss: 0.17373953660329183, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3641, Training Loss: 0.1736163660403221, Validation Loss: 0.17490914662679036, Validation Accuracy: 0.49375\n",
      "Epoch 3642, Training Loss: 0.1741582280205142, Validation Loss: 0.1733598490556081, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 3643, Training Loss: 0.17350050999272254, Validation Loss: 0.17392560839653015, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 3644, Training Loss: 0.17403460558383696, Validation Loss: 0.17370996177196502, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 3645, Training Loss: 0.17355318175208184, Validation Loss: 0.17357858618100483, Validation Accuracy: 0.5125\n",
      "Epoch 3646, Training Loss: 0.1741878645073983, Validation Loss: 0.17343266805013022, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 3647, Training Loss: 0.17344508296059025, Validation Loss: 0.17301755547523498, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 3648, Training Loss: 0.17415673165552079, Validation Loss: 0.17452973524729412, Validation Accuracy: 0.48125\n",
      "Epoch 3649, Training Loss: 0.17347251599834812, Validation Loss: 0.174128915866216, Validation Accuracy: 0.50625\n",
      "Epoch 3650, Training Loss: 0.17437506058523733, Validation Loss: 0.1749990572532018, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 3651, Training Loss: 0.17359226653652807, Validation Loss: 0.17214423716068267, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 3652, Training Loss: 0.1740932560736133, Validation Loss: 0.17520637512207032, Validation Accuracy: 0.475\n",
      "Epoch 3653, Training Loss: 0.173731769765577, Validation Loss: 0.17359870175520578, Validation Accuracy: 0.5125\n",
      "Epoch 3654, Training Loss: 0.1738362100816542, Validation Loss: 0.17567851344744365, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 3655, Training Loss: 0.17388722348597743, Validation Loss: 0.17266081273555756, Validation Accuracy: 0.5375\n",
      "Epoch 3656, Training Loss: 0.17378835043599528, Validation Loss: 0.1753984659910202, Validation Accuracy: 0.4875\n",
      "Epoch 3657, Training Loss: 0.17384901594731114, Validation Loss: 0.1743309239546458, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 3658, Training Loss: 0.17391831403778446, Validation Loss: 0.17581164538860322, Validation Accuracy: 0.475\n",
      "Epoch 3659, Training Loss: 0.17398676228138707, Validation Loss: 0.17186930477619172, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 3660, Training Loss: 0.17375424071665732, Validation Loss: 0.17626333038012187, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 3661, Training Loss: 0.17405405304124277, Validation Loss: 0.1740646799405416, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3662, Training Loss: 0.17364821943544573, Validation Loss: 0.17520436346530915, Validation Accuracy: 0.4875\n",
      "Epoch 3663, Training Loss: 0.17426069465375715, Validation Loss: 0.1727269967397054, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 3664, Training Loss: 0.17335515445278538, Validation Loss: 0.17505113979180653, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 3665, Training Loss: 0.1744885891675949, Validation Loss: 0.17383729716142018, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3666, Training Loss: 0.17359857693795236, Validation Loss: 0.17451110283533733, Validation Accuracy: 0.49375\n",
      "Epoch 3667, Training Loss: 0.17405314839655353, Validation Loss: 0.17360260486602783, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 3668, Training Loss: 0.17349662078965095, Validation Loss: 0.17396358847618104, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 3669, Training Loss: 0.17414910514508525, Validation Loss: 0.17452832460403442, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 3670, Training Loss: 0.17365330457687378, Validation Loss: 0.1736592133839925, Validation Accuracy: 0.5125\n",
      "Epoch 3671, Training Loss: 0.17401097041945304, Validation Loss: 0.17437211175759634, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 3672, Training Loss: 0.1735745322319769, Validation Loss: 0.17294092774391173, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 3673, Training Loss: 0.17400732876793032, Validation Loss: 0.17438745399316152, Validation Accuracy: 0.48125\n",
      "Epoch 3674, Training Loss: 0.1737576050143088, Validation Loss: 0.17383711536725363, Validation Accuracy: 0.50625\n",
      "Epoch 3675, Training Loss: 0.17396178457044786, Validation Loss: 0.17557627658049266, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 3676, Training Loss: 0.173662735089179, Validation Loss: 0.1722171594699224, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 3677, Training Loss: 0.17402647627938178, Validation Loss: 0.17432326078414917, Validation Accuracy: 0.475\n",
      "Epoch 3678, Training Loss: 0.17375860243074356, Validation Loss: 0.17349720100561777, Validation Accuracy: 0.5125\n",
      "Epoch 3679, Training Loss: 0.17398901572150569, Validation Loss: 0.17451307872931163, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 3680, Training Loss: 0.17366731022634813, Validation Loss: 0.1726939121882121, Validation Accuracy: 0.5375\n",
      "Epoch 3681, Training Loss: 0.17403637401519284, Validation Loss: 0.17371173004309337, Validation Accuracy: 0.4875\n",
      "Epoch 3682, Training Loss: 0.17374335613942915, Validation Loss: 0.17405099173386893, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 3683, Training Loss: 0.17406528082586104, Validation Loss: 0.17443188031514487, Validation Accuracy: 0.475\n",
      "Epoch 3684, Training Loss: 0.17370681176262517, Validation Loss: 0.1719106525182724, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 3685, Training Loss: 0.17399099709526186, Validation Loss: 0.17425268193085988, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 3686, Training Loss: 0.1738093005072686, Validation Loss: 0.17364831268787384, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3687, Training Loss: 0.17389348822255288, Validation Loss: 0.17401330669720969, Validation Accuracy: 0.4875\n",
      "Epoch 3688, Training Loss: 0.1738288657319161, Validation Loss: 0.1728545159101486, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 3689, Training Loss: 0.17396814207876882, Validation Loss: 0.17350516021251677, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 3690, Training Loss: 0.17386048359255638, Validation Loss: 0.17353635330994924, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3691, Training Loss: 0.17398393346417335, Validation Loss: 0.17349048455556235, Validation Accuracy: 0.49375\n",
      "Epoch 3692, Training Loss: 0.1738537165426439, Validation Loss: 0.17334671219189962, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 3693, Training Loss: 0.17389878678706386, Validation Loss: 0.17327565054098765, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 3694, Training Loss: 0.17395230695124594, Validation Loss: 0.17363059222698213, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 3695, Training Loss: 0.17363219636101876, Validation Loss: 0.17348282635211945, Validation Accuracy: 0.5125\n",
      "Epoch 3696, Training Loss: 0.17402692523694807, Validation Loss: 0.1736586093902588, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 3697, Training Loss: 0.173838704343765, Validation Loss: 0.1730245441198349, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 3698, Training Loss: 0.17399496176550466, Validation Loss: 0.17355689803759258, Validation Accuracy: 0.48125\n",
      "Epoch 3699, Training Loss: 0.17365496004781417, Validation Loss: 0.173550745844841, Validation Accuracy: 0.50625\n",
      "Epoch 3700, Training Loss: 0.17399021358259262, Validation Loss: 0.1737745056549708, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 3701, Training Loss: 0.17386707903877383, Validation Loss: 0.17280469437440235, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 3702, Training Loss: 0.17391828808092302, Validation Loss: 0.17357753813266755, Validation Accuracy: 0.475\n",
      "Epoch 3703, Training Loss: 0.17380817090311357, Validation Loss: 0.173225536942482, Validation Accuracy: 0.5125\n",
      "Epoch 3704, Training Loss: 0.17391970080714073, Validation Loss: 0.17378552556037902, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 3705, Training Loss: 0.17391170753586677, Validation Loss: 0.17302542328834533, Validation Accuracy: 0.5375\n",
      "Epoch 3706, Training Loss: 0.17391707147321395, Validation Loss: 0.17357825636863708, Validation Accuracy: 0.4875\n",
      "Epoch 3707, Training Loss: 0.17380534785409127, Validation Loss: 0.17368972500165303, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 3708, Training Loss: 0.1738389052690998, Validation Loss: 0.1738946755727132, Validation Accuracy: 0.475\n",
      "Epoch 3709, Training Loss: 0.17404227102956465, Validation Loss: 0.17299225330352783, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 3710, Training Loss: 0.17389045799932173, Validation Loss: 0.1739868253469467, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 3711, Training Loss: 0.17379581255297508, Validation Loss: 0.17359341184298197, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3712, Training Loss: 0.1738259239542869, Validation Loss: 0.17375187675158182, Validation Accuracy: 0.4875\n",
      "Epoch 3713, Training Loss: 0.17401234565242643, Validation Loss: 0.17310073177019755, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 3714, Training Loss: 0.1738200428024415, Validation Loss: 0.17350616951783498, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 3715, Training Loss: 0.17395255306074697, Validation Loss: 0.17353017628192902, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3716, Training Loss: 0.173694004935603, Validation Loss: 0.1737399737040202, Validation Accuracy: 0.49375\n",
      "Epoch 3717, Training Loss: 0.17405503171105538, Validation Loss: 0.17328461011250815, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 3718, Training Loss: 0.1738814490456735, Validation Loss: 0.17328040897846222, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 3719, Training Loss: 0.17388034155291895, Validation Loss: 0.17358385920524597, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 3720, Training Loss: 0.17378511159650742, Validation Loss: 0.17328112522761027, Validation Accuracy: 0.5125\n",
      "Epoch 3721, Training Loss: 0.17401025804781145, Validation Loss: 0.17340620656808217, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 3722, Training Loss: 0.17386932767206623, Validation Loss: 0.1729427476723989, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 3723, Training Loss: 0.17385738895785424, Validation Loss: 0.17360936601956686, Validation Accuracy: 0.48125\n",
      "Epoch 3724, Training Loss: 0.17372883183340873, Validation Loss: 0.17344718078772228, Validation Accuracy: 0.50625\n",
      "Epoch 3725, Training Loss: 0.17400795269396999, Validation Loss: 0.17359989682833354, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 3726, Training Loss: 0.17380428746823343, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.4479166666666667\n",
      "Epoch 3727, Training Loss: 0.1759590857451962, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.525\n",
      "Epoch 3728, Training Loss: 0.17362663966994132, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.4875\n",
      "Epoch 3729, Training Loss: 0.17346320661806292, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 3730, Training Loss: 0.17337607279900583, Validation Loss: 0.17328674495220184, Validation Accuracy: 0.5375\n",
      "Epoch 3731, Training Loss: 0.173070881635912, Validation Loss: 0.17329005698362987, Validation Accuracy: 0.4875\n",
      "Epoch 3732, Training Loss: 0.17427644806523476, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5104166666666666\n",
      "Epoch 3733, Training Loss: 0.17352941007383407, Validation Loss: 0.17409487267335255, Validation Accuracy: 0.475\n",
      "Epoch 3734, Training Loss: 0.17352558864701179, Validation Loss: 0.17272261877854664, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 3735, Training Loss: 0.17341915830489127, Validation Loss: 0.17372900446256, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 3736, Training Loss: 0.1734638738055383, Validation Loss: 0.1735825628042221, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3737, Training Loss: 0.17384970572686964, Validation Loss: 0.17338016033172607, Validation Accuracy: 0.4875\n",
      "Epoch 3738, Training Loss: 0.17347602834624629, Validation Loss: 0.17282512287298837, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 3739, Training Loss: 0.17360367938395468, Validation Loss: 0.17353011667728424, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 3740, Training Loss: 0.17361233215178212, Validation Loss: 0.1737364113330841, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3741, Training Loss: 0.17404977640798014, Validation Loss: 0.17333984375, Validation Accuracy: 0.49375\n",
      "Epoch 3742, Training Loss: 0.17368108370611746, Validation Loss: 0.17366405526796977, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 3743, Training Loss: 0.1739435489139249, Validation Loss: 0.17326553066571554, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 3744, Training Loss: 0.17350003315556434, Validation Loss: 0.1744133085012436, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 3745, Training Loss: 0.1741579420143558, Validation Loss: 0.17321722606817883, Validation Accuracy: 0.5125\n",
      "Epoch 3746, Training Loss: 0.17359686859192386, Validation Loss: 0.1745629648367564, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 3747, Training Loss: 0.17382389162817308, Validation Loss: 0.173245174686114, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 3748, Training Loss: 0.1736747920513153, Validation Loss: 0.17432750165462493, Validation Accuracy: 0.48125\n",
      "Epoch 3749, Training Loss: 0.17412668899182351, Validation Loss: 0.17327726980050404, Validation Accuracy: 0.50625\n",
      "Epoch 3750, Training Loss: 0.17356315207096837, Validation Loss: 0.17492877840995788, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 3751, Training Loss: 0.1742266325219985, Validation Loss: 0.17313127915064494, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 3752, Training Loss: 0.1735031407686972, Validation Loss: 0.17477869093418122, Validation Accuracy: 0.475\n",
      "Epoch 3753, Training Loss: 0.17442766745244304, Validation Loss: 0.1732391357421875, Validation Accuracy: 0.5125\n",
      "Epoch 3754, Training Loss: 0.1734022565426365, Validation Loss: 0.17536755601565043, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 3755, Training Loss: 0.17431840012150426, Validation Loss: 0.17278446356455485, Validation Accuracy: 0.5375\n",
      "Epoch 3756, Training Loss: 0.17350737990871554, Validation Loss: 0.17457548379898072, Validation Accuracy: 0.4875\n",
      "Epoch 3757, Training Loss: 0.17444955581618893, Validation Loss: 0.17380596399307252, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 3758, Training Loss: 0.17354130408456248, Validation Loss: 0.17448120911916096, Validation Accuracy: 0.475\n",
      "Epoch 3759, Training Loss: 0.17432998745672165, Validation Loss: 0.1722888876994451, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 3760, Training Loss: 0.17358479672862637, Validation Loss: 0.175143364071846, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 3761, Training Loss: 0.17429245191235695, Validation Loss: 0.17362109422683716, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3762, Training Loss: 0.173528996206099, Validation Loss: 0.1745122939348221, Validation Accuracy: 0.4875\n",
      "Epoch 3763, Training Loss: 0.17435882601045793, Validation Loss: 0.17277903159459432, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 3764, Training Loss: 0.17347726706535585, Validation Loss: 0.17436122794946035, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 3765, Training Loss: 0.1742474571351082, Validation Loss: 0.1741333305835724, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3766, Training Loss: 0.17366184534565096, Validation Loss: 0.17447823882102967, Validation Accuracy: 0.49375\n",
      "Epoch 3767, Training Loss: 0.17418427957642463, Validation Loss: 0.1737002948919932, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 3768, Training Loss: 0.17363769104403834, Validation Loss: 0.17375776370366414, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 3769, Training Loss: 0.1741071963502515, Validation Loss: 0.17463329335053762, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 3770, Training Loss: 0.17370194388974097, Validation Loss: 0.17363198697566987, Validation Accuracy: 0.5125\n",
      "Epoch 3771, Training Loss: 0.17428970192709275, Validation Loss: 0.17476425170898438, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 3772, Training Loss: 0.1737228093608733, Validation Loss: 0.17294698456923166, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 3773, Training Loss: 0.1741580020996832, Validation Loss: 0.17478131353855134, Validation Accuracy: 0.48125\n",
      "Epoch 3774, Training Loss: 0.1736718935351218, Validation Loss: 0.17376654942830402, Validation Accuracy: 0.50625\n",
      "Epoch 3775, Training Loss: 0.17433830518876353, Validation Loss: 0.17535858849684396, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 3776, Training Loss: 0.17378740685601388, Validation Loss: 0.17215752601623535, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 3777, Training Loss: 0.17406540820675512, Validation Loss: 0.1750356415907542, Validation Accuracy: 0.475\n",
      "Epoch 3778, Training Loss: 0.1739032946286663, Validation Loss: 0.17350253462791443, Validation Accuracy: 0.5125\n",
      "Epoch 3779, Training Loss: 0.1738605619438233, Validation Loss: 0.17526799738407134, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 3780, Training Loss: 0.17399603320706275, Validation Loss: 0.17265934348106385, Validation Accuracy: 0.5375\n",
      "Epoch 3781, Training Loss: 0.17380229648082487, Validation Loss: 0.1747466097275416, Validation Accuracy: 0.4875\n",
      "Epoch 3782, Training Loss: 0.1739784320515971, Validation Loss: 0.17421547571818033, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 3783, Training Loss: 0.17389020323753357, Validation Loss: 0.1753020167350769, Validation Accuracy: 0.475\n",
      "Epoch 3784, Training Loss: 0.17407047075610008, Validation Loss: 0.17187556525071462, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 3785, Training Loss: 0.17371498000237248, Validation Loss: 0.17651948134104412, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 3786, Training Loss: 0.17424972211160966, Validation Loss: 0.17383431792259216, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3787, Training Loss: 0.17367600048741988, Validation Loss: 0.17501330773035687, Validation Accuracy: 0.4875\n",
      "Epoch 3788, Training Loss: 0.17437363391922367, Validation Loss: 0.17273658911387127, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 3789, Training Loss: 0.17339608265507606, Validation Loss: 0.1748803953329722, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 3790, Training Loss: 0.1746135070439308, Validation Loss: 0.17385781705379486, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3791, Training Loss: 0.17354910171801044, Validation Loss: 0.17487273514270782, Validation Accuracy: 0.49375\n",
      "Epoch 3792, Training Loss: 0.17432312186687224, Validation Loss: 0.17354450325171153, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 3793, Training Loss: 0.1737113167201319, Validation Loss: 0.17366168598333995, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 3794, Training Loss: 0.17423025206212076, Validation Loss: 0.17436080873012544, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 3795, Training Loss: 0.17369173803637106, Validation Loss: 0.17365804711977642, Validation Accuracy: 0.5125\n",
      "Epoch 3796, Training Loss: 0.1742112905748429, Validation Loss: 0.17429472506046295, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 3797, Training Loss: 0.17362851144806032, Validation Loss: 0.1730379730463028, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 3798, Training Loss: 0.17422090182381292, Validation Loss: 0.17411760588486988, Validation Accuracy: 0.48125\n",
      "Epoch 3799, Training Loss: 0.17377142031346599, Validation Loss: 0.17365891635417938, Validation Accuracy: 0.50625\n",
      "Epoch 3800, Training Loss: 0.17412007335693605, Validation Loss: 0.17476676205794017, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 3801, Training Loss: 0.17372447348410083, Validation Loss: 0.1721257617076238, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 3802, Training Loss: 0.1742039668944574, Validation Loss: 0.17423214515050253, Validation Accuracy: 0.475\n",
      "Epoch 3803, Training Loss: 0.17379285875828035, Validation Loss: 0.17342185179392497, Validation Accuracy: 0.5125\n",
      "Epoch 3804, Training Loss: 0.17414532649901607, Validation Loss: 0.1745128482580185, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 3805, Training Loss: 0.17372705426908308, Validation Loss: 0.17268084983030954, Validation Accuracy: 0.5375\n",
      "Epoch 3806, Training Loss: 0.17412860499274346, Validation Loss: 0.17401155233383178, Validation Accuracy: 0.4875\n",
      "Epoch 3807, Training Loss: 0.17372568864976207, Validation Loss: 0.17418638368447623, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 3808, Training Loss: 0.1742677674178154, Validation Loss: 0.173993648091952, Validation Accuracy: 0.475\n",
      "Epoch 3809, Training Loss: 0.173782225578062, Validation Loss: 0.17205783426761628, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 3810, Training Loss: 0.17411978638941242, Validation Loss: 0.1741877516110738, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 3811, Training Loss: 0.17383264053252437, Validation Loss: 0.1737550288438797, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3812, Training Loss: 0.17402802023195452, Validation Loss: 0.17393814225991566, Validation Accuracy: 0.4875\n",
      "Epoch 3813, Training Loss: 0.17384389956151286, Validation Loss: 0.17291895151138306, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 3814, Training Loss: 0.17415378266765225, Validation Loss: 0.17356526056925456, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 3815, Training Loss: 0.17380744026553246, Validation Loss: 0.17346985141436258, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3816, Training Loss: 0.17412962644330918, Validation Loss: 0.1735921859741211, Validation Accuracy: 0.49375\n",
      "Epoch 3817, Training Loss: 0.17385943570444662, Validation Loss: 0.1732881983121236, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 3818, Training Loss: 0.17404225132157725, Validation Loss: 0.17333703835805256, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 3819, Training Loss: 0.173956714330181, Validation Loss: 0.17349539796511332, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 3820, Training Loss: 0.1738902296750776, Validation Loss: 0.1732660988966624, Validation Accuracy: 0.5125\n",
      "Epoch 3821, Training Loss: 0.1739011017545577, Validation Loss: 0.17350088159243265, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 3822, Training Loss: 0.1741070463772743, Validation Loss: 0.17299629747867584, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 3823, Training Loss: 0.17397473175679484, Validation Loss: 0.17350797851880392, Validation Accuracy: 0.48125\n",
      "Epoch 3824, Training Loss: 0.17401269991551677, Validation Loss: 0.17333997686704, Validation Accuracy: 0.50625\n",
      "Epoch 3825, Training Loss: 0.17385004508879878, Validation Loss: 0.17354793349901834, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 3826, Training Loss: 0.17417070413789443, Validation Loss: 0.17275951604048412, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 3827, Training Loss: 0.17391342886032596, Validation Loss: 0.17366209030151367, Validation Accuracy: 0.475\n",
      "Epoch 3828, Training Loss: 0.17397914826869965, Validation Loss: 0.1732289711634318, Validation Accuracy: 0.5125\n",
      "Epoch 3829, Training Loss: 0.1738297660504618, Validation Loss: 0.17362873951594035, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 3830, Training Loss: 0.17417693041986035, Validation Loss: 0.17292005121707915, Validation Accuracy: 0.5375\n",
      "Epoch 3831, Training Loss: 0.17381641124525377, Validation Loss: 0.17357858121395112, Validation Accuracy: 0.4875\n",
      "Epoch 3832, Training Loss: 0.17413285374641418, Validation Loss: 0.17349440356095633, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 3833, Training Loss: 0.17377802873811415, Validation Loss: 0.17375532686710357, Validation Accuracy: 0.475\n",
      "Epoch 3834, Training Loss: 0.17419671387441696, Validation Loss: 0.17269880076249441, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 3835, Training Loss: 0.17379913743465178, Validation Loss: 0.17405171791712443, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 3836, Training Loss: 0.1740945322859672, Validation Loss: 0.1735011637210846, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3837, Training Loss: 0.1737917603984956, Validation Loss: 0.17384033501148224, Validation Accuracy: 0.4875\n",
      "Epoch 3838, Training Loss: 0.17420018584497513, Validation Loss: 0.17297913531462353, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 3839, Training Loss: 0.1737078663802916, Validation Loss: 0.1739038278659185, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 3840, Training Loss: 0.1742143443515224, Validation Loss: 0.17356072664260863, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3841, Training Loss: 0.17365881271900668, Validation Loss: 0.1737108051776886, Validation Accuracy: 0.49375\n",
      "Epoch 3842, Training Loss: 0.17429410497988423, Validation Loss: 0.1733063538869222, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 3843, Training Loss: 0.17372329677304915, Validation Loss: 0.17333687245845794, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 3844, Training Loss: 0.17424238112664991, Validation Loss: 0.17349554697672526, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 3845, Training Loss: 0.173780148067782, Validation Loss: 0.17339016993840536, Validation Accuracy: 0.5125\n",
      "Epoch 3846, Training Loss: 0.17410911235117144, Validation Loss: 0.17364473541577657, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 3847, Training Loss: 0.1738675582793451, Validation Loss: 0.17291926244894665, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 3848, Training Loss: 0.17405106800217782, Validation Loss: 0.17372066378593445, Validation Accuracy: 0.48125\n",
      "Epoch 3849, Training Loss: 0.17362342822936275, Validation Loss: 0.17349688907464345, Validation Accuracy: 0.50625\n",
      "Epoch 3850, Training Loss: 0.17437697322137893, Validation Loss: 0.17360923488934835, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 3851, Training Loss: 0.17362467367802897, Validation Loss: 0.17220855156580608, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 3852, Training Loss: 0.1743308445138316, Validation Loss: 0.17361063957214357, Validation Accuracy: 0.475\n",
      "Epoch 3853, Training Loss: 0.17363805540146365, Validation Loss: 0.17337862650553384, Validation Accuracy: 0.5125\n",
      "Epoch 3854, Training Loss: 0.1743370895424197, Validation Loss: 0.17357423404852548, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 3855, Training Loss: 0.17362570378088182, Validation Loss: 0.17265917559464772, Validation Accuracy: 0.5375\n",
      "Epoch 3856, Training Loss: 0.17432090928477625, Validation Loss: 0.173514461517334, Validation Accuracy: 0.4875\n",
      "Epoch 3857, Training Loss: 0.1736241079145862, Validation Loss: 0.1740242749452591, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 3858, Training Loss: 0.17435882408772746, Validation Loss: 0.17346178690592448, Validation Accuracy: 0.475\n",
      "Epoch 3859, Training Loss: 0.17361048825325504, Validation Loss: 0.17194240788618723, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 3860, Training Loss: 0.1743769544747568, Validation Loss: 0.1736213634411494, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 3861, Training Loss: 0.17359850820033781, Validation Loss: 0.17383087774117786, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3862, Training Loss: 0.17433186500303208, Validation Loss: 0.17343012988567352, Validation Accuracy: 0.4875\n",
      "Epoch 3863, Training Loss: 0.17364318476569268, Validation Loss: 0.1727311909198761, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 3864, Training Loss: 0.1743320366067271, Validation Loss: 0.1734085738658905, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 3865, Training Loss: 0.1736406308989371, Validation Loss: 0.17420548697312674, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3866, Training Loss: 0.1743644009674749, Validation Loss: 0.17339758276939393, Validation Accuracy: 0.49375\n",
      "Epoch 3867, Training Loss: 0.17368350105900918, Validation Loss: 0.17364410956700643, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 3868, Training Loss: 0.17431216230315547, Validation Loss: 0.17327110370000204, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 3869, Training Loss: 0.17352934902714146, Validation Loss: 0.17485638360182446, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 3870, Training Loss: 0.17439595489732682, Validation Loss: 0.17321715950965882, Validation Accuracy: 0.5125\n",
      "Epoch 3871, Training Loss: 0.17368016031480604, Validation Loss: 0.17484476367632548, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 3872, Training Loss: 0.1742371056349047, Validation Loss: 0.17302443087100983, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 3873, Training Loss: 0.17360445857048035, Validation Loss: 0.1747066984574, Validation Accuracy: 0.48125\n",
      "Epoch 3874, Training Loss: 0.17441279032538015, Validation Loss: 0.1733002503712972, Validation Accuracy: 0.50625\n",
      "Epoch 3875, Training Loss: 0.17348022086005058, Validation Loss: 0.17549197971820832, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 3876, Training Loss: 0.17434195693462126, Validation Loss: 0.17315450310707092, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 3877, Training Loss: 0.17351488432576578, Validation Loss: 0.1748050312201182, Validation Accuracy: 0.475\n",
      "Epoch 3878, Training Loss: 0.17452406018011032, Validation Loss: 0.17323268254597982, Validation Accuracy: 0.5125\n",
      "Epoch 3879, Training Loss: 0.173414203428453, Validation Loss: 0.17550252278645834, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 3880, Training Loss: 0.17447622168448665, Validation Loss: 0.1727946311235428, Validation Accuracy: 0.5375\n",
      "Epoch 3881, Training Loss: 0.17348447538191272, Validation Loss: 0.17462220092614492, Validation Accuracy: 0.4875\n",
      "Epoch 3882, Training Loss: 0.17456370255639475, Validation Loss: 0.17360073228677114, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 3883, Training Loss: 0.17353543927592616, Validation Loss: 0.1752915322780609, Validation Accuracy: 0.475\n",
      "Epoch 3884, Training Loss: 0.17440086699301197, Validation Loss: 0.1722218304872513, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 3885, Training Loss: 0.1735893262009467, Validation Loss: 0.1752675324678421, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 3886, Training Loss: 0.1744031939775713, Validation Loss: 0.17381324569384257, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3887, Training Loss: 0.17349090114716562, Validation Loss: 0.17468868792057038, Validation Accuracy: 0.4875\n",
      "Epoch 3888, Training Loss: 0.17441860898848502, Validation Loss: 0.17274567087491352, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 3889, Training Loss: 0.17349641553817258, Validation Loss: 0.17440965076287587, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 3890, Training Loss: 0.17432922461340505, Validation Loss: 0.1741075019041697, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3891, Training Loss: 0.17363273760964792, Validation Loss: 0.1746143619219462, Validation Accuracy: 0.49375\n",
      "Epoch 3892, Training Loss: 0.17432171490884596, Validation Loss: 0.17364841401576997, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 3893, Training Loss: 0.17358548554681963, Validation Loss: 0.17379556695620219, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 3894, Training Loss: 0.1742285725570494, Validation Loss: 0.17456559737523397, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 3895, Training Loss: 0.17361923763828893, Validation Loss: 0.17363108396530152, Validation Accuracy: 0.5125\n",
      "Epoch 3896, Training Loss: 0.17431748586316262, Validation Loss: 0.1745559275150299, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 3897, Training Loss: 0.1737169301317584, Validation Loss: 0.17292499442895254, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 3898, Training Loss: 0.17421258697586675, Validation Loss: 0.1746960630019506, Validation Accuracy: 0.48125\n",
      "Epoch 3899, Training Loss: 0.17353277100670722, Validation Loss: 0.17395530343055726, Validation Accuracy: 0.50625\n",
      "Epoch 3900, Training Loss: 0.1744727525980242, Validation Loss: 0.17577087382475534, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 3901, Training Loss: 0.17369491198370535, Validation Loss: 0.1722042312224706, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 3902, Training Loss: 0.1742768576068263, Validation Loss: 0.17580154339472454, Validation Accuracy: 0.475\n",
      "Epoch 3903, Training Loss: 0.1737804239796054, Validation Loss: 0.17339655955632527, Validation Accuracy: 0.5125\n",
      "Epoch 3904, Training Loss: 0.17393337911175144, Validation Loss: 0.1751980185508728, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 3905, Training Loss: 0.17399862937388882, Validation Loss: 0.17265963355700176, Validation Accuracy: 0.5375\n",
      "Epoch 3906, Training Loss: 0.17384715426352718, Validation Loss: 0.17564736306667328, Validation Accuracy: 0.4875\n",
      "Epoch 3907, Training Loss: 0.1740066836918554, Validation Loss: 0.17403816183408102, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 3908, Training Loss: 0.17394985787330136, Validation Loss: 0.17583554089069367, Validation Accuracy: 0.475\n",
      "Epoch 3909, Training Loss: 0.1740369349718094, Validation Loss: 0.17204537590344746, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 3910, Training Loss: 0.17373483219454366, Validation Loss: 0.17690238257249197, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 3911, Training Loss: 0.17423550928792647, Validation Loss: 0.17378053267796834, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3912, Training Loss: 0.17373140540815168, Validation Loss: 0.1748945156733195, Validation Accuracy: 0.4875\n",
      "Epoch 3913, Training Loss: 0.17436627418764175, Validation Loss: 0.17272869348526002, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 3914, Training Loss: 0.17335060479179507, Validation Loss: 0.17557960748672485, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 3915, Training Loss: 0.174687696080054, Validation Loss: 0.17377202808856965, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3916, Training Loss: 0.17362020429103606, Validation Loss: 0.17487784425417582, Validation Accuracy: 0.49375\n",
      "Epoch 3917, Training Loss: 0.174313414962061, Validation Loss: 0.17359416385491688, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 3918, Training Loss: 0.17361059640684434, Validation Loss: 0.17444075147310892, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 3919, Training Loss: 0.17438434352797846, Validation Loss: 0.17394255995750427, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 3920, Training Loss: 0.17373547534788808, Validation Loss: 0.1738962302605311, Validation Accuracy: 0.5125\n",
      "Epoch 3921, Training Loss: 0.17423799105228915, Validation Loss: 0.17421853840351104, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 3922, Training Loss: 0.17359321732674876, Validation Loss: 0.1733037233352661, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 3923, Training Loss: 0.1743630613050153, Validation Loss: 0.17391166190306345, Validation Accuracy: 0.48125\n",
      "Epoch 3924, Training Loss: 0.1737108326727344, Validation Loss: 0.17422389686107637, Validation Accuracy: 0.50625\n",
      "Epoch 3925, Training Loss: 0.17430944356226152, Validation Loss: 0.1744092563788096, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 3926, Training Loss: 0.17364147786171205, Validation Loss: 0.17207784255345662, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 3927, Training Loss: 0.17418731845194294, Validation Loss: 0.17457467118899028, Validation Accuracy: 0.475\n",
      "Epoch 3928, Training Loss: 0.17359823276919703, Validation Loss: 0.17460651993751525, Validation Accuracy: 0.5125\n",
      "Epoch 3929, Training Loss: 0.17427990561531437, Validation Loss: 0.17469585041205088, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 3930, Training Loss: 0.1736182330116149, Validation Loss: 0.17279225985209148, Validation Accuracy: 0.5375\n",
      "Epoch 3931, Training Loss: 0.17427815689194587, Validation Loss: 0.17394181489944457, Validation Accuracy: 0.4875\n",
      "Epoch 3932, Training Loss: 0.17370276585701974, Validation Loss: 0.17521630525588988, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 3933, Training Loss: 0.17427304242887803, Validation Loss: 0.1740635961294174, Validation Accuracy: 0.475\n",
      "Epoch 3934, Training Loss: 0.17369522779218613, Validation Loss: 0.17199367781480154, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 3935, Training Loss: 0.1743585640384305, Validation Loss: 0.1737655649582545, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 3936, Training Loss: 0.17385780907446338, Validation Loss: 0.17364681859811146, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3937, Training Loss: 0.1741016564830657, Validation Loss: 0.1738606423139572, Validation Accuracy: 0.4875\n",
      "Epoch 3938, Training Loss: 0.17383308420258184, Validation Loss: 0.17284020880858103, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 3939, Training Loss: 0.1742504484230472, Validation Loss: 0.17343852122624714, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 3940, Training Loss: 0.17388542188752082, Validation Loss: 0.173444331685702, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3941, Training Loss: 0.17408515128397173, Validation Loss: 0.17363755305608114, Validation Accuracy: 0.49375\n",
      "Epoch 3942, Training Loss: 0.17381507014074632, Validation Loss: 0.17330872317155202, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 3943, Training Loss: 0.17418971561616467, Validation Loss: 0.1732680916786194, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 3944, Training Loss: 0.17392151922948898, Validation Loss: 0.17346951365470886, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 3945, Training Loss: 0.17402166704977712, Validation Loss: 0.1732262780268987, Validation Accuracy: 0.5125\n",
      "Epoch 3946, Training Loss: 0.17397819459438324, Validation Loss: 0.1734827647606532, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 3947, Training Loss: 0.1739619710753041, Validation Loss: 0.1729486624399821, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 3948, Training Loss: 0.17406177520751953, Validation Loss: 0.17361512879530588, Validation Accuracy: 0.48125\n",
      "Epoch 3949, Training Loss: 0.1739940023229968, Validation Loss: 0.17331906457742055, Validation Accuracy: 0.50625\n",
      "Epoch 3950, Training Loss: 0.17389962798164738, Validation Loss: 0.1735555628935496, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 3951, Training Loss: 0.17414502751442693, Validation Loss: 0.17276516954104107, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 3952, Training Loss: 0.17391134125571098, Validation Loss: 0.17357999086380005, Validation Accuracy: 0.475\n",
      "Epoch 3953, Training Loss: 0.17410826250430075, Validation Loss: 0.17321752707163493, Validation Accuracy: 0.5125\n",
      "Epoch 3954, Training Loss: 0.17383506269224228, Validation Loss: 0.17363020877043406, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 3955, Training Loss: 0.17419633653856093, Validation Loss: 0.17300662895043692, Validation Accuracy: 0.5375\n",
      "Epoch 3956, Training Loss: 0.17389359253068123, Validation Loss: 0.1735551546017329, Validation Accuracy: 0.4875\n",
      "Epoch 3957, Training Loss: 0.17410691418955404, Validation Loss: 0.17346788148085276, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 3958, Training Loss: 0.17377968228632404, Validation Loss: 0.1738905727863312, Validation Accuracy: 0.475\n",
      "Epoch 3959, Training Loss: 0.17425853446606668, Validation Loss: 0.17288160820802054, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 3960, Training Loss: 0.1738456545337554, Validation Loss: 0.1739835908015569, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 3961, Training Loss: 0.17412580261307378, Validation Loss: 0.17341957688331605, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3962, Training Loss: 0.17378207127894124, Validation Loss: 0.17370293339093526, Validation Accuracy: 0.4875\n",
      "Epoch 3963, Training Loss: 0.17424346410459088, Validation Loss: 0.17305102050304413, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 3964, Training Loss: 0.17374861096182176, Validation Loss: 0.17368633449077606, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 3965, Training Loss: 0.17424223692186416, Validation Loss: 0.17344505488872528, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3966, Training Loss: 0.17366150502235658, Validation Loss: 0.17373761137326557, Validation Accuracy: 0.49375\n",
      "Epoch 3967, Training Loss: 0.17433554318643385, Validation Loss: 0.17328555583953859, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 3968, Training Loss: 0.17377885599290172, Validation Loss: 0.17332009375095367, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 3969, Training Loss: 0.17422210449172604, Validation Loss: 0.17345046003659567, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 3970, Training Loss: 0.17375082787006133, Validation Loss: 0.1732544372479121, Validation Accuracy: 0.5125\n",
      "Epoch 3971, Training Loss: 0.17425604260736896, Validation Loss: 0.17343704203764598, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 3972, Training Loss: 0.17382676851364873, Validation Loss: 0.17290789087613423, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 3973, Training Loss: 0.1741684103204358, Validation Loss: 0.17350614666938782, Validation Accuracy: 0.48125\n",
      "Epoch 3974, Training Loss: 0.17368392117561832, Validation Loss: 0.17346958220005035, Validation Accuracy: 0.50625\n",
      "Epoch 3975, Training Loss: 0.17434534911186464, Validation Loss: 0.17350612978140514, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 3976, Training Loss: 0.173673715802931, Validation Loss: 0.172328386704127, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 3977, Training Loss: 0.1743579324214689, Validation Loss: 0.17349408864974974, Validation Accuracy: 0.475\n",
      "Epoch 3978, Training Loss: 0.173653656436551, Validation Loss: 0.1733092784881592, Validation Accuracy: 0.5125\n",
      "Epoch 3979, Training Loss: 0.17435859239870502, Validation Loss: 0.1734435349702835, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 3980, Training Loss: 0.1736595510475097, Validation Loss: 0.1726769119501114, Validation Accuracy: 0.5375\n",
      "Epoch 3981, Training Loss: 0.1743664760743418, Validation Loss: 0.1734009176492691, Validation Accuracy: 0.4875\n",
      "Epoch 3982, Training Loss: 0.1736257306991085, Validation Loss: 0.1738184481859207, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 3983, Training Loss: 0.17439649374254287, Validation Loss: 0.173421448469162, Validation Accuracy: 0.475\n",
      "Epoch 3984, Training Loss: 0.1736296602795201, Validation Loss: 0.17195101976394653, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 3985, Training Loss: 0.17431430037944548, Validation Loss: 0.1735527406136195, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 3986, Training Loss: 0.17366606621972977, Validation Loss: 0.1737942377726237, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3987, Training Loss: 0.17440470572440855, Validation Loss: 0.17337387601534526, Validation Accuracy: 0.4875\n",
      "Epoch 3988, Training Loss: 0.17368007956012602, Validation Loss: 0.17272725601991018, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 3989, Training Loss: 0.1743081226464241, Validation Loss: 0.17338060438632966, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 3990, Training Loss: 0.17366901520759828, Validation Loss: 0.17382868826389314, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 3991, Training Loss: 0.1743798025192753, Validation Loss: 0.17335125207901, Validation Accuracy: 0.49375\n",
      "Epoch 3992, Training Loss: 0.17373336947733356, Validation Loss: 0.1735586017370224, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 3993, Training Loss: 0.17428477685297689, Validation Loss: 0.17325626115004222, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 3994, Training Loss: 0.17359843946272327, Validation Loss: 0.17464875876903535, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 3995, Training Loss: 0.17439257617919676, Validation Loss: 0.17324593265851337, Validation Accuracy: 0.5125\n",
      "Epoch 3996, Training Loss: 0.1736860505996212, Validation Loss: 0.17444176177183787, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 3997, Training Loss: 0.17434956325638679, Validation Loss: 0.17307404379049937, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 3998, Training Loss: 0.17360079048141355, Validation Loss: 0.17503642539183298, Validation Accuracy: 0.48125\n",
      "Epoch 3999, Training Loss: 0.17434982618977946, Validation Loss: 0.1732712556918462, Validation Accuracy: 0.50625\n",
      "Epoch 4000, Training Loss: 0.1736039254934557, Validation Loss: 0.17547991673151653, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 4001, Training Loss: 0.17447391921474087, Validation Loss: 0.17291618088881175, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 4002, Training Loss: 0.17347491123983938, Validation Loss: 0.1753110855817795, Validation Accuracy: 0.475\n",
      "Epoch 4003, Training Loss: 0.1742764062458469, Validation Loss: 0.17326894601186116, Validation Accuracy: 0.5125\n",
      "Epoch 4004, Training Loss: 0.17361399579432704, Validation Loss: 0.17508832812309266, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 4005, Training Loss: 0.17443358850094579, Validation Loss: 0.17280097802480063, Validation Accuracy: 0.5375\n",
      "Epoch 4006, Training Loss: 0.1734696222889808, Validation Loss: 0.1748659630616506, Validation Accuracy: 0.4875\n",
      "Epoch 4007, Training Loss: 0.17458684838587238, Validation Loss: 0.1736204852660497, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 4008, Training Loss: 0.17357172216138533, Validation Loss: 0.1754132221142451, Validation Accuracy: 0.475\n",
      "Epoch 4009, Training Loss: 0.1744440024898898, Validation Loss: 0.17230466703573863, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 4010, Training Loss: 0.1735884989461591, Validation Loss: 0.17550216714541117, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 4011, Training Loss: 0.1744087900846235, Validation Loss: 0.17372511823972067, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4012, Training Loss: 0.17352431868353196, Validation Loss: 0.17498935361703236, Validation Accuracy: 0.4875\n",
      "Epoch 4013, Training Loss: 0.17439858999944502, Validation Loss: 0.1727432241042455, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 4014, Training Loss: 0.1735540162171087, Validation Loss: 0.17453953623771667, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 4015, Training Loss: 0.17439404851005924, Validation Loss: 0.17392567098140715, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4016, Training Loss: 0.17356468929398444, Validation Loss: 0.17470018267631532, Validation Accuracy: 0.49375\n",
      "Epoch 4017, Training Loss: 0.1744027224279219, Validation Loss: 0.17371977965037028, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 4018, Training Loss: 0.17358831628676383, Validation Loss: 0.17399635116259257, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 4019, Training Loss: 0.17424885640221258, Validation Loss: 0.17458932002385458, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 4020, Training Loss: 0.1736275202804996, Validation Loss: 0.173862894376119, Validation Accuracy: 0.5125\n",
      "Epoch 4021, Training Loss: 0.17438936233520508, Validation Loss: 0.17485186457633972, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 4022, Training Loss: 0.17372392742864548, Validation Loss: 0.17302594780921937, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 4023, Training Loss: 0.1743286761545366, Validation Loss: 0.17494210104147592, Validation Accuracy: 0.48125\n",
      "Epoch 4024, Training Loss: 0.17355751798998925, Validation Loss: 0.17388996879259747, Validation Accuracy: 0.50625\n",
      "Epoch 4025, Training Loss: 0.17450539527400846, Validation Loss: 0.17572618623574573, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 4026, Training Loss: 0.173725375725377, Validation Loss: 0.17213358680407206, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 4027, Training Loss: 0.17418459153944446, Validation Loss: 0.17545575102170308, Validation Accuracy: 0.475\n",
      "Epoch 4028, Training Loss: 0.17389801384941225, Validation Loss: 0.17358654439449311, Validation Accuracy: 0.5125\n",
      "Epoch 4029, Training Loss: 0.17392971102268465, Validation Loss: 0.17573635379473368, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 4030, Training Loss: 0.17402224531096797, Validation Loss: 0.17265942593415579, Validation Accuracy: 0.5375\n",
      "Epoch 4031, Training Loss: 0.17389226632733498, Validation Loss: 0.17574906249841055, Validation Accuracy: 0.4875\n",
      "Epoch 4032, Training Loss: 0.17397857144955667, Validation Loss: 0.17412417829036714, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 4033, Training Loss: 0.17396074629599048, Validation Loss: 0.17582392394542695, Validation Accuracy: 0.475\n",
      "Epoch 4034, Training Loss: 0.17393110307954973, Validation Loss: 0.17216347952683766, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 4035, Training Loss: 0.17377665206309287, Validation Loss: 0.17722955147425334, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 4036, Training Loss: 0.17417648915321596, Validation Loss: 0.17386593918005624, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4037, Training Loss: 0.17366312540346576, Validation Loss: 0.17573238213857015, Validation Accuracy: 0.4875\n",
      "Epoch 4038, Training Loss: 0.17415985945732362, Validation Loss: 0.17278821468353273, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 4039, Training Loss: 0.17338363201387466, Validation Loss: 0.17617694834868114, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 4040, Training Loss: 0.1746429786566765, Validation Loss: 0.1738795985778173, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4041, Training Loss: 0.17362527597335078, Validation Loss: 0.17532938718795776, Validation Accuracy: 0.49375\n",
      "Epoch 4042, Training Loss: 0.17433393674512063, Validation Loss: 0.17356830437978107, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 4043, Training Loss: 0.1737073419555541, Validation Loss: 0.17391698757807414, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 4044, Training Loss: 0.17431121487771312, Validation Loss: 0.17428955833117168, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 4045, Training Loss: 0.17375526168654043, Validation Loss: 0.1736917833487193, Validation Accuracy: 0.5125\n",
      "Epoch 4046, Training Loss: 0.17422200883588485, Validation Loss: 0.17447247703870136, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 4047, Training Loss: 0.17358934783166455, Validation Loss: 0.1733175406853358, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 4048, Training Loss: 0.17434190838567673, Validation Loss: 0.1739178826411565, Validation Accuracy: 0.48125\n",
      "Epoch 4049, Training Loss: 0.17369217017004568, Validation Loss: 0.17441686987876892, Validation Accuracy: 0.50625\n",
      "Epoch 4050, Training Loss: 0.17429333684905882, Validation Loss: 0.17457706928253175, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 4051, Training Loss: 0.17362188379610738, Validation Loss: 0.17214170694351197, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 4052, Training Loss: 0.17444892564127523, Validation Loss: 0.1738755762577057, Validation Accuracy: 0.475\n",
      "Epoch 4053, Training Loss: 0.17381158711448794, Validation Loss: 0.17346935470898947, Validation Accuracy: 0.5125\n",
      "Epoch 4054, Training Loss: 0.17415759640355263, Validation Loss: 0.17490986486275992, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 4055, Training Loss: 0.17362860277775796, Validation Loss: 0.17284459273020428, Validation Accuracy: 0.5375\n",
      "Epoch 4056, Training Loss: 0.17439749212034286, Validation Loss: 0.1736677497625351, Validation Accuracy: 0.4875\n",
      "Epoch 4057, Training Loss: 0.1738588934944522, Validation Loss: 0.17391482492287955, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 4058, Training Loss: 0.17412806518616214, Validation Loss: 0.17435244123140972, Validation Accuracy: 0.475\n",
      "Epoch 4059, Training Loss: 0.173756736420816, Validation Loss: 0.17183137039343516, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 4060, Training Loss: 0.1742682586754522, Validation Loss: 0.17394508322079977, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 4061, Training Loss: 0.17389425010450424, Validation Loss: 0.17366232673327128, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4062, Training Loss: 0.17410807888354024, Validation Loss: 0.17385813494523367, Validation Accuracy: 0.4875\n",
      "Epoch 4063, Training Loss: 0.17384635873379245, Validation Loss: 0.17284039556980133, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 4064, Training Loss: 0.1742192554858423, Validation Loss: 0.17344087461630503, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 4065, Training Loss: 0.17391209015923162, Validation Loss: 0.17352678875128427, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4066, Training Loss: 0.17407676865977625, Validation Loss: 0.1736419012149175, Validation Accuracy: 0.49375\n",
      "Epoch 4067, Training Loss: 0.1738451579886098, Validation Loss: 0.1733187774817149, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 4068, Training Loss: 0.17418472709194308, Validation Loss: 0.17326670984427134, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 4069, Training Loss: 0.17391389271905344, Validation Loss: 0.17351006269454955, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 4070, Training Loss: 0.17400298099364003, Validation Loss: 0.17323272228240966, Validation Accuracy: 0.5125\n",
      "Epoch 4071, Training Loss: 0.17395605867908848, Validation Loss: 0.17357256511847177, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 4072, Training Loss: 0.17410210688267985, Validation Loss: 0.1730459729830424, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 4073, Training Loss: 0.17399520739432303, Validation Loss: 0.17347046732902527, Validation Accuracy: 0.48125\n",
      "Epoch 4074, Training Loss: 0.17397299168571348, Validation Loss: 0.17336824138959248, Validation Accuracy: 0.50625\n",
      "Epoch 4075, Training Loss: 0.17395038422076933, Validation Loss: 0.17351845502853394, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 4076, Training Loss: 0.17418998335638353, Validation Loss: 0.17290493547916413, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 4077, Training Loss: 0.17389328104834403, Validation Loss: 0.17354693512121835, Validation Accuracy: 0.475\n",
      "Epoch 4078, Training Loss: 0.17412617610346887, Validation Loss: 0.17321776549021403, Validation Accuracy: 0.5125\n",
      "Epoch 4079, Training Loss: 0.173838357290914, Validation Loss: 0.17369690239429475, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 4080, Training Loss: 0.17419607937335968, Validation Loss: 0.1730216920375824, Validation Accuracy: 0.5375\n",
      "Epoch 4081, Training Loss: 0.1738894341453429, Validation Loss: 0.1735446830590566, Validation Accuracy: 0.4875\n",
      "Epoch 4082, Training Loss: 0.1739797875765831, Validation Loss: 0.17363555530707042, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 4083, Training Loss: 0.1738769724484413, Validation Loss: 0.17389049828052522, Validation Accuracy: 0.475\n",
      "Epoch 4084, Training Loss: 0.17404949568933056, Validation Loss: 0.17253350615501403, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 4085, Training Loss: 0.17384822858918098, Validation Loss: 0.17419202327728273, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 4086, Training Loss: 0.17414034806912945, Validation Loss: 0.17344323794047037, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4087, Training Loss: 0.17374593019485474, Validation Loss: 0.1739341696103414, Validation Accuracy: 0.4875\n",
      "Epoch 4088, Training Loss: 0.1742991675292292, Validation Loss: 0.17309041519959767, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 4089, Training Loss: 0.17374567687511444, Validation Loss: 0.17384818196296692, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 4090, Training Loss: 0.174232812658433, Validation Loss: 0.17345619599024456, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4091, Training Loss: 0.17364104332462435, Validation Loss: 0.1739531397819519, Validation Accuracy: 0.49375\n",
      "Epoch 4092, Training Loss: 0.17418145412398922, Validation Loss: 0.1733476310968399, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 4093, Training Loss: 0.17382371233355615, Validation Loss: 0.17330241898695628, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 4094, Training Loss: 0.1742609162484446, Validation Loss: 0.17344671885172527, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 4095, Training Loss: 0.1737394803954709, Validation Loss: 0.17325202922026317, Validation Accuracy: 0.5125\n",
      "Epoch 4096, Training Loss: 0.17426696275511094, Validation Loss: 0.17340108652909597, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 4097, Training Loss: 0.1738155008323731, Validation Loss: 0.172909743587176, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 4098, Training Loss: 0.17416571080684662, Validation Loss: 0.17354255219300588, Validation Accuracy: 0.48125\n",
      "Epoch 4099, Training Loss: 0.17365247588003835, Validation Loss: 0.1735285590092341, Validation Accuracy: 0.50625\n",
      "Epoch 4100, Training Loss: 0.17438657197260088, Validation Loss: 0.17350469728310902, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 4101, Training Loss: 0.17368042853570753, Validation Loss: 0.1722998688618342, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 4102, Training Loss: 0.1742692397486779, Validation Loss: 0.17354915738105775, Validation Accuracy: 0.475\n",
      "Epoch 4103, Training Loss: 0.17365975485694024, Validation Loss: 0.17333285709222157, Validation Accuracy: 0.5125\n",
      "Epoch 4104, Training Loss: 0.17439150137286033, Validation Loss: 0.17347470223903655, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 4105, Training Loss: 0.1736732240646116, Validation Loss: 0.17265914380550385, Validation Accuracy: 0.5375\n",
      "Epoch 4106, Training Loss: 0.17431226613060122, Validation Loss: 0.17344852785269418, Validation Accuracy: 0.4875\n",
      "Epoch 4107, Training Loss: 0.17364218831062317, Validation Loss: 0.1736926128466924, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 4108, Training Loss: 0.1744178398962944, Validation Loss: 0.1734253615140915, Validation Accuracy: 0.475\n",
      "Epoch 4109, Training Loss: 0.17365206922254256, Validation Loss: 0.17191517849763235, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 4110, Training Loss: 0.17432123374554417, Validation Loss: 0.17350809375445048, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 4111, Training Loss: 0.17365251866079146, Validation Loss: 0.17361971735954285, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4112, Training Loss: 0.17439752144198264, Validation Loss: 0.17337255875269572, Validation Accuracy: 0.4875\n",
      "Epoch 4113, Training Loss: 0.17367408064103895, Validation Loss: 0.17277021209398905, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 4114, Training Loss: 0.1743496742940718, Validation Loss: 0.17335942288239797, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 4115, Training Loss: 0.17367638791761092, Validation Loss: 0.17426761587460834, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4116, Training Loss: 0.17434162382156618, Validation Loss: 0.17336674630641938, Validation Accuracy: 0.49375\n",
      "Epoch 4117, Training Loss: 0.17378236689875204, Validation Loss: 0.1737864851951599, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 4118, Training Loss: 0.17408867709098325, Validation Loss: 0.17325991094112397, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 4119, Training Loss: 0.17363148543142504, Validation Loss: 0.17432217995325724, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 4120, Training Loss: 0.17436285701490217, Validation Loss: 0.17326363921165466, Validation Accuracy: 0.5125\n",
      "Epoch 4121, Training Loss: 0.17368481764870305, Validation Loss: 0.174025430281957, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 4122, Training Loss: 0.17437807494594204, Validation Loss: 0.17309346000353495, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 4123, Training Loss: 0.17357965150187094, Validation Loss: 0.17496780157089234, Validation Accuracy: 0.48125\n",
      "Epoch 4124, Training Loss: 0.17440981201587186, Validation Loss: 0.17326941688855488, Validation Accuracy: 0.50625\n",
      "Epoch 4125, Training Loss: 0.17357881847889192, Validation Loss: 0.17584360937277477, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 4126, Training Loss: 0.17443699557935038, Validation Loss: 0.17283338010311128, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 4127, Training Loss: 0.17349968802544377, Validation Loss: 0.1749702682097753, Validation Accuracy: 0.475\n",
      "Epoch 4128, Training Loss: 0.1745100780840843, Validation Loss: 0.1732219914595286, Validation Accuracy: 0.5125\n",
      "Epoch 4129, Training Loss: 0.17347234391397046, Validation Loss: 0.17576641341050467, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 4130, Training Loss: 0.17442863314382492, Validation Loss: 0.17290920714537303, Validation Accuracy: 0.5375\n",
      "Epoch 4131, Training Loss: 0.17351600720036414, Validation Loss: 0.17492288947105408, Validation Accuracy: 0.4875\n",
      "Epoch 4132, Training Loss: 0.1745810902887775, Validation Loss: 0.17349403202533722, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 4133, Training Loss: 0.1736170865835682, Validation Loss: 0.17538325786590575, Validation Accuracy: 0.475\n",
      "Epoch 4134, Training Loss: 0.1744211469927142, Validation Loss: 0.17245618402957916, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 4135, Training Loss: 0.17359045147895813, Validation Loss: 0.17551515400409698, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 4136, Training Loss: 0.17439948695321236, Validation Loss: 0.17350670198599497, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4137, Training Loss: 0.17354917958859475, Validation Loss: 0.1751423716545105, Validation Accuracy: 0.4875\n",
      "Epoch 4138, Training Loss: 0.17436620352729673, Validation Loss: 0.1727402150630951, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 4139, Training Loss: 0.17355491797770223, Validation Loss: 0.1746233860651652, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 4140, Training Loss: 0.1744032540628987, Validation Loss: 0.17398546934127807, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4141, Training Loss: 0.17359239343673952, Validation Loss: 0.1747173100709915, Validation Accuracy: 0.49375\n",
      "Epoch 4142, Training Loss: 0.17442373642998357, Validation Loss: 0.17365777889887493, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 4143, Training Loss: 0.17354167469086185, Validation Loss: 0.17399833599726358, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 4144, Training Loss: 0.17429445972365717, Validation Loss: 0.17455300192038217, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 4145, Training Loss: 0.173617287508903, Validation Loss: 0.1737825890382131, Validation Accuracy: 0.5125\n",
      "Epoch 4146, Training Loss: 0.17435713304627326, Validation Loss: 0.17474654813607535, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 4147, Training Loss: 0.17375759828475215, Validation Loss: 0.17301271657148998, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 4148, Training Loss: 0.1743187125652067, Validation Loss: 0.17488651474316916, Validation Accuracy: 0.48125\n",
      "Epoch 4149, Training Loss: 0.1735630045014043, Validation Loss: 0.17387450039386748, Validation Accuracy: 0.50625\n",
      "Epoch 4150, Training Loss: 0.1744521192965969, Validation Loss: 0.17550028165181478, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 4151, Training Loss: 0.17377562484433573, Validation Loss: 0.17217075526714326, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 4152, Training Loss: 0.17425371370007914, Validation Loss: 0.17570033073425292, Validation Accuracy: 0.475\n",
      "Epoch 4153, Training Loss: 0.1738025002902554, Validation Loss: 0.17347155114014942, Validation Accuracy: 0.5125\n",
      "Epoch 4154, Training Loss: 0.1739868632247371, Validation Loss: 0.1756559689839681, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 4155, Training Loss: 0.17400782963921946, Validation Loss: 0.17266529699166616, Validation Accuracy: 0.5375\n",
      "Epoch 4156, Training Loss: 0.17385132658866145, Validation Loss: 0.17565051217873892, Validation Accuracy: 0.4875\n",
      "Epoch 4157, Training Loss: 0.17398154302950827, Validation Loss: 0.17432426611582438, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 4158, Training Loss: 0.1739595551644602, Validation Loss: 0.17595168948173523, Validation Accuracy: 0.475\n",
      "Epoch 4159, Training Loss: 0.17412394285202026, Validation Loss: 0.17196562588214875, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 4160, Training Loss: 0.1737777220626031, Validation Loss: 0.17704529762268068, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 4161, Training Loss: 0.17424865547687776, Validation Loss: 0.17390794356664022, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4162, Training Loss: 0.17369290513377036, Validation Loss: 0.17550567587216695, Validation Accuracy: 0.4875\n",
      "Epoch 4163, Training Loss: 0.17436395970083052, Validation Loss: 0.17276640236377716, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 4164, Training Loss: 0.17340056405913445, Validation Loss: 0.17563449939092, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 4165, Training Loss: 0.17467551702453243, Validation Loss: 0.1737364908059438, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4166, Training Loss: 0.17369791865348816, Validation Loss: 0.17417779763539631, Validation Accuracy: 0.49375\n",
      "Epoch 4167, Training Loss: 0.17422588650257356, Validation Loss: 0.17381300230820973, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 4168, Training Loss: 0.17361658811569214, Validation Loss: 0.17446222404638925, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 4169, Training Loss: 0.17437320803442308, Validation Loss: 0.17394657929738364, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 4170, Training Loss: 0.17375059570035628, Validation Loss: 0.17409027417500814, Validation Accuracy: 0.5125\n",
      "Epoch 4171, Training Loss: 0.17412369674251926, Validation Loss: 0.17489975690841675, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 4172, Training Loss: 0.17360128414246342, Validation Loss: 0.17330949306488036, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 4173, Training Loss: 0.17430249769841472, Validation Loss: 0.1739664038022359, Validation Accuracy: 0.48125\n",
      "Epoch 4174, Training Loss: 0.17378118730360462, Validation Loss: 0.17378176848093668, Validation Accuracy: 0.50625\n",
      "Epoch 4175, Training Loss: 0.17420316944199224, Validation Loss: 0.17481122712294261, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 4176, Training Loss: 0.1736908857860873, Validation Loss: 0.1720883975426356, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 4177, Training Loss: 0.17435606304676302, Validation Loss: 0.17397066950798035, Validation Accuracy: 0.475\n",
      "Epoch 4178, Training Loss: 0.17373196828749873, Validation Loss: 0.1737479865550995, Validation Accuracy: 0.5125\n",
      "Epoch 4179, Training Loss: 0.17432647799291917, Validation Loss: 0.1742110977570216, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 4180, Training Loss: 0.17365180148232368, Validation Loss: 0.17268324891726175, Validation Accuracy: 0.5375\n",
      "Epoch 4181, Training Loss: 0.17436853531868227, Validation Loss: 0.1736905097961426, Validation Accuracy: 0.4875\n",
      "Epoch 4182, Training Loss: 0.17383824529186373, Validation Loss: 0.17393909990787507, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 4183, Training Loss: 0.17414424688585342, Validation Loss: 0.17430199086666107, Validation Accuracy: 0.475\n",
      "Epoch 4184, Training Loss: 0.173748827749683, Validation Loss: 0.17175131837526958, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 4185, Training Loss: 0.17428359533509902, Validation Loss: 0.1738503396511078, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 4186, Training Loss: 0.17383939268127566, Validation Loss: 0.17381710509459178, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4187, Training Loss: 0.17417946794340688, Validation Loss: 0.17373408675193786, Validation Accuracy: 0.4875\n",
      "Epoch 4188, Training Loss: 0.17381999857964053, Validation Loss: 0.1728133589029312, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 4189, Training Loss: 0.17424519936884603, Validation Loss: 0.1734245906273524, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 4190, Training Loss: 0.17385041040758933, Validation Loss: 0.17348362306753795, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4191, Training Loss: 0.17416090926816385, Validation Loss: 0.17354219357172648, Validation Accuracy: 0.49375\n",
      "Epoch 4192, Training Loss: 0.17383382974132414, Validation Loss: 0.1733061522245407, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 4193, Training Loss: 0.1741682675576979, Validation Loss: 0.17327183187007905, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 4194, Training Loss: 0.17392938511986886, Validation Loss: 0.17350236972173055, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 4195, Training Loss: 0.17402793899659189, Validation Loss: 0.17322289148966472, Validation Accuracy: 0.5125\n",
      "Epoch 4196, Training Loss: 0.17391242279160407, Validation Loss: 0.17352281610171, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 4197, Training Loss: 0.1739198906767753, Validation Loss: 0.17292955617109934, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 4198, Training Loss: 0.17409621803991257, Validation Loss: 0.1737398604551951, Validation Accuracy: 0.48125\n",
      "Epoch 4199, Training Loss: 0.17400269594884687, Validation Loss: 0.17330973247687023, Validation Accuracy: 0.50625\n",
      "Epoch 4200, Training Loss: 0.17389081514650775, Validation Loss: 0.17359642485777538, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 4201, Training Loss: 0.17415727867234138, Validation Loss: 0.17290798525015513, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 4202, Training Loss: 0.1740222967440082, Validation Loss: 0.17374168038368226, Validation Accuracy: 0.475\n",
      "Epoch 4203, Training Loss: 0.17393066517768369, Validation Loss: 0.17323294878005982, Validation Accuracy: 0.5125\n",
      "Epoch 4204, Training Loss: 0.17390129354692274, Validation Loss: 0.17372818887233735, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 4205, Training Loss: 0.1741700864607288, Validation Loss: 0.1730031152566274, Validation Accuracy: 0.5375\n",
      "Epoch 4206, Training Loss: 0.1738912227653688, Validation Loss: 0.17358049750328064, Validation Accuracy: 0.4875\n",
      "Epoch 4207, Training Loss: 0.1741154102548476, Validation Loss: 0.1734507530927658, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 4208, Training Loss: 0.1738077123318949, Validation Loss: 0.1737714687983195, Validation Accuracy: 0.475\n",
      "Epoch 4209, Training Loss: 0.17404753306219656, Validation Loss: 0.17243704895178477, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 4210, Training Loss: 0.17392129763480155, Validation Loss: 0.17408934235572815, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 4211, Training Loss: 0.17415041933136602, Validation Loss: 0.17343074083328247, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4212, Training Loss: 0.17373810996932368, Validation Loss: 0.17390094498793285, Validation Accuracy: 0.4875\n",
      "Epoch 4213, Training Loss: 0.17432154378583353, Validation Loss: 0.17310270369052888, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 4214, Training Loss: 0.1737591100315894, Validation Loss: 0.17374390065670015, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 4215, Training Loss: 0.17414154304612067, Validation Loss: 0.17359283963839214, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4216, Training Loss: 0.1737209447929936, Validation Loss: 0.1737936705350876, Validation Accuracy: 0.49375\n",
      "Epoch 4217, Training Loss: 0.17430851632548916, Validation Loss: 0.17328576147556304, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 4218, Training Loss: 0.1738290330094676, Validation Loss: 0.17332590719064075, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 4219, Training Loss: 0.17415815303402563, Validation Loss: 0.17353588143984477, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 4220, Training Loss: 0.17383695081357034, Validation Loss: 0.17330047885576885, Validation Accuracy: 0.5125\n",
      "Epoch 4221, Training Loss: 0.17414478957653046, Validation Loss: 0.17351889610290527, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 4222, Training Loss: 0.17390055666046758, Validation Loss: 0.17290745973587035, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 4223, Training Loss: 0.17408981630879064, Validation Loss: 0.17359775106112163, Validation Accuracy: 0.48125\n",
      "Epoch 4224, Training Loss: 0.17366001923238078, Validation Loss: 0.17349248230457306, Validation Accuracy: 0.50625\n",
      "Epoch 4225, Training Loss: 0.17437468324938127, Validation Loss: 0.1735086699326833, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 4226, Training Loss: 0.1737280286127521, Validation Loss: 0.17230522533257803, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 4227, Training Loss: 0.17431365530337056, Validation Loss: 0.17351397077242534, Validation Accuracy: 0.475\n",
      "Epoch 4228, Training Loss: 0.17367239344504573, Validation Loss: 0.1732968161503474, Validation Accuracy: 0.5125\n",
      "Epoch 4229, Training Loss: 0.1743613842033571, Validation Loss: 0.1734409878651301, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 4230, Training Loss: 0.17367360140046767, Validation Loss: 0.17269384463628132, Validation Accuracy: 0.5375\n",
      "Epoch 4231, Training Loss: 0.1743612419213018, Validation Loss: 0.17339863280455273, Validation Accuracy: 0.4875\n",
      "Epoch 4232, Training Loss: 0.17362575136846112, Validation Loss: 0.17373386124769846, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 4233, Training Loss: 0.17440498596237552, Validation Loss: 0.1734232097864151, Validation Accuracy: 0.475\n",
      "Epoch 4234, Training Loss: 0.17363792465579125, Validation Loss: 0.1720325062672297, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 4235, Training Loss: 0.17437758753376623, Validation Loss: 0.17351161042849222, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 4236, Training Loss: 0.17365518164250157, Validation Loss: 0.1737873156865438, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4237, Training Loss: 0.17432746771843202, Validation Loss: 0.17337901393572488, Validation Accuracy: 0.4875\n",
      "Epoch 4238, Training Loss: 0.17375702194629178, Validation Loss: 0.17272723615169525, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 4239, Training Loss: 0.1742502220215336, Validation Loss: 0.17332462271054586, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 4240, Training Loss: 0.1736677135190656, Validation Loss: 0.17362520098686218, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4241, Training Loss: 0.17441184674539872, Validation Loss: 0.1733328213294347, Validation Accuracy: 0.49375\n",
      "Epoch 4242, Training Loss: 0.17374000337816053, Validation Loss: 0.17356782456239064, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 4243, Training Loss: 0.17412329152707132, Validation Loss: 0.17326365808645885, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 4244, Training Loss: 0.1736787211510443, Validation Loss: 0.1743102272351583, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 4245, Training Loss: 0.17436359149794425, Validation Loss: 0.1732586642106374, Validation Accuracy: 0.5125\n",
      "Epoch 4246, Training Loss: 0.17373130879094523, Validation Loss: 0.17454619705677032, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 4247, Training Loss: 0.17435114277947333, Validation Loss: 0.17303786476453145, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 4248, Training Loss: 0.17361192309087323, Validation Loss: 0.17502168516318004, Validation Accuracy: 0.48125\n",
      "Epoch 4249, Training Loss: 0.17436902561495382, Validation Loss: 0.17326942086219788, Validation Accuracy: 0.50625\n",
      "Epoch 4250, Training Loss: 0.17362582299017137, Validation Loss: 0.17577868998050689, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 4251, Training Loss: 0.1744113189558829, Validation Loss: 0.17276257971922557, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 4252, Training Loss: 0.17350392572341428, Validation Loss: 0.17487144470214844, Validation Accuracy: 0.475\n",
      "Epoch 4253, Training Loss: 0.17451172634478537, Validation Loss: 0.17321763435999551, Validation Accuracy: 0.5125\n",
      "Epoch 4254, Training Loss: 0.17346454676120512, Validation Loss: 0.17551692326863608, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 4255, Training Loss: 0.17425575083301914, Validation Loss: 0.1732077807188034, Validation Accuracy: 0.5375\n",
      "Epoch 4256, Training Loss: 0.17358616138658217, Validation Loss: 0.17424661417802176, Validation Accuracy: 0.4875\n",
      "Epoch 4257, Training Loss: 0.17455026267036314, Validation Loss: 0.1735952744881312, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 4258, Training Loss: 0.17359932776420348, Validation Loss: 0.1755587100982666, Validation Accuracy: 0.475\n",
      "Epoch 4259, Training Loss: 0.17423073707088346, Validation Loss: 0.17283147275447847, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 4260, Training Loss: 0.17365089731831704, Validation Loss: 0.17486696938673654, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 4261, Training Loss: 0.17437634641124355, Validation Loss: 0.17361127336819968, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4262, Training Loss: 0.1735713179073026, Validation Loss: 0.1751695344845454, Validation Accuracy: 0.4875\n",
      "Epoch 4263, Training Loss: 0.1742764961334967, Validation Loss: 0.1727391868829727, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 4264, Training Loss: 0.1735919391916644, Validation Loss: 0.17469662527243296, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 4265, Training Loss: 0.17433963091142715, Validation Loss: 0.17406239211559296, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4266, Training Loss: 0.1736235176363299, Validation Loss: 0.1747738560040792, Validation Accuracy: 0.49375\n",
      "Epoch 4267, Training Loss: 0.17438505589962006, Validation Loss: 0.17361355125904082, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 4268, Training Loss: 0.17354955404035508, Validation Loss: 0.17393377820650738, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 4269, Training Loss: 0.17434587738206309, Validation Loss: 0.17446218331654867, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 4270, Training Loss: 0.17357947461066708, Validation Loss: 0.17378715872764589, Validation Accuracy: 0.5125\n",
      "Epoch 4271, Training Loss: 0.1743337901369218, Validation Loss: 0.17471424341201783, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 4272, Training Loss: 0.17377848971274593, Validation Loss: 0.1729774534702301, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 4273, Training Loss: 0.17431910768631967, Validation Loss: 0.17489082713921864, Validation Accuracy: 0.48125\n",
      "Epoch 4274, Training Loss: 0.1735551179416718, Validation Loss: 0.17388100028038025, Validation Accuracy: 0.50625\n",
      "Epoch 4275, Training Loss: 0.1744345873594284, Validation Loss: 0.175432684024175, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 4276, Training Loss: 0.1737891608668912, Validation Loss: 0.1721365878979365, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 4277, Training Loss: 0.17423707390985183, Validation Loss: 0.17568408846855163, Validation Accuracy: 0.475\n",
      "Epoch 4278, Training Loss: 0.17381096751459182, Validation Loss: 0.17349209785461425, Validation Accuracy: 0.5125\n",
      "Epoch 4279, Training Loss: 0.1739924160703536, Validation Loss: 0.17590843836466472, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 4280, Training Loss: 0.17398492415105143, Validation Loss: 0.17266249060630798, Validation Accuracy: 0.5375\n",
      "Epoch 4281, Training Loss: 0.1738948134645339, Validation Loss: 0.17585154473781586, Validation Accuracy: 0.4875\n",
      "Epoch 4282, Training Loss: 0.174007085542525, Validation Loss: 0.17413853406906127, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 4283, Training Loss: 0.1739766073803748, Validation Loss: 0.1757689505815506, Validation Accuracy: 0.475\n",
      "Epoch 4284, Training Loss: 0.1741105495922027, Validation Loss: 0.17192450165748596, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 4285, Training Loss: 0.1738105050979122, Validation Loss: 0.1769575277964274, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 4286, Training Loss: 0.17421906561620773, Validation Loss: 0.17390876213709514, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4287, Training Loss: 0.17369129340494832, Validation Loss: 0.17547616958618165, Validation Accuracy: 0.4875\n",
      "Epoch 4288, Training Loss: 0.1744250496548991, Validation Loss: 0.17273131012916565, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 4289, Training Loss: 0.17335812314864127, Validation Loss: 0.1755646308263143, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 4290, Training Loss: 0.17468477208768168, Validation Loss: 0.17369884649912518, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4291, Training Loss: 0.17369510906357918, Validation Loss: 0.17432788014411926, Validation Accuracy: 0.49375\n",
      "Epoch 4292, Training Loss: 0.17424960338300274, Validation Loss: 0.17370202640692392, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 4293, Training Loss: 0.17366757940861485, Validation Loss: 0.17451440890630085, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 4294, Training Loss: 0.17435562995172316, Validation Loss: 0.17396067976951599, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 4295, Training Loss: 0.1737406623940314, Validation Loss: 0.17402673959732057, Validation Accuracy: 0.5125\n",
      "Epoch 4296, Training Loss: 0.174275555437611, Validation Loss: 0.17415368060270944, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 4297, Training Loss: 0.1735799120318505, Validation Loss: 0.17339264849821726, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 4298, Training Loss: 0.17434825435761483, Validation Loss: 0.1739283194144567, Validation Accuracy: 0.48125\n",
      "Epoch 4299, Training Loss: 0.1737444612287706, Validation Loss: 0.17399071057637533, Validation Accuracy: 0.50625\n",
      "Epoch 4300, Training Loss: 0.17427090435258805, Validation Loss: 0.17455475628376008, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 4301, Training Loss: 0.17363685513696364, Validation Loss: 0.17208871642748516, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 4302, Training Loss: 0.17432432357342012, Validation Loss: 0.17412555913130442, Validation Accuracy: 0.475\n",
      "Epoch 4303, Training Loss: 0.17387098122027614, Validation Loss: 0.17343175113201142, Validation Accuracy: 0.5125\n",
      "Epoch 4304, Training Loss: 0.17421384299955062, Validation Loss: 0.1745164006948471, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 4305, Training Loss: 0.17364237577684463, Validation Loss: 0.17275795539220173, Validation Accuracy: 0.5375\n",
      "Epoch 4306, Training Loss: 0.17437076520535252, Validation Loss: 0.17366701662540435, Validation Accuracy: 0.4875\n",
      "Epoch 4307, Training Loss: 0.17380288483635073, Validation Loss: 0.17415988246599834, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 4308, Training Loss: 0.174172681185507, Validation Loss: 0.17437141140302023, Validation Accuracy: 0.475\n",
      "Epoch 4309, Training Loss: 0.1737193157595973, Validation Loss: 0.17173491219679515, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 4310, Training Loss: 0.1743482538769322, Validation Loss: 0.17376813888549805, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 4311, Training Loss: 0.1737876183563663, Validation Loss: 0.17391239205996195, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4312, Training Loss: 0.17424484077961214, Validation Loss: 0.17363385558128358, Validation Accuracy: 0.4875\n",
      "Epoch 4313, Training Loss: 0.17381964239381975, Validation Loss: 0.17285889287789663, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 4314, Training Loss: 0.1742273074003958, Validation Loss: 0.1734595477581024, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 4315, Training Loss: 0.17383291356025204, Validation Loss: 0.17353515128294628, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4316, Training Loss: 0.17419396773461374, Validation Loss: 0.17349050243695577, Validation Accuracy: 0.49375\n",
      "Epoch 4317, Training Loss: 0.17381330988099497, Validation Loss: 0.17330774466196697, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 4318, Training Loss: 0.17411083223358279, Validation Loss: 0.17330182592074075, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 4319, Training Loss: 0.17399869522740763, Validation Loss: 0.17350528637568155, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 4320, Training Loss: 0.17402732083874364, Validation Loss: 0.1732251693805059, Validation Accuracy: 0.5125\n",
      "Epoch 4321, Training Loss: 0.17391299768801657, Validation Loss: 0.17350629965464273, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 4322, Training Loss: 0.17406929548709624, Validation Loss: 0.1730104774236679, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 4323, Training Loss: 0.17401960732475405, Validation Loss: 0.17350480953852335, Validation Accuracy: 0.48125\n",
      "Epoch 4324, Training Loss: 0.17403905622420773, Validation Loss: 0.17331085900465648, Validation Accuracy: 0.50625\n",
      "Epoch 4325, Training Loss: 0.17389196686206326, Validation Loss: 0.17368507087230683, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 4326, Training Loss: 0.1741748014765401, Validation Loss: 0.1729110836982727, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 4327, Training Loss: 0.1740184190773195, Validation Loss: 0.17386287649472554, Validation Accuracy: 0.475\n",
      "Epoch 4328, Training Loss: 0.17388751045350107, Validation Loss: 0.17324137687683105, Validation Accuracy: 0.5125\n",
      "Epoch 4329, Training Loss: 0.1739401908651475, Validation Loss: 0.17386169830958048, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 4330, Training Loss: 0.1741007955804948, Validation Loss: 0.17296460171540579, Validation Accuracy: 0.5375\n",
      "Epoch 4331, Training Loss: 0.17394980499821325, Validation Loss: 0.17362751960754394, Validation Accuracy: 0.4875\n",
      "Epoch 4332, Training Loss: 0.17402053840698734, Validation Loss: 0.17354292869567872, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 4333, Training Loss: 0.1737969503287346, Validation Loss: 0.17400100032488505, Validation Accuracy: 0.475\n",
      "Epoch 4334, Training Loss: 0.17428634339763271, Validation Loss: 0.17292921443780263, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 4335, Training Loss: 0.17387458537855455, Validation Loss: 0.17404648959636687, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 4336, Training Loss: 0.17409370310844913, Validation Loss: 0.17343897819519044, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4337, Training Loss: 0.17379677103411767, Validation Loss: 0.1737916111946106, Validation Accuracy: 0.4875\n",
      "Epoch 4338, Training Loss: 0.17424629099907413, Validation Loss: 0.173057426015536, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 4339, Training Loss: 0.17375389991268034, Validation Loss: 0.1736942261457443, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 4340, Training Loss: 0.1742897855658685, Validation Loss: 0.17339758475621542, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4341, Training Loss: 0.17368647408100865, Validation Loss: 0.17365039189656575, Validation Accuracy: 0.49375\n",
      "Epoch 4342, Training Loss: 0.1743134784121667, Validation Loss: 0.17328461905320486, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 4343, Training Loss: 0.1738246876385904, Validation Loss: 0.17332503100236257, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 4344, Training Loss: 0.17374289852957572, Validation Loss: 0.1746050904194514, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 4345, Training Loss: 0.173945146702951, Validation Loss: 0.17332242627938588, Validation Accuracy: 0.5125\n",
      "Epoch 4346, Training Loss: 0.17417009559369856, Validation Loss: 0.173551673690478, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 4347, Training Loss: 0.17385481009560247, Validation Loss: 0.17296065787474316, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 4348, Training Loss: 0.17404104625025102, Validation Loss: 0.17363414963086446, Validation Accuracy: 0.48125\n",
      "Epoch 4349, Training Loss: 0.17367454882591002, Validation Loss: 0.173582524061203, Validation Accuracy: 0.50625\n",
      "Epoch 4350, Training Loss: 0.17402813367305264, Validation Loss: 0.17437658309936524, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 4351, Training Loss: 0.1738295122500389, Validation Loss: 0.17245130141576132, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 4352, Training Loss: 0.1743007384000286, Validation Loss: 0.1735414187113444, Validation Accuracy: 0.475\n",
      "Epoch 4353, Training Loss: 0.1736579902710453, Validation Loss: 0.17331386705239613, Validation Accuracy: 0.5125\n",
      "Epoch 4354, Training Loss: 0.17427035493235435, Validation Loss: 0.1736333300669988, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 4355, Training Loss: 0.17380114957209555, Validation Loss: 0.17266228795051575, Validation Accuracy: 0.5375\n",
      "Epoch 4356, Training Loss: 0.17426449396917898, Validation Loss: 0.17343975603580475, Validation Accuracy: 0.4875\n",
      "Epoch 4357, Training Loss: 0.17364440906432368, Validation Loss: 0.1736524095137914, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 4358, Training Loss: 0.17444019356081564, Validation Loss: 0.17338084181149802, Validation Accuracy: 0.475\n",
      "Epoch 4359, Training Loss: 0.17364073136160452, Validation Loss: 0.1723360280195872, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 4360, Training Loss: 0.17426759196865943, Validation Loss: 0.17355639934539796, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 4361, Training Loss: 0.1737350239869087, Validation Loss: 0.17377573549747466, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4362, Training Loss: 0.17435753874240384, Validation Loss: 0.17336487372716267, Validation Accuracy: 0.4875\n",
      "Epoch 4363, Training Loss: 0.17372250749218848, Validation Loss: 0.17273206412792205, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 4364, Training Loss: 0.17426122869214705, Validation Loss: 0.17339322865009307, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 4365, Training Loss: 0.17367439260405879, Validation Loss: 0.17372041046619416, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4366, Training Loss: 0.17439967730352957, Validation Loss: 0.1733421931664149, Validation Accuracy: 0.49375\n",
      "Epoch 4367, Training Loss: 0.1737834330528013, Validation Loss: 0.17388712068398793, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 4368, Training Loss: 0.17419622838497162, Validation Loss: 0.1732562412818273, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 4369, Training Loss: 0.17358673676367728, Validation Loss: 0.17400607566038767, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 4370, Training Loss: 0.17448126500652683, Validation Loss: 0.17322694659233093, Validation Accuracy: 0.5125\n",
      "Epoch 4371, Training Loss: 0.17365870600746525, Validation Loss: 0.17455133001009623, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 4372, Training Loss: 0.1743041791262165, Validation Loss: 0.17316442131996154, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 4373, Training Loss: 0.17364787094054684, Validation Loss: 0.17486887673536936, Validation Accuracy: 0.48125\n",
      "Epoch 4374, Training Loss: 0.17442337255324086, Validation Loss: 0.17328407963116962, Validation Accuracy: 0.50625\n",
      "Epoch 4375, Training Loss: 0.17352211283099267, Validation Loss: 0.17586120863755544, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 4376, Training Loss: 0.17449914207381587, Validation Loss: 0.17265552779038748, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 4377, Training Loss: 0.17347918643105414, Validation Loss: 0.175176802277565, Validation Accuracy: 0.475\n",
      "Epoch 4378, Training Loss: 0.17452105495237535, Validation Loss: 0.1732177625099818, Validation Accuracy: 0.5125\n",
      "Epoch 4379, Training Loss: 0.173468031710194, Validation Loss: 0.17559348146120707, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 4380, Training Loss: 0.17446365135331307, Validation Loss: 0.17299080193042754, Validation Accuracy: 0.5375\n",
      "Epoch 4381, Training Loss: 0.17349278013552388, Validation Loss: 0.17475365300973256, Validation Accuracy: 0.4875\n",
      "Epoch 4382, Training Loss: 0.1746075475408185, Validation Loss: 0.17360260287920634, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 4383, Training Loss: 0.17355395420905081, Validation Loss: 0.17540587484836578, Validation Accuracy: 0.475\n",
      "Epoch 4384, Training Loss: 0.17446849134660536, Validation Loss: 0.17231481969356538, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 4385, Training Loss: 0.1735811791112346, Validation Loss: 0.17548676133155822, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 4386, Training Loss: 0.17441697899372346, Validation Loss: 0.17372952699661254, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4387, Training Loss: 0.17351748770283115, Validation Loss: 0.17500246465206146, Validation Accuracy: 0.4875\n",
      "Epoch 4388, Training Loss: 0.17421859454724095, Validation Loss: 0.17309518953164418, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 4389, Training Loss: 0.17361449185879, Validation Loss: 0.1739329606294632, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 4390, Training Loss: 0.1743301148376157, Validation Loss: 0.17400569915771485, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4391, Training Loss: 0.1736061260584862, Validation Loss: 0.1748281439145406, Validation Accuracy: 0.49375\n",
      "Epoch 4392, Training Loss: 0.17436124095993658, Validation Loss: 0.17372897366682688, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 4393, Training Loss: 0.1736064447510627, Validation Loss: 0.17398669322331747, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 4394, Training Loss: 0.17428518014569436, Validation Loss: 0.17446014980475108, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 4395, Training Loss: 0.17359505882186274, Validation Loss: 0.17392706473668415, Validation Accuracy: 0.5125\n",
      "Epoch 4396, Training Loss: 0.17432659576016088, Validation Loss: 0.17474125822385153, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 4397, Training Loss: 0.17378174970226903, Validation Loss: 0.17300396064917248, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 4398, Training Loss: 0.17430327736562298, Validation Loss: 0.174898225069046, Validation Accuracy: 0.48125\n",
      "Epoch 4399, Training Loss: 0.17357520566832635, Validation Loss: 0.17387808859348297, Validation Accuracy: 0.50625\n",
      "Epoch 4400, Training Loss: 0.17450239389173447, Validation Loss: 0.17566064695517222, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 4401, Training Loss: 0.17372501473273, Validation Loss: 0.17212088604768117, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 4402, Training Loss: 0.17423387016019515, Validation Loss: 0.17578741510709125, Validation Accuracy: 0.475\n",
      "Epoch 4403, Training Loss: 0.17382298938689694, Validation Loss: 0.17351266145706176, Validation Accuracy: 0.5125\n",
      "Epoch 4404, Training Loss: 0.1740041519365003, Validation Loss: 0.17610391875108083, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 4405, Training Loss: 0.17398160071142257, Validation Loss: 0.1726601074139277, Validation Accuracy: 0.5375\n",
      "Epoch 4406, Training Loss: 0.1738859285270014, Validation Loss: 0.17561090489228567, Validation Accuracy: 0.4875\n",
      "Epoch 4407, Training Loss: 0.17399558617222693, Validation Loss: 0.17408447265625, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 4408, Training Loss: 0.17396231139859847, Validation Loss: 0.17562033931414286, Validation Accuracy: 0.475\n",
      "Epoch 4409, Training Loss: 0.17411660330910836, Validation Loss: 0.17190025746822357, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 4410, Training Loss: 0.1738140054287449, Validation Loss: 0.1769160101811091, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 4411, Training Loss: 0.1742195116896783, Validation Loss: 0.17390808661778767, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4412, Training Loss: 0.17372577901809447, Validation Loss: 0.1751538594563802, Validation Accuracy: 0.4875\n",
      "Epoch 4413, Training Loss: 0.1743855087026473, Validation Loss: 0.17273184756437937, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 4414, Training Loss: 0.17336993352059396, Validation Loss: 0.17561328709125518, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 4415, Training Loss: 0.17469840568880882, Validation Loss: 0.17382943431536357, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4416, Training Loss: 0.17365850844690878, Validation Loss: 0.17441198329130808, Validation Accuracy: 0.49375\n",
      "Epoch 4417, Training Loss: 0.17425996353549342, Validation Loss: 0.17375640471776327, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 4418, Training Loss: 0.1736360466287982, Validation Loss: 0.17423611879348755, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 4419, Training Loss: 0.17436074345342575, Validation Loss: 0.1740671843290329, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 4420, Training Loss: 0.17378673293898184, Validation Loss: 0.17361950973669688, Validation Accuracy: 0.5125\n",
      "Epoch 4421, Training Loss: 0.17421112089387833, Validation Loss: 0.17444935540358225, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 4422, Training Loss: 0.17361057958295267, Validation Loss: 0.17333160638809203, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 4423, Training Loss: 0.17432317714537343, Validation Loss: 0.1739361474911372, Validation Accuracy: 0.48125\n",
      "Epoch 4424, Training Loss: 0.17370055904311518, Validation Loss: 0.1743044763803482, Validation Accuracy: 0.50625\n",
      "Epoch 4425, Training Loss: 0.17432095158484676, Validation Loss: 0.1743798981110255, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 4426, Training Loss: 0.17361472162508196, Validation Loss: 0.17208132843176524, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 4427, Training Loss: 0.17440492203158717, Validation Loss: 0.1739303449789683, Validation Accuracy: 0.475\n",
      "Epoch 4428, Training Loss: 0.17371754780892404, Validation Loss: 0.173823149005572, Validation Accuracy: 0.5125\n",
      "Epoch 4429, Training Loss: 0.17436151639107736, Validation Loss: 0.17412625551223754, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 4430, Training Loss: 0.17358907720734995, Validation Loss: 0.17274188101291657, Validation Accuracy: 0.5375\n",
      "Epoch 4431, Training Loss: 0.17442116141319275, Validation Loss: 0.17362382113933564, Validation Accuracy: 0.4875\n",
      "Epoch 4432, Training Loss: 0.17376272909102902, Validation Loss: 0.17435838282108307, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 4433, Training Loss: 0.17413584215025749, Validation Loss: 0.17459284663200378, Validation Accuracy: 0.475\n",
      "Epoch 4434, Training Loss: 0.173728356918981, Validation Loss: 0.17175616323947906, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 4435, Training Loss: 0.1742960084830561, Validation Loss: 0.17398140132427214, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 4436, Training Loss: 0.17385567003680813, Validation Loss: 0.1741377850373586, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4437, Training Loss: 0.17422534333121392, Validation Loss: 0.17367082834243774, Validation Accuracy: 0.4875\n",
      "Epoch 4438, Training Loss: 0.17380354000676063, Validation Loss: 0.17281188468138378, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 4439, Training Loss: 0.1742496423182949, Validation Loss: 0.1734218140443166, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 4440, Training Loss: 0.17385621705362875, Validation Loss: 0.17349771161874136, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4441, Training Loss: 0.1740011611292439, Validation Loss: 0.17398510575294496, Validation Accuracy: 0.49375\n",
      "Epoch 4442, Training Loss: 0.17389063440984295, Validation Loss: 0.17339036365350088, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 4443, Training Loss: 0.17405976114734525, Validation Loss: 0.17328402002652485, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 4444, Training Loss: 0.17390476792089402, Validation Loss: 0.17357990543047588, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 4445, Training Loss: 0.17411413692658947, Validation Loss: 0.17321771283944448, Validation Accuracy: 0.5125\n",
      "Epoch 4446, Training Loss: 0.17389470867572293, Validation Loss: 0.17346173028151193, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 4447, Training Loss: 0.17405435106446665, Validation Loss: 0.17299126187960306, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 4448, Training Loss: 0.17409411841823208, Validation Loss: 0.17367182274659473, Validation Accuracy: 0.48125\n",
      "Epoch 4449, Training Loss: 0.17390094024519767, Validation Loss: 0.1733646790186564, Validation Accuracy: 0.50625\n",
      "Epoch 4450, Training Loss: 0.1739407907570562, Validation Loss: 0.1735746959845225, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 4451, Training Loss: 0.17417515429758257, Validation Loss: 0.1728871424992879, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 4452, Training Loss: 0.17392663946074824, Validation Loss: 0.1736023763815562, Validation Accuracy: 0.475\n",
      "Epoch 4453, Training Loss: 0.17383511364459991, Validation Loss: 0.1733268787463506, Validation Accuracy: 0.5125\n",
      "Epoch 4454, Training Loss: 0.17394497077311238, Validation Loss: 0.1737375368674596, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 4455, Training Loss: 0.17419747960182927, Validation Loss: 0.17301189303398132, Validation Accuracy: 0.5375\n",
      "Epoch 4456, Training Loss: 0.17397454236784288, Validation Loss: 0.17375413179397584, Validation Accuracy: 0.4875\n",
      "Epoch 4457, Training Loss: 0.17395323034255736, Validation Loss: 0.17360781530539196, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 4458, Training Loss: 0.17384043720460707, Validation Loss: 0.17387793958187103, Validation Accuracy: 0.475\n",
      "Epoch 4459, Training Loss: 0.17419700997491036, Validation Loss: 0.17273804148038227, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 4460, Training Loss: 0.17386658730045443, Validation Loss: 0.1739533523718516, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 4461, Training Loss: 0.17417605365476302, Validation Loss: 0.17339259386062622, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4462, Training Loss: 0.17376234262220322, Validation Loss: 0.1737018326918284, Validation Accuracy: 0.4875\n",
      "Epoch 4463, Training Loss: 0.17428083621686505, Validation Loss: 0.17308366497357686, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 4464, Training Loss: 0.17374061288372164, Validation Loss: 0.17364047169685365, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 4465, Training Loss: 0.1742880291515781, Validation Loss: 0.17339714467525483, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4466, Training Loss: 0.17366582491705496, Validation Loss: 0.1736814002195994, Validation Accuracy: 0.49375\n",
      "Epoch 4467, Training Loss: 0.17434117630604776, Validation Loss: 0.1732819527387619, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 4468, Training Loss: 0.17380314680837816, Validation Loss: 0.17333709597587585, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 4469, Training Loss: 0.17418969302408158, Validation Loss: 0.17345713675022126, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 4470, Training Loss: 0.17380068811678118, Validation Loss: 0.17326203684012095, Validation Accuracy: 0.5125\n",
      "Epoch 4471, Training Loss: 0.174183189868927, Validation Loss: 0.1734955370426178, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 4472, Training Loss: 0.17384487294381665, Validation Loss: 0.17292679051558177, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 4473, Training Loss: 0.17421902139340678, Validation Loss: 0.17347335517406465, Validation Accuracy: 0.48125\n",
      "Epoch 4474, Training Loss: 0.1736632672048384, Validation Loss: 0.17349304556846618, Validation Accuracy: 0.50625\n",
      "Epoch 4475, Training Loss: 0.1743449717760086, Validation Loss: 0.17350383202234904, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 4476, Training Loss: 0.17372885106071348, Validation Loss: 0.17222495277722677, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 4477, Training Loss: 0.1742730611755002, Validation Loss: 0.17356677452723185, Validation Accuracy: 0.475\n",
      "Epoch 4478, Training Loss: 0.1736654672891863, Validation Loss: 0.17326363225777944, Validation Accuracy: 0.5125\n",
      "Epoch 4479, Training Loss: 0.17434130609035492, Validation Loss: 0.1734784185886383, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 4480, Training Loss: 0.17373339158873405, Validation Loss: 0.17268546521663666, Validation Accuracy: 0.5375\n",
      "Epoch 4481, Training Loss: 0.1743337223606725, Validation Loss: 0.1733980307976405, Validation Accuracy: 0.4875\n",
      "Epoch 4482, Training Loss: 0.17362193570983026, Validation Loss: 0.1736888974905014, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 4483, Training Loss: 0.17441190923413924, Validation Loss: 0.17341954211393992, Validation Accuracy: 0.475\n",
      "Epoch 4484, Training Loss: 0.17363594424340031, Validation Loss: 0.17199459175268808, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 4485, Training Loss: 0.1743731878457531, Validation Loss: 0.1735743502775828, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 4486, Training Loss: 0.1736610007862891, Validation Loss: 0.17391111254692077, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4487, Training Loss: 0.17432333240585943, Validation Loss: 0.17335302631060281, Validation Accuracy: 0.4875\n",
      "Epoch 4488, Training Loss: 0.173720121383667, Validation Loss: 0.17279304265975953, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 4489, Training Loss: 0.17429495386538968, Validation Loss: 0.17332740823427836, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 4490, Training Loss: 0.17366842492934195, Validation Loss: 0.17390116751194, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4491, Training Loss: 0.17439487095802061, Validation Loss: 0.1733111282189687, Validation Accuracy: 0.49375\n",
      "Epoch 4492, Training Loss: 0.17374125747911393, Validation Loss: 0.1733916421731313, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 4493, Training Loss: 0.17396966872676725, Validation Loss: 0.17325607140858967, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 4494, Training Loss: 0.17371966281244833, Validation Loss: 0.17411347528298696, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 4495, Training Loss: 0.1744645478263978, Validation Loss: 0.1732564171155294, Validation Accuracy: 0.5125\n",
      "Epoch 4496, Training Loss: 0.17367475071261007, Validation Loss: 0.17432365715503692, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 4497, Training Loss: 0.17424897320808902, Validation Loss: 0.17319222191969555, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 4498, Training Loss: 0.17365670877118264, Validation Loss: 0.174636705716451, Validation Accuracy: 0.48125\n",
      "Epoch 4499, Training Loss: 0.1744113064581348, Validation Loss: 0.17327970266342163, Validation Accuracy: 0.50625\n",
      "Epoch 4500, Training Loss: 0.1735405494128504, Validation Loss: 0.17575176457564037, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 4501, Training Loss: 0.174501393591204, Validation Loss: 0.17276448408762615, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 4502, Training Loss: 0.17348614527333167, Validation Loss: 0.17543669939041137, Validation Accuracy: 0.475\n",
      "Epoch 4503, Training Loss: 0.1745006177694567, Validation Loss: 0.17321819464365643, Validation Accuracy: 0.5125\n",
      "Epoch 4504, Training Loss: 0.17348493539517926, Validation Loss: 0.17553932170073192, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 4505, Training Loss: 0.17449966409514028, Validation Loss: 0.17299674749374389, Validation Accuracy: 0.5375\n",
      "Epoch 4506, Training Loss: 0.1734616684336816, Validation Loss: 0.17506923774878183, Validation Accuracy: 0.4875\n",
      "Epoch 4507, Training Loss: 0.1745812450685809, Validation Loss: 0.1734119047721227, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 4508, Training Loss: 0.17359716421173466, Validation Loss: 0.17540234923362732, Validation Accuracy: 0.475\n",
      "Epoch 4509, Training Loss: 0.17409102138011687, Validation Loss: 0.17315402130285898, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 4510, Training Loss: 0.1736892375253862, Validation Loss: 0.17437675197919209, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 4511, Training Loss: 0.17443418791217188, Validation Loss: 0.17355946103731792, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4512, Training Loss: 0.1735763410406728, Validation Loss: 0.17516185939311982, Validation Accuracy: 0.4875\n",
      "Epoch 4513, Training Loss: 0.17429999478401675, Validation Loss: 0.172738978266716, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 4514, Training Loss: 0.17359073027487723, Validation Loss: 0.17451755901177723, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 4515, Training Loss: 0.17440879585281496, Validation Loss: 0.17394278844197592, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4516, Training Loss: 0.1735775629358907, Validation Loss: 0.17475931346416473, Validation Accuracy: 0.49375\n",
      "Epoch 4517, Training Loss: 0.17441590707148275, Validation Loss: 0.1736451158920924, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 4518, Training Loss: 0.17353616174190276, Validation Loss: 0.174151411652565, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 4519, Training Loss: 0.17428933468557173, Validation Loss: 0.17460945943991343, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 4520, Training Loss: 0.17363440269424069, Validation Loss: 0.17379293839136759, Validation Accuracy: 0.5125\n",
      "Epoch 4521, Training Loss: 0.17431801028790012, Validation Loss: 0.17469155887762705, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 4522, Training Loss: 0.17375461949456122, Validation Loss: 0.17298386494318643, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 4523, Training Loss: 0.1743349293547292, Validation Loss: 0.17497516473134359, Validation Accuracy: 0.48125\n",
      "Epoch 4524, Training Loss: 0.17358042732361825, Validation Loss: 0.1738805780808131, Validation Accuracy: 0.50625\n",
      "Epoch 4525, Training Loss: 0.17439975998094004, Validation Loss: 0.17533338566621146, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 4526, Training Loss: 0.17380989366962063, Validation Loss: 0.17212885121504465, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 4527, Training Loss: 0.17421379685401917, Validation Loss: 0.17572088539600372, Validation Accuracy: 0.475\n",
      "Epoch 4528, Training Loss: 0.1738290459878983, Validation Loss: 0.1734920084476471, Validation Accuracy: 0.5125\n",
      "Epoch 4529, Training Loss: 0.173988064931285, Validation Loss: 0.17589908540248872, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 4530, Training Loss: 0.17400562907418898, Validation Loss: 0.17265919744968414, Validation Accuracy: 0.5375\n",
      "Epoch 4531, Training Loss: 0.17387350432334409, Validation Loss: 0.17578079799811044, Validation Accuracy: 0.4875\n",
      "Epoch 4532, Training Loss: 0.1740064250846063, Validation Loss: 0.1741357624530792, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 4533, Training Loss: 0.1739715443503472, Validation Loss: 0.1758938878774643, Validation Accuracy: 0.475\n",
      "Epoch 4534, Training Loss: 0.17411225505413547, Validation Loss: 0.1719186822573344, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 4535, Training Loss: 0.1737862181278967, Validation Loss: 0.17714163462320964, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 4536, Training Loss: 0.17420784408046353, Validation Loss: 0.17393499612808228, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4537, Training Loss: 0.17370571003806207, Validation Loss: 0.17520856161912282, Validation Accuracy: 0.4875\n",
      "Epoch 4538, Training Loss: 0.17434468961531116, Validation Loss: 0.17273030777772266, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 4539, Training Loss: 0.17331569521657883, Validation Loss: 0.1755694439013799, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 4540, Training Loss: 0.17466345813966566, Validation Loss: 0.17382699251174927, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4541, Training Loss: 0.17366574560442277, Validation Loss: 0.1741842826207479, Validation Accuracy: 0.49375\n",
      "Epoch 4542, Training Loss: 0.17422358739760616, Validation Loss: 0.17377376357714336, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 4543, Training Loss: 0.17362872919728678, Validation Loss: 0.17422682344913482, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 4544, Training Loss: 0.17433922617666184, Validation Loss: 0.17414920926094055, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 4545, Training Loss: 0.1737862407199798, Validation Loss: 0.17366396387418112, Validation Accuracy: 0.5125\n",
      "Epoch 4546, Training Loss: 0.17420518398284912, Validation Loss: 0.17461744944254556, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 4547, Training Loss: 0.17358531730790291, Validation Loss: 0.17334413627783457, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 4548, Training Loss: 0.1742879666628376, Validation Loss: 0.17399232884248098, Validation Accuracy: 0.48125\n",
      "Epoch 4549, Training Loss: 0.17378763902571895, Validation Loss: 0.17396050989627837, Validation Accuracy: 0.50625\n",
      "Epoch 4550, Training Loss: 0.17426932146472315, Validation Loss: 0.17455382744471232, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 4551, Training Loss: 0.17364732680782194, Validation Loss: 0.17207910120487213, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 4552, Training Loss: 0.17438299088708817, Validation Loss: 0.17395092844963073, Validation Accuracy: 0.475\n",
      "Epoch 4553, Training Loss: 0.17375162580320913, Validation Loss: 0.1736597239971161, Validation Accuracy: 0.5125\n",
      "Epoch 4554, Training Loss: 0.17422833221573983, Validation Loss: 0.17464225788911183, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 4555, Training Loss: 0.17355852934621996, Validation Loss: 0.17292481859525044, Validation Accuracy: 0.5375\n",
      "Epoch 4556, Training Loss: 0.17452171156483312, Validation Loss: 0.17356794973214468, Validation Accuracy: 0.4875\n",
      "Epoch 4557, Training Loss: 0.173766337575451, Validation Loss: 0.1742306927839915, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 4558, Training Loss: 0.17426031395312278, Validation Loss: 0.1740302860736847, Validation Accuracy: 0.475\n",
      "Epoch 4559, Training Loss: 0.1737047140636752, Validation Loss: 0.17177009681860606, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 4560, Training Loss: 0.1743318678871278, Validation Loss: 0.17378239929676056, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 4561, Training Loss: 0.17382205926602887, Validation Loss: 0.17369774381319683, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4562, Training Loss: 0.1741003692150116, Validation Loss: 0.17397933502991994, Validation Accuracy: 0.4875\n",
      "Epoch 4563, Training Loss: 0.1738678490923297, Validation Loss: 0.1727540632088979, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 4564, Training Loss: 0.17402665124785516, Validation Loss: 0.17370458443959555, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 4565, Training Loss: 0.17382567736410326, Validation Loss: 0.17371720870335897, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4566, Training Loss: 0.17408440189976845, Validation Loss: 0.17363541722297668, Validation Accuracy: 0.49375\n",
      "Epoch 4567, Training Loss: 0.17385090839478276, Validation Loss: 0.1733242074648539, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 4568, Training Loss: 0.1739143075481538, Validation Loss: 0.17345603307088217, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 4569, Training Loss: 0.1740609412231753, Validation Loss: 0.17343211273352305, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 4570, Training Loss: 0.17384126782417297, Validation Loss: 0.17334636946519216, Validation Accuracy: 0.5125\n",
      "Epoch 4571, Training Loss: 0.17398934306636935, Validation Loss: 0.17345577975114188, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 4572, Training Loss: 0.17412613524544623, Validation Loss: 0.17298574149608612, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 4573, Training Loss: 0.17398443481614512, Validation Loss: 0.1735726535320282, Validation Accuracy: 0.48125\n",
      "Epoch 4574, Training Loss: 0.17389572772287554, Validation Loss: 0.17341947952906292, Validation Accuracy: 0.50625\n",
      "Epoch 4575, Training Loss: 0.17396330208547653, Validation Loss: 0.17360040346781414, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 4576, Training Loss: 0.17424529214059153, Validation Loss: 0.17288568913936614, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 4577, Training Loss: 0.17404553726796182, Validation Loss: 0.17374914685885112, Validation Accuracy: 0.475\n",
      "Epoch 4578, Training Loss: 0.17380862514818868, Validation Loss: 0.17336103916168213, Validation Accuracy: 0.5125\n",
      "Epoch 4579, Training Loss: 0.1739439647043905, Validation Loss: 0.1737222731113434, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 4580, Training Loss: 0.17420034831570042, Validation Loss: 0.17303362886110943, Validation Accuracy: 0.5375\n",
      "Epoch 4581, Training Loss: 0.17397035994837362, Validation Loss: 0.17369673351446788, Validation Accuracy: 0.4875\n",
      "Epoch 4582, Training Loss: 0.17384747487883415, Validation Loss: 0.17390894989172617, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 4583, Training Loss: 0.1738864399733082, Validation Loss: 0.17408447861671447, Validation Accuracy: 0.475\n",
      "Epoch 4584, Training Loss: 0.1742384688508126, Validation Loss: 0.17284425099690756, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 4585, Training Loss: 0.1738993251515973, Validation Loss: 0.17410534818967183, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 4586, Training Loss: 0.17404163797055522, Validation Loss: 0.17350194652875264, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4587, Training Loss: 0.17380377890602236, Validation Loss: 0.17376888791720072, Validation Accuracy: 0.4875\n",
      "Epoch 4588, Training Loss: 0.1742579831231025, Validation Loss: 0.17306747436523437, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 4589, Training Loss: 0.17376819445240882, Validation Loss: 0.17364082336425782, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 4590, Training Loss: 0.17426797603407213, Validation Loss: 0.17340958913167318, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4591, Training Loss: 0.1737012291146863, Validation Loss: 0.1736782302459081, Validation Accuracy: 0.49375\n",
      "Epoch 4592, Training Loss: 0.17429644878833525, Validation Loss: 0.17328642706076305, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 4593, Training Loss: 0.17384622510402434, Validation Loss: 0.1733763833840688, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 4594, Training Loss: 0.17413510670585017, Validation Loss: 0.17350944479306538, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 4595, Training Loss: 0.17375949553904996, Validation Loss: 0.1732617606719335, Validation Accuracy: 0.5125\n",
      "Epoch 4596, Training Loss: 0.1742668757515569, Validation Loss: 0.17343423167864483, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 4597, Training Loss: 0.17381801143769296, Validation Loss: 0.17291379968325296, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 4598, Training Loss: 0.174215734485657, Validation Loss: 0.17346995770931245, Validation Accuracy: 0.48125\n",
      "Epoch 4599, Training Loss: 0.1736565693732231, Validation Loss: 0.17348493039608, Validation Accuracy: 0.50625\n",
      "Epoch 4600, Training Loss: 0.1743602531571542, Validation Loss: 0.17348690827687582, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 4601, Training Loss: 0.17369189858436584, Validation Loss: 0.1722793529431025, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 4602, Training Loss: 0.17428860260594276, Validation Loss: 0.17354685068130493, Validation Accuracy: 0.475\n",
      "Epoch 4603, Training Loss: 0.1737274758277401, Validation Loss: 0.17332707047462464, Validation Accuracy: 0.5125\n",
      "Epoch 4604, Training Loss: 0.1743196633554274, Validation Loss: 0.17349717617034913, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 4605, Training Loss: 0.1736941183767011, Validation Loss: 0.1726644535859426, Validation Accuracy: 0.5375\n",
      "Epoch 4606, Training Loss: 0.1743002341639611, Validation Loss: 0.17346234122912088, Validation Accuracy: 0.4875\n",
      "Epoch 4607, Training Loss: 0.1736724679508517, Validation Loss: 0.17407847344875335, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 4608, Training Loss: 0.17433355556380364, Validation Loss: 0.1734342783689499, Validation Accuracy: 0.475\n",
      "Epoch 4609, Training Loss: 0.17367649895529594, Validation Loss: 0.1722161183754603, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 4610, Training Loss: 0.17433242932442697, Validation Loss: 0.1735017071167628, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 4611, Training Loss: 0.17364976338801846, Validation Loss: 0.17382786671320596, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4612, Training Loss: 0.17437878539485316, Validation Loss: 0.17338651021321613, Validation Accuracy: 0.4875\n",
      "Epoch 4613, Training Loss: 0.17369485285974318, Validation Loss: 0.17272833089033762, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 4614, Training Loss: 0.17427608563053992, Validation Loss: 0.17337678174177806, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 4615, Training Loss: 0.17365864303804213, Validation Loss: 0.17366074124972025, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4616, Training Loss: 0.17441861523735908, Validation Loss: 0.1733504831790924, Validation Accuracy: 0.49375\n",
      "Epoch 4617, Training Loss: 0.17376361546977873, Validation Loss: 0.17371424833933513, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 4618, Training Loss: 0.1742436073480114, Validation Loss: 0.17326367994149525, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 4619, Training Loss: 0.17359014143866877, Validation Loss: 0.1744173377752304, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 4620, Training Loss: 0.174326925027755, Validation Loss: 0.17326025466124217, Validation Accuracy: 0.5125\n",
      "Epoch 4621, Training Loss: 0.17377580365827006, Validation Loss: 0.17471636335055032, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 4622, Training Loss: 0.17427543863173453, Validation Loss: 0.1730817566315333, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 4623, Training Loss: 0.17360897698710043, Validation Loss: 0.1743589202562968, Validation Accuracy: 0.48125\n",
      "Epoch 4624, Training Loss: 0.1744301256633574, Validation Loss: 0.1732719530661901, Validation Accuracy: 0.50625\n",
      "Epoch 4625, Training Loss: 0.173547730330498, Validation Loss: 0.1757057617108027, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 4626, Training Loss: 0.17451123460646598, Validation Loss: 0.1727552245060603, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 4627, Training Loss: 0.1734675269934439, Validation Loss: 0.175492391983668, Validation Accuracy: 0.475\n",
      "Epoch 4628, Training Loss: 0.17449289848727564, Validation Loss: 0.17321726083755493, Validation Accuracy: 0.5125\n",
      "Epoch 4629, Training Loss: 0.17348989988526992, Validation Loss: 0.17533807555834452, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 4630, Training Loss: 0.17419188109136396, Validation Loss: 0.17320068379243214, Validation Accuracy: 0.5375\n",
      "Epoch 4631, Training Loss: 0.17360644330901484, Validation Loss: 0.17426782846450806, Validation Accuracy: 0.4875\n",
      "Epoch 4632, Training Loss: 0.17441624547204665, Validation Loss: 0.17331325908501943, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 4633, Training Loss: 0.17368371159799637, Validation Loss: 0.17490277687708536, Validation Accuracy: 0.475\n",
      "Epoch 4634, Training Loss: 0.17439190033943422, Validation Loss: 0.17246384421984354, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 4635, Training Loss: 0.17356821269758285, Validation Loss: 0.1755754232406616, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 4636, Training Loss: 0.17442003661586392, Validation Loss: 0.17368342677752177, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4637, Training Loss: 0.17352765269817844, Validation Loss: 0.17503360013167063, Validation Accuracy: 0.4875\n",
      "Epoch 4638, Training Loss: 0.1744047422562876, Validation Loss: 0.17275011241436006, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 4639, Training Loss: 0.17352722585201263, Validation Loss: 0.1746750811735789, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 4640, Training Loss: 0.17439308089594688, Validation Loss: 0.1740100423494975, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4641, Training Loss: 0.17359516649476944, Validation Loss: 0.17475877900918324, Validation Accuracy: 0.49375\n",
      "Epoch 4642, Training Loss: 0.1744350108408159, Validation Loss: 0.17361901104450225, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 4643, Training Loss: 0.1735229770983419, Validation Loss: 0.17393908103307087, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 4644, Training Loss: 0.17430918351296457, Validation Loss: 0.17449544072151185, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 4645, Training Loss: 0.17359096148321707, Validation Loss: 0.17377702196439107, Validation Accuracy: 0.5125\n",
      "Epoch 4646, Training Loss: 0.1743422338078099, Validation Loss: 0.17466461857159932, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 4647, Training Loss: 0.17374511832191097, Validation Loss: 0.1729555735985438, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 4648, Training Loss: 0.17430956950110774, Validation Loss: 0.17495280206203462, Validation Accuracy: 0.48125\n",
      "Epoch 4649, Training Loss: 0.173559584444569, Validation Loss: 0.1739123692115148, Validation Accuracy: 0.50625\n",
      "Epoch 4650, Training Loss: 0.17449906324186631, Validation Loss: 0.1757024794816971, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 4651, Training Loss: 0.17373482450362174, Validation Loss: 0.17215372224648792, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 4652, Training Loss: 0.17425114829694072, Validation Loss: 0.17577797770500184, Validation Accuracy: 0.475\n",
      "Epoch 4653, Training Loss: 0.17383284338058963, Validation Loss: 0.17347374459107717, Validation Accuracy: 0.5125\n",
      "Epoch 4654, Training Loss: 0.17397357235031743, Validation Loss: 0.1754567176103592, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 4655, Training Loss: 0.174017995595932, Validation Loss: 0.17266371548175813, Validation Accuracy: 0.5375\n",
      "Epoch 4656, Training Loss: 0.17388197298972838, Validation Loss: 0.1756854126850764, Validation Accuracy: 0.4875\n",
      "Epoch 4657, Training Loss: 0.17396969179953298, Validation Loss: 0.17417295078436534, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 4658, Training Loss: 0.17398498663979192, Validation Loss: 0.17604760825634003, Validation Accuracy: 0.475\n",
      "Epoch 4659, Training Loss: 0.17406818222615025, Validation Loss: 0.1719895710547765, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 4660, Training Loss: 0.17378933535468194, Validation Loss: 0.17712336281935373, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 4661, Training Loss: 0.17421086757413803, Validation Loss: 0.17387556234995524, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4662, Training Loss: 0.17377643287181854, Validation Loss: 0.1746131698290507, Validation Accuracy: 0.4875\n",
      "Epoch 4663, Training Loss: 0.1743294870661151, Validation Loss: 0.17272735138734183, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 4664, Training Loss: 0.1733595041498061, Validation Loss: 0.175658655166626, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 4665, Training Loss: 0.17461528028211287, Validation Loss: 0.17372063000996907, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4666, Training Loss: 0.17365977696834073, Validation Loss: 0.17461390495300294, Validation Accuracy: 0.49375\n",
      "Epoch 4667, Training Loss: 0.17430038557898614, Validation Loss: 0.17363060116767884, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 4668, Training Loss: 0.17364267524211638, Validation Loss: 0.1746510128180186, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 4669, Training Loss: 0.17432483934587048, Validation Loss: 0.17396117250124613, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 4670, Training Loss: 0.17381475096748722, Validation Loss: 0.17366387943426767, Validation Accuracy: 0.5125\n",
      "Epoch 4671, Training Loss: 0.17420887850945996, Validation Loss: 0.17460483411947886, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 4672, Training Loss: 0.1735861171637812, Validation Loss: 0.17342613140741983, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 4673, Training Loss: 0.17436139622042257, Validation Loss: 0.1739051342010498, Validation Accuracy: 0.48125\n",
      "Epoch 4674, Training Loss: 0.17371832314998872, Validation Loss: 0.17417359948158265, Validation Accuracy: 0.50625\n",
      "Epoch 4675, Training Loss: 0.17421734477243117, Validation Loss: 0.1748681515455246, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 4676, Training Loss: 0.17364492243336094, Validation Loss: 0.1721894274155299, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 4677, Training Loss: 0.1743948733614337, Validation Loss: 0.17393122911453246, Validation Accuracy: 0.475\n",
      "Epoch 4678, Training Loss: 0.17381462887410196, Validation Loss: 0.1733980119228363, Validation Accuracy: 0.5125\n",
      "Epoch 4679, Training Loss: 0.17410397193124216, Validation Loss: 0.17524902522563934, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 4680, Training Loss: 0.17369189377753966, Validation Loss: 0.17267016271750132, Validation Accuracy: 0.5375\n",
      "Epoch 4681, Training Loss: 0.17429248748287077, Validation Loss: 0.17374733785788218, Validation Accuracy: 0.4875\n",
      "Epoch 4682, Training Loss: 0.1738487333059311, Validation Loss: 0.17390742003917695, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 4683, Training Loss: 0.1740626673544607, Validation Loss: 0.17485383450984954, Validation Accuracy: 0.475\n",
      "Epoch 4684, Training Loss: 0.17375844668957494, Validation Loss: 0.1718050052722295, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 4685, Training Loss: 0.1742896750088661, Validation Loss: 0.17383606831232706, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 4686, Training Loss: 0.17390272886522354, Validation Loss: 0.17367041508356731, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4687, Training Loss: 0.17392469654160161, Validation Loss: 0.17479659020900726, Validation Accuracy: 0.4875\n",
      "Epoch 4688, Training Loss: 0.17392405290757457, Validation Loss: 0.1728576312462489, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 4689, Training Loss: 0.17416105972182366, Validation Loss: 0.17350842356681823, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 4690, Training Loss: 0.17396503975314478, Validation Loss: 0.1735179881254832, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4691, Training Loss: 0.17403297462771017, Validation Loss: 0.17370336055755614, Validation Accuracy: 0.49375\n",
      "Epoch 4692, Training Loss: 0.1738495788266582, Validation Loss: 0.173300967613856, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 4693, Training Loss: 0.17415885819542792, Validation Loss: 0.17326973676681517, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 4694, Training Loss: 0.1739472573803317, Validation Loss: 0.17346350451310474, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 4695, Training Loss: 0.17399529391719448, Validation Loss: 0.17323437929153443, Validation Accuracy: 0.5125\n",
      "Epoch 4696, Training Loss: 0.17394194199192908, Validation Loss: 0.17353693544864654, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 4697, Training Loss: 0.1741126794968882, Validation Loss: 0.1730401446421941, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 4698, Training Loss: 0.1739692851420372, Validation Loss: 0.17350630660851796, Validation Accuracy: 0.48125\n",
      "Epoch 4699, Training Loss: 0.17409411553413637, Validation Loss: 0.17328864137331645, Validation Accuracy: 0.50625\n",
      "Epoch 4700, Training Loss: 0.17388207537512626, Validation Loss: 0.1735713591178258, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 4701, Training Loss: 0.17418594369965215, Validation Loss: 0.17287378311157225, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 4702, Training Loss: 0.1738802449357125, Validation Loss: 0.17363711297512055, Validation Accuracy: 0.475\n",
      "Epoch 4703, Training Loss: 0.17413136459166004, Validation Loss: 0.17321961323420207, Validation Accuracy: 0.5125\n",
      "Epoch 4704, Training Loss: 0.1738522211390157, Validation Loss: 0.17361913919448851, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 4705, Training Loss: 0.1741660540142367, Validation Loss: 0.17299190759658814, Validation Accuracy: 0.5375\n",
      "Epoch 4706, Training Loss: 0.1739435306479854, Validation Loss: 0.17360912064711254, Validation Accuracy: 0.4875\n",
      "Epoch 4707, Training Loss: 0.1740447566393883, Validation Loss: 0.17350591520468395, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 4708, Training Loss: 0.17379591253495985, Validation Loss: 0.17394163012504577, Validation Accuracy: 0.475\n",
      "Epoch 4709, Training Loss: 0.1742607258981274, Validation Loss: 0.17287106613318126, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 4710, Training Loss: 0.17383520257088445, Validation Loss: 0.1739471952120463, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 4711, Training Loss: 0.1741756474779498, Validation Loss: 0.17339446842670442, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4712, Training Loss: 0.17377077235329536, Validation Loss: 0.17370811800161998, Validation Accuracy: 0.4875\n",
      "Epoch 4713, Training Loss: 0.1742621112254358, Validation Loss: 0.17306604584058125, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 4714, Training Loss: 0.17371436184452427, Validation Loss: 0.17364720006783804, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 4715, Training Loss: 0.17433831576378114, Validation Loss: 0.17337002356847128, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4716, Training Loss: 0.17366652238753535, Validation Loss: 0.173658416668574, Validation Accuracy: 0.49375\n",
      "Epoch 4717, Training Loss: 0.1743389146943246, Validation Loss: 0.17328239977359772, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 4718, Training Loss: 0.17377161306719627, Validation Loss: 0.1733089437087377, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 4719, Training Loss: 0.17408803970583023, Validation Loss: 0.17361212770144144, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 4720, Training Loss: 0.17379937633391349, Validation Loss: 0.17327315310637156, Validation Accuracy: 0.5125\n",
      "Epoch 4721, Training Loss: 0.1743087802202471, Validation Loss: 0.17342061003049214, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 4722, Training Loss: 0.17380928272201168, Validation Loss: 0.17290993531545004, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 4723, Training Loss: 0.17422092297384817, Validation Loss: 0.17346623341242473, Validation Accuracy: 0.48125\n",
      "Epoch 4724, Training Loss: 0.17365040221521932, Validation Loss: 0.1734633555014928, Validation Accuracy: 0.50625\n",
      "Epoch 4725, Training Loss: 0.17437252161964292, Validation Loss: 0.17347598175207773, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 4726, Training Loss: 0.1736769224366834, Validation Loss: 0.17234411537647248, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 4727, Training Loss: 0.17424928709383933, Validation Loss: 0.1735501637061437, Validation Accuracy: 0.475\n",
      "Epoch 4728, Training Loss: 0.17364487196168593, Validation Loss: 0.17335299452145894, Validation Accuracy: 0.5125\n",
      "Epoch 4729, Training Loss: 0.1743698509470109, Validation Loss: 0.17337046066919962, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 4730, Training Loss: 0.1737054499887651, Validation Loss: 0.17269080976645151, Validation Accuracy: 0.5375\n",
      "Epoch 4731, Training Loss: 0.1741405600501645, Validation Loss: 0.17355500360329945, Validation Accuracy: 0.4875\n",
      "Epoch 4732, Training Loss: 0.17371254342217599, Validation Loss: 0.1739199032386144, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 4733, Training Loss: 0.17433920406526135, Validation Loss: 0.17342453102270763, Validation Accuracy: 0.475\n",
      "Epoch 4734, Training Loss: 0.17365007006352948, Validation Loss: 0.17216622730096182, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 4735, Training Loss: 0.17441700302785443, Validation Loss: 0.17345720132191975, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 4736, Training Loss: 0.17359894802493434, Validation Loss: 0.17365329762299855, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4737, Training Loss: 0.17443399323571113, Validation Loss: 0.1733669310808182, Validation Accuracy: 0.4875\n",
      "Epoch 4738, Training Loss: 0.1736760610534299, Validation Loss: 0.17273255189259848, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 4739, Training Loss: 0.17428078718723788, Validation Loss: 0.17333451509475709, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 4740, Training Loss: 0.17368064628493401, Validation Loss: 0.17392511467138927, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4741, Training Loss: 0.17428901214753428, Validation Loss: 0.17329837381839752, Validation Accuracy: 0.49375\n",
      "Epoch 4742, Training Loss: 0.17375085142350966, Validation Loss: 0.1734076629082362, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 4743, Training Loss: 0.17431648796604526, Validation Loss: 0.17326051294803618, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 4744, Training Loss: 0.17356076980790786, Validation Loss: 0.17423943181832632, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 4745, Training Loss: 0.17446848365568346, Validation Loss: 0.17323488493760428, Validation Accuracy: 0.5125\n",
      "Epoch 4746, Training Loss: 0.17367872211240953, Validation Loss: 0.17498109340667725, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 4747, Training Loss: 0.17423579529408487, Validation Loss: 0.17317658364772798, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 4748, Training Loss: 0.17368671682573134, Validation Loss: 0.1747192233800888, Validation Accuracy: 0.48125\n",
      "Epoch 4749, Training Loss: 0.17441672278988746, Validation Loss: 0.17328248620033265, Validation Accuracy: 0.50625\n",
      "Epoch 4750, Training Loss: 0.17352843669153029, Validation Loss: 0.1758342872063319, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 4751, Training Loss: 0.17448160581050381, Validation Loss: 0.17278215587139129, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 4752, Training Loss: 0.17349146354583003, Validation Loss: 0.17505649328231812, Validation Accuracy: 0.475\n",
      "Epoch 4753, Training Loss: 0.17452176443992123, Validation Loss: 0.17321895956993102, Validation Accuracy: 0.5125\n",
      "Epoch 4754, Training Loss: 0.17345146690645524, Validation Loss: 0.1757100800673167, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 4755, Training Loss: 0.17445751399763168, Validation Loss: 0.17300526003042857, Validation Accuracy: 0.5375\n",
      "Epoch 4756, Training Loss: 0.17349013734248378, Validation Loss: 0.17473649978637695, Validation Accuracy: 0.4875\n",
      "Epoch 4757, Training Loss: 0.17451696001714276, Validation Loss: 0.17334835628668468, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 4758, Training Loss: 0.17365636604447518, Validation Loss: 0.17563477158546448, Validation Accuracy: 0.475\n",
      "Epoch 4759, Training Loss: 0.17434153729869473, Validation Loss: 0.1722651739915212, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 4760, Training Loss: 0.17363662008316286, Validation Loss: 0.17512913346290587, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 4761, Training Loss: 0.17440482829847642, Validation Loss: 0.1736145983139674, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4762, Training Loss: 0.17354097914311192, Validation Loss: 0.17510032951831817, Validation Accuracy: 0.4875\n",
      "Epoch 4763, Training Loss: 0.17438492707667813, Validation Loss: 0.17274424930413565, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 4764, Training Loss: 0.1735332718779964, Validation Loss: 0.17461168666680654, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 4765, Training Loss: 0.1744058636888381, Validation Loss: 0.17396914660930635, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4766, Training Loss: 0.173578389229313, Validation Loss: 0.17473303278287253, Validation Accuracy: 0.49375\n",
      "Epoch 4767, Training Loss: 0.17434198529489578, Validation Loss: 0.17371939420700072, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 4768, Training Loss: 0.17362672330871706, Validation Loss: 0.17399366497993468, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 4769, Training Loss: 0.17427181092000776, Validation Loss: 0.1745216925938924, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 4770, Training Loss: 0.17360404422206263, Validation Loss: 0.1737913727760315, Validation Accuracy: 0.5125\n",
      "Epoch 4771, Training Loss: 0.1744237498890969, Validation Loss: 0.17481465339660646, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 4772, Training Loss: 0.17370167711088735, Validation Loss: 0.1730288843313853, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 4773, Training Loss: 0.17426513904525387, Validation Loss: 0.17493668695290884, Validation Accuracy: 0.48125\n",
      "Epoch 4774, Training Loss: 0.17366202560163313, Validation Loss: 0.1739575147628784, Validation Accuracy: 0.50625\n",
      "Epoch 4775, Training Loss: 0.1744449479926017, Validation Loss: 0.17558375597000123, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 4776, Training Loss: 0.17377701305573987, Validation Loss: 0.1721330334742864, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 4777, Training Loss: 0.17424015700817108, Validation Loss: 0.17575008273124695, Validation Accuracy: 0.475\n",
      "Epoch 4778, Training Loss: 0.17379804340101057, Validation Loss: 0.17345614433288575, Validation Accuracy: 0.5125\n",
      "Epoch 4779, Training Loss: 0.1740563665666888, Validation Loss: 0.17610755066076914, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 4780, Training Loss: 0.1739469910821607, Validation Loss: 0.17265949646631876, Validation Accuracy: 0.5375\n",
      "Epoch 4781, Training Loss: 0.1738827343909971, Validation Loss: 0.1757475088040034, Validation Accuracy: 0.4875\n",
      "Epoch 4782, Training Loss: 0.1739839070266293, Validation Loss: 0.17408358454704284, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 4783, Training Loss: 0.17397493268212966, Validation Loss: 0.1757642447948456, Validation Accuracy: 0.475\n",
      "Epoch 4784, Training Loss: 0.17409908627310106, Validation Loss: 0.17198666632175447, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 4785, Training Loss: 0.1737698403096968, Validation Loss: 0.17729482849438985, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 4786, Training Loss: 0.1742596871429874, Validation Loss: 0.17386976679166158, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4787, Training Loss: 0.17373246627469216, Validation Loss: 0.17516313195228578, Validation Accuracy: 0.4875\n",
      "Epoch 4788, Training Loss: 0.17439212674094784, Validation Loss: 0.1727272778749466, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 4789, Training Loss: 0.17338375699135564, Validation Loss: 0.17532209157943726, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 4790, Training Loss: 0.17466787945839665, Validation Loss: 0.17384306093056998, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4791, Training Loss: 0.1735980313631796, Validation Loss: 0.17508649826049805, Validation Accuracy: 0.49375\n",
      "Epoch 4792, Training Loss: 0.1743331027607764, Validation Loss: 0.17358622451623282, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 4793, Training Loss: 0.1736283734921486, Validation Loss: 0.17446881632010142, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 4794, Training Loss: 0.1744024335376678, Validation Loss: 0.17397095561027526, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 4795, Training Loss: 0.17379856638370023, Validation Loss: 0.17360009451707203, Validation Accuracy: 0.5125\n",
      "Epoch 4796, Training Loss: 0.17419524010150664, Validation Loss: 0.17448598643143973, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 4797, Training Loss: 0.1735916603957453, Validation Loss: 0.17325331270694733, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 4798, Training Loss: 0.17433269658396322, Validation Loss: 0.17396881580352783, Validation Accuracy: 0.48125\n",
      "Epoch 4799, Training Loss: 0.17369970679283142, Validation Loss: 0.17433158457279205, Validation Accuracy: 0.50625\n",
      "Epoch 4800, Training Loss: 0.17434537458804347, Validation Loss: 0.17434784273306528, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 4801, Training Loss: 0.1736178917269553, Validation Loss: 0.17208341956138612, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 4802, Training Loss: 0.17439945859293784, Validation Loss: 0.1739307661851247, Validation Accuracy: 0.475\n",
      "Epoch 4803, Training Loss: 0.17372089768609694, Validation Loss: 0.17375191748142244, Validation Accuracy: 0.5125\n",
      "Epoch 4804, Training Loss: 0.17429724431806995, Validation Loss: 0.17438989281654357, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 4805, Training Loss: 0.1735633933736432, Validation Loss: 0.1728435516357422, Validation Accuracy: 0.5375\n",
      "Epoch 4806, Training Loss: 0.17449421603833476, Validation Loss: 0.1735808253288269, Validation Accuracy: 0.4875\n",
      "Epoch 4807, Training Loss: 0.17369452887965786, Validation Loss: 0.1747737298409144, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 4808, Training Loss: 0.17432768883243685, Validation Loss: 0.17387886047363282, Validation Accuracy: 0.475\n",
      "Epoch 4809, Training Loss: 0.1736802492410906, Validation Loss: 0.17183979948361713, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 4810, Training Loss: 0.17425367909093056, Validation Loss: 0.17408641676108041, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 4811, Training Loss: 0.17386811298708763, Validation Loss: 0.1739185094833374, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4812, Training Loss: 0.17416346842242825, Validation Loss: 0.17375565469264984, Validation Accuracy: 0.4875\n",
      "Epoch 4813, Training Loss: 0.17382807404764236, Validation Loss: 0.17280208965142568, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 4814, Training Loss: 0.17424492586043575, Validation Loss: 0.17341823279857635, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 4815, Training Loss: 0.17386366523081256, Validation Loss: 0.17346359888712565, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4816, Training Loss: 0.17412692116152856, Validation Loss: 0.17360611160596212, Validation Accuracy: 0.49375\n",
      "Epoch 4817, Training Loss: 0.17384475806067068, Validation Loss: 0.17332230905691784, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 4818, Training Loss: 0.1741765179941731, Validation Loss: 0.1732667028903961, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 4819, Training Loss: 0.1739326705855708, Validation Loss: 0.1734758416811625, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 4820, Training Loss: 0.17402633303596127, Validation Loss: 0.17322486539681753, Validation Accuracy: 0.5125\n",
      "Epoch 4821, Training Loss: 0.17391278282288583, Validation Loss: 0.17349186638991038, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 4822, Training Loss: 0.17409980585498194, Validation Loss: 0.17301365037759145, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 4823, Training Loss: 0.17400345590806776, Validation Loss: 0.17350684901078542, Validation Accuracy: 0.48125\n",
      "Epoch 4824, Training Loss: 0.17384885972545994, Validation Loss: 0.17352726658185322, Validation Accuracy: 0.50625\n",
      "Epoch 4825, Training Loss: 0.17401929968787777, Validation Loss: 0.17359980444113413, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 4826, Training Loss: 0.17407508050241777, Validation Loss: 0.1727762222290039, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 4827, Training Loss: 0.17397185390995396, Validation Loss: 0.17372241616249084, Validation Accuracy: 0.475\n",
      "Epoch 4828, Training Loss: 0.17401750914512143, Validation Loss: 0.17321859697500866, Validation Accuracy: 0.5125\n",
      "Epoch 4829, Training Loss: 0.1739002235474125, Validation Loss: 0.17364029387633007, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 4830, Training Loss: 0.17417089304616373, Validation Loss: 0.17298464675744374, Validation Accuracy: 0.5375\n",
      "Epoch 4831, Training Loss: 0.17387374995216245, Validation Loss: 0.1735920051733653, Validation Accuracy: 0.4875\n",
      "Epoch 4832, Training Loss: 0.17416968268732871, Validation Loss: 0.17341488103071848, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 4833, Training Loss: 0.1737698326187749, Validation Loss: 0.17382239898045856, Validation Accuracy: 0.475\n",
      "Epoch 4834, Training Loss: 0.17417473946848222, Validation Loss: 0.1727730244398117, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 4835, Training Loss: 0.1739333204684719, Validation Loss: 0.17392431497573851, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 4836, Training Loss: 0.17377634442621662, Validation Loss: 0.17399615744749705, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4837, Training Loss: 0.1739109283493411, Validation Loss: 0.17390392820040385, Validation Accuracy: 0.4875\n",
      "Epoch 4838, Training Loss: 0.17425830325772684, Validation Loss: 0.17301530142625174, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 4839, Training Loss: 0.17378345612556703, Validation Loss: 0.17365963757038116, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 4840, Training Loss: 0.17423651439528312, Validation Loss: 0.1734186589717865, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4841, Training Loss: 0.17366820429601976, Validation Loss: 0.17379121681054432, Validation Accuracy: 0.49375\n",
      "Epoch 4842, Training Loss: 0.174328621356718, Validation Loss: 0.17328532934188842, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 4843, Training Loss: 0.17382403679432407, Validation Loss: 0.1733188529809316, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 4844, Training Loss: 0.17421154293321794, Validation Loss: 0.1734497606754303, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 4845, Training Loss: 0.17374488134537974, Validation Loss: 0.17325898508230844, Validation Accuracy: 0.5125\n",
      "Epoch 4846, Training Loss: 0.17401112471857377, Validation Loss: 0.17371240854263306, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 4847, Training Loss: 0.17391135375345906, Validation Loss: 0.172917244831721, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 4848, Training Loss: 0.17423071303675253, Validation Loss: 0.1734630634387334, Validation Accuracy: 0.48125\n",
      "Epoch 4849, Training Loss: 0.17363904608834174, Validation Loss: 0.173471666375796, Validation Accuracy: 0.50625\n",
      "Epoch 4850, Training Loss: 0.17437536581870047, Validation Loss: 0.1735240360101064, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 4851, Training Loss: 0.17370983525629966, Validation Loss: 0.17220197816689808, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 4852, Training Loss: 0.17425166070461273, Validation Loss: 0.17359623908996583, Validation Accuracy: 0.475\n",
      "Epoch 4853, Training Loss: 0.17368374572646234, Validation Loss: 0.17328360676765442, Validation Accuracy: 0.5125\n",
      "Epoch 4854, Training Loss: 0.17436747829760274, Validation Loss: 0.17343136767546335, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 4855, Training Loss: 0.17365433804450497, Validation Loss: 0.17275720834732056, Validation Accuracy: 0.5375\n",
      "Epoch 4856, Training Loss: 0.17429035709750268, Validation Loss: 0.1734221398830414, Validation Accuracy: 0.4875\n",
      "Epoch 4857, Training Loss: 0.17362479336800113, Validation Loss: 0.1738921582698822, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 4858, Training Loss: 0.17441943816600308, Validation Loss: 0.1734384834766388, Validation Accuracy: 0.475\n",
      "Epoch 4859, Training Loss: 0.17365590266643033, Validation Loss: 0.17184537748495737, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 4860, Training Loss: 0.1742411241416008, Validation Loss: 0.1736483206351598, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 4861, Training Loss: 0.17372713934990666, Validation Loss: 0.17386045257250468, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4862, Training Loss: 0.17434584902178857, Validation Loss: 0.1733741730451584, Validation Accuracy: 0.4875\n",
      "Epoch 4863, Training Loss: 0.173738504609754, Validation Loss: 0.17274016340573628, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 4864, Training Loss: 0.17428962742128679, Validation Loss: 0.17333545287450156, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 4865, Training Loss: 0.17366639019981508, Validation Loss: 0.17374665041764578, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4866, Training Loss: 0.17439960472045407, Validation Loss: 0.17336146434148153, Validation Accuracy: 0.49375\n",
      "Epoch 4867, Training Loss: 0.17375409603118896, Validation Loss: 0.17389612197875975, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 4868, Training Loss: 0.1742115967696713, Validation Loss: 0.17325990001360575, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 4869, Training Loss: 0.1736165265883169, Validation Loss: 0.1743300000826518, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 4870, Training Loss: 0.17423384035787276, Validation Loss: 0.1732807755470276, Validation Accuracy: 0.5125\n",
      "Epoch 4871, Training Loss: 0.173792774638822, Validation Loss: 0.1737384617328644, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 4872, Training Loss: 0.1740007164978212, Validation Loss: 0.173216046889623, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 4873, Training Loss: 0.17371472572126695, Validation Loss: 0.17444773614406586, Validation Accuracy: 0.48125\n",
      "Epoch 4874, Training Loss: 0.1744175591776448, Validation Loss: 0.17326989968617756, Validation Accuracy: 0.50625\n",
      "Epoch 4875, Training Loss: 0.17355212376963708, Validation Loss: 0.1750704675912857, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 4876, Training Loss: 0.17397520859395305, Validation Loss: 0.17314859529336293, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 4877, Training Loss: 0.17362175497316545, Validation Loss: 0.17463087439537048, Validation Accuracy: 0.475\n",
      "Epoch 4878, Training Loss: 0.17463573284687534, Validation Loss: 0.1732298751672109, Validation Accuracy: 0.5125\n",
      "Epoch 4879, Training Loss: 0.1734661094604, Validation Loss: 0.17570899824301403, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 4880, Training Loss: 0.1744436530336257, Validation Loss: 0.17283988893032073, Validation Accuracy: 0.5375\n",
      "Epoch 4881, Training Loss: 0.1735348326544608, Validation Loss: 0.17450546622276306, Validation Accuracy: 0.4875\n",
      "Epoch 4882, Training Loss: 0.17458668399241664, Validation Loss: 0.17359887262185414, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 4883, Training Loss: 0.17357483746544008, Validation Loss: 0.17547003626823426, Validation Accuracy: 0.475\n",
      "Epoch 4884, Training Loss: 0.17443197965621948, Validation Loss: 0.17230388621489207, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 4885, Training Loss: 0.17359903310575792, Validation Loss: 0.17554605106512705, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 4886, Training Loss: 0.17441151555507414, Validation Loss: 0.17374624411265055, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4887, Training Loss: 0.1735256189300168, Validation Loss: 0.17499630053838094, Validation Accuracy: 0.4875\n",
      "Epoch 4888, Training Loss: 0.17439464647923747, Validation Loss: 0.17281243999799092, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 4889, Training Loss: 0.17351282267801224, Validation Loss: 0.17474763989448547, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 4890, Training Loss: 0.1744157296995963, Validation Loss: 0.1739517589410146, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4891, Training Loss: 0.17356946679853624, Validation Loss: 0.1747203141450882, Validation Accuracy: 0.49375\n",
      "Epoch 4892, Training Loss: 0.17436089150367245, Validation Loss: 0.17371719380219777, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 4893, Training Loss: 0.1736149759061875, Validation Loss: 0.17397572994232177, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 4894, Training Loss: 0.1743105121197239, Validation Loss: 0.17448994517326355, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 4895, Training Loss: 0.1735873640544953, Validation Loss: 0.17378746271133422, Validation Accuracy: 0.5125\n",
      "Epoch 4896, Training Loss: 0.17431382402296988, Validation Loss: 0.1746973474820455, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 4897, Training Loss: 0.17376527046003648, Validation Loss: 0.17303053736686708, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 4898, Training Loss: 0.174295739781472, Validation Loss: 0.17499865690867106, Validation Accuracy: 0.48125\n",
      "Epoch 4899, Training Loss: 0.17359914702753867, Validation Loss: 0.17391104300816854, Validation Accuracy: 0.50625\n",
      "Epoch 4900, Training Loss: 0.1744724564975308, Validation Loss: 0.1753793478012085, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 4901, Training Loss: 0.17371560392841215, Validation Loss: 0.17221584518750507, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 4902, Training Loss: 0.17420053337850877, Validation Loss: 0.1756448358297348, Validation Accuracy: 0.475\n",
      "Epoch 4903, Training Loss: 0.17381044837736315, Validation Loss: 0.1735022137562434, Validation Accuracy: 0.5125\n",
      "Epoch 4904, Training Loss: 0.1739632761286151, Validation Loss: 0.17541640996932983, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 4905, Training Loss: 0.17400692499453022, Validation Loss: 0.1726634701093038, Validation Accuracy: 0.5375\n",
      "Epoch 4906, Training Loss: 0.17390875806731562, Validation Loss: 0.1756860703229904, Validation Accuracy: 0.4875\n",
      "Epoch 4907, Training Loss: 0.17398085228858456, Validation Loss: 0.17415888905525206, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 4908, Training Loss: 0.17398011492144677, Validation Loss: 0.17612310647964477, Validation Accuracy: 0.475\n",
      "Epoch 4909, Training Loss: 0.1741009796819379, Validation Loss: 0.1720257471005122, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 4910, Training Loss: 0.1737747956668177, Validation Loss: 0.1770464301109314, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 4911, Training Loss: 0.1742599606513977, Validation Loss: 0.17389905552069346, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4912, Training Loss: 0.17371521745958635, Validation Loss: 0.17533694605032604, Validation Accuracy: 0.4875\n",
      "Epoch 4913, Training Loss: 0.17437375408987846, Validation Loss: 0.1727274258931478, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 4914, Training Loss: 0.17331112680896635, Validation Loss: 0.17601467768351237, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 4915, Training Loss: 0.17472636074789108, Validation Loss: 0.17375370462735493, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4916, Training Loss: 0.17361740095000114, Validation Loss: 0.17535906533400217, Validation Accuracy: 0.49375\n",
      "Epoch 4917, Training Loss: 0.17429059936154273, Validation Loss: 0.173655171195666, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 4918, Training Loss: 0.173661008477211, Validation Loss: 0.17484815617402394, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 4919, Training Loss: 0.17434575048185164, Validation Loss: 0.17394075393676758, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 4920, Training Loss: 0.1738149442019001, Validation Loss: 0.17349138955275217, Validation Accuracy: 0.5125\n",
      "Epoch 4921, Training Loss: 0.1741646893562809, Validation Loss: 0.17467565834522247, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 4922, Training Loss: 0.1736033332924689, Validation Loss: 0.17345080375671387, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 4923, Training Loss: 0.17432355063576851, Validation Loss: 0.1739328036705653, Validation Accuracy: 0.48125\n",
      "Epoch 4924, Training Loss: 0.17381830321204278, Validation Loss: 0.17362368901570638, Validation Accuracy: 0.50625\n",
      "Epoch 4925, Training Loss: 0.17412559351613444, Validation Loss: 0.17493825356165568, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 4926, Training Loss: 0.17365090548992157, Validation Loss: 0.17209920585155486, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 4927, Training Loss: 0.17435811171608587, Validation Loss: 0.17394430935382843, Validation Accuracy: 0.475\n",
      "Epoch 4928, Training Loss: 0.17381791770458221, Validation Loss: 0.17343579332033793, Validation Accuracy: 0.5125\n",
      "Epoch 4929, Training Loss: 0.17421368629701675, Validation Loss: 0.17455681065718334, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 4930, Training Loss: 0.1736303755352574, Validation Loss: 0.17281587421894073, Validation Accuracy: 0.5375\n",
      "Epoch 4931, Training Loss: 0.17440822528254601, Validation Loss: 0.17359375655651094, Validation Accuracy: 0.4875\n",
      "Epoch 4932, Training Loss: 0.17379870001346834, Validation Loss: 0.17407417098681133, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 4933, Training Loss: 0.17418173628468667, Validation Loss: 0.17429228027661642, Validation Accuracy: 0.475\n",
      "Epoch 4934, Training Loss: 0.17373656313265523, Validation Loss: 0.17175958255926768, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 4935, Training Loss: 0.1742940862332621, Validation Loss: 0.17390167713165283, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 4936, Training Loss: 0.1738739311695099, Validation Loss: 0.173742413520813, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4937, Training Loss: 0.17411352934375887, Validation Loss: 0.17385038534800212, Validation Accuracy: 0.4875\n",
      "Epoch 4938, Training Loss: 0.17384273775162234, Validation Loss: 0.17286835312843324, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 4939, Training Loss: 0.17424501863218123, Validation Loss: 0.173433052500089, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 4940, Training Loss: 0.17390194102641074, Validation Loss: 0.17346054911613465, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4941, Training Loss: 0.1740563199404747, Validation Loss: 0.17372675637404125, Validation Accuracy: 0.49375\n",
      "Epoch 4942, Training Loss: 0.17386059799501974, Validation Loss: 0.17334021826585133, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 4943, Training Loss: 0.17419083512598468, Validation Loss: 0.17326354384422302, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 4944, Training Loss: 0.17394346479446657, Validation Loss: 0.17345483899116515, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 4945, Training Loss: 0.17397424819007998, Validation Loss: 0.17324479818344116, Validation Accuracy: 0.5125\n",
      "Epoch 4946, Training Loss: 0.17396157162804757, Validation Loss: 0.17352284987767538, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 4947, Training Loss: 0.17411913458378084, Validation Loss: 0.17303547859191895, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 4948, Training Loss: 0.17399720895674922, Validation Loss: 0.1735146164894104, Validation Accuracy: 0.48125\n",
      "Epoch 4949, Training Loss: 0.17396810843098548, Validation Loss: 0.17335225244363148, Validation Accuracy: 0.50625\n",
      "Epoch 4950, Training Loss: 0.17398098832176578, Validation Loss: 0.1736398329337438, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 4951, Training Loss: 0.1740695632273151, Validation Loss: 0.17277154624462127, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 4952, Training Loss: 0.17396080734268313, Validation Loss: 0.17349838614463806, Validation Accuracy: 0.475\n",
      "Epoch 4953, Training Loss: 0.1740462597339384, Validation Loss: 0.1732174813747406, Validation Accuracy: 0.5125\n",
      "Epoch 4954, Training Loss: 0.1738812159146032, Validation Loss: 0.1737515926361084, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 4955, Training Loss: 0.17416369482394187, Validation Loss: 0.1730364292860031, Validation Accuracy: 0.5375\n",
      "Epoch 4956, Training Loss: 0.17388883521479945, Validation Loss: 0.1735568106174469, Validation Accuracy: 0.4875\n",
      "Epoch 4957, Training Loss: 0.174015321077839, Validation Loss: 0.17356727123260499, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 4958, Training Loss: 0.1738455045607782, Validation Loss: 0.1740734914938609, Validation Accuracy: 0.475\n",
      "Epoch 4959, Training Loss: 0.1742128119353325, Validation Loss: 0.17286394437154134, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 4960, Training Loss: 0.17390054560476734, Validation Loss: 0.17415741284688313, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 4961, Training Loss: 0.17403730846220447, Validation Loss: 0.17348934809366862, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4962, Training Loss: 0.17380166774795902, Validation Loss: 0.1737957994143168, Validation Accuracy: 0.4875\n",
      "Epoch 4963, Training Loss: 0.17426121619439894, Validation Loss: 0.17308224141597747, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 4964, Training Loss: 0.1737683189492072, Validation Loss: 0.17368129293123882, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 4965, Training Loss: 0.17407881636773387, Validation Loss: 0.17371730208396913, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4966, Training Loss: 0.1737173790893247, Validation Loss: 0.1739140103260676, Validation Accuracy: 0.49375\n",
      "Epoch 4967, Training Loss: 0.17433526775529307, Validation Loss: 0.17328984439373016, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 4968, Training Loss: 0.17387899468022008, Validation Loss: 0.17339899043242138, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 4969, Training Loss: 0.17410237846835966, Validation Loss: 0.1735614021619161, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 4970, Training Loss: 0.17374272596451543, Validation Loss: 0.17328399618466694, Validation Accuracy: 0.5125\n",
      "Epoch 4971, Training Loss: 0.17429505817351804, Validation Loss: 0.17342220743497214, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 4972, Training Loss: 0.17382122624304988, Validation Loss: 0.17291158835093182, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 4973, Training Loss: 0.1741948598815549, Validation Loss: 0.17346538503964742, Validation Accuracy: 0.48125\n",
      "Epoch 4974, Training Loss: 0.1736620645369253, Validation Loss: 0.17348630726337433, Validation Accuracy: 0.50625\n",
      "Epoch 4975, Training Loss: 0.17434512607512936, Validation Loss: 0.17350856363773345, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 4976, Training Loss: 0.173717301699423, Validation Loss: 0.1722786416610082, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 4977, Training Loss: 0.17429398577059468, Validation Loss: 0.17353685796260834, Validation Accuracy: 0.475\n",
      "Epoch 4978, Training Loss: 0.17369080791550298, Validation Loss: 0.17326348026593527, Validation Accuracy: 0.5125\n",
      "Epoch 4979, Training Loss: 0.17433270715898083, Validation Loss: 0.1734344869852066, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 4980, Training Loss: 0.17372622605293028, Validation Loss: 0.1727520207564036, Validation Accuracy: 0.5375\n",
      "Epoch 4981, Training Loss: 0.17434621722467483, Validation Loss: 0.1734204649925232, Validation Accuracy: 0.4875\n",
      "Epoch 4982, Training Loss: 0.17365333437919617, Validation Loss: 0.174041485786438, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 4983, Training Loss: 0.1743577560109477, Validation Loss: 0.17343226075172424, Validation Accuracy: 0.475\n",
      "Epoch 4984, Training Loss: 0.17366285670188167, Validation Loss: 0.1721181680758794, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 4985, Training Loss: 0.1743593167874121, Validation Loss: 0.17354539334774016, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 4986, Training Loss: 0.17366484095973353, Validation Loss: 0.17399466633796692, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4987, Training Loss: 0.17433159918554367, Validation Loss: 0.17336330115795134, Validation Accuracy: 0.4875\n",
      "Epoch 4988, Training Loss: 0.17372127694468345, Validation Loss: 0.17276326914628345, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 4989, Training Loss: 0.17431836214757734, Validation Loss: 0.17332349121570587, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 4990, Training Loss: 0.1736581253428613, Validation Loss: 0.17371713022391003, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 4991, Training Loss: 0.1743316121639744, Validation Loss: 0.17331767280896504, Validation Accuracy: 0.49375\n",
      "Epoch 4992, Training Loss: 0.17381207644939423, Validation Loss: 0.17359200318654378, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 4993, Training Loss: 0.17427115286550215, Validation Loss: 0.1732578009366989, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 4994, Training Loss: 0.17357807582424534, Validation Loss: 0.1746092180411021, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 4995, Training Loss: 0.17437982511135838, Validation Loss: 0.17325927714506786, Validation Accuracy: 0.5125\n",
      "Epoch 4996, Training Loss: 0.17373133859326761, Validation Loss: 0.17435867786407472, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 4997, Training Loss: 0.17434086722712364, Validation Loss: 0.1730914423863093, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 4998, Training Loss: 0.17359311638339872, Validation Loss: 0.1747458130121231, Validation Accuracy: 0.48125\n",
      "Epoch 4999, Training Loss: 0.17444557191864138, Validation Loss: 0.1732779026031494, Validation Accuracy: 0.50625\n",
      "Epoch 5000, Training Loss: 0.1735099669425718, Validation Loss: 0.17555871307849885, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 5001, Training Loss: 0.17440142698826328, Validation Loss: 0.1731620063384374, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 5002, Training Loss: 0.1735355906909512, Validation Loss: 0.17517587741216023, Validation Accuracy: 0.475\n",
      "Epoch 5003, Training Loss: 0.1745214303655009, Validation Loss: 0.17321873009204863, Validation Accuracy: 0.5125\n",
      "Epoch 5004, Training Loss: 0.17345787007962504, Validation Loss: 0.1757628430922826, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 5005, Training Loss: 0.17446080715425552, Validation Loss: 0.17287729879220326, Validation Accuracy: 0.5375\n",
      "Epoch 5006, Training Loss: 0.173513971509472, Validation Loss: 0.17443069517612458, Validation Accuracy: 0.4875\n",
      "Epoch 5007, Training Loss: 0.1745760162030497, Validation Loss: 0.17359744211037953, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 5008, Training Loss: 0.17357435101462948, Validation Loss: 0.1755262146393458, Validation Accuracy: 0.475\n",
      "Epoch 5009, Training Loss: 0.17439513004595233, Validation Loss: 0.17222825884819032, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 5010, Training Loss: 0.1736209358899824, Validation Loss: 0.1753797709941864, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 5011, Training Loss: 0.17439955088400072, Validation Loss: 0.17373917400836944, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5012, Training Loss: 0.1735369933228339, Validation Loss: 0.1750476539134979, Validation Accuracy: 0.4875\n",
      "Epoch 5013, Training Loss: 0.17433476255786035, Validation Loss: 0.1727385660012563, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 5014, Training Loss: 0.17358362482440087, Validation Loss: 0.17454790969689687, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 5015, Training Loss: 0.1743855111060604, Validation Loss: 0.1739032030105591, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5016, Training Loss: 0.17357808159243676, Validation Loss: 0.1748496582110723, Validation Accuracy: 0.49375\n",
      "Epoch 5017, Training Loss: 0.17439901251946727, Validation Loss: 0.17363264362017314, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 5018, Training Loss: 0.17353164524801315, Validation Loss: 0.17404769361019135, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 5019, Training Loss: 0.17432412841627676, Validation Loss: 0.1745317796866099, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 5020, Training Loss: 0.17359765306595834, Validation Loss: 0.1737081547578176, Validation Accuracy: 0.5125\n",
      "Epoch 5021, Training Loss: 0.17440031997619138, Validation Loss: 0.1748112142086029, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 5022, Training Loss: 0.17372435331344604, Validation Loss: 0.17302715082963308, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 5023, Training Loss: 0.17432459467841732, Validation Loss: 0.17496626277764638, Validation Accuracy: 0.48125\n",
      "Epoch 5024, Training Loss: 0.17358442035413557, Validation Loss: 0.17385052839914958, Validation Accuracy: 0.50625\n",
      "Epoch 5025, Training Loss: 0.17439495363543112, Validation Loss: 0.173921928803126, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 5026, Training Loss: 0.17361968226971164, Validation Loss: 0.17254699965318043, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 5027, Training Loss: 0.17428163318864762, Validation Loss: 0.17561680674552918, Validation Accuracy: 0.475\n",
      "Epoch 5028, Training Loss: 0.17375614614255966, Validation Loss: 0.17347667415936788, Validation Accuracy: 0.5125\n",
      "Epoch 5029, Training Loss: 0.1740047590386483, Validation Loss: 0.17598473230997722, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 5030, Training Loss: 0.1739480048418045, Validation Loss: 0.17266263961791992, Validation Accuracy: 0.5375\n",
      "Epoch 5031, Training Loss: 0.17394024998910965, Validation Loss: 0.17575692236423493, Validation Accuracy: 0.4875\n",
      "Epoch 5032, Training Loss: 0.17391379658252962, Validation Loss: 0.17406890491644542, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 5033, Training Loss: 0.1739818799880243, Validation Loss: 0.1753613849480947, Validation Accuracy: 0.475\n",
      "Epoch 5034, Training Loss: 0.17408558774378993, Validation Loss: 0.1719113101561864, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 5035, Training Loss: 0.17379595819980867, Validation Loss: 0.17694687247276306, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 5036, Training Loss: 0.1742154465567681, Validation Loss: 0.17392998933792114, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5037, Training Loss: 0.17372505511007003, Validation Loss: 0.17520985802014669, Validation Accuracy: 0.4875\n",
      "Epoch 5038, Training Loss: 0.17438123831825872, Validation Loss: 0.17273658414681753, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 5039, Training Loss: 0.17351310676144016, Validation Loss: 0.17459548513094583, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 5040, Training Loss: 0.17456604780689364, Validation Loss: 0.17399597863356273, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5041, Training Loss: 0.17359668593252858, Validation Loss: 0.17442467510700227, Validation Accuracy: 0.49375\n",
      "Epoch 5042, Training Loss: 0.1742769580694937, Validation Loss: 0.17369533578554788, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 5043, Training Loss: 0.17363961858134117, Validation Loss: 0.17462563018004099, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 5044, Training Loss: 0.17437727989688998, Validation Loss: 0.17392409940560657, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 5045, Training Loss: 0.17381293975537823, Validation Loss: 0.1735465298096339, Validation Accuracy: 0.5125\n",
      "Epoch 5046, Training Loss: 0.17418511115735577, Validation Loss: 0.1745027184486389, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 5047, Training Loss: 0.1736527705384839, Validation Loss: 0.17333501776059468, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 5048, Training Loss: 0.1742994842990752, Validation Loss: 0.17395794490973154, Validation Accuracy: 0.48125\n",
      "Epoch 5049, Training Loss: 0.1737278872920621, Validation Loss: 0.1741172214349111, Validation Accuracy: 0.50625\n",
      "Epoch 5050, Training Loss: 0.17420428606771654, Validation Loss: 0.17477073272069296, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 5051, Training Loss: 0.1736659696025233, Validation Loss: 0.1720954845348994, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 5052, Training Loss: 0.17439553622276552, Validation Loss: 0.17397187054157257, Validation Accuracy: 0.475\n",
      "Epoch 5053, Training Loss: 0.1738106435345065, Validation Loss: 0.17353307008743285, Validation Accuracy: 0.5125\n",
      "Epoch 5054, Training Loss: 0.1742084886758558, Validation Loss: 0.17465664446353912, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 5055, Training Loss: 0.17357348770864547, Validation Loss: 0.17290182411670685, Validation Accuracy: 0.5375\n",
      "Epoch 5056, Training Loss: 0.17447103848380427, Validation Loss: 0.1736099640528361, Validation Accuracy: 0.4875\n",
      "Epoch 5057, Training Loss: 0.17375501605772203, Validation Loss: 0.17474173704783122, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 5058, Training Loss: 0.17428068912798358, Validation Loss: 0.17403626640637715, Validation Accuracy: 0.475\n",
      "Epoch 5059, Training Loss: 0.17369543112093402, Validation Loss: 0.171818279226621, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 5060, Training Loss: 0.17427647258004836, Validation Loss: 0.17403625547885895, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 5061, Training Loss: 0.173874776690237, Validation Loss: 0.17392094930013022, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5062, Training Loss: 0.17419449312071647, Validation Loss: 0.1737136423587799, Validation Accuracy: 0.4875\n",
      "Epoch 5063, Training Loss: 0.1738230658154334, Validation Loss: 0.17282932698726655, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 5064, Training Loss: 0.1742344416918293, Validation Loss: 0.173447318871816, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 5065, Training Loss: 0.17386840956826363, Validation Loss: 0.17352350950241088, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5066, Training Loss: 0.1741585058550681, Validation Loss: 0.17354661226272583, Validation Accuracy: 0.49375\n",
      "Epoch 5067, Training Loss: 0.17382605133518095, Validation Loss: 0.17331749896208445, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 5068, Training Loss: 0.17418977570149205, Validation Loss: 0.17326576213041942, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 5069, Training Loss: 0.1739307690051294, Validation Loss: 0.17348002195358275, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 5070, Training Loss: 0.17403898412181484, Validation Loss: 0.17322346170743305, Validation Accuracy: 0.5125\n",
      "Epoch 5071, Training Loss: 0.17391094132777182, Validation Loss: 0.17348476747671762, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 5072, Training Loss: 0.17409624495813925, Validation Loss: 0.1730095426241557, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 5073, Training Loss: 0.17400017380714417, Validation Loss: 0.17353489597638447, Validation Accuracy: 0.48125\n",
      "Epoch 5074, Training Loss: 0.17405274270042295, Validation Loss: 0.17330547471841176, Validation Accuracy: 0.50625\n",
      "Epoch 5075, Training Loss: 0.17390130652535346, Validation Loss: 0.17358027895291647, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 5076, Training Loss: 0.1741747942663008, Validation Loss: 0.17285042305787404, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 5077, Training Loss: 0.1738935737840591, Validation Loss: 0.17366870443026225, Validation Accuracy: 0.475\n",
      "Epoch 5078, Training Loss: 0.17413325655844905, Validation Loss: 0.17321935097376506, Validation Accuracy: 0.5125\n",
      "Epoch 5079, Training Loss: 0.17383288664202537, Validation Loss: 0.1736451913913091, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 5080, Training Loss: 0.1741573719247695, Validation Loss: 0.17296983699003857, Validation Accuracy: 0.5375\n",
      "Epoch 5081, Training Loss: 0.1739201146748758, Validation Loss: 0.17355893353621166, Validation Accuracy: 0.4875\n",
      "Epoch 5082, Training Loss: 0.1741266255417178, Validation Loss: 0.17345116039117178, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 5083, Training Loss: 0.17380567135349398, Validation Loss: 0.17375460068384807, Validation Accuracy: 0.475\n",
      "Epoch 5084, Training Loss: 0.17423060344111535, Validation Loss: 0.17282633284727733, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 5085, Training Loss: 0.17382693915597855, Validation Loss: 0.1740044246117274, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 5086, Training Loss: 0.1740863279950234, Validation Loss: 0.17345741987228394, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5087, Training Loss: 0.17379333703748642, Validation Loss: 0.17388655742009482, Validation Accuracy: 0.4875\n",
      "Epoch 5088, Training Loss: 0.17428000559729914, Validation Loss: 0.17308710118134815, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 5089, Training Loss: 0.17375627929164517, Validation Loss: 0.1738294134537379, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 5090, Training Loss: 0.1742077883212797, Validation Loss: 0.17348748842875164, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5091, Training Loss: 0.17367447287805618, Validation Loss: 0.1737232466538747, Validation Accuracy: 0.49375\n",
      "Epoch 5092, Training Loss: 0.17434641334318346, Validation Loss: 0.17328192293643951, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 5093, Training Loss: 0.1738391879104799, Validation Loss: 0.17336001296838124, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 5094, Training Loss: 0.1741442911086544, Validation Loss: 0.1735016405582428, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 5095, Training Loss: 0.17375398355145608, Validation Loss: 0.17326241532961528, Validation Accuracy: 0.5125\n",
      "Epoch 5096, Training Loss: 0.17420113471246534, Validation Loss: 0.17347366213798524, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 5097, Training Loss: 0.17392198501094694, Validation Loss: 0.17290978332360585, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 5098, Training Loss: 0.17390432280878867, Validation Loss: 0.17397827903429666, Validation Accuracy: 0.48125\n",
      "Epoch 5099, Training Loss: 0.17374787215263612, Validation Loss: 0.17362960974375408, Validation Accuracy: 0.50625\n",
      "Epoch 5100, Training Loss: 0.17433818549879135, Validation Loss: 0.17360036770502726, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 5101, Training Loss: 0.1737564907919976, Validation Loss: 0.17225392361481984, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 5102, Training Loss: 0.17425474764839297, Validation Loss: 0.17357771694660187, Validation Accuracy: 0.475\n",
      "Epoch 5103, Training Loss: 0.17366608929249547, Validation Loss: 0.17327268222967784, Validation Accuracy: 0.5125\n",
      "Epoch 5104, Training Loss: 0.17439004202042857, Validation Loss: 0.173448650042216, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 5105, Training Loss: 0.1736770079981896, Validation Loss: 0.172683917482694, Validation Accuracy: 0.5375\n",
      "Epoch 5106, Training Loss: 0.17432810029675883, Validation Loss: 0.1734192838271459, Validation Accuracy: 0.4875\n",
      "Epoch 5107, Training Loss: 0.17365979956042382, Validation Loss: 0.17384144465128581, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 5108, Training Loss: 0.17440127076641207, Validation Loss: 0.17340199649333954, Validation Accuracy: 0.475\n",
      "Epoch 5109, Training Loss: 0.17363530493551685, Validation Loss: 0.17224780817826588, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 5110, Training Loss: 0.17407145086796053, Validation Loss: 0.17389459311962127, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 5111, Training Loss: 0.17371512709125395, Validation Loss: 0.1738367180029551, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5112, Training Loss: 0.1743595004081726, Validation Loss: 0.17332481741905212, Validation Accuracy: 0.4875\n",
      "Epoch 5113, Training Loss: 0.17375080383593036, Validation Loss: 0.17277113497257232, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 5114, Training Loss: 0.17395841642733542, Validation Loss: 0.17341719170411427, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 5115, Training Loss: 0.17371984883662192, Validation Loss: 0.17382648487885793, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5116, Training Loss: 0.17453117187946074, Validation Loss: 0.17335160672664643, Validation Accuracy: 0.49375\n",
      "Epoch 5117, Training Loss: 0.17377194137342514, Validation Loss: 0.1738934983809789, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 5118, Training Loss: 0.17420393997623074, Validation Loss: 0.17325584093729654, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 5119, Training Loss: 0.17361417941508756, Validation Loss: 0.17427023152510326, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 5120, Training Loss: 0.17445136077942386, Validation Loss: 0.17323362032572429, Validation Accuracy: 0.5125\n",
      "Epoch 5121, Training Loss: 0.17365841567516327, Validation Loss: 0.1745474934577942, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 5122, Training Loss: 0.17436888141016807, Validation Loss: 0.17305547495683035, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 5123, Training Loss: 0.17359892254875553, Validation Loss: 0.1749204397201538, Validation Accuracy: 0.48125\n",
      "Epoch 5124, Training Loss: 0.17436843677874533, Validation Loss: 0.1732698192199071, Validation Accuracy: 0.50625\n",
      "Epoch 5125, Training Loss: 0.17358783272004896, Validation Loss: 0.17570078472296397, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 5126, Training Loss: 0.17450090281424985, Validation Loss: 0.1727256993452708, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 5127, Training Loss: 0.17346463232271134, Validation Loss: 0.17525923252105713, Validation Accuracy: 0.475\n",
      "Epoch 5128, Training Loss: 0.1745342251754576, Validation Loss: 0.1732171873251597, Validation Accuracy: 0.5125\n",
      "Epoch 5129, Training Loss: 0.17346041433272824, Validation Loss: 0.17570376098155976, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 5130, Training Loss: 0.17450070429232814, Validation Loss: 0.17282022535800934, Validation Accuracy: 0.5375\n",
      "Epoch 5131, Training Loss: 0.17348378367962375, Validation Loss: 0.17478940387566885, Validation Accuracy: 0.4875\n",
      "Epoch 5132, Training Loss: 0.17457388149153802, Validation Loss: 0.17355764110883076, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 5133, Training Loss: 0.17357796767065603, Validation Loss: 0.17555491328239442, Validation Accuracy: 0.475\n",
      "Epoch 5134, Training Loss: 0.17432461919323092, Validation Loss: 0.17221397956212361, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 5135, Training Loss: 0.17365628048296897, Validation Loss: 0.17531634171803792, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 5136, Training Loss: 0.1743923565072398, Validation Loss: 0.1737379550933838, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5137, Training Loss: 0.17354436699421175, Validation Loss: 0.17499189972877502, Validation Accuracy: 0.4875\n",
      "Epoch 5138, Training Loss: 0.17439171768003894, Validation Loss: 0.172859525680542, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 5139, Training Loss: 0.17348790649444826, Validation Loss: 0.1745155582825343, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 5140, Training Loss: 0.17444763212434708, Validation Loss: 0.17388906478881835, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5141, Training Loss: 0.1735441242494891, Validation Loss: 0.1746687243382136, Validation Accuracy: 0.49375\n",
      "Epoch 5142, Training Loss: 0.17441048977836485, Validation Loss: 0.17371587852636974, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 5143, Training Loss: 0.17358820717180928, Validation Loss: 0.17399543523788452, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 5144, Training Loss: 0.17427675618279365, Validation Loss: 0.17453552981217701, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 5145, Training Loss: 0.1736117947486139, Validation Loss: 0.17379174133141836, Validation Accuracy: 0.5125\n",
      "Epoch 5146, Training Loss: 0.17439259156104056, Validation Loss: 0.1737604727347692, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 5147, Training Loss: 0.1736382923779949, Validation Loss: 0.17291167875130972, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 5148, Training Loss: 0.17420072036404763, Validation Loss: 0.17494111657142639, Validation Accuracy: 0.48125\n",
      "Epoch 5149, Training Loss: 0.17361113861683877, Validation Loss: 0.17397691110769908, Validation Accuracy: 0.50625\n",
      "Epoch 5150, Training Loss: 0.17440160772492808, Validation Loss: 0.17524949312210084, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 5151, Training Loss: 0.17375488915751058, Validation Loss: 0.17231973508993784, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 5152, Training Loss: 0.17426554233797134, Validation Loss: 0.17583467562993368, Validation Accuracy: 0.475\n",
      "Epoch 5153, Training Loss: 0.1737746500199841, Validation Loss: 0.17345262169837952, Validation Accuracy: 0.5125\n",
      "Epoch 5154, Training Loss: 0.17403277129896225, Validation Loss: 0.1761724591255188, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 5155, Training Loss: 0.1739803009456204, Validation Loss: 0.17266187965869903, Validation Accuracy: 0.5375\n",
      "Epoch 5156, Training Loss: 0.17388005554676056, Validation Loss: 0.1757569839557012, Validation Accuracy: 0.4875\n",
      "Epoch 5157, Training Loss: 0.17400407310455077, Validation Loss: 0.17415319681167601, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 5158, Training Loss: 0.17397918672330917, Validation Loss: 0.17633052865664164, Validation Accuracy: 0.475\n",
      "Epoch 5159, Training Loss: 0.17407037365821101, Validation Loss: 0.1720426271359126, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 5160, Training Loss: 0.17379619854111825, Validation Loss: 0.1770298421382904, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 5161, Training Loss: 0.17420938995576674, Validation Loss: 0.17383916477362316, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5162, Training Loss: 0.17376873618172062, Validation Loss: 0.17483378052711487, Validation Accuracy: 0.4875\n",
      "Epoch 5163, Training Loss: 0.1743556155312446, Validation Loss: 0.1727294147014618, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 5164, Training Loss: 0.1733714423833355, Validation Loss: 0.17562921742598217, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 5165, Training Loss: 0.1746553115306362, Validation Loss: 0.17369681596755981, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5166, Training Loss: 0.17362939253930124, Validation Loss: 0.1750976065794627, Validation Accuracy: 0.49375\n",
      "Epoch 5167, Training Loss: 0.1743440608824453, Validation Loss: 0.17359931568304698, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 5168, Training Loss: 0.17362452755051275, Validation Loss: 0.1746401906013489, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 5169, Training Loss: 0.17439378076984036, Validation Loss: 0.1739352325598399, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 5170, Training Loss: 0.17377129437461977, Validation Loss: 0.17380106449127197, Validation Accuracy: 0.5125\n",
      "Epoch 5171, Training Loss: 0.17424142889438138, Validation Loss: 0.17431937654813132, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 5172, Training Loss: 0.17361571856083408, Validation Loss: 0.17318653762340547, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 5173, Training Loss: 0.17430656715746848, Validation Loss: 0.17402525345484415, Validation Accuracy: 0.48125\n",
      "Epoch 5174, Training Loss: 0.17379724546786277, Validation Loss: 0.1737517386674881, Validation Accuracy: 0.50625\n",
      "Epoch 5175, Training Loss: 0.1741795539855957, Validation Loss: 0.17476173639297485, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 5176, Training Loss: 0.1736785831951326, Validation Loss: 0.17207518815994263, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 5177, Training Loss: 0.17436112992225156, Validation Loss: 0.1739929070075353, Validation Accuracy: 0.475\n",
      "Epoch 5178, Training Loss: 0.17384343233800703, Validation Loss: 0.1734050581852595, Validation Accuracy: 0.5125\n",
      "Epoch 5179, Training Loss: 0.1741766482591629, Validation Loss: 0.17452694475650787, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 5180, Training Loss: 0.1736386432763069, Validation Loss: 0.17270865241686503, Validation Accuracy: 0.5375\n",
      "Epoch 5181, Training Loss: 0.17438309615658176, Validation Loss: 0.17366212010383605, Validation Accuracy: 0.4875\n",
      "Epoch 5182, Training Loss: 0.17376568576981943, Validation Loss: 0.17445422212282816, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 5183, Training Loss: 0.17401000328602328, Validation Loss: 0.17494647800922394, Validation Accuracy: 0.475\n",
      "Epoch 5184, Training Loss: 0.17376335686252964, Validation Loss: 0.17173303961753844, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 5185, Training Loss: 0.17426466509219138, Validation Loss: 0.17391059398651124, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 5186, Training Loss: 0.17379337308868284, Validation Loss: 0.17417855858802794, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5187, Training Loss: 0.1740363807447495, Validation Loss: 0.17425401310125987, Validation Accuracy: 0.4875\n",
      "Epoch 5188, Training Loss: 0.173862129930527, Validation Loss: 0.17288483281930286, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 5189, Training Loss: 0.17430459059053852, Validation Loss: 0.17340925733248394, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 5190, Training Loss: 0.17394791399278947, Validation Loss: 0.1736128826936086, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5191, Training Loss: 0.17397363099359697, Validation Loss: 0.1737999459107717, Validation Accuracy: 0.49375\n",
      "Epoch 5192, Training Loss: 0.17386904647273402, Validation Loss: 0.17330850660800934, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 5193, Training Loss: 0.1741776144312274, Validation Loss: 0.1732674092054367, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 5194, Training Loss: 0.17399520979773614, Validation Loss: 0.17346056699752807, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 5195, Training Loss: 0.17391110235644924, Validation Loss: 0.17325808405876159, Validation Accuracy: 0.5125\n",
      "Epoch 5196, Training Loss: 0.1739506793598975, Validation Loss: 0.17350691358248393, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 5197, Training Loss: 0.1741228747752405, Validation Loss: 0.17305129567782085, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 5198, Training Loss: 0.17402898928811472, Validation Loss: 0.1735259344180425, Validation Accuracy: 0.48125\n",
      "Epoch 5199, Training Loss: 0.1737240937448317, Validation Loss: 0.1736889511346817, Validation Accuracy: 0.50625\n",
      "Epoch 5200, Training Loss: 0.1740526052251939, Validation Loss: 0.17358887592951458, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 5201, Training Loss: 0.17414732181256817, Validation Loss: 0.17285722196102143, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 5202, Training Loss: 0.17404267191886902, Validation Loss: 0.1739247351884842, Validation Accuracy: 0.475\n",
      "Epoch 5203, Training Loss: 0.1739282420566005, Validation Loss: 0.17323060631752013, Validation Accuracy: 0.5125\n",
      "Epoch 5204, Training Loss: 0.17390302784981265, Validation Loss: 0.17369730571905773, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 5205, Training Loss: 0.17417493510630824, Validation Loss: 0.17301540672779084, Validation Accuracy: 0.5375\n",
      "Epoch 5206, Training Loss: 0.17390566775875707, Validation Loss: 0.1735651562611262, Validation Accuracy: 0.4875\n",
      "Epoch 5207, Training Loss: 0.17407649707409642, Validation Loss: 0.17348272601763406, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 5208, Training Loss: 0.17385005470245116, Validation Loss: 0.17385928432146708, Validation Accuracy: 0.475\n",
      "Epoch 5209, Training Loss: 0.17421838112415805, Validation Loss: 0.1728456070025762, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 5210, Training Loss: 0.17389573829789315, Validation Loss: 0.17408569852511088, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 5211, Training Loss: 0.1740519183297311, Validation Loss: 0.17348348299662272, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5212, Training Loss: 0.17379269580687245, Validation Loss: 0.1738979438940684, Validation Accuracy: 0.4875\n",
      "Epoch 5213, Training Loss: 0.17428126306303085, Validation Loss: 0.17307051320870717, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 5214, Training Loss: 0.17371823182029109, Validation Loss: 0.17365223268667856, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 5215, Training Loss: 0.17432772488363327, Validation Loss: 0.17338196337223052, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5216, Training Loss: 0.17368775077404514, Validation Loss: 0.17362586955229442, Validation Accuracy: 0.49375\n",
      "Epoch 5217, Training Loss: 0.17432541328091775, Validation Loss: 0.1732818901538849, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 5218, Training Loss: 0.1738328092521237, Validation Loss: 0.17336322565873463, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 5219, Training Loss: 0.17415484449555796, Validation Loss: 0.17349680761496225, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 5220, Training Loss: 0.17375853225108115, Validation Loss: 0.17326373358567557, Validation Accuracy: 0.5125\n",
      "Epoch 5221, Training Loss: 0.17427186475646111, Validation Loss: 0.17343910137812296, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 5222, Training Loss: 0.1737846578321149, Validation Loss: 0.17293214797973633, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 5223, Training Loss: 0.17416981102958803, Validation Loss: 0.17351152996222177, Validation Accuracy: 0.48125\n",
      "Epoch 5224, Training Loss: 0.173662087609691, Validation Loss: 0.17351596554120383, Validation Accuracy: 0.50625\n",
      "Epoch 5225, Training Loss: 0.17429224810292643, Validation Loss: 0.17354523340861003, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 5226, Training Loss: 0.17372277475172473, Validation Loss: 0.17249786257743835, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 5227, Training Loss: 0.1740801267085537, Validation Loss: 0.17386687994003297, Validation Accuracy: 0.475\n",
      "Epoch 5228, Training Loss: 0.17371220886707306, Validation Loss: 0.1733547349770864, Validation Accuracy: 0.5125\n",
      "Epoch 5229, Training Loss: 0.1744520342157733, Validation Loss: 0.17347646256287894, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 5230, Training Loss: 0.1736573077017261, Validation Loss: 0.1726837456226349, Validation Accuracy: 0.5375\n",
      "Epoch 5231, Training Loss: 0.17438737615462271, Validation Loss: 0.17341794073581696, Validation Accuracy: 0.4875\n",
      "Epoch 5232, Training Loss: 0.17365272871909604, Validation Loss: 0.17402454217274985, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 5233, Training Loss: 0.17435492238690775, Validation Loss: 0.17343451182047526, Validation Accuracy: 0.475\n",
      "Epoch 5234, Training Loss: 0.17369104296930374, Validation Loss: 0.17195001443227131, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 5235, Training Loss: 0.1742892390297305, Validation Loss: 0.17353224953015645, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 5236, Training Loss: 0.17368746476788674, Validation Loss: 0.17367148001988728, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5237, Training Loss: 0.17440291133619124, Validation Loss: 0.17334936757882435, Validation Accuracy: 0.4875\n",
      "Epoch 5238, Training Loss: 0.1736597462046531, Validation Loss: 0.17282443443934123, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 5239, Training Loss: 0.1743171186216416, Validation Loss: 0.17332286834716798, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 5240, Training Loss: 0.17366704681227285, Validation Loss: 0.17382276852925618, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5241, Training Loss: 0.17442287696946052, Validation Loss: 0.1733401397864024, Validation Accuracy: 0.49375\n",
      "Epoch 5242, Training Loss: 0.1737202550134351, Validation Loss: 0.17366985678672792, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 5243, Training Loss: 0.17426112678743177, Validation Loss: 0.173260032137235, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 5244, Training Loss: 0.17361747833990282, Validation Loss: 0.17449320356051126, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 5245, Training Loss: 0.1744550759753873, Validation Loss: 0.1732286920150121, Validation Accuracy: 0.5125\n",
      "Epoch 5246, Training Loss: 0.1736716075289634, Validation Loss: 0.17489533623059592, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 5247, Training Loss: 0.17430850094364536, Validation Loss: 0.17310978968938193, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 5248, Training Loss: 0.1735973685018478, Validation Loss: 0.17430688540140787, Validation Accuracy: 0.48125\n",
      "Epoch 5249, Training Loss: 0.17444795466238452, Validation Loss: 0.17328122953573863, Validation Accuracy: 0.50625\n",
      "Epoch 5250, Training Loss: 0.17352535359321103, Validation Loss: 0.17584717273712158, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 5251, Training Loss: 0.17446793856159334, Validation Loss: 0.17288343906402587, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 5252, Training Loss: 0.17349294308693178, Validation Loss: 0.17494288484255474, Validation Accuracy: 0.475\n",
      "Epoch 5253, Training Loss: 0.17448076413523766, Validation Loss: 0.17324384649594624, Validation Accuracy: 0.5125\n",
      "Epoch 5254, Training Loss: 0.17349690727649197, Validation Loss: 0.17577298780282338, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 5255, Training Loss: 0.17442985600040806, Validation Loss: 0.17288791338602702, Validation Accuracy: 0.5375\n",
      "Epoch 5256, Training Loss: 0.17351861346152522, Validation Loss: 0.1745307445526123, Validation Accuracy: 0.4875\n",
      "Epoch 5257, Training Loss: 0.17458161615556286, Validation Loss: 0.17359700600306194, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 5258, Training Loss: 0.17357219659513043, Validation Loss: 0.1755277305841446, Validation Accuracy: 0.475\n",
      "Epoch 5259, Training Loss: 0.1743907731386923, Validation Loss: 0.17222237984339397, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 5260, Training Loss: 0.17362867488015082, Validation Loss: 0.17542791763941448, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 5261, Training Loss: 0.17438751891736062, Validation Loss: 0.17376542290051777, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5262, Training Loss: 0.17353978608885118, Validation Loss: 0.17507782975832623, Validation Accuracy: 0.4875\n",
      "Epoch 5263, Training Loss: 0.1743119873346821, Validation Loss: 0.17274252672990162, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 5264, Training Loss: 0.1735866444726144, Validation Loss: 0.17453665932019552, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 5265, Training Loss: 0.17441791728619607, Validation Loss: 0.1738815168539683, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5266, Training Loss: 0.17354896376209875, Validation Loss: 0.17479003171126048, Validation Accuracy: 0.49375\n",
      "Epoch 5267, Training Loss: 0.17433249085180222, Validation Loss: 0.17337379455566407, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 5268, Training Loss: 0.17359574667869077, Validation Loss: 0.17363059123357136, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 5269, Training Loss: 0.17416285843618454, Validation Loss: 0.17452845374743145, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 5270, Training Loss: 0.17363589761718626, Validation Loss: 0.17389393448829651, Validation Accuracy: 0.5125\n",
      "Epoch 5271, Training Loss: 0.17432248207830614, Validation Loss: 0.17479007343451183, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 5272, Training Loss: 0.1737680709169757, Validation Loss: 0.17303340137004852, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 5273, Training Loss: 0.17430085328317457, Validation Loss: 0.17497289776802064, Validation Accuracy: 0.48125\n",
      "Epoch 5274, Training Loss: 0.17359759298063093, Validation Loss: 0.1738801747560501, Validation Accuracy: 0.50625\n",
      "Epoch 5275, Training Loss: 0.1744300881701131, Validation Loss: 0.17545584440231324, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 5276, Training Loss: 0.17378789234545924, Validation Loss: 0.17215814193089804, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 5277, Training Loss: 0.17425226924880857, Validation Loss: 0.17567855715751649, Validation Accuracy: 0.475\n",
      "Epoch 5278, Training Loss: 0.17380235416273918, Validation Loss: 0.1734860082467397, Validation Accuracy: 0.5125\n",
      "Epoch 5279, Training Loss: 0.17398927769353312, Validation Loss: 0.1758155514796575, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 5280, Training Loss: 0.17400690240244712, Validation Loss: 0.1726614862680435, Validation Accuracy: 0.5375\n",
      "Epoch 5281, Training Loss: 0.17387119800813736, Validation Loss: 0.17576309541861215, Validation Accuracy: 0.4875\n",
      "Epoch 5282, Training Loss: 0.1739983827837052, Validation Loss: 0.1741407593091329, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 5283, Training Loss: 0.1739862056509141, Validation Loss: 0.17632902264595032, Validation Accuracy: 0.475\n",
      "Epoch 5284, Training Loss: 0.174098547427885, Validation Loss: 0.1719328870375951, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 5285, Training Loss: 0.17376664184754895, Validation Loss: 0.17689957519372304, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 5286, Training Loss: 0.1742617872453505, Validation Loss: 0.17390578985214233, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5287, Training Loss: 0.1736988156072555, Validation Loss: 0.17548945148785908, Validation Accuracy: 0.4875\n",
      "Epoch 5288, Training Loss: 0.1744210821005606, Validation Loss: 0.17274369498093922, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 5289, Training Loss: 0.1733555971614776, Validation Loss: 0.17572205364704133, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 5290, Training Loss: 0.17470953012666396, Validation Loss: 0.17376307845115663, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5291, Training Loss: 0.17361510520981205, Validation Loss: 0.17523403863112133, Validation Accuracy: 0.49375\n",
      "Epoch 5292, Training Loss: 0.17433102573117903, Validation Loss: 0.17354848980903625, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 5293, Training Loss: 0.17363339133800998, Validation Loss: 0.17462563912073772, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 5294, Training Loss: 0.17441366420638177, Validation Loss: 0.1739319125811259, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 5295, Training Loss: 0.1737619431749467, Validation Loss: 0.17392895718415577, Validation Accuracy: 0.5125\n",
      "Epoch 5296, Training Loss: 0.1742463655048801, Validation Loss: 0.17418715357780457, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 5297, Training Loss: 0.17360853043294722, Validation Loss: 0.17321984171867372, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 5298, Training Loss: 0.17433589985293726, Validation Loss: 0.1739699443181356, Validation Accuracy: 0.48125\n",
      "Epoch 5299, Training Loss: 0.17375025008955308, Validation Loss: 0.17396931151549022, Validation Accuracy: 0.50625\n",
      "Epoch 5300, Training Loss: 0.1742630995089008, Validation Loss: 0.17455868820349377, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 5301, Training Loss: 0.17361729616119015, Validation Loss: 0.17216481765111288, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 5302, Training Loss: 0.17437781970347127, Validation Loss: 0.17396411299705505, Validation Accuracy: 0.475\n",
      "Epoch 5303, Training Loss: 0.1737458643413359, Validation Loss: 0.17370624641577403, Validation Accuracy: 0.5125\n",
      "Epoch 5304, Training Loss: 0.1742945529760853, Validation Loss: 0.17441637913386027, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 5305, Training Loss: 0.1735835253230987, Validation Loss: 0.17285486459732055, Validation Accuracy: 0.5375\n",
      "Epoch 5306, Training Loss: 0.17438061727631476, Validation Loss: 0.1737914433081945, Validation Accuracy: 0.4875\n",
      "Epoch 5307, Training Loss: 0.17381622762449325, Validation Loss: 0.1743210067351659, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 5308, Training Loss: 0.17427673359071055, Validation Loss: 0.17400919497013093, Validation Accuracy: 0.475\n",
      "Epoch 5309, Training Loss: 0.17370748423760937, Validation Loss: 0.17188347081343333, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 5310, Training Loss: 0.1742838784571617, Validation Loss: 0.17393527030944825, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 5311, Training Loss: 0.17384870782975229, Validation Loss: 0.17381571531295775, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5312, Training Loss: 0.17420015604265274, Validation Loss: 0.173703200618426, Validation Accuracy: 0.4875\n",
      "Epoch 5313, Training Loss: 0.17381101606353636, Validation Loss: 0.17281337479750317, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 5314, Training Loss: 0.1742508022054549, Validation Loss: 0.17343158026536307, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 5315, Training Loss: 0.17382646568359866, Validation Loss: 0.17352033853530885, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5316, Training Loss: 0.17419805594028964, Validation Loss: 0.1734916905562083, Validation Accuracy: 0.49375\n",
      "Epoch 5317, Training Loss: 0.17383046063684648, Validation Loss: 0.17330013314882914, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 5318, Training Loss: 0.17414846103037557, Validation Loss: 0.17328137556711834, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 5319, Training Loss: 0.17400136782277015, Validation Loss: 0.1735243022441864, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 5320, Training Loss: 0.1738582839888911, Validation Loss: 0.17328866521517436, Validation Accuracy: 0.5125\n",
      "Epoch 5321, Training Loss: 0.1740174461756983, Validation Loss: 0.17352178692817688, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 5322, Training Loss: 0.1740820744345265, Validation Loss: 0.1730104625225067, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 5323, Training Loss: 0.17398428676589842, Validation Loss: 0.17355599602063496, Validation Accuracy: 0.48125\n",
      "Epoch 5324, Training Loss: 0.1736549989831063, Validation Loss: 0.17362408141295116, Validation Accuracy: 0.50625\n",
      "Epoch 5325, Training Loss: 0.17403745939654688, Validation Loss: 0.17337508499622345, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 5326, Training Loss: 0.17377085406934062, Validation Loss: 0.17212122480074565, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 5327, Training Loss: 0.1832470360302156, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.525\n",
      "Epoch 5328, Training Loss: 0.1733327248404103, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.4875\n",
      "Epoch 5329, Training Loss: 0.17355283229581772, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 5330, Training Loss: 0.17328606882402975, Validation Loss: 0.1731533706188202, Validation Accuracy: 0.5375\n",
      "Epoch 5331, Training Loss: 0.17349455529643643, Validation Loss: 0.1732867846886317, Validation Accuracy: 0.4875\n",
      "Epoch 5332, Training Loss: 0.17345444761937664, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5104166666666666\n",
      "Epoch 5333, Training Loss: 0.17334180926122972, Validation Loss: 0.1732874721288681, Validation Accuracy: 0.475\n",
      "Epoch 5334, Training Loss: 0.17528668094065883, Validation Loss: 0.1727273533741633, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 5335, Training Loss: 0.17358163624040543, Validation Loss: 0.17344420552253723, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 5336, Training Loss: 0.17328869911932177, Validation Loss: 0.17332086165746052, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5337, Training Loss: 0.17341889969764218, Validation Loss: 0.17337394058704375, Validation Accuracy: 0.4875\n",
      "Epoch 5338, Training Loss: 0.17342129974595963, Validation Loss: 0.1732289065917333, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 5339, Training Loss: 0.1734855766257932, Validation Loss: 0.17337215840816497, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 5340, Training Loss: 0.17344102840269765, Validation Loss: 0.17330653170744578, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5341, Training Loss: 0.17343143541966716, Validation Loss: 0.1733306348323822, Validation Accuracy: 0.49375\n",
      "Epoch 5342, Training Loss: 0.1733856326149356, Validation Loss: 0.17328534225622813, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 5343, Training Loss: 0.17352503874609548, Validation Loss: 0.17328434685866037, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 5344, Training Loss: 0.17351364128051266, Validation Loss: 0.17328699032465616, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 5345, Training Loss: 0.17345856226259662, Validation Loss: 0.17327892581621807, Validation Accuracy: 0.5125\n",
      "Epoch 5346, Training Loss: 0.1735695028497327, Validation Loss: 0.17328730126221975, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 5347, Training Loss: 0.17351447718758736, Validation Loss: 0.17328352530797322, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 5348, Training Loss: 0.17343339516270545, Validation Loss: 0.17335841159025828, Validation Accuracy: 0.48125\n",
      "Epoch 5349, Training Loss: 0.1733779263111853, Validation Loss: 0.1733513722817103, Validation Accuracy: 0.50625\n",
      "Epoch 5350, Training Loss: 0.17354033214430656, Validation Loss: 0.17339024047056834, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 5351, Training Loss: 0.1734329793722399, Validation Loss: 0.1727564533551534, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 5352, Training Loss: 0.17353604109056533, Validation Loss: 0.17333983182907103, Validation Accuracy: 0.475\n",
      "Epoch 5353, Training Loss: 0.1734363653006092, Validation Loss: 0.1732193797826767, Validation Accuracy: 0.5125\n",
      "Epoch 5354, Training Loss: 0.1755471642940275, Validation Loss: 0.1733197788397471, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 5355, Training Loss: 0.17378644260667986, Validation Loss: 0.17273553411165873, Validation Accuracy: 0.5375\n",
      "Epoch 5356, Training Loss: 0.17376744795230128, Validation Loss: 0.17332116961479188, Validation Accuracy: 0.4875\n",
      "Epoch 5357, Training Loss: 0.17348223588159006, Validation Loss: 0.17352138161659242, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 5358, Training Loss: 0.17367707673580415, Validation Loss: 0.173306006193161, Validation Accuracy: 0.475\n",
      "Epoch 5359, Training Loss: 0.17353644342191757, Validation Loss: 0.17290295660495758, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 5360, Training Loss: 0.1735581765251775, Validation Loss: 0.17333557903766633, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 5361, Training Loss: 0.17351715122499772, Validation Loss: 0.17342189351717632, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5362, Training Loss: 0.17443818142337184, Validation Loss: 0.1733145942290624, Validation Accuracy: 0.4875\n",
      "Epoch 5363, Training Loss: 0.1736497042640563, Validation Loss: 0.17298866709073385, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 5364, Training Loss: 0.17365392658018297, Validation Loss: 0.17371856371561686, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 5365, Training Loss: 0.17354861718993034, Validation Loss: 0.17357666293780008, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5366, Training Loss: 0.1737500121516566, Validation Loss: 0.17329939901828767, Validation Accuracy: 0.49375\n",
      "Epoch 5367, Training Loss: 0.17359630715462468, Validation Loss: 0.1732978940010071, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 5368, Training Loss: 0.17361054689653457, Validation Loss: 0.17325923442840577, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 5369, Training Loss: 0.17350010333522672, Validation Loss: 0.1737246771653493, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 5370, Training Loss: 0.17375483339832676, Validation Loss: 0.17326372663180034, Validation Accuracy: 0.5125\n",
      "Epoch 5371, Training Loss: 0.17358305521549716, Validation Loss: 0.1736665775378545, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 5372, Training Loss: 0.17374764382839203, Validation Loss: 0.17324357430140178, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 5373, Training Loss: 0.17350414539537123, Validation Loss: 0.17359845638275145, Validation Accuracy: 0.48125\n",
      "Epoch 5374, Training Loss: 0.17371115905623283, Validation Loss: 0.17326940695444742, Validation Accuracy: 0.50625\n",
      "Epoch 5375, Training Loss: 0.1735417814024033, Validation Loss: 0.17409392694632211, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 5376, Training Loss: 0.17376084962198812, Validation Loss: 0.1732564071814219, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 5377, Training Loss: 0.17346730587943907, Validation Loss: 0.1741372048854828, Validation Accuracy: 0.475\n",
      "Epoch 5378, Training Loss: 0.1738535108104829, Validation Loss: 0.17327312926451366, Validation Accuracy: 0.5125\n",
      "Epoch 5379, Training Loss: 0.17350827349770453, Validation Loss: 0.17407581706841788, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 5380, Training Loss: 0.17383639610582782, Validation Loss: 0.1732009450594584, Validation Accuracy: 0.5375\n",
      "Epoch 5381, Training Loss: 0.17347322260179826, Validation Loss: 0.1742139349381129, Validation Accuracy: 0.4875\n",
      "Epoch 5382, Training Loss: 0.17399418209829637, Validation Loss: 0.1733196665843328, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 5383, Training Loss: 0.17362081716137548, Validation Loss: 0.17432676255702972, Validation Accuracy: 0.475\n",
      "Epoch 5384, Training Loss: 0.17374806298363593, Validation Loss: 0.17320194045702617, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 5385, Training Loss: 0.17355492038111534, Validation Loss: 0.1741815209388733, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 5386, Training Loss: 0.17391486658203986, Validation Loss: 0.17336644927660624, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5387, Training Loss: 0.17356767577509727, Validation Loss: 0.17460895776748658, Validation Accuracy: 0.4875\n",
      "Epoch 5388, Training Loss: 0.1738950725524656, Validation Loss: 0.17321997384230295, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 5389, Training Loss: 0.17345994230239623, Validation Loss: 0.17410326997439066, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 5390, Training Loss: 0.17401550806337787, Validation Loss: 0.17348893185456593, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5391, Training Loss: 0.17351542028688616, Validation Loss: 0.17483145793279012, Validation Accuracy: 0.49375\n",
      "Epoch 5392, Training Loss: 0.17396543535494036, Validation Loss: 0.17327905893325807, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 5393, Training Loss: 0.17345561519745858, Validation Loss: 0.1736136426528295, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 5394, Training Loss: 0.1739421102308458, Validation Loss: 0.17383569081624348, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 5395, Training Loss: 0.17344839486383623, Validation Loss: 0.17397882242997487, Validation Accuracy: 0.5125\n",
      "Epoch 5396, Training Loss: 0.17413297151365587, Validation Loss: 0.1734305848677953, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 5397, Training Loss: 0.17347368453779527, Validation Loss: 0.17291508714358012, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 5398, Training Loss: 0.17399925281924586, Validation Loss: 0.17367267111937204, Validation Accuracy: 0.48125\n",
      "Epoch 5399, Training Loss: 0.17342797065934829, Validation Loss: 0.17365667919317881, Validation Accuracy: 0.50625\n",
      "Epoch 5400, Training Loss: 0.1741175973607648, Validation Loss: 0.17377674678961436, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 5401, Training Loss: 0.17352911060856235, Validation Loss: 0.1723071982463201, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 5402, Training Loss: 0.1739845722913742, Validation Loss: 0.17494004567464191, Validation Accuracy: 0.475\n",
      "Epoch 5403, Training Loss: 0.17372805024347, Validation Loss: 0.17361763219038645, Validation Accuracy: 0.5125\n",
      "Epoch 5404, Training Loss: 0.17376916543129953, Validation Loss: 0.17539003392060598, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 5405, Training Loss: 0.1737390333606351, Validation Loss: 0.17266178826491038, Validation Accuracy: 0.5375\n",
      "Epoch 5406, Training Loss: 0.1736790600322908, Validation Loss: 0.17522873282432555, Validation Accuracy: 0.4875\n",
      "Epoch 5407, Training Loss: 0.17375825345516205, Validation Loss: 0.17446207503477731, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 5408, Training Loss: 0.1738422599530989, Validation Loss: 0.17582171261310578, Validation Accuracy: 0.475\n",
      "Epoch 5409, Training Loss: 0.1739014377517085, Validation Loss: 0.17201715211073557, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 5410, Training Loss: 0.17365036664470548, Validation Loss: 0.17624759276707966, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 5411, Training Loss: 0.1739976026358143, Validation Loss: 0.1741664985815684, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5412, Training Loss: 0.17355350477080192, Validation Loss: 0.1751600444316864, Validation Accuracy: 0.4875\n",
      "Epoch 5413, Training Loss: 0.17423937782164542, Validation Loss: 0.17272922893365225, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 5414, Training Loss: 0.17329961686365067, Validation Loss: 0.175070924560229, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 5415, Training Loss: 0.17442061631910263, Validation Loss: 0.17387070258458456, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5416, Training Loss: 0.17348497433047141, Validation Loss: 0.17443302075068157, Validation Accuracy: 0.49375\n",
      "Epoch 5417, Training Loss: 0.17408250416478804, Validation Loss: 0.1736242413520813, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 5418, Training Loss: 0.17356101495604362, Validation Loss: 0.17369848092397053, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 5419, Training Loss: 0.17405006433686904, Validation Loss: 0.17449744939804077, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 5420, Training Loss: 0.1735287255817844, Validation Loss: 0.17393208146095276, Validation Accuracy: 0.5125\n",
      "Epoch 5421, Training Loss: 0.17392858959013416, Validation Loss: 0.17396909693876902, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 5422, Training Loss: 0.17357082184283965, Validation Loss: 0.17294716636339824, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 5423, Training Loss: 0.1740256134540804, Validation Loss: 0.17435869872570037, Validation Accuracy: 0.48125\n",
      "Epoch 5424, Training Loss: 0.17369796768311532, Validation Loss: 0.17369117538134257, Validation Accuracy: 0.50625\n",
      "Epoch 5425, Training Loss: 0.1740129465057004, Validation Loss: 0.17499360938866934, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 5426, Training Loss: 0.1736356769838641, Validation Loss: 0.17220474978288014, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 5427, Training Loss: 0.17405898820969365, Validation Loss: 0.17412704626719158, Validation Accuracy: 0.475\n",
      "Epoch 5428, Training Loss: 0.17371813616444987, Validation Loss: 0.17337858776251475, Validation Accuracy: 0.5125\n",
      "Epoch 5429, Training Loss: 0.17395944364609256, Validation Loss: 0.17488504548867542, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 5430, Training Loss: 0.1735901169238552, Validation Loss: 0.17266247272491456, Validation Accuracy: 0.5375\n",
      "Epoch 5431, Training Loss: 0.17401141457019315, Validation Loss: 0.17400187055269878, Validation Accuracy: 0.4875\n",
      "Epoch 5432, Training Loss: 0.17361528546579422, Validation Loss: 0.17684105634689332, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 5433, Training Loss: 0.17388571318118803, Validation Loss: 0.1743196964263916, Validation Accuracy: 0.475\n",
      "Epoch 5434, Training Loss: 0.17365668906319526, Validation Loss: 0.1720482756694158, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 5435, Training Loss: 0.1740347497886227, Validation Loss: 0.17390324771404267, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 5436, Training Loss: 0.17376909765505022, Validation Loss: 0.17362890938917797, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5437, Training Loss: 0.17386813077234453, Validation Loss: 0.17424535552660625, Validation Accuracy: 0.4875\n",
      "Epoch 5438, Training Loss: 0.1738219472669786, Validation Loss: 0.17282605469226836, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 5439, Training Loss: 0.17395786748778436, Validation Loss: 0.1735284795363744, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 5440, Training Loss: 0.17378168577148068, Validation Loss: 0.17358593742052714, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5441, Training Loss: 0.17392012573057605, Validation Loss: 0.17360979318618774, Validation Accuracy: 0.49375\n",
      "Epoch 5442, Training Loss: 0.17381459138085764, Validation Loss: 0.17335092822710674, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 5443, Training Loss: 0.1739239635006074, Validation Loss: 0.1732631504535675, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 5444, Training Loss: 0.1738993025595142, Validation Loss: 0.17364744941393534, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 5445, Training Loss: 0.17366068786190403, Validation Loss: 0.17329270442326863, Validation Accuracy: 0.5125\n",
      "Epoch 5446, Training Loss: 0.1739616326747402, Validation Loss: 0.1737094392379125, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 5447, Training Loss: 0.1737358598939834, Validation Loss: 0.17291113237539926, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 5448, Training Loss: 0.17399758533124002, Validation Loss: 0.17360824843247732, Validation Accuracy: 0.48125\n",
      "Epoch 5449, Training Loss: 0.17374939062903005, Validation Loss: 0.17336652775605518, Validation Accuracy: 0.50625\n",
      "Epoch 5450, Training Loss: 0.1739373399365333, Validation Loss: 0.17376675407091777, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 5451, Training Loss: 0.1738751256658185, Validation Loss: 0.17290388246377308, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 5452, Training Loss: 0.17393987024984053, Validation Loss: 0.17391046682993572, Validation Accuracy: 0.475\n",
      "Epoch 5453, Training Loss: 0.1736072522978629, Validation Loss: 0.17337924043337505, Validation Accuracy: 0.5125\n",
      "Epoch 5454, Training Loss: 0.17390424445752176, Validation Loss: 0.1738476832707723, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 5455, Training Loss: 0.17389254320052364, Validation Loss: 0.1730034112930298, Validation Accuracy: 0.5375\n",
      "Epoch 5456, Training Loss: 0.17386112290043984, Validation Loss: 0.17356677154699962, Validation Accuracy: 0.4875\n",
      "Epoch 5457, Training Loss: 0.17388931349400552, Validation Loss: 0.17345639566580454, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 5458, Training Loss: 0.17377634490689925, Validation Loss: 0.1739300012588501, Validation Accuracy: 0.475\n",
      "Epoch 5459, Training Loss: 0.17396677597876517, Validation Loss: 0.17286866704622905, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 5460, Training Loss: 0.1738159228717127, Validation Loss: 0.173857914408048, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 5461, Training Loss: 0.1738349925125799, Validation Loss: 0.1734899640083313, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5462, Training Loss: 0.17379890334221623, Validation Loss: 0.17376213570435842, Validation Accuracy: 0.4875\n",
      "Epoch 5463, Training Loss: 0.1739623527373037, Validation Loss: 0.17304541766643525, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 5464, Training Loss: 0.17373521770200423, Validation Loss: 0.17355340719223022, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 5465, Training Loss: 0.17401343199514574, Validation Loss: 0.17340612808863323, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5466, Training Loss: 0.17363755789495283, Validation Loss: 0.17371704578399658, Validation Accuracy: 0.49375\n",
      "Epoch 5467, Training Loss: 0.17407862986287764, Validation Loss: 0.1732805182536443, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 5468, Training Loss: 0.17377908575919368, Validation Loss: 0.17330243885517121, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 5469, Training Loss: 0.17393153280981125, Validation Loss: 0.17345974047978718, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 5470, Training Loss: 0.17374139831912133, Validation Loss: 0.173267924785614, Validation Accuracy: 0.5125\n",
      "Epoch 5471, Training Loss: 0.17398067395533284, Validation Loss: 0.17343381345272063, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 5472, Training Loss: 0.17380598716197476, Validation Loss: 0.1729377567768097, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 5473, Training Loss: 0.1739013824732073, Validation Loss: 0.1735090583562851, Validation Accuracy: 0.48125\n",
      "Epoch 5474, Training Loss: 0.1736623957272499, Validation Loss: 0.17341136634349824, Validation Accuracy: 0.50625\n",
      "Epoch 5475, Training Loss: 0.1740859992081119, Validation Loss: 0.17347864905993143, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 5476, Training Loss: 0.17370084937541716, Validation Loss: 0.17242037256558737, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 5477, Training Loss: 0.173893787207142, Validation Loss: 0.1737233132123947, Validation Accuracy: 0.475\n",
      "Epoch 5478, Training Loss: 0.17373160585280387, Validation Loss: 0.1733047236998876, Validation Accuracy: 0.5125\n",
      "Epoch 5479, Training Loss: 0.17387343077890335, Validation Loss: 0.17375264664491016, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 5480, Training Loss: 0.17381879975718836, Validation Loss: 0.17319511771202087, Validation Accuracy: 0.5375\n",
      "Epoch 5481, Training Loss: 0.1742467337077664, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5125\n",
      "Epoch 5482, Training Loss: 0.2589833279771189, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5104166666666666\n",
      "Epoch 5483, Training Loss: 0.17364083711178072, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.525\n",
      "Epoch 5484, Training Loss: 0.17325732304203895, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.4395833333333333\n",
      "Epoch 5485, Training Loss: 0.17320076159892545, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5270833333333333\n",
      "Epoch 5486, Training Loss: 0.1733181058399139, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 5487, Training Loss: 0.1732274039137748, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5125\n",
      "Epoch 5488, Training Loss: 0.1735498458147049, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.46458333333333335\n",
      "Epoch 5489, Training Loss: 0.1734909689234149, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 5490, Training Loss: 0.17434471941763355, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 5491, Training Loss: 0.17330059985960683, Validation Loss: 0.17328680157661439, Validation Accuracy: 0.49375\n",
      "Epoch 5492, Training Loss: 0.1733816910174585, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 5493, Training Loss: 0.17553418970877124, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5494, Training Loss: 0.17351478530514625, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5166666666666667\n",
      "Epoch 5495, Training Loss: 0.1740338336075506, Validation Loss: 0.17328190306822458, Validation Accuracy: 0.5125\n",
      "Epoch 5496, Training Loss: 0.17547300938637025, Validation Loss: 0.17361410955588022, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 5497, Training Loss: 0.17401064692005033, Validation Loss: 0.17296899954477946, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 5498, Training Loss: 0.1740159954755537, Validation Loss: 0.174870099623998, Validation Accuracy: 0.48125\n",
      "Epoch 5499, Training Loss: 0.1741170710132968, Validation Loss: 0.1732803871234258, Validation Accuracy: 0.50625\n",
      "Epoch 5500, Training Loss: 0.17380635055803484, Validation Loss: 0.1742847204208374, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 5501, Training Loss: 0.17426573076555807, Validation Loss: 0.17307329475879668, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 5502, Training Loss: 0.17360646157495438, Validation Loss: 0.1750008225440979, Validation Accuracy: 0.475\n",
      "Epoch 5503, Training Loss: 0.1743711454253043, Validation Loss: 0.17325034737586975, Validation Accuracy: 0.5125\n",
      "Epoch 5504, Training Loss: 0.17361458318848763, Validation Loss: 0.17519867718219756, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 5505, Training Loss: 0.17409767162415288, Validation Loss: 0.17320742209752402, Validation Accuracy: 0.5375\n",
      "Epoch 5506, Training Loss: 0.17358013314585533, Validation Loss: 0.1740091303984324, Validation Accuracy: 0.4875\n",
      "Epoch 5507, Training Loss: 0.17440058579367976, Validation Loss: 0.17349047760168712, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 5508, Training Loss: 0.1736881660838281, Validation Loss: 0.17532362639904023, Validation Accuracy: 0.475\n",
      "Epoch 5509, Training Loss: 0.17424958559774584, Validation Loss: 0.17252460221449534, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 5510, Training Loss: 0.17362145743062418, Validation Loss: 0.17504978875319163, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 5511, Training Loss: 0.17426262171037735, Validation Loss: 0.17362083594004313, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5512, Training Loss: 0.17359020056263094, Validation Loss: 0.17506679197152455, Validation Accuracy: 0.4875\n",
      "Epoch 5513, Training Loss: 0.17425597723453276, Validation Loss: 0.17279139757156373, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 5514, Training Loss: 0.17352656154863297, Validation Loss: 0.17457532087961833, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 5515, Training Loss: 0.1742149894275973, Validation Loss: 0.17394275565942127, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5516, Training Loss: 0.17363312407847373, Validation Loss: 0.1748264839251836, Validation Accuracy: 0.49375\n",
      "Epoch 5517, Training Loss: 0.17429341856510408, Validation Loss: 0.17359267274538676, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 5518, Training Loss: 0.17352040640769467, Validation Loss: 0.17401672999064127, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 5519, Training Loss: 0.17412851654714154, Validation Loss: 0.17442909280459087, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 5520, Training Loss: 0.17359844426954946, Validation Loss: 0.17394642929236095, Validation Accuracy: 0.5125\n",
      "Epoch 5521, Training Loss: 0.17424617611592816, Validation Loss: 0.17468900978565216, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 5522, Training Loss: 0.17369807343329152, Validation Loss: 0.1730328659216563, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 5523, Training Loss: 0.1740995914705338, Validation Loss: 0.1746685077746709, Validation Accuracy: 0.48125\n",
      "Epoch 5524, Training Loss: 0.17357502925780513, Validation Loss: 0.17402862906455993, Validation Accuracy: 0.50625\n",
      "Epoch 5525, Training Loss: 0.174277518064745, Validation Loss: 0.17527173360188802, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 5526, Training Loss: 0.17372562568033895, Validation Loss: 0.1721456080675125, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 5527, Training Loss: 0.17408391737168835, Validation Loss: 0.17535363137722015, Validation Accuracy: 0.475\n",
      "Epoch 5528, Training Loss: 0.17377619204982633, Validation Loss: 0.17353750268618265, Validation Accuracy: 0.5125\n",
      "Epoch 5529, Training Loss: 0.1738455011959999, Validation Loss: 0.17533707916736602, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 5530, Training Loss: 0.1739206785155881, Validation Loss: 0.17265921831130981, Validation Accuracy: 0.5375\n",
      "Epoch 5531, Training Loss: 0.1737468026338085, Validation Loss: 0.1750158727169037, Validation Accuracy: 0.4875\n",
      "Epoch 5532, Training Loss: 0.17388444465975608, Validation Loss: 0.1743392954270045, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 5533, Training Loss: 0.17386810433480046, Validation Loss: 0.1756601631641388, Validation Accuracy: 0.475\n",
      "Epoch 5534, Training Loss: 0.17400708073569882, Validation Loss: 0.1719024916489919, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 5535, Training Loss: 0.17372439897829486, Validation Loss: 0.17538072168827057, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 5536, Training Loss: 0.1740653197611532, Validation Loss: 0.1741407920916875, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5537, Training Loss: 0.17361663858736714, Validation Loss: 0.17469391624132793, Validation Accuracy: 0.4875\n",
      "Epoch 5538, Training Loss: 0.17425079114975467, Validation Loss: 0.17272869745890299, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 5539, Training Loss: 0.1733591402730634, Validation Loss: 0.17479075789451598, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 5540, Training Loss: 0.1744719546648764, Validation Loss: 0.17384501496950786, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5541, Training Loss: 0.17352995420655898, Validation Loss: 0.17465703586737316, Validation Accuracy: 0.49375\n",
      "Epoch 5542, Training Loss: 0.17419752094053453, Validation Loss: 0.17360003193219503, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 5543, Training Loss: 0.17361557964355714, Validation Loss: 0.1737266441186269, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 5544, Training Loss: 0.17419030204896005, Validation Loss: 0.17414935032526652, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 5545, Training Loss: 0.17365600937797177, Validation Loss: 0.17375459869702656, Validation Accuracy: 0.5125\n",
      "Epoch 5546, Training Loss: 0.17408780176793376, Validation Loss: 0.17421706517537436, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 5547, Training Loss: 0.17360136009031726, Validation Loss: 0.17294425169626873, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 5548, Training Loss: 0.17410159303295997, Validation Loss: 0.17410686612129211, Validation Accuracy: 0.48125\n",
      "Epoch 5549, Training Loss: 0.1737311477622678, Validation Loss: 0.17363985379536948, Validation Accuracy: 0.50625\n",
      "Epoch 5550, Training Loss: 0.17399357691887887, Validation Loss: 0.17511250376701354, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 5551, Training Loss: 0.17367963637075118, Validation Loss: 0.17220328549544017, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 5552, Training Loss: 0.1741029937421122, Validation Loss: 0.17408213317394255, Validation Accuracy: 0.475\n",
      "Epoch 5553, Training Loss: 0.17368442877646414, Validation Loss: 0.17346363365650178, Validation Accuracy: 0.5125\n",
      "Epoch 5554, Training Loss: 0.17408756575276774, Validation Loss: 0.1743405818939209, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 5555, Training Loss: 0.17367608797165654, Validation Loss: 0.1727249006430308, Validation Accuracy: 0.5375\n",
      "Epoch 5556, Training Loss: 0.17408651353851443, Validation Loss: 0.17375395596027374, Validation Accuracy: 0.4875\n",
      "Epoch 5557, Training Loss: 0.17372884433115682, Validation Loss: 0.17384693622589112, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 5558, Training Loss: 0.17404834349309245, Validation Loss: 0.1739789992570877, Validation Accuracy: 0.475\n",
      "Epoch 5559, Training Loss: 0.17369882474022527, Validation Loss: 0.17221963504950205, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 5560, Training Loss: 0.17397553690018192, Validation Loss: 0.17447628279527028, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 5561, Training Loss: 0.17371980076836002, Validation Loss: 0.17385634779930115, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5562, Training Loss: 0.17407979167276813, Validation Loss: 0.17358500162760418, Validation Accuracy: 0.4875\n",
      "Epoch 5563, Training Loss: 0.1737843905725787, Validation Loss: 0.1728523721297582, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 5564, Training Loss: 0.17403526315765996, Validation Loss: 0.17342527310053507, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 5565, Training Loss: 0.1738467788504016, Validation Loss: 0.17354941368103027, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5566, Training Loss: 0.17393848636457998, Validation Loss: 0.17359092235565185, Validation Accuracy: 0.49375\n",
      "Epoch 5567, Training Loss: 0.17382700260608427, Validation Loss: 0.17335186004638672, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 5568, Training Loss: 0.17383521795272827, Validation Loss: 0.17335107028484345, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 5569, Training Loss: 0.17389795568681532, Validation Loss: 0.1736938347419103, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 5570, Training Loss: 0.17365695920682722, Validation Loss: 0.17328508893648784, Validation Accuracy: 0.5125\n",
      "Epoch 5571, Training Loss: 0.1739602175451094, Validation Loss: 0.1736043820778529, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 5572, Training Loss: 0.1739030091031905, Validation Loss: 0.17304188013076782, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 5573, Training Loss: 0.17396921880783572, Validation Loss: 0.1736477126677831, Validation Accuracy: 0.48125\n",
      "Epoch 5574, Training Loss: 0.17364446386214225, Validation Loss: 0.17362394134203593, Validation Accuracy: 0.50625\n",
      "Epoch 5575, Training Loss: 0.174015024496663, Validation Loss: 0.17392573257287344, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 5576, Training Loss: 0.17384181195689785, Validation Loss: 0.17273263434569042, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 5577, Training Loss: 0.17395032750022027, Validation Loss: 0.1737921953201294, Validation Accuracy: 0.475\n",
      "Epoch 5578, Training Loss: 0.17374207415888387, Validation Loss: 0.17324653665224712, Validation Accuracy: 0.5125\n",
      "Epoch 5579, Training Loss: 0.1738936059897946, Validation Loss: 0.17391776343186696, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 5580, Training Loss: 0.17394295238679455, Validation Loss: 0.1730631152788798, Validation Accuracy: 0.5375\n",
      "Epoch 5581, Training Loss: 0.17390973000757157, Validation Loss: 0.17366749445597332, Validation Accuracy: 0.4875\n",
      "Epoch 5582, Training Loss: 0.17378694203592115, Validation Loss: 0.1736256053050359, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 5583, Training Loss: 0.1738017956095357, Validation Loss: 0.17412965297698973, Validation Accuracy: 0.475\n",
      "Epoch 5584, Training Loss: 0.17398984586038896, Validation Loss: 0.17286728223164877, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 5585, Training Loss: 0.17386874220063608, Validation Loss: 0.17398722171783448, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 5586, Training Loss: 0.17393403235943086, Validation Loss: 0.17341180443763732, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5587, Training Loss: 0.17377144194418384, Validation Loss: 0.1737366646528244, Validation Accuracy: 0.4875\n",
      "Epoch 5588, Training Loss: 0.17402249815002566, Validation Loss: 0.17306841810544332, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 5589, Training Loss: 0.1737801259563815, Validation Loss: 0.17354540328184764, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 5590, Training Loss: 0.1739252805709839, Validation Loss: 0.17376404802004497, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5591, Training Loss: 0.17361972168568643, Validation Loss: 0.17376592357953388, Validation Accuracy: 0.49375\n",
      "Epoch 5592, Training Loss: 0.17410245778099184, Validation Loss: 0.17328358292579651, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 5593, Training Loss: 0.1738523946654412, Validation Loss: 0.1732987811168035, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 5594, Training Loss: 0.1739244956162668, Validation Loss: 0.17350703875223797, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 5595, Training Loss: 0.1737516705066927, Validation Loss: 0.1732534497976303, Validation Accuracy: 0.5125\n",
      "Epoch 5596, Training Loss: 0.174071101892379, Validation Loss: 0.17338313460350036, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 5597, Training Loss: 0.17381925159885037, Validation Loss: 0.17292845944563548, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 5598, Training Loss: 0.17395602743471822, Validation Loss: 0.17353367110093434, Validation Accuracy: 0.48125\n",
      "Epoch 5599, Training Loss: 0.17364453596453513, Validation Loss: 0.1734537313381831, Validation Accuracy: 0.50625\n",
      "Epoch 5600, Training Loss: 0.17416102222857938, Validation Loss: 0.1734491934378942, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 5601, Training Loss: 0.173727584462012, Validation Loss: 0.17241915663083393, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 5602, Training Loss: 0.1740024882939554, Validation Loss: 0.17356000542640687, Validation Accuracy: 0.475\n",
      "Epoch 5603, Training Loss: 0.17367658740089786, Validation Loss: 0.1732443412144979, Validation Accuracy: 0.5125\n",
      "Epoch 5604, Training Loss: 0.17403043518143316, Validation Loss: 0.17357052862644196, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 5605, Training Loss: 0.1737663164254158, Validation Loss: 0.17271959781646729, Validation Accuracy: 0.5375\n",
      "Epoch 5606, Training Loss: 0.17399993106242148, Validation Loss: 0.17345648407936096, Validation Accuracy: 0.4875\n",
      "Epoch 5607, Training Loss: 0.17368366545246494, Validation Loss: 0.17378576795260112, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 5608, Training Loss: 0.17407609762683993, Validation Loss: 0.1734033723672231, Validation Accuracy: 0.475\n",
      "Epoch 5609, Training Loss: 0.1736320415812154, Validation Loss: 0.1725372870763143, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 5610, Training Loss: 0.17385179381216725, Validation Loss: 0.17398587663968404, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 5611, Training Loss: 0.1736861712509586, Validation Loss: 0.17366061011950176, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5612, Training Loss: 0.1742052464715896, Validation Loss: 0.1733429729938507, Validation Accuracy: 0.4875\n",
      "Epoch 5613, Training Loss: 0.17373925880078347, Validation Loss: 0.1728789617617925, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 5614, Training Loss: 0.17377261384840934, Validation Loss: 0.17358801861604053, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 5615, Training Loss: 0.17373979428122122, Validation Loss: 0.17391790946324667, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5616, Training Loss: 0.17407496129312822, Validation Loss: 0.1733166366815567, Validation Accuracy: 0.49375\n",
      "Epoch 5617, Training Loss: 0.1738241680206791, Validation Loss: 0.17356214920679727, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 5618, Training Loss: 0.17396853960329486, Validation Loss: 0.17327394982179006, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 5619, Training Loss: 0.1736144115847926, Validation Loss: 0.17400617102781932, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 5620, Training Loss: 0.17422425794985988, Validation Loss: 0.17325480779012045, Validation Accuracy: 0.5125\n",
      "Epoch 5621, Training Loss: 0.17373787635757076, Validation Loss: 0.17458788553873697, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 5622, Training Loss: 0.17407147826686983, Validation Loss: 0.17317406038443248, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 5623, Training Loss: 0.17364930097133882, Validation Loss: 0.17432079215844473, Validation Accuracy: 0.48125\n",
      "Epoch 5624, Training Loss: 0.1740976466286567, Validation Loss: 0.17327861984570822, Validation Accuracy: 0.50625\n",
      "Epoch 5625, Training Loss: 0.17363799483545364, Validation Loss: 0.1748979280392329, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 5626, Training Loss: 0.1741175723652686, Validation Loss: 0.17318651874860128, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 5627, Training Loss: 0.17356755175898153, Validation Loss: 0.17503197391827902, Validation Accuracy: 0.475\n",
      "Epoch 5628, Training Loss: 0.1742326847968563, Validation Loss: 0.17325382828712463, Validation Accuracy: 0.5125\n",
      "Epoch 5629, Training Loss: 0.17355133785355475, Validation Loss: 0.17532384594281514, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 5630, Training Loss: 0.17422012071455678, Validation Loss: 0.17298330068588258, Validation Accuracy: 0.5375\n",
      "Epoch 5631, Training Loss: 0.17349224946191233, Validation Loss: 0.17464760839939117, Validation Accuracy: 0.4875\n",
      "Epoch 5632, Training Loss: 0.1742947063138408, Validation Loss: 0.17331451574961346, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 5633, Training Loss: 0.1736698035270937, Validation Loss: 0.17530052065849305, Validation Accuracy: 0.475\n",
      "Epoch 5634, Training Loss: 0.1741240846533929, Validation Loss: 0.1728366603453954, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 5635, Training Loss: 0.17362600757229713, Validation Loss: 0.1750781963268916, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 5636, Training Loss: 0.17420698942676668, Validation Loss: 0.1735476076602936, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5637, Training Loss: 0.17355980892335215, Validation Loss: 0.17523400485515594, Validation Accuracy: 0.4875\n",
      "Epoch 5638, Training Loss: 0.1741555453308167, Validation Loss: 0.17288428048292795, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 5639, Training Loss: 0.17353119484839902, Validation Loss: 0.17446900109450023, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 5640, Training Loss: 0.1742036174381933, Validation Loss: 0.17352028687795004, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5641, Training Loss: 0.17356906542854925, Validation Loss: 0.17484484712282816, Validation Accuracy: 0.49375\n",
      "Epoch 5642, Training Loss: 0.1741957337625565, Validation Loss: 0.17335134049256642, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 5643, Training Loss: 0.17345271908467816, Validation Loss: 0.17420859436194103, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 5644, Training Loss: 0.17408886311515684, Validation Loss: 0.17434850533803303, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 5645, Training Loss: 0.17358047202710183, Validation Loss: 0.174111407995224, Validation Accuracy: 0.5125\n",
      "Epoch 5646, Training Loss: 0.1742579129434401, Validation Loss: 0.17450739244620006, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 5647, Training Loss: 0.17360438791013533, Validation Loss: 0.17298491795857748, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 5648, Training Loss: 0.17424533636339248, Validation Loss: 0.17438244819641113, Validation Accuracy: 0.48125\n",
      "Epoch 5649, Training Loss: 0.17341463892690598, Validation Loss: 0.17423720757166544, Validation Accuracy: 0.50625\n",
      "Epoch 5650, Training Loss: 0.17437300807045353, Validation Loss: 0.17511239846547444, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 5651, Training Loss: 0.17362790001976874, Validation Loss: 0.17221391797065735, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 5652, Training Loss: 0.17417629639948567, Validation Loss: 0.17539826035499573, Validation Accuracy: 0.475\n",
      "Epoch 5653, Training Loss: 0.17368099141505458, Validation Loss: 0.17352730135122935, Validation Accuracy: 0.5125\n",
      "Epoch 5654, Training Loss: 0.17392721243443027, Validation Loss: 0.17569513519605, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 5655, Training Loss: 0.17390589896709688, Validation Loss: 0.17265930771827698, Validation Accuracy: 0.5375\n",
      "Epoch 5656, Training Loss: 0.17383140277478001, Validation Loss: 0.17525950173536936, Validation Accuracy: 0.4875\n",
      "Epoch 5657, Training Loss: 0.1738297285572175, Validation Loss: 0.17446828683217366, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 5658, Training Loss: 0.1738981657451199, Validation Loss: 0.17561026116212208, Validation Accuracy: 0.475\n",
      "Epoch 5659, Training Loss: 0.17397702365152298, Validation Loss: 0.17207985023657482, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 5660, Training Loss: 0.17361594159756938, Validation Loss: 0.17655368944009145, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 5661, Training Loss: 0.17408981630879064, Validation Loss: 0.174004989862442, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5662, Training Loss: 0.17367109223719565, Validation Loss: 0.17505513827006022, Validation Accuracy: 0.4875\n",
      "Epoch 5663, Training Loss: 0.174245439229473, Validation Loss: 0.1727711468935013, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 5664, Training Loss: 0.17335998915856884, Validation Loss: 0.17537489533424377, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 5665, Training Loss: 0.17446762563720827, Validation Loss: 0.17393263777097065, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5666, Training Loss: 0.17355738676363422, Validation Loss: 0.17438548703988394, Validation Accuracy: 0.49375\n",
      "Epoch 5667, Training Loss: 0.1740308298218635, Validation Loss: 0.17336026628812154, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 5668, Training Loss: 0.17355919413028226, Validation Loss: 0.17382603188355764, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 5669, Training Loss: 0.1741349846124649, Validation Loss: 0.1747163563966751, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 5670, Training Loss: 0.17357289070083248, Validation Loss: 0.1740787128607432, Validation Accuracy: 0.5125\n",
      "Epoch 5671, Training Loss: 0.17408893665959757, Validation Loss: 0.17450331151485443, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 5672, Training Loss: 0.17358589845318947, Validation Loss: 0.17310767273108166, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 5673, Training Loss: 0.17416228402045467, Validation Loss: 0.1739560544490814, Validation Accuracy: 0.48125\n",
      "Epoch 5674, Training Loss: 0.17370286151286093, Validation Loss: 0.17378728886445363, Validation Accuracy: 0.50625\n",
      "Epoch 5675, Training Loss: 0.17411699170066464, Validation Loss: 0.17464983562628428, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 5676, Training Loss: 0.17366566677247325, Validation Loss: 0.17217698991298674, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 5677, Training Loss: 0.1741528602377061, Validation Loss: 0.17404485046863555, Validation Accuracy: 0.475\n",
      "Epoch 5678, Training Loss: 0.1737587365411943, Validation Loss: 0.17333425084749857, Validation Accuracy: 0.5125\n",
      "Epoch 5679, Training Loss: 0.1741041853543251, Validation Loss: 0.1744824339946111, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 5680, Training Loss: 0.17366322923091151, Validation Loss: 0.17266470193862915, Validation Accuracy: 0.5375\n",
      "Epoch 5681, Training Loss: 0.1740198721808772, Validation Loss: 0.17419504622618356, Validation Accuracy: 0.4875\n",
      "Epoch 5682, Training Loss: 0.17377621464190945, Validation Loss: 0.1741093764702479, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 5683, Training Loss: 0.1740606403158557, Validation Loss: 0.1741986632347107, Validation Accuracy: 0.475\n",
      "Epoch 5684, Training Loss: 0.17372890201307112, Validation Loss: 0.17208184401194254, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 5685, Training Loss: 0.17406614749662339, Validation Loss: 0.17392730712890625, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 5686, Training Loss: 0.17378812980267308, Validation Loss: 0.17369174659252168, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5687, Training Loss: 0.17395147440894956, Validation Loss: 0.17406878570715587, Validation Accuracy: 0.4875\n",
      "Epoch 5688, Training Loss: 0.17385510859950895, Validation Loss: 0.17283791502316792, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 5689, Training Loss: 0.17400881359654088, Validation Loss: 0.17345162133375805, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 5690, Training Loss: 0.173862476983378, Validation Loss: 0.17353238463401793, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5691, Training Loss: 0.17390293748148025, Validation Loss: 0.1739734411239624, Validation Accuracy: 0.49375\n",
      "Epoch 5692, Training Loss: 0.1738193251432911, Validation Loss: 0.17330832183361053, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 5693, Training Loss: 0.17397358052192197, Validation Loss: 0.1732585072517395, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 5694, Training Loss: 0.1739945512625479, Validation Loss: 0.17354084451993307, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 5695, Training Loss: 0.1735966114267226, Validation Loss: 0.1734803130229314, Validation Accuracy: 0.5125\n",
      "Epoch 5696, Training Loss: 0.17401860221739737, Validation Loss: 0.17355295022328696, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 5697, Training Loss: 0.17381924583065894, Validation Loss: 0.17298532327016194, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 5698, Training Loss: 0.17404987879337802, Validation Loss: 0.1736606905857722, Validation Accuracy: 0.48125\n",
      "Epoch 5699, Training Loss: 0.17365139915097144, Validation Loss: 0.17362104256947836, Validation Accuracy: 0.50625\n",
      "Epoch 5700, Training Loss: 0.17400879196582303, Validation Loss: 0.17362584074338278, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 5701, Training Loss: 0.1738873056827053, Validation Loss: 0.1726286401351293, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 5702, Training Loss: 0.1739567696086822, Validation Loss: 0.1736624777317047, Validation Accuracy: 0.475\n",
      "Epoch 5703, Training Loss: 0.17381871467636478, Validation Loss: 0.17322094241778055, Validation Accuracy: 0.5125\n",
      "Epoch 5704, Training Loss: 0.17391824049334373, Validation Loss: 0.1738700747489929, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 5705, Training Loss: 0.17396924380333192, Validation Loss: 0.1730730543533961, Validation Accuracy: 0.5375\n",
      "Epoch 5706, Training Loss: 0.17391035249156336, Validation Loss: 0.17363407115141552, Validation Accuracy: 0.4875\n",
      "Epoch 5707, Training Loss: 0.17392446677530965, Validation Loss: 0.17344571153322855, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 5708, Training Loss: 0.17380546225655463, Validation Loss: 0.17395870983600617, Validation Accuracy: 0.475\n",
      "Epoch 5709, Training Loss: 0.17399774780196528, Validation Loss: 0.1728373517592748, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 5710, Training Loss: 0.17386628254767386, Validation Loss: 0.17387330929438274, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 5711, Training Loss: 0.17398408872465934, Validation Loss: 0.17338443001111348, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5712, Training Loss: 0.17378072344487713, Validation Loss: 0.17385606169700624, Validation Accuracy: 0.4875\n",
      "Epoch 5713, Training Loss: 0.1740825113750273, Validation Loss: 0.17312544584274292, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 5714, Training Loss: 0.17375626775526232, Validation Loss: 0.17357505758603414, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 5715, Training Loss: 0.17402714827368337, Validation Loss: 0.17343124449253083, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5716, Training Loss: 0.173722188799612, Validation Loss: 0.17361265122890474, Validation Accuracy: 0.49375\n",
      "Epoch 5717, Training Loss: 0.17406522650872508, Validation Loss: 0.17328262130419414, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 5718, Training Loss: 0.17385523117357685, Validation Loss: 0.17328319152196248, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 5719, Training Loss: 0.1738956037067598, Validation Loss: 0.1735529790321986, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 5720, Training Loss: 0.17381658573304454, Validation Loss: 0.17324593762556711, Validation Accuracy: 0.5125\n",
      "Epoch 5721, Training Loss: 0.1740245847932754, Validation Loss: 0.17340429325898488, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 5722, Training Loss: 0.17385719380071085, Validation Loss: 0.17293182810147603, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 5723, Training Loss: 0.17375813568792037, Validation Loss: 0.17387594978014628, Validation Accuracy: 0.48125\n",
      "Epoch 5724, Training Loss: 0.17375913262367249, Validation Loss: 0.17339524527390798, Validation Accuracy: 0.50625\n",
      "Epoch 5725, Training Loss: 0.173839075430747, Validation Loss: 0.17403313815593718, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 5726, Training Loss: 0.17381789943864268, Validation Loss: 0.17235787014166515, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 5727, Training Loss: 0.17383837219207518, Validation Loss: 0.17401089370250702, Validation Accuracy: 0.475\n",
      "Epoch 5728, Training Loss: 0.17378021440198343, Validation Loss: 0.17325338919957478, Validation Accuracy: 0.5125\n",
      "Epoch 5729, Training Loss: 0.17408025072466943, Validation Loss: 0.17343436578909557, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 5730, Training Loss: 0.1737780296994794, Validation Loss: 0.17281695703665415, Validation Accuracy: 0.5375\n",
      "Epoch 5731, Training Loss: 0.17384402886513742, Validation Loss: 0.1736912359793981, Validation Accuracy: 0.4875\n",
      "Epoch 5732, Training Loss: 0.17371140468505122, Validation Loss: 0.17380788028240204, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 5733, Training Loss: 0.174229028724855, Validation Loss: 0.17336034774780273, Validation Accuracy: 0.475\n",
      "Epoch 5734, Training Loss: 0.17366438911807153, Validation Loss: 0.1726194461186727, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 5735, Training Loss: 0.17416298966253957, Validation Loss: 0.17344444195429484, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 5736, Training Loss: 0.1736444547291725, Validation Loss: 0.17353273630142213, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5737, Training Loss: 0.17416012575549464, Validation Loss: 0.17333019276460013, Validation Accuracy: 0.4875\n",
      "Epoch 5738, Training Loss: 0.17374947619053624, Validation Loss: 0.17299703359603882, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 5739, Training Loss: 0.17406674883057993, Validation Loss: 0.1733344574769338, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 5740, Training Loss: 0.17373414145361993, Validation Loss: 0.17359819412231445, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5741, Training Loss: 0.1740897581461937, Validation Loss: 0.173301500082016, Validation Accuracy: 0.49375\n",
      "Epoch 5742, Training Loss: 0.1738458852614126, Validation Loss: 0.17337778210639954, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 5743, Training Loss: 0.17396167882027164, Validation Loss: 0.17326562305291493, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 5744, Training Loss: 0.1736507584010401, Validation Loss: 0.1740233600139618, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 5745, Training Loss: 0.1741648273121926, Validation Loss: 0.17327120999495188, Validation Accuracy: 0.5125\n",
      "Epoch 5746, Training Loss: 0.17377716350939967, Validation Loss: 0.17433713475863138, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 5747, Training Loss: 0.17406104264720793, Validation Loss: 0.1732308695713679, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 5748, Training Loss: 0.17364772433234799, Validation Loss: 0.17421810626983641, Validation Accuracy: 0.48125\n",
      "Epoch 5749, Training Loss: 0.17418484197508904, Validation Loss: 0.17327486375967663, Validation Accuracy: 0.50625\n",
      "Epoch 5750, Training Loss: 0.17364952256602625, Validation Loss: 0.17508134841918946, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 5751, Training Loss: 0.17414262169791805, Validation Loss: 0.1732249637444814, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 5752, Training Loss: 0.17358654160653392, Validation Loss: 0.1748692254225413, Validation Accuracy: 0.475\n",
      "Epoch 5753, Training Loss: 0.17426643304286465, Validation Loss: 0.17325791120529174, Validation Accuracy: 0.5125\n",
      "Epoch 5754, Training Loss: 0.17355167673480126, Validation Loss: 0.1755341132481893, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 5755, Training Loss: 0.17425694917478868, Validation Loss: 0.17309551934401193, Validation Accuracy: 0.5375\n",
      "Epoch 5756, Training Loss: 0.17350627818415243, Validation Loss: 0.17465047736962636, Validation Accuracy: 0.4875\n",
      "Epoch 5757, Training Loss: 0.17434195405052555, Validation Loss: 0.17341842452685038, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 5758, Training Loss: 0.1736604614603904, Validation Loss: 0.17533867359161376, Validation Accuracy: 0.475\n",
      "Epoch 5759, Training Loss: 0.17414441079862655, Validation Loss: 0.173113943139712, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 5760, Training Loss: 0.17364407258649026, Validation Loss: 0.175273792942365, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 5761, Training Loss: 0.17420162164395855, Validation Loss: 0.1735074758529663, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5762, Training Loss: 0.17358675743302993, Validation Loss: 0.1752078433831533, Validation Accuracy: 0.4875\n",
      "Epoch 5763, Training Loss: 0.17419999309124484, Validation Loss: 0.17296765148639678, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 5764, Training Loss: 0.1734952325782468, Validation Loss: 0.17474561830361685, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 5765, Training Loss: 0.1742269689998319, Validation Loss: 0.17364840507507323, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5766, Training Loss: 0.17359651625156403, Validation Loss: 0.1750667631626129, Validation Accuracy: 0.49375\n",
      "Epoch 5767, Training Loss: 0.17422589419349546, Validation Loss: 0.17338455021381377, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 5768, Training Loss: 0.17348218012240627, Validation Loss: 0.1739690770705541, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 5769, Training Loss: 0.17411633701093734, Validation Loss: 0.17414373457431792, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 5770, Training Loss: 0.1736269021226514, Validation Loss: 0.17409070928891499, Validation Accuracy: 0.5125\n",
      "Epoch 5771, Training Loss: 0.19246417668557936, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5208333333333334\n",
      "Epoch 5772, Training Loss: 0.17330413528027072, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 5773, Training Loss: 0.17358275815363852, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.51875\n",
      "Epoch 5774, Training Loss: 0.1874667103252103, Validation Loss: 0.3580181380112966, Validation Accuracy: 0.50625\n",
      "Epoch 5775, Training Loss: 0.2701859099249686, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5333333333333333\n",
      "Epoch 5776, Training Loss: 0.2439849001746024, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.4479166666666667\n",
      "Epoch 5777, Training Loss: 0.1732867956161499, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.525\n",
      "Epoch 5778, Training Loss: 0.17485594076495017, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.4875\n",
      "Epoch 5779, Training Loss: 0.17328680859458062, Validation Loss: 0.17328706979751587, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 5780, Training Loss: 0.17328706095295568, Validation Loss: 0.17320608695348103, Validation Accuracy: 0.5375\n",
      "Epoch 5781, Training Loss: 0.17341716924021322, Validation Loss: 0.17335990369319915, Validation Accuracy: 0.4875\n",
      "Epoch 5782, Training Loss: 0.1733499010724406, Validation Loss: 0.1745519389708837, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 5783, Training Loss: 0.17354857537054247, Validation Loss: 0.17380839983622234, Validation Accuracy: 0.475\n",
      "Epoch 5784, Training Loss: 0.1733697691271382, Validation Loss: 0.17251859605312347, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 5785, Training Loss: 0.1734717656527796, Validation Loss: 0.17348067859808605, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 5786, Training Loss: 0.17337257583295146, Validation Loss: 0.17332762082417805, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5787, Training Loss: 0.17332580829820327, Validation Loss: 0.17409493029117584, Validation Accuracy: 0.4875\n",
      "Epoch 5788, Training Loss: 0.1735715053735241, Validation Loss: 0.1729538599650065, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 5789, Training Loss: 0.173184716413098, Validation Loss: 0.17478401064872742, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 5790, Training Loss: 0.17371295200240228, Validation Loss: 0.17332254449526469, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5791, Training Loss: 0.17339352878832048, Validation Loss: 0.1735520839691162, Validation Accuracy: 0.49375\n",
      "Epoch 5792, Training Loss: 0.17349059591370244, Validation Loss: 0.1733334501584371, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 5793, Training Loss: 0.17333613576427584, Validation Loss: 0.17332095205783843, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 5794, Training Loss: 0.1735858715349628, Validation Loss: 0.17343661189079285, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 5795, Training Loss: 0.1733967190788638, Validation Loss: 0.17321763634681703, Validation Accuracy: 0.5125\n",
      "Epoch 5796, Training Loss: 0.17348964223938604, Validation Loss: 0.1737240602572759, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 5797, Training Loss: 0.17323310336759012, Validation Loss: 0.1731188694636027, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 5798, Training Loss: 0.1733569719137684, Validation Loss: 0.1737738827864329, Validation Accuracy: 0.48125\n",
      "Epoch 5799, Training Loss: 0.17336443306938296, Validation Loss: 0.17335628271102904, Validation Accuracy: 0.50625\n",
      "Epoch 5800, Training Loss: 0.17346263027960254, Validation Loss: 0.1737559527158737, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 5801, Training Loss: 0.17339645662615377, Validation Loss: 0.17219256460666657, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 5802, Training Loss: 0.17355574907795077, Validation Loss: 0.17356971899668375, Validation Accuracy: 0.475\n",
      "Epoch 5803, Training Loss: 0.17341425966831944, Validation Loss: 0.173220889767011, Validation Accuracy: 0.5125\n",
      "Epoch 5804, Training Loss: 0.17357681883919623, Validation Loss: 0.17370590468247732, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 5805, Training Loss: 0.17338370940377634, Validation Loss: 0.1729134331146876, Validation Accuracy: 0.5375\n",
      "Epoch 5806, Training Loss: 0.17361432025509496, Validation Loss: 0.17339876790841421, Validation Accuracy: 0.4875\n",
      "Epoch 5807, Training Loss: 0.17342771397482964, Validation Loss: 0.17348034878571827, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 5808, Training Loss: 0.17361267968531577, Validation Loss: 0.17350886166095733, Validation Accuracy: 0.475\n",
      "Epoch 5809, Training Loss: 0.17344503489232832, Validation Loss: 0.1726880580186844, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 5810, Training Loss: 0.17359278615443938, Validation Loss: 0.17349208891391754, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 5811, Training Loss: 0.1734771300708094, Validation Loss: 0.17344180246194205, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5812, Training Loss: 0.17347018901378877, Validation Loss: 0.17379338840643566, Validation Accuracy: 0.4875\n",
      "Epoch 5813, Training Loss: 0.17352016125955888, Validation Loss: 0.1729270120461782, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 5814, Training Loss: 0.1734261594472393, Validation Loss: 0.17337005535761515, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 5815, Training Loss: 0.17355622783783944, Validation Loss: 0.173410431543986, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5816, Training Loss: 0.17359101147420944, Validation Loss: 0.17336511015892028, Validation Accuracy: 0.49375\n",
      "Epoch 5817, Training Loss: 0.17352647550644412, Validation Loss: 0.17329380412896475, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 5818, Training Loss: 0.1735179256046972, Validation Loss: 0.17325960397720336, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 5819, Training Loss: 0.17357468172427146, Validation Loss: 0.1734230081240336, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 5820, Training Loss: 0.17349387272711722, Validation Loss: 0.1732191264629364, Validation Accuracy: 0.5125\n",
      "Epoch 5821, Training Loss: 0.17359713056395132, Validation Loss: 0.173378586769104, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 5822, Training Loss: 0.17353372420034102, Validation Loss: 0.1730739454428355, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 5823, Training Loss: 0.17364178982473188, Validation Loss: 0.17358021438121796, Validation Accuracy: 0.48125\n",
      "Epoch 5824, Training Loss: 0.17344739648603624, Validation Loss: 0.1733167827129364, Validation Accuracy: 0.50625\n",
      "Epoch 5825, Training Loss: 0.17361794027589983, Validation Loss: 0.1736257622639338, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 5826, Training Loss: 0.17360490320190305, Validation Loss: 0.17299177944660188, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 5827, Training Loss: 0.17361424238451065, Validation Loss: 0.1736987789471944, Validation Accuracy: 0.475\n",
      "Epoch 5828, Training Loss: 0.1735580962511801, Validation Loss: 0.17322313785552979, Validation Accuracy: 0.5125\n",
      "Epoch 5829, Training Loss: 0.17360558432917442, Validation Loss: 0.17382424771785737, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 5830, Training Loss: 0.17358143916053156, Validation Loss: 0.17301907936731975, Validation Accuracy: 0.5375\n",
      "Epoch 5831, Training Loss: 0.17367510257228727, Validation Loss: 0.17363994419574738, Validation Accuracy: 0.4875\n",
      "Epoch 5832, Training Loss: 0.17352222531072556, Validation Loss: 0.1734788844982783, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 5833, Training Loss: 0.17356890680328493, Validation Loss: 0.1738039751847585, Validation Accuracy: 0.475\n",
      "Epoch 5834, Training Loss: 0.17369543400502974, Validation Loss: 0.1728896955649058, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 5835, Training Loss: 0.17359027410707167, Validation Loss: 0.1738818645477295, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 5836, Training Loss: 0.17347371145602195, Validation Loss: 0.1737439582745234, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5837, Training Loss: 0.1735612327052701, Validation Loss: 0.1736901581287384, Validation Accuracy: 0.4875\n",
      "Epoch 5838, Training Loss: 0.1737344394768438, Validation Loss: 0.17306262453397114, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 5839, Training Loss: 0.17353203700434777, Validation Loss: 0.17352071901162466, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 5840, Training Loss: 0.17381973468488263, Validation Loss: 0.17340831756591796, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5841, Training Loss: 0.17348536512544077, Validation Loss: 0.1735657423734665, Validation Accuracy: 0.49375\n",
      "Epoch 5842, Training Loss: 0.1738372714288773, Validation Loss: 0.17328696250915526, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 5843, Training Loss: 0.1735883859857436, Validation Loss: 0.17328197558720906, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 5844, Training Loss: 0.17383460364034098, Validation Loss: 0.17341670592625935, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 5845, Training Loss: 0.17358653055083367, Validation Loss: 0.17330154081185659, Validation Accuracy: 0.5125\n",
      "Epoch 5846, Training Loss: 0.1736186694714331, Validation Loss: 0.17387060721715292, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 5847, Training Loss: 0.17372230897026678, Validation Loss: 0.1729227026303609, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 5848, Training Loss: 0.17388665291570848, Validation Loss: 0.17346227367719014, Validation Accuracy: 0.48125\n",
      "Epoch 5849, Training Loss: 0.1734919197136356, Validation Loss: 0.173481089870135, Validation Accuracy: 0.50625\n",
      "Epoch 5850, Training Loss: 0.17391652205298025, Validation Loss: 0.17369427879651386, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 5851, Training Loss: 0.17357304788404895, Validation Loss: 0.1725311855475108, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 5852, Training Loss: 0.17397801481908368, Validation Loss: 0.17349385420481364, Validation Accuracy: 0.475\n",
      "Epoch 5853, Training Loss: 0.17352246132589155, Validation Loss: 0.1732612500588099, Validation Accuracy: 0.5125\n",
      "Epoch 5854, Training Loss: 0.17400896405020067, Validation Loss: 0.17348869343598683, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 5855, Training Loss: 0.17353472594291933, Validation Loss: 0.17268235484759012, Validation Accuracy: 0.5375\n",
      "Epoch 5856, Training Loss: 0.1739607217811769, Validation Loss: 0.173466627796491, Validation Accuracy: 0.4875\n",
      "Epoch 5857, Training Loss: 0.17354287351331404, Validation Loss: 0.1738320102294286, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 5858, Training Loss: 0.1739894329540191, Validation Loss: 0.17340350449085234, Validation Accuracy: 0.475\n",
      "Epoch 5859, Training Loss: 0.17355067595358817, Validation Loss: 0.1725381205479304, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 5860, Training Loss: 0.17402637437466653, Validation Loss: 0.17346126437187195, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 5861, Training Loss: 0.17352782045641252, Validation Loss: 0.1736081798871358, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5862, Training Loss: 0.1740418307242855, Validation Loss: 0.17336242496967316, Validation Accuracy: 0.4875\n",
      "Epoch 5863, Training Loss: 0.1735914469726624, Validation Loss: 0.17292840977509816, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 5864, Training Loss: 0.17411123312288715, Validation Loss: 0.17337199648221333, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 5865, Training Loss: 0.17356334530538128, Validation Loss: 0.17423449556032816, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5866, Training Loss: 0.17396798874101332, Validation Loss: 0.1733733574549357, Validation Accuracy: 0.49375\n",
      "Epoch 5867, Training Loss: 0.17377111363795497, Validation Loss: 0.1736304094394048, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 5868, Training Loss: 0.17399023473262787, Validation Loss: 0.17325698534647624, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 5869, Training Loss: 0.17351382393990794, Validation Loss: 0.17424955666065217, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 5870, Training Loss: 0.17423343370037694, Validation Loss: 0.17322075565656025, Validation Accuracy: 0.5125\n",
      "Epoch 5871, Training Loss: 0.17358293792893809, Validation Loss: 0.174672927459081, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 5872, Training Loss: 0.1741063181431063, Validation Loss: 0.17300583720207213, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 5873, Training Loss: 0.17354987609770992, Validation Loss: 0.17450257937113445, Validation Accuracy: 0.48125\n",
      "Epoch 5874, Training Loss: 0.17422180070031074, Validation Loss: 0.17329592406749725, Validation Accuracy: 0.50625\n",
      "Epoch 5875, Training Loss: 0.1734674515262727, Validation Loss: 0.1753242939710617, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 5876, Training Loss: 0.17434817744839576, Validation Loss: 0.17260919710000355, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 5877, Training Loss: 0.17340442009510532, Validation Loss: 0.1751565992832184, Validation Accuracy: 0.475\n",
      "Epoch 5878, Training Loss: 0.17429580467362557, Validation Loss: 0.17324852148691813, Validation Accuracy: 0.5125\n",
      "Epoch 5879, Training Loss: 0.17346811727170022, Validation Loss: 0.17524179617563884, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 5880, Training Loss: 0.17427461281899484, Validation Loss: 0.17275500098864238, Validation Accuracy: 0.5375\n",
      "Epoch 5881, Training Loss: 0.17346087098121643, Validation Loss: 0.1746387153863907, Validation Accuracy: 0.4875\n",
      "Epoch 5882, Training Loss: 0.1743017247607631, Validation Loss: 0.17381442685921986, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 5883, Training Loss: 0.17360310304549434, Validation Loss: 0.17511964042981465, Validation Accuracy: 0.475\n",
      "Epoch 5884, Training Loss: 0.17415519827796566, Validation Loss: 0.1721732864777247, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 5885, Training Loss: 0.1736023849056613, Validation Loss: 0.17507734894752502, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 5886, Training Loss: 0.17424740714411582, Validation Loss: 0.1738227794567744, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5887, Training Loss: 0.17351330287994876, Validation Loss: 0.17474382519721984, Validation Accuracy: 0.4875\n",
      "Epoch 5888, Training Loss: 0.17415567415375863, Validation Loss: 0.17273813486099243, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 5889, Training Loss: 0.17359011355907686, Validation Loss: 0.17435467739899954, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 5890, Training Loss: 0.17420456486363564, Validation Loss: 0.17399139006932576, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5891, Training Loss: 0.17360635390204768, Validation Loss: 0.1744919826587041, Validation Accuracy: 0.49375\n",
      "Epoch 5892, Training Loss: 0.17426455886133255, Validation Loss: 0.17369697093963624, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 5893, Training Loss: 0.17355647827348403, Validation Loss: 0.17382078965504963, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 5894, Training Loss: 0.17412425096957915, Validation Loss: 0.17453696429729462, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 5895, Training Loss: 0.17365578249577554, Validation Loss: 0.17369225521882375, Validation Accuracy: 0.5125\n",
      "Epoch 5896, Training Loss: 0.17419155999537436, Validation Loss: 0.17463077108065286, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 5897, Training Loss: 0.17376639862214366, Validation Loss: 0.17296934227148691, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 5898, Training Loss: 0.17410448866505776, Validation Loss: 0.17472651799519856, Validation Accuracy: 0.48125\n",
      "Epoch 5899, Training Loss: 0.17363717863636632, Validation Loss: 0.17384832898775737, Validation Accuracy: 0.50625\n",
      "Epoch 5900, Training Loss: 0.1742786241154517, Validation Loss: 0.1753067930539449, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 5901, Training Loss: 0.17379742524316233, Validation Loss: 0.1721398482720057, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 5902, Training Loss: 0.17403805592367727, Validation Loss: 0.1751771907011668, Validation Accuracy: 0.475\n",
      "Epoch 5903, Training Loss: 0.17394306342447957, Validation Loss: 0.17348799109458923, Validation Accuracy: 0.5125\n",
      "Epoch 5904, Training Loss: 0.17386849320703937, Validation Loss: 0.17570294439792633, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 5905, Training Loss: 0.17399623653581064, Validation Loss: 0.17266111969947814, Validation Accuracy: 0.5375\n",
      "Epoch 5906, Training Loss: 0.1737927568535651, Validation Loss: 0.17548946142196656, Validation Accuracy: 0.4875\n",
      "Epoch 5907, Training Loss: 0.1739627694891345, Validation Loss: 0.1742000718911489, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 5908, Training Loss: 0.17386909982850474, Validation Loss: 0.1755681057771047, Validation Accuracy: 0.475\n",
      "Epoch 5909, Training Loss: 0.1741051039388103, Validation Loss: 0.17194968263308208, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 5910, Training Loss: 0.17371015923638497, Validation Loss: 0.17668693164984386, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 5911, Training Loss: 0.1742271627149274, Validation Loss: 0.17387709617614747, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5912, Training Loss: 0.17368905871145188, Validation Loss: 0.17479050755500794, Validation Accuracy: 0.4875\n",
      "Epoch 5913, Training Loss: 0.17434251981396828, Validation Loss: 0.17272747457027435, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 5914, Training Loss: 0.17332468734633538, Validation Loss: 0.17509774565696717, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 5915, Training Loss: 0.17464396117195005, Validation Loss: 0.17386223673820494, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5916, Training Loss: 0.17359439067302213, Validation Loss: 0.17440421581268312, Validation Accuracy: 0.49375\n",
      "Epoch 5917, Training Loss: 0.17425142324739887, Validation Loss: 0.1736720363299052, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 5918, Training Loss: 0.17358645700639294, Validation Loss: 0.174383740623792, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 5919, Training Loss: 0.1743644259629711, Validation Loss: 0.17400061388810475, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 5920, Training Loss: 0.17371699550459463, Validation Loss: 0.1737229347229004, Validation Accuracy: 0.5125\n",
      "Epoch 5921, Training Loss: 0.17421304458572018, Validation Loss: 0.17431944608688354, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 5922, Training Loss: 0.17357093288052466, Validation Loss: 0.17314121623833975, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 5923, Training Loss: 0.17428495951237216, Validation Loss: 0.1740483691294988, Validation Accuracy: 0.48125\n",
      "Epoch 5924, Training Loss: 0.1737164234922778, Validation Loss: 0.17391267915566763, Validation Accuracy: 0.50625\n",
      "Epoch 5925, Training Loss: 0.17422767223850374, Validation Loss: 0.17460515002409618, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 5926, Training Loss: 0.17360125962764986, Validation Loss: 0.17207606236139933, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 5927, Training Loss: 0.17435565206312365, Validation Loss: 0.17404590745766957, Validation Accuracy: 0.475\n",
      "Epoch 5928, Training Loss: 0.17377764851816238, Validation Loss: 0.17349267701307933, Validation Accuracy: 0.5125\n",
      "Epoch 5929, Training Loss: 0.17419798527994462, Validation Loss: 0.17449946204821268, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 5930, Training Loss: 0.1735874169295834, Validation Loss: 0.17271343767642974, Validation Accuracy: 0.5375\n",
      "Epoch 5931, Training Loss: 0.17436871557466446, Validation Loss: 0.1737290879090627, Validation Accuracy: 0.4875\n",
      "Epoch 5932, Training Loss: 0.17364452683156537, Validation Loss: 0.17475750744342805, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 5933, Training Loss: 0.17431001701662618, Validation Loss: 0.17399790287017822, Validation Accuracy: 0.475\n",
      "Epoch 5934, Training Loss: 0.17374390123351927, Validation Loss: 0.17211024463176727, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 5935, Training Loss: 0.17419812131312587, Validation Loss: 0.1741025745868683, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 5936, Training Loss: 0.17384502868498525, Validation Loss: 0.17368341286977132, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5937, Training Loss: 0.1739960043661056, Validation Loss: 0.17415574590365093, Validation Accuracy: 0.4875\n",
      "Epoch 5938, Training Loss: 0.17381222065417998, Validation Loss: 0.17284138798713683, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 5939, Training Loss: 0.1742266628050035, Validation Loss: 0.1734581152598063, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 5940, Training Loss: 0.17385741635676352, Validation Loss: 0.17359676559766132, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5941, Training Loss: 0.17403653937001382, Validation Loss: 0.1737211227416992, Validation Accuracy: 0.49375\n",
      "Epoch 5942, Training Loss: 0.1737847150333466, Validation Loss: 0.17330010930697123, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 5943, Training Loss: 0.17417507017812422, Validation Loss: 0.173279203971227, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 5944, Training Loss: 0.17390297064858098, Validation Loss: 0.17344175378481547, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 5945, Training Loss: 0.1739762463877278, Validation Loss: 0.17324739098548889, Validation Accuracy: 0.5125\n",
      "Epoch 5946, Training Loss: 0.17390096235659816, Validation Loss: 0.1734630843003591, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 5947, Training Loss: 0.17406594705197118, Validation Loss: 0.17297150790691376, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 5948, Training Loss: 0.17398071385199024, Validation Loss: 0.17350653310616812, Validation Accuracy: 0.48125\n",
      "Epoch 5949, Training Loss: 0.1739768462796365, Validation Loss: 0.17335545619328815, Validation Accuracy: 0.50625\n",
      "Epoch 5950, Training Loss: 0.1738952931857878, Validation Loss: 0.1735312690337499, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 5951, Training Loss: 0.1741263755867558, Validation Loss: 0.17264556686083476, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 5952, Training Loss: 0.17388479459670284, Validation Loss: 0.17359429597854614, Validation Accuracy: 0.475\n",
      "Epoch 5953, Training Loss: 0.17401923095026323, Validation Loss: 0.17323110699653627, Validation Accuracy: 0.5125\n",
      "Epoch 5954, Training Loss: 0.17381173372268677, Validation Loss: 0.1736392617225647, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 5955, Training Loss: 0.17414508808043697, Validation Loss: 0.172879825035731, Validation Accuracy: 0.5375\n",
      "Epoch 5956, Training Loss: 0.17383031450933026, Validation Loss: 0.17357136110464733, Validation Accuracy: 0.4875\n",
      "Epoch 5957, Training Loss: 0.17406078163654573, Validation Loss: 0.1735787957906723, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 5958, Training Loss: 0.1737672177053267, Validation Loss: 0.1738079478343328, Validation Accuracy: 0.475\n",
      "Epoch 5959, Training Loss: 0.17423000595261973, Validation Loss: 0.17265530625979106, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 5960, Training Loss: 0.17377132850308571, Validation Loss: 0.1740080237388611, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 5961, Training Loss: 0.17414449876354587, Validation Loss: 0.17346517344315845, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5962, Training Loss: 0.17376778827559564, Validation Loss: 0.17374184528986614, Validation Accuracy: 0.4875\n",
      "Epoch 5963, Training Loss: 0.17417258408761793, Validation Loss: 0.17293911079565685, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 5964, Training Loss: 0.1737147064939622, Validation Loss: 0.1738147775332133, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 5965, Training Loss: 0.17425159917723748, Validation Loss: 0.1735432247320811, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5966, Training Loss: 0.17362806585527235, Validation Loss: 0.17366361021995544, Validation Accuracy: 0.49375\n",
      "Epoch 5967, Training Loss: 0.17430410750450626, Validation Loss: 0.17329981128374736, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 5968, Training Loss: 0.17377359972846124, Validation Loss: 0.17343054910500844, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 5969, Training Loss: 0.1741394482312664, Validation Loss: 0.1735995610555013, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 5970, Training Loss: 0.17374985016161396, Validation Loss: 0.17328305244445802, Validation Accuracy: 0.5125\n",
      "Epoch 5971, Training Loss: 0.17419255308566556, Validation Loss: 0.17359640995661418, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 5972, Training Loss: 0.17379439886539214, Validation Loss: 0.17290777663389842, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 5973, Training Loss: 0.1742018033419886, Validation Loss: 0.1735642264286677, Validation Accuracy: 0.48125\n",
      "Epoch 5974, Training Loss: 0.1735839795681738, Validation Loss: 0.17351472079753877, Validation Accuracy: 0.50625\n",
      "Epoch 5975, Training Loss: 0.17437120743336215, Validation Loss: 0.1736076255639394, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 5976, Training Loss: 0.17359669362345048, Validation Loss: 0.17220758497714997, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 5977, Training Loss: 0.17435440997923574, Validation Loss: 0.1736154854297638, Validation Accuracy: 0.475\n",
      "Epoch 5978, Training Loss: 0.17361413375023874, Validation Loss: 0.17337916394074757, Validation Accuracy: 0.5125\n",
      "Epoch 5979, Training Loss: 0.17425182413670323, Validation Loss: 0.1736389567454656, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 5980, Training Loss: 0.17369282005294676, Validation Loss: 0.172666472196579, Validation Accuracy: 0.5375\n",
      "Epoch 5981, Training Loss: 0.17434097730344342, Validation Loss: 0.17351231674353282, Validation Accuracy: 0.4875\n",
      "Epoch 5982, Training Loss: 0.17360090007705073, Validation Loss: 0.17414236068725586, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 5983, Training Loss: 0.17436026661626755, Validation Loss: 0.17351566155751547, Validation Accuracy: 0.475\n",
      "Epoch 5984, Training Loss: 0.17358031099842441, Validation Loss: 0.17205489079157513, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 5985, Training Loss: 0.1744000296438894, Validation Loss: 0.173698295156161, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 5986, Training Loss: 0.17358939541924384, Validation Loss: 0.17422382632891337, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5987, Training Loss: 0.17433506442654517, Validation Loss: 0.17344491481781005, Validation Accuracy: 0.4875\n",
      "Epoch 5988, Training Loss: 0.17363658739674476, Validation Loss: 0.1727411299943924, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 5989, Training Loss: 0.1743296778971149, Validation Loss: 0.1734349697828293, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 5990, Training Loss: 0.17361847864043328, Validation Loss: 0.17421439588069915, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 5991, Training Loss: 0.17436268637257238, Validation Loss: 0.17339422404766083, Validation Accuracy: 0.49375\n",
      "Epoch 5992, Training Loss: 0.17366788079661707, Validation Loss: 0.1736707478761673, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 5993, Training Loss: 0.17429120694437333, Validation Loss: 0.1732614705959956, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 5994, Training Loss: 0.1735298321131737, Validation Loss: 0.17461658616860706, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 5995, Training Loss: 0.17443490941678325, Validation Loss: 0.17322136958440146, Validation Accuracy: 0.5125\n",
      "Epoch 5996, Training Loss: 0.17357420729052636, Validation Loss: 0.17415648698806763, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 5997, Training Loss: 0.17436456343820017, Validation Loss: 0.1729922652244568, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 5998, Training Loss: 0.17355740791366947, Validation Loss: 0.17477298279603323, Validation Accuracy: 0.48125\n",
      "Epoch 5999, Training Loss: 0.1743989961762582, Validation Loss: 0.1732818712790807, Validation Accuracy: 0.50625\n",
      "Epoch 6000, Training Loss: 0.17347250157786953, Validation Loss: 0.17514700591564178, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 6001, Training Loss: 0.17427652978128003, Validation Loss: 0.17315867741902669, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 6002, Training Loss: 0.17356448163909297, Validation Loss: 0.17453590035438538, Validation Accuracy: 0.475\n",
      "Epoch 6003, Training Loss: 0.17447203397750854, Validation Loss: 0.1732203503449758, Validation Accuracy: 0.5125\n",
      "Epoch 6004, Training Loss: 0.17343875717732213, Validation Loss: 0.17535396416982016, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 6005, Training Loss: 0.17445699005357682, Validation Loss: 0.17274645169576008, Validation Accuracy: 0.5375\n",
      "Epoch 6006, Training Loss: 0.17348352987920085, Validation Loss: 0.17465437650680543, Validation Accuracy: 0.4875\n",
      "Epoch 6007, Training Loss: 0.1745511466456998, Validation Loss: 0.17369085947672527, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 6008, Training Loss: 0.17353134578274143, Validation Loss: 0.17502706348896027, Validation Accuracy: 0.475\n",
      "Epoch 6009, Training Loss: 0.1744371239216097, Validation Loss: 0.17216849327087402, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 6010, Training Loss: 0.17353634295925016, Validation Loss: 0.17515919208526612, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 6011, Training Loss: 0.1743960351713242, Validation Loss: 0.17390930255254108, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6012, Training Loss: 0.1735030609753824, Validation Loss: 0.17460376818974813, Validation Accuracy: 0.4875\n",
      "Epoch 6013, Training Loss: 0.17436625592170224, Validation Loss: 0.17273297409216562, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 6014, Training Loss: 0.17352743254553887, Validation Loss: 0.17431310812632242, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 6015, Training Loss: 0.1743130558921445, Validation Loss: 0.1741397668917974, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6016, Training Loss: 0.17361677654327884, Validation Loss: 0.17441334823767343, Validation Accuracy: 0.49375\n",
      "Epoch 6017, Training Loss: 0.1743259838511867, Validation Loss: 0.17375704050064086, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 6018, Training Loss: 0.17360373129767756, Validation Loss: 0.17380463580290476, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 6019, Training Loss: 0.17416421588390105, Validation Loss: 0.17468420366446177, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 6020, Training Loss: 0.17369416163813683, Validation Loss: 0.17359121044476827, Validation Accuracy: 0.5125\n",
      "Epoch 6021, Training Loss: 0.1743244557611404, Validation Loss: 0.17486246526241303, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 6022, Training Loss: 0.17372244356140013, Validation Loss: 0.17294825613498688, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 6023, Training Loss: 0.174229048913525, Validation Loss: 0.17504254678885142, Validation Accuracy: 0.48125\n",
      "Epoch 6024, Training Loss: 0.17364974175730058, Validation Loss: 0.17367564837137858, Validation Accuracy: 0.50625\n",
      "Epoch 6025, Training Loss: 0.1743713117414905, Validation Loss: 0.17552506426970163, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 6026, Training Loss: 0.17377380401857437, Validation Loss: 0.1721811294555664, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 6027, Training Loss: 0.17413077046794276, Validation Loss: 0.17559367418289185, Validation Accuracy: 0.475\n",
      "Epoch 6028, Training Loss: 0.17387279627784605, Validation Loss: 0.17342632015546164, Validation Accuracy: 0.5125\n",
      "Epoch 6029, Training Loss: 0.17392662936641323, Validation Loss: 0.17570580542087555, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 6030, Training Loss: 0.17400352128090396, Validation Loss: 0.1726599931716919, Validation Accuracy: 0.5375\n",
      "Epoch 6031, Training Loss: 0.17381807681052916, Validation Loss: 0.17523957490921022, Validation Accuracy: 0.4875\n",
      "Epoch 6032, Training Loss: 0.1740087237088911, Validation Loss: 0.17411678234736125, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 6033, Training Loss: 0.17391376966430294, Validation Loss: 0.1758144587278366, Validation Accuracy: 0.475\n",
      "Epoch 6034, Training Loss: 0.17411551888911955, Validation Loss: 0.1719695101181666, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 6035, Training Loss: 0.17376072272177664, Validation Loss: 0.17601861258347828, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 6036, Training Loss: 0.17421561287295434, Validation Loss: 0.17394475936889647, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6037, Training Loss: 0.173676329755014, Validation Loss: 0.17492374181747436, Validation Accuracy: 0.4875\n",
      "Epoch 6038, Training Loss: 0.17436730957800342, Validation Loss: 0.17273907562096913, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 6039, Training Loss: 0.1733231318573798, Validation Loss: 0.1755334476629893, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 6040, Training Loss: 0.17469238946514745, Validation Loss: 0.17374776204427084, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6041, Training Loss: 0.17361136886381334, Validation Loss: 0.17461151281992596, Validation Accuracy: 0.49375\n",
      "Epoch 6042, Training Loss: 0.1742633052410618, Validation Loss: 0.1735604594151179, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 6043, Training Loss: 0.17363263906971102, Validation Loss: 0.17417495250701903, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 6044, Training Loss: 0.17435796558856964, Validation Loss: 0.17399362524350484, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 6045, Training Loss: 0.17369519847054635, Validation Loss: 0.17396282156308493, Validation Accuracy: 0.5125\n",
      "Epoch 6046, Training Loss: 0.1742704847166615, Validation Loss: 0.17412633697191873, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 6047, Training Loss: 0.17356428552058437, Validation Loss: 0.1732710748910904, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 6048, Training Loss: 0.1743383902695871, Validation Loss: 0.17394722898801168, Validation Accuracy: 0.48125\n",
      "Epoch 6049, Training Loss: 0.17371219925342068, Validation Loss: 0.17400121092796325, Validation Accuracy: 0.50625\n",
      "Epoch 6050, Training Loss: 0.17424339344424586, Validation Loss: 0.17450938920180004, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 6051, Training Loss: 0.17362254521539133, Validation Loss: 0.1720747043689092, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 6052, Training Loss: 0.17436714230045194, Validation Loss: 0.17398137152194976, Validation Accuracy: 0.475\n",
      "Epoch 6053, Training Loss: 0.17372444320109584, Validation Loss: 0.1737152874469757, Validation Accuracy: 0.5125\n",
      "Epoch 6054, Training Loss: 0.17413569650342386, Validation Loss: 0.1751476675271988, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 6055, Training Loss: 0.17362366280248087, Validation Loss: 0.17269930044809978, Validation Accuracy: 0.5375\n",
      "Epoch 6056, Training Loss: 0.17437204958931093, Validation Loss: 0.17369704941908518, Validation Accuracy: 0.4875\n",
      "Epoch 6057, Training Loss: 0.17376918850406523, Validation Loss: 0.1741771012544632, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 6058, Training Loss: 0.1741965913003491, Validation Loss: 0.17417250076929727, Validation Accuracy: 0.475\n",
      "Epoch 6059, Training Loss: 0.17366666851505155, Validation Loss: 0.1717234949270884, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 6060, Training Loss: 0.17433956553859095, Validation Loss: 0.1738180160522461, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 6061, Training Loss: 0.17379354565374314, Validation Loss: 0.17373244365056356, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6062, Training Loss: 0.1741391146375287, Validation Loss: 0.1738232046365738, Validation Accuracy: 0.4875\n",
      "Epoch 6063, Training Loss: 0.17378889360735494, Validation Loss: 0.17276615301767986, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 6064, Training Loss: 0.17425187508906087, Validation Loss: 0.17343892951806386, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 6065, Training Loss: 0.17384317853758413, Validation Loss: 0.17342358430226643, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6066, Training Loss: 0.17409986642099196, Validation Loss: 0.1736342877149582, Validation Accuracy: 0.49375\n",
      "Epoch 6067, Training Loss: 0.1737906687682675, Validation Loss: 0.17330421408017477, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 6068, Training Loss: 0.17417559027671814, Validation Loss: 0.1732763042052587, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 6069, Training Loss: 0.17389733416418876, Validation Loss: 0.17344756722450255, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 6070, Training Loss: 0.17399549532321193, Validation Loss: 0.17323444883028666, Validation Accuracy: 0.5125\n",
      "Epoch 6071, Training Loss: 0.17389494709430203, Validation Loss: 0.17347558240095776, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 6072, Training Loss: 0.17410506115805718, Validation Loss: 0.17300587793191274, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 6073, Training Loss: 0.17392093135464576, Validation Loss: 0.17349045077959696, Validation Accuracy: 0.48125\n",
      "Epoch 6074, Training Loss: 0.17403090480835207, Validation Loss: 0.17334523499011995, Validation Accuracy: 0.50625\n",
      "Epoch 6075, Training Loss: 0.17389057432451555, Validation Loss: 0.17355620761712393, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 6076, Training Loss: 0.17420802001030214, Validation Loss: 0.17284302314122518, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 6077, Training Loss: 0.17387522997394686, Validation Loss: 0.17355514963467916, Validation Accuracy: 0.475\n",
      "Epoch 6078, Training Loss: 0.17406418246607627, Validation Loss: 0.17322320342063904, Validation Accuracy: 0.5125\n",
      "Epoch 6079, Training Loss: 0.17385622762864636, Validation Loss: 0.17366109291712442, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 6080, Training Loss: 0.17418544330904562, Validation Loss: 0.1729704648256302, Validation Accuracy: 0.5375\n",
      "Epoch 6081, Training Loss: 0.1738609383183141, Validation Loss: 0.17357364296913147, Validation Accuracy: 0.4875\n",
      "Epoch 6082, Training Loss: 0.17411426478816616, Validation Loss: 0.17348143458366394, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 6083, Training Loss: 0.17379833854013874, Validation Loss: 0.17373754878838857, Validation Accuracy: 0.475\n",
      "Epoch 6084, Training Loss: 0.17420868335231657, Validation Loss: 0.17272132734457651, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 6085, Training Loss: 0.17385455917927525, Validation Loss: 0.17426022390524545, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 6086, Training Loss: 0.17415096394477353, Validation Loss: 0.1734384338061015, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6087, Training Loss: 0.1737498386252311, Validation Loss: 0.1736969788869222, Validation Accuracy: 0.4875\n",
      "Epoch 6088, Training Loss: 0.17427236562775028, Validation Loss: 0.17303908467292786, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 6089, Training Loss: 0.17366359983721086, Validation Loss: 0.17364849050839742, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 6090, Training Loss: 0.17436022143210134, Validation Loss: 0.1733908216158549, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6091, Training Loss: 0.17366930025239144, Validation Loss: 0.1736773133277893, Validation Accuracy: 0.49375\n",
      "Epoch 6092, Training Loss: 0.1742959176340411, Validation Loss: 0.17329342166582742, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 6093, Training Loss: 0.17375022845883523, Validation Loss: 0.17332491079966228, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 6094, Training Loss: 0.17425618537010684, Validation Loss: 0.17345733841260275, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 6095, Training Loss: 0.17373872380102834, Validation Loss: 0.17326050301392873, Validation Accuracy: 0.5125\n",
      "Epoch 6096, Training Loss: 0.17423706237346895, Validation Loss: 0.17346551716327668, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 6097, Training Loss: 0.1738008544329674, Validation Loss: 0.17290843824545543, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 6098, Training Loss: 0.17419729021287733, Validation Loss: 0.17349857091903687, Validation Accuracy: 0.48125\n",
      "Epoch 6099, Training Loss: 0.17363060097540578, Validation Loss: 0.17345908184846243, Validation Accuracy: 0.50625\n",
      "Epoch 6100, Training Loss: 0.17431997772186034, Validation Loss: 0.17355027198791503, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 6101, Training Loss: 0.17371131143262308, Validation Loss: 0.17231896022955576, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 6102, Training Loss: 0.17426936232274579, Validation Loss: 0.17356781264146168, Validation Accuracy: 0.475\n",
      "Epoch 6103, Training Loss: 0.1736443441721701, Validation Loss: 0.17332803606987, Validation Accuracy: 0.5125\n",
      "Epoch 6104, Training Loss: 0.17442691037731786, Validation Loss: 0.1734324167172114, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 6105, Training Loss: 0.17363038178413145, Validation Loss: 0.17267786661783854, Validation Accuracy: 0.5375\n",
      "Epoch 6106, Training Loss: 0.17431786031492294, Validation Loss: 0.17346040904521942, Validation Accuracy: 0.4875\n",
      "Epoch 6107, Training Loss: 0.17365126215642498, Validation Loss: 0.17380226751168568, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 6108, Training Loss: 0.17439365723440725, Validation Loss: 0.17344484925270082, Validation Accuracy: 0.475\n",
      "Epoch 6109, Training Loss: 0.17360638899187888, Validation Loss: 0.17216201722621918, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 6110, Training Loss: 0.1744196294776855, Validation Loss: 0.17352294325828552, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 6111, Training Loss: 0.17361654341220856, Validation Loss: 0.1741137186686198, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6112, Training Loss: 0.1743510471236321, Validation Loss: 0.17338966131210326, Validation Accuracy: 0.4875\n",
      "Epoch 6113, Training Loss: 0.17368208448733052, Validation Loss: 0.1727708488702774, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 6114, Training Loss: 0.1743409965307482, Validation Loss: 0.17334563533465067, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 6115, Training Loss: 0.17363563852925454, Validation Loss: 0.1740128755569458, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6116, Training Loss: 0.17439857894374478, Validation Loss: 0.17334437171618144, Validation Accuracy: 0.49375\n",
      "Epoch 6117, Training Loss: 0.17368239548898512, Validation Loss: 0.1735307067632675, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 6118, Training Loss: 0.1743388868147327, Validation Loss: 0.17325582305590312, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 6119, Training Loss: 0.1735514037070736, Validation Loss: 0.174584099650383, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 6120, Training Loss: 0.17447400525692972, Validation Loss: 0.17322264313697816, Validation Accuracy: 0.5125\n",
      "Epoch 6121, Training Loss: 0.1736121461276085, Validation Loss: 0.17469856937726339, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 6122, Training Loss: 0.1743691130991905, Validation Loss: 0.17306680579980213, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 6123, Training Loss: 0.1735770130349744, Validation Loss: 0.1748041828473409, Validation Accuracy: 0.48125\n",
      "Epoch 6124, Training Loss: 0.17442915131968836, Validation Loss: 0.17328525483608245, Validation Accuracy: 0.50625\n",
      "Epoch 6125, Training Loss: 0.17349077232422366, Validation Loss: 0.1757077137629191, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 6126, Training Loss: 0.17439681387716724, Validation Loss: 0.17311145663261412, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 6127, Training Loss: 0.17351291593044035, Validation Loss: 0.1749049663543701, Validation Accuracy: 0.475\n",
      "Epoch 6128, Training Loss: 0.1745714824045858, Validation Loss: 0.17322085897127787, Validation Accuracy: 0.5125\n",
      "Epoch 6129, Training Loss: 0.17341246720283263, Validation Loss: 0.1756241927544276, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 6130, Training Loss: 0.1745180271325573, Validation Loss: 0.17280595600605012, Validation Accuracy: 0.5375\n",
      "Epoch 6131, Training Loss: 0.17347656238463618, Validation Loss: 0.1748079886039098, Validation Accuracy: 0.4875\n",
      "Epoch 6132, Training Loss: 0.17458118498325348, Validation Loss: 0.17362147867679595, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 6133, Training Loss: 0.1735475827609339, Validation Loss: 0.17533409198125202, Validation Accuracy: 0.475\n",
      "Epoch 6134, Training Loss: 0.1744444432758516, Validation Loss: 0.17231814960638683, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 6135, Training Loss: 0.17357820032104368, Validation Loss: 0.17545310854911805, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 6136, Training Loss: 0.17441632911082236, Validation Loss: 0.17373095949490866, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6137, Training Loss: 0.17350037011408037, Validation Loss: 0.1748520165681839, Validation Accuracy: 0.4875\n",
      "Epoch 6138, Training Loss: 0.17432337807070825, Validation Loss: 0.17305178145567576, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 6139, Training Loss: 0.1734862236245986, Validation Loss: 0.17459381818771363, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 6140, Training Loss: 0.1744123029132043, Validation Loss: 0.17395246922969818, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6141, Training Loss: 0.1735561946707387, Validation Loss: 0.17460877001285552, Validation Accuracy: 0.49375\n",
      "Epoch 6142, Training Loss: 0.1744045009536128, Validation Loss: 0.1737124373515447, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 6143, Training Loss: 0.1735901347091121, Validation Loss: 0.17394832670688629, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 6144, Training Loss: 0.17427875389975886, Validation Loss: 0.17454175353050233, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 6145, Training Loss: 0.1736051151829381, Validation Loss: 0.17371837397416431, Validation Accuracy: 0.5125\n",
      "Epoch 6146, Training Loss: 0.17435868180567218, Validation Loss: 0.17478518187999725, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 6147, Training Loss: 0.1737348259456696, Validation Loss: 0.17302931944529215, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 6148, Training Loss: 0.1742687182080361, Validation Loss: 0.17499200701713563, Validation Accuracy: 0.48125\n",
      "Epoch 6149, Training Loss: 0.17362738424731838, Validation Loss: 0.17386575639247895, Validation Accuracy: 0.50625\n",
      "Epoch 6150, Training Loss: 0.17448493838310242, Validation Loss: 0.1756789674361547, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 6151, Training Loss: 0.17373197309432492, Validation Loss: 0.1721311261256536, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 6152, Training Loss: 0.1742320671196907, Validation Loss: 0.17577528059482575, Validation Accuracy: 0.475\n",
      "Epoch 6153, Training Loss: 0.17380568385124207, Validation Loss: 0.17348117729028065, Validation Accuracy: 0.5125\n",
      "Epoch 6154, Training Loss: 0.17399845488609805, Validation Loss: 0.17602845132350922, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 6155, Training Loss: 0.1739697249666337, Validation Loss: 0.1726658801237742, Validation Accuracy: 0.5375\n",
      "Epoch 6156, Training Loss: 0.17390815673335905, Validation Loss: 0.17609870533148447, Validation Accuracy: 0.4875\n",
      "Epoch 6157, Training Loss: 0.17400015842530034, Validation Loss: 0.17399503688017529, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 6158, Training Loss: 0.17399499685533584, Validation Loss: 0.17609496911366782, Validation Accuracy: 0.475\n",
      "Epoch 6159, Training Loss: 0.17400676156243972, Validation Loss: 0.17186515231927235, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 6160, Training Loss: 0.17371302170138206, Validation Loss: 0.17662167648474375, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 6161, Training Loss: 0.17421209764096043, Validation Loss: 0.1739808311065038, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6162, Training Loss: 0.1737246508559873, Validation Loss: 0.17496796250343322, Validation Accuracy: 0.4875\n",
      "Epoch 6163, Training Loss: 0.1743820631696332, Validation Loss: 0.17272728979587554, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 6164, Training Loss: 0.1733548790216446, Validation Loss: 0.1756203552087148, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 6165, Training Loss: 0.17468290511638887, Validation Loss: 0.173776779572169, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6166, Training Loss: 0.17362507745142905, Validation Loss: 0.17496537466843923, Validation Accuracy: 0.49375\n",
      "Epoch 6167, Training Loss: 0.174323326637668, Validation Loss: 0.1735880861679713, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 6168, Training Loss: 0.17361938184307468, Validation Loss: 0.17462816834449768, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 6169, Training Loss: 0.1743937668300444, Validation Loss: 0.17394193013509116, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 6170, Training Loss: 0.17374004135208745, Validation Loss: 0.1740880350271861, Validation Accuracy: 0.5125\n",
      "Epoch 6171, Training Loss: 0.17428224317489133, Validation Loss: 0.17414554953575134, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 6172, Training Loss: 0.1735937282923729, Validation Loss: 0.1732935518026352, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 6173, Training Loss: 0.174294761592342, Validation Loss: 0.17400948107242584, Validation Accuracy: 0.48125\n",
      "Epoch 6174, Training Loss: 0.17375927442504513, Validation Loss: 0.17406013309955598, Validation Accuracy: 0.50625\n",
      "Epoch 6175, Training Loss: 0.1742990973495668, Validation Loss: 0.1744784305493037, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 6176, Training Loss: 0.17361355164358694, Validation Loss: 0.17211330632368724, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 6177, Training Loss: 0.1744067769858145, Validation Loss: 0.1739073355992635, Validation Accuracy: 0.475\n",
      "Epoch 6178, Training Loss: 0.17370697807881139, Validation Loss: 0.17382288575172425, Validation Accuracy: 0.5125\n",
      "Epoch 6179, Training Loss: 0.1743539398716342, Validation Loss: 0.17413189311822255, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 6180, Training Loss: 0.17361591660207318, Validation Loss: 0.17270111044247946, Validation Accuracy: 0.5375\n",
      "Epoch 6181, Training Loss: 0.17438683538667618, Validation Loss: 0.17365940908590952, Validation Accuracy: 0.4875\n",
      "Epoch 6182, Training Loss: 0.1737121271510278, Validation Loss: 0.1747194468975067, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 6183, Training Loss: 0.17409176163135037, Validation Loss: 0.17455696165561677, Validation Accuracy: 0.475\n",
      "Epoch 6184, Training Loss: 0.17372117119450722, Validation Loss: 0.17168429692586262, Validation Accuracy: 0.5604166666666667\n",
      "New best validation loss, checkpoint saved\n",
      "Epoch 6185, Training Loss: 0.17427468396002246, Validation Loss: 0.17395935157934825, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 6186, Training Loss: 0.1738558954769565, Validation Loss: 0.17416039407253264, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6187, Training Loss: 0.17389223700569523, Validation Loss: 0.17465238372484843, Validation Accuracy: 0.4875\n",
      "Epoch 6188, Training Loss: 0.17382606912043788, Validation Loss: 0.17290296653906503, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 6189, Training Loss: 0.1741619494653517, Validation Loss: 0.17354069749514262, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 6190, Training Loss: 0.17380559877041848, Validation Loss: 0.17364869316418965, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6191, Training Loss: 0.1742264392875856, Validation Loss: 0.17342984974384307, Validation Accuracy: 0.49375\n",
      "Epoch 6192, Training Loss: 0.17384337705950584, Validation Loss: 0.17329076131184895, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 6193, Training Loss: 0.17412111547685438, Validation Loss: 0.17328291138013205, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 6194, Training Loss: 0.17402594897054857, Validation Loss: 0.1735717236995697, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 6195, Training Loss: 0.1738498826180735, Validation Loss: 0.17326937317848207, Validation Accuracy: 0.5125\n",
      "Epoch 6196, Training Loss: 0.17397318203603068, Validation Loss: 0.17349957823753356, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 6197, Training Loss: 0.17412187495539266, Validation Loss: 0.17303039928277333, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 6198, Training Loss: 0.1739698600384497, Validation Loss: 0.17349031070868173, Validation Accuracy: 0.48125\n",
      "Epoch 6199, Training Loss: 0.17403342070118075, Validation Loss: 0.17332913378874462, Validation Accuracy: 0.50625\n",
      "Epoch 6200, Training Loss: 0.17392856988214678, Validation Loss: 0.17356516420841217, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 6201, Training Loss: 0.17420102511682817, Validation Loss: 0.17288544277350107, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 6202, Training Loss: 0.1738776377131862, Validation Loss: 0.1736368268728256, Validation Accuracy: 0.475\n",
      "Epoch 6203, Training Loss: 0.17414510586569387, Validation Loss: 0.17321949402491252, Validation Accuracy: 0.5125\n",
      "Epoch 6204, Training Loss: 0.17384391734676977, Validation Loss: 0.1736333876848221, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 6205, Training Loss: 0.17416927026164147, Validation Loss: 0.17299287617206574, Validation Accuracy: 0.5375\n",
      "Epoch 6206, Training Loss: 0.1739394208115916, Validation Loss: 0.17362796068191527, Validation Accuracy: 0.4875\n",
      "Epoch 6207, Training Loss: 0.1739841425611127, Validation Loss: 0.17360447545846303, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 6208, Training Loss: 0.17384533920595724, Validation Loss: 0.173960883418719, Validation Accuracy: 0.475\n",
      "Epoch 6209, Training Loss: 0.1742415831935021, Validation Loss: 0.17288164099057515, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 6210, Training Loss: 0.17388290791742264, Validation Loss: 0.17396562894185383, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 6211, Training Loss: 0.17409784466989578, Validation Loss: 0.17345239520072936, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6212, Training Loss: 0.17377347715439334, Validation Loss: 0.17389636834462482, Validation Accuracy: 0.4875\n",
      "Epoch 6213, Training Loss: 0.17427742192822118, Validation Loss: 0.17308372557163237, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 6214, Training Loss: 0.17374683916568756, Validation Loss: 0.17366478939851124, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 6215, Training Loss: 0.17426307835886556, Validation Loss: 0.1734154184659322, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6216, Training Loss: 0.1736885371708101, Validation Loss: 0.17365732888380686, Validation Accuracy: 0.49375\n",
      "Epoch 6217, Training Loss: 0.17431259828229104, Validation Loss: 0.17328499952952067, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 6218, Training Loss: 0.17381356993029196, Validation Loss: 0.17331061561902364, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 6219, Training Loss: 0.17420687838908164, Validation Loss: 0.17346298595269521, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 6220, Training Loss: 0.17376000506262626, Validation Loss: 0.17325166662534078, Validation Accuracy: 0.5125\n",
      "Epoch 6221, Training Loss: 0.17427689654211845, Validation Loss: 0.17341160774230957, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 6222, Training Loss: 0.17382842542663698, Validation Loss: 0.17290854553381602, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 6223, Training Loss: 0.17418828702742054, Validation Loss: 0.1734863479932149, Validation Accuracy: 0.48125\n",
      "Epoch 6224, Training Loss: 0.17360929712172476, Validation Loss: 0.17348720331986744, Validation Accuracy: 0.50625\n",
      "Epoch 6225, Training Loss: 0.17441244471457698, Validation Loss: 0.17347254355748495, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 6226, Training Loss: 0.17369217930301542, Validation Loss: 0.17219088872273763, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 6227, Training Loss: 0.1742575870406243, Validation Loss: 0.17359941005706786, Validation Accuracy: 0.475\n",
      "Epoch 6228, Training Loss: 0.17366154107355303, Validation Loss: 0.1732666939496994, Validation Accuracy: 0.5125\n",
      "Epoch 6229, Training Loss: 0.17438630182896891, Validation Loss: 0.17346642712752025, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 6230, Training Loss: 0.17368028288887394, Validation Loss: 0.1726846883694331, Validation Accuracy: 0.5375\n",
      "Epoch 6231, Training Loss: 0.17425198949152423, Validation Loss: 0.17349837124347686, Validation Accuracy: 0.4875\n",
      "Epoch 6232, Training Loss: 0.1736731106235135, Validation Loss: 0.17386462887128193, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 6233, Training Loss: 0.1743524213952403, Validation Loss: 0.17344931960105897, Validation Accuracy: 0.475\n",
      "Epoch 6234, Training Loss: 0.17370254330096707, Validation Loss: 0.17204435269037882, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 6235, Training Loss: 0.17398606384954146, Validation Loss: 0.17423743704954783, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 6236, Training Loss: 0.17382320761680603, Validation Loss: 0.17380989690621693, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6237, Training Loss: 0.17438662677041947, Validation Loss: 0.17341536680857342, Validation Accuracy: 0.4875\n",
      "Epoch 6238, Training Loss: 0.17370743713071268, Validation Loss: 0.1727307140827179, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 6239, Training Loss: 0.1742138881837168, Validation Loss: 0.1733745942513148, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 6240, Training Loss: 0.17372217534049864, Validation Loss: 0.17399836778640748, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6241, Training Loss: 0.17430899845015618, Validation Loss: 0.17330748637517293, Validation Accuracy: 0.49375\n",
      "Epoch 6242, Training Loss: 0.1737838993149419, Validation Loss: 0.17349105477333068, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 6243, Training Loss: 0.17430889077724948, Validation Loss: 0.17325694064299266, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 6244, Training Loss: 0.17358121420106581, Validation Loss: 0.17474128703276318, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 6245, Training Loss: 0.17443577464549773, Validation Loss: 0.17322359283765157, Validation Accuracy: 0.5125\n",
      "Epoch 6246, Training Loss: 0.17368593763920567, Validation Loss: 0.17493269940217335, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 6247, Training Loss: 0.17427736761108523, Validation Loss: 0.1730134834845861, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 6248, Training Loss: 0.17362426702053316, Validation Loss: 0.17455364167690277, Validation Accuracy: 0.48125\n",
      "Epoch 6249, Training Loss: 0.1743962101397976, Validation Loss: 0.17327237923940023, Validation Accuracy: 0.50625\n",
      "Epoch 6250, Training Loss: 0.17354300906581263, Validation Loss: 0.1756187359491984, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 6251, Training Loss: 0.1745055466890335, Validation Loss: 0.17287388344605764, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 6252, Training Loss: 0.17347605093832938, Validation Loss: 0.17554255425930024, Validation Accuracy: 0.475\n",
      "Epoch 6253, Training Loss: 0.17448981202417804, Validation Loss: 0.17321857810020447, Validation Accuracy: 0.5125\n",
      "Epoch 6254, Training Loss: 0.17350127812354796, Validation Loss: 0.17562616566816966, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 6255, Training Loss: 0.1744945030058584, Validation Loss: 0.17283668915430705, Validation Accuracy: 0.5375\n",
      "Epoch 6256, Training Loss: 0.17347304186513346, Validation Loss: 0.17497850755850475, Validation Accuracy: 0.4875\n",
      "Epoch 6257, Training Loss: 0.17458018420204038, Validation Loss: 0.17361198365688324, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 6258, Training Loss: 0.17358348110029775, Validation Loss: 0.17552202145258586, Validation Accuracy: 0.475\n",
      "Epoch 6259, Training Loss: 0.1743514605106846, Validation Loss: 0.1723593940337499, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 6260, Training Loss: 0.17365201490540658, Validation Loss: 0.17544417182604471, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 6261, Training Loss: 0.17440391788559576, Validation Loss: 0.17374680538972218, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6262, Training Loss: 0.17351785109889123, Validation Loss: 0.17495661278565725, Validation Accuracy: 0.4875\n",
      "Epoch 6263, Training Loss: 0.17412622176831768, Validation Loss: 0.1731604943672816, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 6264, Training Loss: 0.173634419998815, Validation Loss: 0.173861434062322, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 6265, Training Loss: 0.17441981165639817, Validation Loss: 0.17376822034517925, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6266, Training Loss: 0.17354132619596296, Validation Loss: 0.17470826903978984, Validation Accuracy: 0.49375\n",
      "Epoch 6267, Training Loss: 0.1744035674679664, Validation Loss: 0.17336029012997944, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 6268, Training Loss: 0.17342148577013322, Validation Loss: 0.1739019900560379, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 6269, Training Loss: 0.17435204213665378, Validation Loss: 0.17344036996364592, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 6270, Training Loss: 0.17351538279364187, Validation Loss: 0.17388270397981007, Validation Accuracy: 0.5125\n",
      "Epoch 6271, Training Loss: 0.17425828547246994, Validation Loss: 0.17469379703203838, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 6272, Training Loss: 0.17369745527544328, Validation Loss: 0.17303398350874583, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 6273, Training Loss: 0.1743244557611404, Validation Loss: 0.17473962903022766, Validation Accuracy: 0.48125\n",
      "Epoch 6274, Training Loss: 0.17349278830712841, Validation Loss: 0.17393357356389363, Validation Accuracy: 0.50625\n",
      "Epoch 6275, Training Loss: 0.17451757048406907, Validation Loss: 0.1754428078730901, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 6276, Training Loss: 0.17361398858408775, Validation Loss: 0.17217424809932708, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 6277, Training Loss: 0.17435116777496953, Validation Loss: 0.17575994928677877, Validation Accuracy: 0.475\n",
      "Epoch 6278, Training Loss: 0.17375122058776118, Validation Loss: 0.17343052824338276, Validation Accuracy: 0.5125\n",
      "Epoch 6279, Training Loss: 0.17398329559833772, Validation Loss: 0.1754324972629547, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 6280, Training Loss: 0.17401117711297928, Validation Loss: 0.17266115844249724, Validation Accuracy: 0.5375\n",
      "Epoch 6281, Training Loss: 0.1738407890642843, Validation Loss: 0.1755103478829066, Validation Accuracy: 0.4875\n",
      "Epoch 6282, Training Loss: 0.17401220288968855, Validation Loss: 0.17423029243946075, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 6283, Training Loss: 0.17397022295382716, Validation Loss: 0.17604876856009166, Validation Accuracy: 0.475\n",
      "Epoch 6284, Training Loss: 0.17411793479996343, Validation Loss: 0.17192557752132415, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 6285, Training Loss: 0.17379549145698547, Validation Loss: 0.17711282670497894, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 6286, Training Loss: 0.17424630541955272, Validation Loss: 0.1738649825255076, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6287, Training Loss: 0.1737211481217415, Validation Loss: 0.17526775896549224, Validation Accuracy: 0.4875\n",
      "Epoch 6288, Training Loss: 0.1744029098941434, Validation Loss: 0.17273203233877818, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 6289, Training Loss: 0.17339267557667148, Validation Loss: 0.1757297287384669, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 6290, Training Loss: 0.17467763971897862, Validation Loss: 0.17378170688947042, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6291, Training Loss: 0.17366638971913245, Validation Loss: 0.17448938290278118, Validation Accuracy: 0.49375\n",
      "Epoch 6292, Training Loss: 0.1742708832025528, Validation Loss: 0.17369042336940765, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 6293, Training Loss: 0.17364469891594303, Validation Loss: 0.174517426888148, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 6294, Training Loss: 0.17437072290528205, Validation Loss: 0.17396317919095358, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 6295, Training Loss: 0.173771119886829, Validation Loss: 0.17383577823638915, Validation Accuracy: 0.5125\n",
      "Epoch 6296, Training Loss: 0.17425091132040946, Validation Loss: 0.17427999873956043, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 6297, Training Loss: 0.17359503911387536, Validation Loss: 0.17329653004805248, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 6298, Training Loss: 0.17433792593017702, Validation Loss: 0.17395948966344196, Validation Accuracy: 0.48125\n",
      "Epoch 6299, Training Loss: 0.17371234441957167, Validation Loss: 0.17420779367287953, Validation Accuracy: 0.50625\n",
      "Epoch 6300, Training Loss: 0.1743259338601943, Validation Loss: 0.17439969877401987, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 6301, Training Loss: 0.17363997909330553, Validation Loss: 0.1720753014087677, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 6302, Training Loss: 0.1743687141326166, Validation Loss: 0.17398956815401714, Validation Accuracy: 0.475\n",
      "Epoch 6303, Training Loss: 0.17372664472749155, Validation Loss: 0.17375303010145823, Validation Accuracy: 0.5125\n",
      "Epoch 6304, Training Loss: 0.17424809500094382, Validation Loss: 0.17460469901561737, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 6305, Training Loss: 0.17362576194347873, Validation Loss: 0.1727951129277547, Validation Accuracy: 0.5375\n",
      "Epoch 6306, Training Loss: 0.17443244111153386, Validation Loss: 0.17363483905792237, Validation Accuracy: 0.4875\n",
      "Epoch 6307, Training Loss: 0.17385558351393668, Validation Loss: 0.1738778551419576, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 6308, Training Loss: 0.17410598070390762, Validation Loss: 0.17436395585536957, Validation Accuracy: 0.475\n",
      "Epoch 6309, Training Loss: 0.17372225561449606, Validation Loss: 0.17192731499671937, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 6310, Training Loss: 0.1743164889274105, Validation Loss: 0.1738049457470576, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 6311, Training Loss: 0.17389302868996898, Validation Loss: 0.17369774281978606, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6312, Training Loss: 0.1739324273601655, Validation Loss: 0.1745283583799998, Validation Accuracy: 0.4875\n",
      "Epoch 6313, Training Loss: 0.1738936564614696, Validation Loss: 0.17282926340897878, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 6314, Training Loss: 0.17422058649601474, Validation Loss: 0.17343772252400716, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 6315, Training Loss: 0.1739438493405619, Validation Loss: 0.17354753216107685, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6316, Training Loss: 0.17391745986477022, Validation Loss: 0.17423927485942842, Validation Accuracy: 0.49375\n",
      "Epoch 6317, Training Loss: 0.1739140696102573, Validation Loss: 0.1733479917049408, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 6318, Training Loss: 0.17406258035090663, Validation Loss: 0.1732860008875529, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 6319, Training Loss: 0.17403486851722963, Validation Loss: 0.17349109252293904, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 6320, Training Loss: 0.17391393069298036, Validation Loss: 0.1732555290063222, Validation Accuracy: 0.5125\n",
      "Epoch 6321, Training Loss: 0.1739657852918871, Validation Loss: 0.17347096900145212, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 6322, Training Loss: 0.17411556936079456, Validation Loss: 0.173041628797849, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 6323, Training Loss: 0.17396905633711046, Validation Loss: 0.17350925207138063, Validation Accuracy: 0.48125\n",
      "Epoch 6324, Training Loss: 0.17407827079296112, Validation Loss: 0.17329901456832886, Validation Accuracy: 0.50625\n",
      "Epoch 6325, Training Loss: 0.17388809592493118, Validation Loss: 0.17358643511931102, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 6326, Training Loss: 0.1741795140889383, Validation Loss: 0.1728568345308304, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 6327, Training Loss: 0.17390814375492833, Validation Loss: 0.1735927830139796, Validation Accuracy: 0.475\n",
      "Epoch 6328, Training Loss: 0.17410029951603181, Validation Loss: 0.1732173482577006, Validation Accuracy: 0.5125\n",
      "Epoch 6329, Training Loss: 0.17383932202093064, Validation Loss: 0.173678923646609, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 6330, Training Loss: 0.17418451414954278, Validation Loss: 0.1730226198832194, Validation Accuracy: 0.5375\n",
      "Epoch 6331, Training Loss: 0.1739338929614713, Validation Loss: 0.1735754579305649, Validation Accuracy: 0.4875\n",
      "Epoch 6332, Training Loss: 0.17405808404568704, Validation Loss: 0.17351528108119965, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 6333, Training Loss: 0.17379563854586694, Validation Loss: 0.1739966928958893, Validation Accuracy: 0.475\n",
      "Epoch 6334, Training Loss: 0.17416455716856064, Validation Loss: 0.1726854940255483, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 6335, Training Loss: 0.17391343366715215, Validation Loss: 0.17398299276828766, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 6336, Training Loss: 0.1741457336371945, Validation Loss: 0.17341401080290478, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6337, Training Loss: 0.17377714956960372, Validation Loss: 0.17368732790152233, Validation Accuracy: 0.4875\n",
      "Epoch 6338, Training Loss: 0.1742269492918445, Validation Loss: 0.173036190867424, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 6339, Training Loss: 0.17372140769035585, Validation Loss: 0.1736460655927658, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 6340, Training Loss: 0.17428789504112735, Validation Loss: 0.1734081357717514, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6341, Training Loss: 0.1737434652543837, Validation Loss: 0.17362549304962158, Validation Accuracy: 0.49375\n",
      "Epoch 6342, Training Loss: 0.1742823181613799, Validation Loss: 0.1732882301012675, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 6343, Training Loss: 0.17379305151201063, Validation Loss: 0.17332015037536622, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 6344, Training Loss: 0.17421690110237367, Validation Loss: 0.17344921429951984, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 6345, Training Loss: 0.17375783910674433, Validation Loss: 0.17324582735697427, Validation Accuracy: 0.5125\n",
      "Epoch 6346, Training Loss: 0.17428881891312137, Validation Loss: 0.17341653207937877, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 6347, Training Loss: 0.17382086140494193, Validation Loss: 0.17290818790594736, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 6348, Training Loss: 0.17386215781011888, Validation Loss: 0.17414472897847494, Validation Accuracy: 0.48125\n",
      "Epoch 6349, Training Loss: 0.17374648826737557, Validation Loss: 0.17367154757181805, Validation Accuracy: 0.50625\n",
      "Epoch 6350, Training Loss: 0.17443172104897037, Validation Loss: 0.17355745832125347, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 6351, Training Loss: 0.1737074270363777, Validation Loss: 0.1723298877477646, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 6352, Training Loss: 0.1742497451843754, Validation Loss: 0.1734756698211034, Validation Accuracy: 0.475\n",
      "Epoch 6353, Training Loss: 0.17370816392283286, Validation Loss: 0.17326119244098664, Validation Accuracy: 0.5125\n",
      "Epoch 6354, Training Loss: 0.17434830963611603, Validation Loss: 0.17348494827747346, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 6355, Training Loss: 0.17369983225099503, Validation Loss: 0.17266029020150503, Validation Accuracy: 0.5375\n",
      "Epoch 6356, Training Loss: 0.1742804233104952, Validation Loss: 0.17342437903086344, Validation Accuracy: 0.4875\n",
      "Epoch 6357, Training Loss: 0.1736350698817161, Validation Loss: 0.17365875244140624, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 6358, Training Loss: 0.17444699666192454, Validation Loss: 0.17343196670214336, Validation Accuracy: 0.475\n",
      "Epoch 6359, Training Loss: 0.17363989978067337, Validation Loss: 0.1720618615547816, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 6360, Training Loss: 0.17434787557971093, Validation Loss: 0.17351207236448923, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 6361, Training Loss: 0.17366235967605345, Validation Loss: 0.17383996546268463, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6362, Training Loss: 0.17439052991328702, Validation Loss: 0.17337115506331127, Validation Accuracy: 0.4875\n",
      "Epoch 6363, Training Loss: 0.1736910045146942, Validation Loss: 0.17272696296374004, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 6364, Training Loss: 0.17429984048489602, Validation Loss: 0.17333263258139292, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 6365, Training Loss: 0.1736552950835997, Validation Loss: 0.17366598943869274, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6366, Training Loss: 0.17429685111968748, Validation Loss: 0.1733142375946045, Validation Accuracy: 0.49375\n",
      "Epoch 6367, Training Loss: 0.17382394931008738, Validation Loss: 0.1736657092968623, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 6368, Training Loss: 0.17424704951624717, Validation Loss: 0.1732618421316147, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 6369, Training Loss: 0.17357870359574595, Validation Loss: 0.1744514246781667, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 6370, Training Loss: 0.17445072387495347, Validation Loss: 0.17322674294312795, Validation Accuracy: 0.5125\n",
      "Epoch 6371, Training Loss: 0.17367330481929164, Validation Loss: 0.17482913335164388, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 6372, Training Loss: 0.17431719601154327, Validation Loss: 0.17305160264174144, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 6373, Training Loss: 0.17362554563630012, Validation Loss: 0.17481931845347087, Validation Accuracy: 0.48125\n",
      "Epoch 6374, Training Loss: 0.17439300158331472, Validation Loss: 0.17327331006526947, Validation Accuracy: 0.50625\n",
      "Epoch 6375, Training Loss: 0.17353612472934107, Validation Loss: 0.17544018824895222, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 6376, Training Loss: 0.1745080308568093, Validation Loss: 0.17308800717194875, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 6377, Training Loss: 0.17349048247260432, Validation Loss: 0.17565770149230958, Validation Accuracy: 0.475\n",
      "Epoch 6378, Training Loss: 0.17424697645248904, Validation Loss: 0.17326717972755432, Validation Accuracy: 0.5125\n",
      "Epoch 6379, Training Loss: 0.17363859953418856, Validation Loss: 0.17499853074550628, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 6380, Training Loss: 0.17441940932504593, Validation Loss: 0.17285989820957184, Validation Accuracy: 0.5375\n",
      "Epoch 6381, Training Loss: 0.17347070574760437, Validation Loss: 0.17501532832781475, Validation Accuracy: 0.4875\n",
      "Epoch 6382, Training Loss: 0.17457902816034132, Validation Loss: 0.17364492217699687, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 6383, Training Loss: 0.17358944733296672, Validation Loss: 0.17538018226623536, Validation Accuracy: 0.475\n",
      "Epoch 6384, Training Loss: 0.17444944525918654, Validation Loss: 0.17232921123504638, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 6385, Training Loss: 0.17358062344212685, Validation Loss: 0.17551862100760143, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 6386, Training Loss: 0.17440759462694969, Validation Loss: 0.17364450792471567, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6387, Training Loss: 0.17354533556968935, Validation Loss: 0.17512276470661164, Validation Accuracy: 0.4875\n",
      "Epoch 6388, Training Loss: 0.17431873659933766, Validation Loss: 0.1727405955394109, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 6389, Training Loss: 0.1735819164783724, Validation Loss: 0.1745941698551178, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 6390, Training Loss: 0.17439906299114227, Validation Loss: 0.173833363254865, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6391, Training Loss: 0.1735666432688313, Validation Loss: 0.17492278118928273, Validation Accuracy: 0.49375\n",
      "Epoch 6392, Training Loss: 0.1743438224638662, Validation Loss: 0.17373307247956593, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 6393, Training Loss: 0.1736167827921529, Validation Loss: 0.1740519255399704, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 6394, Training Loss: 0.17427329670998357, Validation Loss: 0.17453079322973888, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 6395, Training Loss: 0.17361343916385405, Validation Loss: 0.17384826640288034, Validation Accuracy: 0.5125\n",
      "Epoch 6396, Training Loss: 0.17431688981671487, Validation Loss: 0.17471844255924224, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 6397, Training Loss: 0.17377400398254395, Validation Loss: 0.17302934924761454, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 6398, Training Loss: 0.17430993530058092, Validation Loss: 0.17494585911432903, Validation Accuracy: 0.48125\n",
      "Epoch 6399, Training Loss: 0.1735798942465936, Validation Loss: 0.17389392256736755, Validation Accuracy: 0.50625\n",
      "Epoch 6400, Training Loss: 0.17443294294418826, Validation Loss: 0.1751929670572281, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 6401, Training Loss: 0.17375985172487074, Validation Loss: 0.17225912908713023, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 6402, Training Loss: 0.17416456437879993, Validation Loss: 0.1756148099899292, Validation Accuracy: 0.475\n",
      "Epoch 6403, Training Loss: 0.1738146125308929, Validation Loss: 0.17346670627593994, Validation Accuracy: 0.5125\n",
      "Epoch 6404, Training Loss: 0.17397035898700838, Validation Loss: 0.17547565301259357, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 6405, Training Loss: 0.17402266110143355, Validation Loss: 0.17266098757584888, Validation Accuracy: 0.5375\n",
      "Epoch 6406, Training Loss: 0.17388493351397977, Validation Loss: 0.17566419740517933, Validation Accuracy: 0.4875\n",
      "Epoch 6407, Training Loss: 0.17397983612552767, Validation Loss: 0.17416374584039052, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 6408, Training Loss: 0.17398830959873815, Validation Loss: 0.17616644104321796, Validation Accuracy: 0.475\n",
      "Epoch 6409, Training Loss: 0.174097292846249, Validation Loss: 0.171915669242541, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 6410, Training Loss: 0.17377719859923085, Validation Loss: 0.1769404113292694, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 6411, Training Loss: 0.17421798119621892, Validation Loss: 0.17379338145256043, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6412, Training Loss: 0.17371698396821175, Validation Loss: 0.17526338001092276, Validation Accuracy: 0.4875\n",
      "Epoch 6413, Training Loss: 0.1744136699745732, Validation Loss: 0.17272700766722363, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 6414, Training Loss: 0.17331761025613354, Validation Loss: 0.17583685517311096, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 6415, Training Loss: 0.17472087808193698, Validation Loss: 0.17364651759465535, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6416, Training Loss: 0.17363839908953635, Validation Loss: 0.1752223829428355, Validation Accuracy: 0.49375\n",
      "Epoch 6417, Training Loss: 0.1743469416133819, Validation Loss: 0.17356258829434712, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 6418, Training Loss: 0.173626717059843, Validation Loss: 0.17475332021713258, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 6419, Training Loss: 0.17439279585115372, Validation Loss: 0.1738651971022288, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 6420, Training Loss: 0.1737792943754504, Validation Loss: 0.17418374319871266, Validation Accuracy: 0.5125\n",
      "Epoch 6421, Training Loss: 0.17425474428361462, Validation Loss: 0.17411437233289082, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 6422, Training Loss: 0.1735816136483223, Validation Loss: 0.17343144118785858, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 6423, Training Loss: 0.17437646081370692, Validation Loss: 0.17389304836591085, Validation Accuracy: 0.48125\n",
      "Epoch 6424, Training Loss: 0.17375113214215926, Validation Loss: 0.1739646424849828, Validation Accuracy: 0.50625\n",
      "Epoch 6425, Training Loss: 0.17425192219595756, Validation Loss: 0.1745767891407013, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 6426, Training Loss: 0.17365264411895506, Validation Loss: 0.17207473814487456, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 6427, Training Loss: 0.17436605307363695, Validation Loss: 0.1739873468875885, Validation Accuracy: 0.475\n",
      "Epoch 6428, Training Loss: 0.1736930219396468, Validation Loss: 0.17395237783590953, Validation Accuracy: 0.5125\n",
      "Epoch 6429, Training Loss: 0.1743981323895916, Validation Loss: 0.17405948638916016, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 6430, Training Loss: 0.1735778691307191, Validation Loss: 0.1727393627166748, Validation Accuracy: 0.5375\n",
      "Epoch 6431, Training Loss: 0.17441335705018812, Validation Loss: 0.17364469667275748, Validation Accuracy: 0.4875\n",
      "Epoch 6432, Training Loss: 0.17376059774429567, Validation Loss: 0.17437826097011566, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 6433, Training Loss: 0.17417666027622838, Validation Loss: 0.17440297901630403, Validation Accuracy: 0.475\n",
      "Epoch 6434, Training Loss: 0.17365067716567748, Validation Loss: 0.17166628440221152, Validation Accuracy: 0.5604166666666667\n",
      "New best validation loss, checkpoint saved\n",
      "Epoch 6435, Training Loss: 0.17438821350374528, Validation Loss: 0.17374486327171326, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 6436, Training Loss: 0.17389631511703615, Validation Loss: 0.17368285953998566, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6437, Training Loss: 0.17411630913134543, Validation Loss: 0.1738183965285619, Validation Accuracy: 0.4875\n",
      "Epoch 6438, Training Loss: 0.17383151092836935, Validation Loss: 0.17282966673374175, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 6439, Training Loss: 0.17423118747049762, Validation Loss: 0.17343994379043579, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 6440, Training Loss: 0.17385765717875573, Validation Loss: 0.1735187570254008, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6441, Training Loss: 0.17388449368938322, Validation Loss: 0.1744308054447174, Validation Accuracy: 0.49375\n",
      "Epoch 6442, Training Loss: 0.17388588718829617, Validation Loss: 0.1732981046040853, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 6443, Training Loss: 0.17412927410294932, Validation Loss: 0.17327949206034343, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 6444, Training Loss: 0.17392132359166299, Validation Loss: 0.17359637022018432, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 6445, Training Loss: 0.17361365066420648, Validation Loss: 0.1735767463843028, Validation Accuracy: 0.5125\n",
      "Epoch 6446, Training Loss: 0.17404628184533888, Validation Loss: 0.17347713212172192, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 6447, Training Loss: 0.1742038385521981, Validation Loss: 0.17304931581020355, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 6448, Training Loss: 0.173979303048503, Validation Loss: 0.1735026737054189, Validation Accuracy: 0.48125\n",
      "Epoch 6449, Training Loss: 0.17405836572570185, Validation Loss: 0.17330154081185659, Validation Accuracy: 0.50625\n",
      "Epoch 6450, Training Loss: 0.1739032547320089, Validation Loss: 0.1736299326022466, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 6451, Training Loss: 0.17418797554508333, Validation Loss: 0.1729206532239914, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 6452, Training Loss: 0.17402334847757894, Validation Loss: 0.17394143740336102, Validation Accuracy: 0.475\n",
      "Epoch 6453, Training Loss: 0.1738715652496584, Validation Loss: 0.17324261566003163, Validation Accuracy: 0.5125\n",
      "Epoch 6454, Training Loss: 0.17390188046040073, Validation Loss: 0.17375557124614716, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 6455, Training Loss: 0.17417136267308267, Validation Loss: 0.17302875717480978, Validation Accuracy: 0.5375\n",
      "Epoch 6456, Training Loss: 0.1739223426388156, Validation Loss: 0.1736116329828898, Validation Accuracy: 0.4875\n",
      "Epoch 6457, Training Loss: 0.17407101056268137, Validation Loss: 0.1734721193710963, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 6458, Training Loss: 0.173807795489988, Validation Loss: 0.17384759386380513, Validation Accuracy: 0.475\n",
      "Epoch 6459, Training Loss: 0.17422991077746114, Validation Loss: 0.17279998163382213, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 6460, Training Loss: 0.1738641002485829, Validation Loss: 0.17400692105293275, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 6461, Training Loss: 0.17373580028933863, Validation Loss: 0.17392196655273437, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6462, Training Loss: 0.17390528801948793, Validation Loss: 0.1737725834051768, Validation Accuracy: 0.4875\n",
      "Epoch 6463, Training Loss: 0.17414269428099355, Validation Loss: 0.17294001777966816, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 6464, Training Loss: 0.1737028379594126, Validation Loss: 0.17393162250518798, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 6465, Training Loss: 0.17437709867954254, Validation Loss: 0.17338797847429913, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6466, Training Loss: 0.17371007848170497, Validation Loss: 0.17366426984469097, Validation Accuracy: 0.49375\n",
      "Epoch 6467, Training Loss: 0.17429002927195641, Validation Loss: 0.1732890437046687, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 6468, Training Loss: 0.17379227424821547, Validation Loss: 0.17330775260925294, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 6469, Training Loss: 0.17424925921424742, Validation Loss: 0.1734292685985565, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 6470, Training Loss: 0.17375123933438333, Validation Loss: 0.17325141032536825, Validation Accuracy: 0.5125\n",
      "Epoch 6471, Training Loss: 0.17426478189806785, Validation Loss: 0.1734172483285268, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 6472, Training Loss: 0.1737897987327268, Validation Loss: 0.17292091647783916, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 6473, Training Loss: 0.1742659148670012, Validation Loss: 0.17345675428708393, Validation Accuracy: 0.48125\n",
      "Epoch 6474, Training Loss: 0.173632669352716, Validation Loss: 0.1734677920738856, Validation Accuracy: 0.50625\n",
      "Epoch 6475, Training Loss: 0.17439009922166024, Validation Loss: 0.17348362108071644, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 6476, Training Loss: 0.17369182840470346, Validation Loss: 0.17222379346688588, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 6477, Training Loss: 0.17428675774605043, Validation Loss: 0.1735900193452835, Validation Accuracy: 0.475\n",
      "Epoch 6478, Training Loss: 0.17369928715690489, Validation Loss: 0.17326205174128215, Validation Accuracy: 0.5125\n",
      "Epoch 6479, Training Loss: 0.1742940064399473, Validation Loss: 0.1735374003648758, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 6480, Training Loss: 0.17376910630733736, Validation Loss: 0.1726629982391993, Validation Accuracy: 0.5375\n",
      "Epoch 6481, Training Loss: 0.17420131256503443, Validation Loss: 0.17351942360401154, Validation Accuracy: 0.4875\n",
      "Epoch 6482, Training Loss: 0.1737367525216072, Validation Loss: 0.17385721405347188, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 6483, Training Loss: 0.174380176490353, Validation Loss: 0.1733975291252136, Validation Accuracy: 0.475\n",
      "Epoch 6484, Training Loss: 0.1736607772688712, Validation Loss: 0.1723186602195104, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 6485, Training Loss: 0.1741996378667893, Validation Loss: 0.17359642883141835, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 6486, Training Loss: 0.17368987298780872, Validation Loss: 0.17371456225713094, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6487, Training Loss: 0.17429258458075986, Validation Loss: 0.1733071486155192, Validation Accuracy: 0.4875\n",
      "Epoch 6488, Training Loss: 0.1737305449862634, Validation Loss: 0.17275284032026927, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 6489, Training Loss: 0.17423903797903367, Validation Loss: 0.1733388125896454, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 6490, Training Loss: 0.17368838046827623, Validation Loss: 0.17393290003140768, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6491, Training Loss: 0.17430348502051446, Validation Loss: 0.1732971300681432, Validation Accuracy: 0.49375\n",
      "Epoch 6492, Training Loss: 0.1736887510745756, Validation Loss: 0.17332970102628073, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 6493, Training Loss: 0.174388290893647, Validation Loss: 0.17325642108917236, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 6494, Training Loss: 0.17356981625480036, Validation Loss: 0.17505010763804119, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 6495, Training Loss: 0.17435763968575385, Validation Loss: 0.17322586476802826, Validation Accuracy: 0.5125\n",
      "Epoch 6496, Training Loss: 0.17378436221230414, Validation Loss: 0.1748335063457489, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 6497, Training Loss: 0.17420615592310507, Validation Loss: 0.1730029821395874, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 6498, Training Loss: 0.1736290882672033, Validation Loss: 0.1744059960047404, Validation Accuracy: 0.48125\n",
      "Epoch 6499, Training Loss: 0.1744182239617071, Validation Loss: 0.1732763836781184, Validation Accuracy: 0.50625\n",
      "Epoch 6500, Training Loss: 0.17355143014461763, Validation Loss: 0.17569837371508282, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 6501, Training Loss: 0.17445874214172363, Validation Loss: 0.17302916447321573, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 6502, Training Loss: 0.17350977947635035, Validation Loss: 0.1754870394865672, Validation Accuracy: 0.475\n",
      "Epoch 6503, Training Loss: 0.17454346293403256, Validation Loss: 0.17321931223074596, Validation Accuracy: 0.5125\n",
      "Epoch 6504, Training Loss: 0.1734464447344503, Validation Loss: 0.1755391756693522, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 6505, Training Loss: 0.17443181382071588, Validation Loss: 0.17318182090918224, Validation Accuracy: 0.5375\n",
      "Epoch 6506, Training Loss: 0.17347550007604784, Validation Loss: 0.17459575533866883, Validation Accuracy: 0.4875\n",
      "Epoch 6507, Training Loss: 0.17433158091960416, Validation Loss: 0.17330244183540344, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 6508, Training Loss: 0.17370668342036585, Validation Loss: 0.1745173692703247, Validation Accuracy: 0.475\n",
      "Epoch 6509, Training Loss: 0.17438395705915266, Validation Loss: 0.1723177343606949, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 6510, Training Loss: 0.1736231537595872, Validation Loss: 0.17541745404402415, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 6511, Training Loss: 0.1744004593741509, Validation Loss: 0.1737215538819631, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6512, Training Loss: 0.17354297734075977, Validation Loss: 0.17501431703567505, Validation Accuracy: 0.4875\n",
      "Epoch 6513, Training Loss: 0.17426413634131033, Validation Loss: 0.1730732411146164, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 6514, Training Loss: 0.1735693826790779, Validation Loss: 0.17410709361235302, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 6515, Training Loss: 0.17431512138535898, Validation Loss: 0.1739699383576711, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6516, Training Loss: 0.17364640197446268, Validation Loss: 0.17485422194004058, Validation Accuracy: 0.49375\n",
      "Epoch 6517, Training Loss: 0.17432004357537917, Validation Loss: 0.1737058957417806, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 6518, Training Loss: 0.17363304092038062, Validation Loss: 0.17389898697535197, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 6519, Training Loss: 0.17427516848810257, Validation Loss: 0.1744673530260722, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 6520, Training Loss: 0.17359203725091873, Validation Loss: 0.17381417353947956, Validation Accuracy: 0.5125\n",
      "Epoch 6521, Training Loss: 0.17436065837260215, Validation Loss: 0.17477779189745585, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 6522, Training Loss: 0.17375656529780356, Validation Loss: 0.1729825456937154, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 6523, Training Loss: 0.17433613731015113, Validation Loss: 0.17483211954434713, Validation Accuracy: 0.48125\n",
      "Epoch 6524, Training Loss: 0.17354179053537308, Validation Loss: 0.1738747239112854, Validation Accuracy: 0.50625\n",
      "Epoch 6525, Training Loss: 0.17443344189274695, Validation Loss: 0.17538805007934571, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 6526, Training Loss: 0.17379444164614524, Validation Loss: 0.1721135824918747, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 6527, Training Loss: 0.17423075677887087, Validation Loss: 0.17570828795433044, Validation Accuracy: 0.475\n",
      "Epoch 6528, Training Loss: 0.17377604496094487, Validation Loss: 0.17347615361213684, Validation Accuracy: 0.5125\n",
      "Epoch 6529, Training Loss: 0.1739649849553262, Validation Loss: 0.1753388633330663, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 6530, Training Loss: 0.17401377135707485, Validation Loss: 0.17266541719436646, Validation Accuracy: 0.5375\n",
      "Epoch 6531, Training Loss: 0.17384171582037403, Validation Loss: 0.17566810846328734, Validation Accuracy: 0.4875\n",
      "Epoch 6532, Training Loss: 0.1739994013501752, Validation Loss: 0.17422182261943817, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 6533, Training Loss: 0.17396484363463618, Validation Loss: 0.17630211412906646, Validation Accuracy: 0.475\n",
      "Epoch 6534, Training Loss: 0.17412583001198306, Validation Loss: 0.17195475498835247, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 6535, Training Loss: 0.17379780161765315, Validation Loss: 0.17692549228668214, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 6536, Training Loss: 0.17412645778348368, Validation Loss: 0.174241570631663, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6537, Training Loss: 0.1735940993793549, Validation Loss: 0.17557885646820068, Validation Accuracy: 0.4875\n",
      "Epoch 6538, Training Loss: 0.1744187387727922, Validation Loss: 0.17272843917210898, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 6539, Training Loss: 0.17337671931712859, Validation Loss: 0.17542755007743835, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 6540, Training Loss: 0.17464265804136953, Validation Loss: 0.17364166577657064, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6541, Training Loss: 0.17368145431241683, Validation Loss: 0.17469121118386585, Validation Accuracy: 0.49375\n",
      "Epoch 6542, Training Loss: 0.17431099568643876, Validation Loss: 0.17365665038426717, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 6543, Training Loss: 0.17364513008825241, Validation Loss: 0.1746304710706075, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 6544, Training Loss: 0.1743783571066395, Validation Loss: 0.17396974563598633, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 6545, Training Loss: 0.17380399232910526, Validation Loss: 0.17355313897132874, Validation Accuracy: 0.5125\n",
      "Epoch 6546, Training Loss: 0.17415748344313714, Validation Loss: 0.17465114096800485, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 6547, Training Loss: 0.17358852201892483, Validation Loss: 0.17343315184116365, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 6548, Training Loss: 0.174327943594225, Validation Loss: 0.17395394146442414, Validation Accuracy: 0.48125\n",
      "Epoch 6549, Training Loss: 0.1737938263723927, Validation Loss: 0.17380753457546233, Validation Accuracy: 0.50625\n",
      "Epoch 6550, Training Loss: 0.1742066063227192, Validation Loss: 0.1747247815132141, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 6551, Training Loss: 0.1736661195755005, Validation Loss: 0.1720748613278071, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 6552, Training Loss: 0.17437663722422816, Validation Loss: 0.1739670991897583, Validation Accuracy: 0.475\n",
      "Epoch 6553, Training Loss: 0.17372048141494875, Validation Loss: 0.17379392683506012, Validation Accuracy: 0.5125\n",
      "Epoch 6554, Training Loss: 0.17435384325442776, Validation Loss: 0.17414368490378063, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 6555, Training Loss: 0.17359680850659648, Validation Loss: 0.1727196921904882, Validation Accuracy: 0.5375\n",
      "Epoch 6556, Training Loss: 0.17440171251373907, Validation Loss: 0.1736467093229294, Validation Accuracy: 0.4875\n",
      "Epoch 6557, Training Loss: 0.17379367928351125, Validation Loss: 0.17415637175242107, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 6558, Training Loss: 0.1742166429758072, Validation Loss: 0.1741269071896871, Validation Accuracy: 0.475\n",
      "Epoch 6559, Training Loss: 0.17371997525615077, Validation Loss: 0.17174853483835856, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 6560, Training Loss: 0.17431367789545366, Validation Loss: 0.17379918893178303, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 6561, Training Loss: 0.17385873342714003, Validation Loss: 0.1736541231473287, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6562, Training Loss: 0.17413279942927823, Validation Loss: 0.17379853129386902, Validation Accuracy: 0.4875\n",
      "Epoch 6563, Training Loss: 0.173839517178074, Validation Loss: 0.17283032139142354, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 6564, Training Loss: 0.17422101574559365, Validation Loss: 0.1734399845202764, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 6565, Training Loss: 0.17384535891394462, Validation Loss: 0.17354227105776468, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6566, Training Loss: 0.17399675903781767, Validation Loss: 0.1739504426717758, Validation Accuracy: 0.49375\n",
      "Epoch 6567, Training Loss: 0.17390637436220724, Validation Loss: 0.17340623140335082, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 6568, Training Loss: 0.17411633941435045, Validation Loss: 0.17327362596988677, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 6569, Training Loss: 0.17396453071025111, Validation Loss: 0.17348973949750265, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 6570, Training Loss: 0.17364686054568138, Validation Loss: 0.17358274857203165, Validation Accuracy: 0.5125\n",
      "Epoch 6571, Training Loss: 0.17406590763599641, Validation Loss: 0.173452228307724, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 6572, Training Loss: 0.1741401788688475, Validation Loss: 0.1730424424012502, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 6573, Training Loss: 0.17397982362777956, Validation Loss: 0.17349175413449605, Validation Accuracy: 0.48125\n",
      "Epoch 6574, Training Loss: 0.17407980417051622, Validation Loss: 0.1732980231444041, Validation Accuracy: 0.50625\n",
      "Epoch 6575, Training Loss: 0.17390324944450009, Validation Loss: 0.1735771099726359, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 6576, Training Loss: 0.17417976260185242, Validation Loss: 0.17288911541302998, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 6577, Training Loss: 0.17391353845596313, Validation Loss: 0.173588889837265, Validation Accuracy: 0.475\n",
      "Epoch 6578, Training Loss: 0.17406755733874538, Validation Loss: 0.1732180595397949, Validation Accuracy: 0.5125\n",
      "Epoch 6579, Training Loss: 0.17391125569420476, Validation Loss: 0.17367359002431235, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 6580, Training Loss: 0.174123881324645, Validation Loss: 0.17296908994515736, Validation Accuracy: 0.5375\n",
      "Epoch 6581, Training Loss: 0.1739538460969925, Validation Loss: 0.1736827313899994, Validation Accuracy: 0.4875\n",
      "Epoch 6582, Training Loss: 0.17401404198138945, Validation Loss: 0.17353122333685558, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 6583, Training Loss: 0.17381021813038858, Validation Loss: 0.17396339476108552, Validation Accuracy: 0.475\n",
      "Epoch 6584, Training Loss: 0.17425058397554583, Validation Loss: 0.17284512023131052, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 6585, Training Loss: 0.173856153603523, Validation Loss: 0.17397776544094085, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 6586, Training Loss: 0.17380994125719992, Validation Loss: 0.17391467889149984, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6587, Training Loss: 0.1739082860369836, Validation Loss: 0.1738651047150294, Validation Accuracy: 0.4875\n",
      "Epoch 6588, Training Loss: 0.17429356517330294, Validation Loss: 0.17306557794411978, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 6589, Training Loss: 0.17376158554707805, Validation Loss: 0.1736548443635305, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 6590, Training Loss: 0.17427532855541475, Validation Loss: 0.1734154184659322, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6591, Training Loss: 0.17365502878542868, Validation Loss: 0.1737458864847819, Validation Accuracy: 0.49375\n",
      "Epoch 6592, Training Loss: 0.17435307031677616, Validation Loss: 0.1732824107011159, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 6593, Training Loss: 0.173791735883682, Validation Loss: 0.17332318822542828, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 6594, Training Loss: 0.17417960541863595, Validation Loss: 0.17348478337128956, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 6595, Training Loss: 0.17375903600646603, Validation Loss: 0.17327108184496562, Validation Accuracy: 0.5125\n",
      "Epoch 6596, Training Loss: 0.17428138131095516, Validation Loss: 0.17341857254505158, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 6597, Training Loss: 0.17376115725886437, Validation Loss: 0.17292631268501282, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 6598, Training Loss: 0.1737893776547524, Validation Loss: 0.17483424146970114, Validation Accuracy: 0.48125\n",
      "Epoch 6599, Training Loss: 0.17371673353256717, Validation Loss: 0.17371843953927357, Validation Accuracy: 0.50625\n",
      "Epoch 6600, Training Loss: 0.1742419768725672, Validation Loss: 0.17395658195018768, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 6601, Training Loss: 0.17371957532821164, Validation Loss: 0.1724431574344635, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 6602, Training Loss: 0.17406877442713706, Validation Loss: 0.17366669476032257, Validation Accuracy: 0.475\n",
      "Epoch 6603, Training Loss: 0.1737250171361431, Validation Loss: 0.17326229711373647, Validation Accuracy: 0.5125\n",
      "Epoch 6604, Training Loss: 0.17438679020250997, Validation Loss: 0.173458202679952, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 6605, Training Loss: 0.17370038936215063, Validation Loss: 0.1726591447989146, Validation Accuracy: 0.5375\n",
      "Epoch 6606, Training Loss: 0.1742909295905021, Validation Loss: 0.1734163135290146, Validation Accuracy: 0.4875\n",
      "Epoch 6607, Training Loss: 0.17364114619070484, Validation Loss: 0.17363373835881551, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 6608, Training Loss: 0.17444506672120863, Validation Loss: 0.17339050471782685, Validation Accuracy: 0.475\n",
      "Epoch 6609, Training Loss: 0.1736438481077071, Validation Loss: 0.17228792707125345, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 6610, Training Loss: 0.1743362142193702, Validation Loss: 0.1734955797592799, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 6611, Training Loss: 0.17368098805027624, Validation Loss: 0.17379895250002544, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6612, Training Loss: 0.1743679440790607, Validation Loss: 0.17334683736165366, Validation Accuracy: 0.4875\n",
      "Epoch 6613, Training Loss: 0.1737173959132164, Validation Loss: 0.17272831698258717, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 6614, Training Loss: 0.17428468696532712, Validation Loss: 0.17335915664831797, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 6615, Training Loss: 0.173673881157752, Validation Loss: 0.17369342545668284, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6616, Training Loss: 0.1744026017765845, Validation Loss: 0.17333979109923045, Validation Accuracy: 0.49375\n",
      "Epoch 6617, Training Loss: 0.1737701157408376, Validation Loss: 0.17384606699148814, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 6618, Training Loss: 0.17422702427833311, Validation Loss: 0.17325627009073893, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 6619, Training Loss: 0.17360702108952306, Validation Loss: 0.17427663604418436, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 6620, Training Loss: 0.17446213672238012, Validation Loss: 0.17322508096694947, Validation Accuracy: 0.5125\n",
      "Epoch 6621, Training Loss: 0.17365716734240133, Validation Loss: 0.1746628979841868, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 6622, Training Loss: 0.17425978327951125, Validation Loss: 0.17319594025611879, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 6623, Training Loss: 0.17363990699091264, Validation Loss: 0.17465083797772726, Validation Accuracy: 0.48125\n",
      "Epoch 6624, Training Loss: 0.17437433523516502, Validation Loss: 0.1732732246319453, Validation Accuracy: 0.50625\n",
      "Epoch 6625, Training Loss: 0.1735771360897249, Validation Loss: 0.1754518121480942, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 6626, Training Loss: 0.17447494499145016, Validation Loss: 0.17309899826844533, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 6627, Training Loss: 0.17348056839358422, Validation Loss: 0.17506828904151917, Validation Accuracy: 0.475\n",
      "Epoch 6628, Training Loss: 0.17446834569977177, Validation Loss: 0.17325623432795206, Validation Accuracy: 0.5125\n",
      "Epoch 6629, Training Loss: 0.1735274959956446, Validation Loss: 0.1757431447505951, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 6630, Training Loss: 0.17445937472005044, Validation Loss: 0.17281523247559866, Validation Accuracy: 0.5375\n",
      "Epoch 6631, Training Loss: 0.173500154768267, Validation Loss: 0.17467170854409536, Validation Accuracy: 0.4875\n",
      "Epoch 6632, Training Loss: 0.17456594301808265, Validation Loss: 0.17350173195203145, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 6633, Training Loss: 0.1735951559197518, Validation Loss: 0.17550127406915028, Validation Accuracy: 0.475\n",
      "Epoch 6634, Training Loss: 0.17439806076788134, Validation Loss: 0.17224950194358826, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 6635, Training Loss: 0.1736166953079162, Validation Loss: 0.17535113394260407, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 6636, Training Loss: 0.17440084920775506, Validation Loss: 0.17370728651682535, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6637, Training Loss: 0.17352377647353756, Validation Loss: 0.17505521575609842, Validation Accuracy: 0.4875\n",
      "Epoch 6638, Training Loss: 0.17424763835245563, Validation Loss: 0.17296778361002604, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 6639, Training Loss: 0.17359679793157884, Validation Loss: 0.1741415152947108, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 6640, Training Loss: 0.17435788627593748, Validation Loss: 0.174004860719045, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6641, Training Loss: 0.17359643357415352, Validation Loss: 0.17479197382926942, Validation Accuracy: 0.49375\n",
      "Epoch 6642, Training Loss: 0.17436175432897383, Validation Loss: 0.17372552752494813, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 6643, Training Loss: 0.1736105372828822, Validation Loss: 0.17401187519232433, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 6644, Training Loss: 0.17426994106461924, Validation Loss: 0.17453108628590902, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 6645, Training Loss: 0.1736242155874929, Validation Loss: 0.17386253376801808, Validation Accuracy: 0.5125\n",
      "Epoch 6646, Training Loss: 0.1743593018862509, Validation Loss: 0.17481800218423207, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 6647, Training Loss: 0.17374541105762606, Validation Loss: 0.17304275035858155, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 6648, Training Loss: 0.1742623212837404, Validation Loss: 0.17495953937371572, Validation Accuracy: 0.48125\n",
      "Epoch 6649, Training Loss: 0.1736310153238235, Validation Loss: 0.1739532639582952, Validation Accuracy: 0.50625\n",
      "Epoch 6650, Training Loss: 0.17443718785239803, Validation Loss: 0.17550691465536752, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 6651, Training Loss: 0.1737844309499187, Validation Loss: 0.17215129534403484, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 6652, Training Loss: 0.1742442827070913, Validation Loss: 0.17569583455721538, Validation Accuracy: 0.475\n",
      "Epoch 6653, Training Loss: 0.17380221668751009, Validation Loss: 0.17348785599072775, Validation Accuracy: 0.5125\n",
      "Epoch 6654, Training Loss: 0.17399579286575317, Validation Loss: 0.1758569707473119, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 6655, Training Loss: 0.17396361356781376, Validation Loss: 0.17267382144927979, Validation Accuracy: 0.5375\n",
      "Epoch 6656, Training Loss: 0.17390802598768665, Validation Loss: 0.17563874423503875, Validation Accuracy: 0.4875\n",
      "Epoch 6657, Training Loss: 0.17391482908879558, Validation Loss: 0.1743166873852412, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 6658, Training Loss: 0.1739782940956854, Validation Loss: 0.1766471803188324, Validation Accuracy: 0.475\n",
      "Epoch 6659, Training Loss: 0.17408342467200372, Validation Loss: 0.1720209131638209, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 6660, Training Loss: 0.17379917060175248, Validation Loss: 0.17756522595882415, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 6661, Training Loss: 0.17418780298002304, Validation Loss: 0.1739296793937683, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6662, Training Loss: 0.1737530178600742, Validation Loss: 0.1746489077806473, Validation Accuracy: 0.4875\n",
      "Epoch 6663, Training Loss: 0.17432258782848234, Validation Loss: 0.17274394929409026, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 6664, Training Loss: 0.17335008421251852, Validation Loss: 0.17575461864471437, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 6665, Training Loss: 0.1746899144303414, Validation Loss: 0.17374187807242075, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6666, Training Loss: 0.17368038335154135, Validation Loss: 0.1742377519607544, Validation Accuracy: 0.49375\n",
      "Epoch 6667, Training Loss: 0.17423703064841609, Validation Loss: 0.17376139760017395, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 6668, Training Loss: 0.17364874049540488, Validation Loss: 0.17448191742102306, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 6669, Training Loss: 0.17436677121346997, Validation Loss: 0.1739659587542216, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 6670, Training Loss: 0.17375895813588174, Validation Loss: 0.1739550193150838, Validation Accuracy: 0.5125\n",
      "Epoch 6671, Training Loss: 0.1742618949182572, Validation Loss: 0.17420748472213746, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 6672, Training Loss: 0.17359859087774832, Validation Loss: 0.17329914569854737, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 6673, Training Loss: 0.1741543815981957, Validation Loss: 0.17478926281134288, Validation Accuracy: 0.48125\n",
      "Epoch 6674, Training Loss: 0.1737412420972701, Validation Loss: 0.17426055669784546, Validation Accuracy: 0.50625\n",
      "Epoch 6675, Training Loss: 0.17432787677934092, Validation Loss: 0.17441150744756062, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 6676, Training Loss: 0.17362632386146054, Validation Loss: 0.17211638589700062, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 6677, Training Loss: 0.17440468361300807, Validation Loss: 0.17391393780708314, Validation Accuracy: 0.475\n",
      "Epoch 6678, Training Loss: 0.1737957135323555, Validation Loss: 0.173519233862559, Validation Accuracy: 0.5125\n",
      "Epoch 6679, Training Loss: 0.17424452449044875, Validation Loss: 0.174390909075737, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 6680, Training Loss: 0.17361831424697752, Validation Loss: 0.1727389484643936, Validation Accuracy: 0.5375\n",
      "Epoch 6681, Training Loss: 0.17438403733315005, Validation Loss: 0.1736454725265503, Validation Accuracy: 0.4875\n",
      "Epoch 6682, Training Loss: 0.17377014986930356, Validation Loss: 0.17426595191160837, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 6683, Training Loss: 0.17407611925755778, Validation Loss: 0.17480303545792897, Validation Accuracy: 0.475\n",
      "Epoch 6684, Training Loss: 0.1737433994008649, Validation Loss: 0.17179808914661407, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 6685, Training Loss: 0.17433388675412825, Validation Loss: 0.17383950253327687, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 6686, Training Loss: 0.17389522973568208, Validation Loss: 0.17372430562973024, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6687, Training Loss: 0.17408630876771866, Validation Loss: 0.17389315962791443, Validation Accuracy: 0.4875\n",
      "Epoch 6688, Training Loss: 0.17385024313003786, Validation Loss: 0.17286666929721833, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 6689, Training Loss: 0.1742404458984252, Validation Loss: 0.17343209783236185, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 6690, Training Loss: 0.1738616415569859, Validation Loss: 0.17349278330802917, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6691, Training Loss: 0.17414765444494062, Validation Loss: 0.1735570251941681, Validation Accuracy: 0.49375\n",
      "Epoch 6692, Training Loss: 0.17385210721723496, Validation Loss: 0.17330017884572346, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 6693, Training Loss: 0.1741413752878866, Validation Loss: 0.17328120867411295, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 6694, Training Loss: 0.17394650847681106, Validation Loss: 0.17350923617680866, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 6695, Training Loss: 0.17403410375118256, Validation Loss: 0.17322323421637217, Validation Accuracy: 0.5125\n",
      "Epoch 6696, Training Loss: 0.1739040978493229, Validation Loss: 0.17350134352842966, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 6697, Training Loss: 0.17413444192178787, Validation Loss: 0.17304378549257915, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 6698, Training Loss: 0.17396541949241393, Validation Loss: 0.17348967591921488, Validation Accuracy: 0.48125\n",
      "Epoch 6699, Training Loss: 0.1739996806267769, Validation Loss: 0.1733473539352417, Validation Accuracy: 0.50625\n",
      "Epoch 6700, Training Loss: 0.17396697305863904, Validation Loss: 0.1736053595940272, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 6701, Training Loss: 0.17412785128239663, Validation Loss: 0.17289299269517264, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 6702, Training Loss: 0.17394711413691122, Validation Loss: 0.1735945185025533, Validation Accuracy: 0.475\n",
      "Epoch 6703, Training Loss: 0.17386514477191434, Validation Loss: 0.1732981612284978, Validation Accuracy: 0.5125\n",
      "Epoch 6704, Training Loss: 0.1739213509905723, Validation Loss: 0.173846169312795, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 6705, Training Loss: 0.17416150675665948, Validation Loss: 0.17299779454867045, Validation Accuracy: 0.5375\n",
      "Epoch 6706, Training Loss: 0.1739441675524558, Validation Loss: 0.1735793888568878, Validation Accuracy: 0.4875\n",
      "Epoch 6707, Training Loss: 0.17406682525911638, Validation Loss: 0.1734891007343928, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 6708, Training Loss: 0.1737945892157093, Validation Loss: 0.17384267052014668, Validation Accuracy: 0.475\n",
      "Epoch 6709, Training Loss: 0.17424219366042845, Validation Loss: 0.17288218438625336, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 6710, Training Loss: 0.1738522716106907, Validation Loss: 0.17394726475079855, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 6711, Training Loss: 0.17410854562636344, Validation Loss: 0.17343507210413614, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6712, Training Loss: 0.1738369801352101, Validation Loss: 0.17368499239285787, Validation Accuracy: 0.4875\n",
      "Epoch 6713, Training Loss: 0.1742274809268213, Validation Loss: 0.17305922706921895, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 6714, Training Loss: 0.17377545131791022, Validation Loss: 0.1737248162428538, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 6715, Training Loss: 0.1742165655859055, Validation Loss: 0.17348493536313375, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6716, Training Loss: 0.17367771171754406, Validation Loss: 0.17374283472696941, Validation Accuracy: 0.49375\n",
      "Epoch 6717, Training Loss: 0.17434759293833085, Validation Loss: 0.17328212062517803, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 6718, Training Loss: 0.17380881597918849, Validation Loss: 0.17333066761493682, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 6719, Training Loss: 0.17420203022418485, Validation Loss: 0.1734488993883133, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 6720, Training Loss: 0.17374999532776494, Validation Loss: 0.17325543065865834, Validation Accuracy: 0.5125\n",
      "Epoch 6721, Training Loss: 0.17423093991894875, Validation Loss: 0.1734481285015742, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 6722, Training Loss: 0.173869367088041, Validation Loss: 0.17290733754634857, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 6723, Training Loss: 0.17414047641138877, Validation Loss: 0.1735220382610957, Validation Accuracy: 0.48125\n",
      "Epoch 6724, Training Loss: 0.1736388994801429, Validation Loss: 0.17347360650698343, Validation Accuracy: 0.50625\n",
      "Epoch 6725, Training Loss: 0.1743956059217453, Validation Loss: 0.17347450355688732, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 6726, Training Loss: 0.17368768347847846, Validation Loss: 0.1722996880610784, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 6727, Training Loss: 0.17433841045825713, Validation Loss: 0.17349207798639935, Validation Accuracy: 0.475\n",
      "Epoch 6728, Training Loss: 0.17366157231792326, Validation Loss: 0.1732780635356903, Validation Accuracy: 0.5125\n",
      "Epoch 6729, Training Loss: 0.17434962910990562, Validation Loss: 0.17344445983568826, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 6730, Training Loss: 0.1736783596777147, Validation Loss: 0.17269157767295837, Validation Accuracy: 0.5375\n",
      "Epoch 6731, Training Loss: 0.17436732495984725, Validation Loss: 0.173395037651062, Validation Accuracy: 0.4875\n",
      "Epoch 6732, Training Loss: 0.17363378645912295, Validation Loss: 0.17379613916079203, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 6733, Training Loss: 0.17435977295521768, Validation Loss: 0.17343009014924368, Validation Accuracy: 0.475\n",
      "Epoch 6734, Training Loss: 0.17367654462014476, Validation Loss: 0.17211463352044423, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 6735, Training Loss: 0.17436692839668644, Validation Loss: 0.17355124255021412, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 6736, Training Loss: 0.17365729904943897, Validation Loss: 0.17394438187281291, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6737, Training Loss: 0.17433633919685118, Validation Loss: 0.17335598170757294, Validation Accuracy: 0.4875\n",
      "Epoch 6738, Training Loss: 0.17368817521679786, Validation Loss: 0.17288144528865815, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 6739, Training Loss: 0.17389304887863896, Validation Loss: 0.17350682814915974, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 6740, Training Loss: 0.17378520869439648, Validation Loss: 0.1737886091073354, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6741, Training Loss: 0.17450755209692062, Validation Loss: 0.17332936227321624, Validation Accuracy: 0.49375\n",
      "Epoch 6742, Training Loss: 0.17374909741263236, Validation Loss: 0.17368693947792052, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 6743, Training Loss: 0.1742577201897098, Validation Loss: 0.17325672606627146, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 6744, Training Loss: 0.1736298866810337, Validation Loss: 0.17464629411697388, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 6745, Training Loss: 0.17443956723136286, Validation Loss: 0.1732248346010844, Validation Accuracy: 0.5125\n",
      "Epoch 6746, Training Loss: 0.17366352437003965, Validation Loss: 0.17458756268024445, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 6747, Training Loss: 0.1741576055365224, Validation Loss: 0.1732136934995651, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 6748, Training Loss: 0.17366283699389426, Validation Loss: 0.1744858851035436, Validation Accuracy: 0.48125\n",
      "Epoch 6749, Training Loss: 0.17434149499862425, Validation Loss: 0.17327870925267538, Validation Accuracy: 0.50625\n",
      "Epoch 6750, Training Loss: 0.17358143098892703, Validation Loss: 0.1748701830705007, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 6751, Training Loss: 0.17443697154521942, Validation Loss: 0.17316827476024627, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 6752, Training Loss: 0.17346955835819244, Validation Loss: 0.17505813241004944, Validation Accuracy: 0.475\n",
      "Epoch 6753, Training Loss: 0.17446966036673514, Validation Loss: 0.1732626954714457, Validation Accuracy: 0.5125\n",
      "Epoch 6754, Training Loss: 0.17354200636186906, Validation Loss: 0.1757725030183792, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 6755, Training Loss: 0.17440476629041857, Validation Loss: 0.1728119323650996, Validation Accuracy: 0.5375\n",
      "Epoch 6756, Training Loss: 0.17352612220471905, Validation Loss: 0.17484508752822875, Validation Accuracy: 0.4875\n",
      "Epoch 6757, Training Loss: 0.17457561146828435, Validation Loss: 0.17361831168333688, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 6758, Training Loss: 0.17357437793285616, Validation Loss: 0.1751730114221573, Validation Accuracy: 0.475\n",
      "Epoch 6759, Training Loss: 0.174480787688686, Validation Loss: 0.17235787510871886, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 6760, Training Loss: 0.1735644749095363, Validation Loss: 0.1755290408929189, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 6761, Training Loss: 0.1744243315150661, Validation Loss: 0.17374909520149232, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6762, Training Loss: 0.1735289442923761, Validation Loss: 0.17498561640580496, Validation Accuracy: 0.4875\n",
      "Epoch 6763, Training Loss: 0.17441130741950003, Validation Loss: 0.17274863322575887, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 6764, Training Loss: 0.17352644522343913, Validation Loss: 0.17461851040522258, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 6765, Training Loss: 0.17433830326603306, Validation Loss: 0.17349226276079813, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6766, Training Loss: 0.17357684383469243, Validation Loss: 0.1746378461519877, Validation Accuracy: 0.49375\n",
      "Epoch 6767, Training Loss: 0.1743401865805349, Validation Loss: 0.17372001310189564, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 6768, Training Loss: 0.17356335251562058, Validation Loss: 0.17406685849030812, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 6769, Training Loss: 0.17429337818776408, Validation Loss: 0.17459168334801992, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 6770, Training Loss: 0.173635694769121, Validation Loss: 0.17380695343017577, Validation Accuracy: 0.5125\n",
      "Epoch 6771, Training Loss: 0.1743221422356944, Validation Loss: 0.1746543010075887, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 6772, Training Loss: 0.1737517329954332, Validation Loss: 0.17296383678913116, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 6773, Training Loss: 0.17432634340178582, Validation Loss: 0.17499364813168844, Validation Accuracy: 0.48125\n",
      "Epoch 6774, Training Loss: 0.17358115940324723, Validation Loss: 0.17384499410788218, Validation Accuracy: 0.50625\n",
      "Epoch 6775, Training Loss: 0.17449799468440394, Validation Loss: 0.17565136154492697, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 6776, Training Loss: 0.17373556187075953, Validation Loss: 0.172145011027654, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 6777, Training Loss: 0.17423110527376975, Validation Loss: 0.17576453884442647, Validation Accuracy: 0.475\n",
      "Epoch 6778, Training Loss: 0.17382861048944534, Validation Loss: 0.17349449396133423, Validation Accuracy: 0.5125\n",
      "Epoch 6779, Training Loss: 0.17400732924861292, Validation Loss: 0.1752439131339391, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 6780, Training Loss: 0.1737899270749861, Validation Loss: 0.17275777558485667, Validation Accuracy: 0.5375\n",
      "Epoch 6781, Training Loss: 0.1739043439588239, Validation Loss: 0.17565804024537404, Validation Accuracy: 0.4875\n",
      "Epoch 6782, Training Loss: 0.1738837779529633, Validation Loss: 0.17417925596237183, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 6783, Training Loss: 0.17396593286145118, Validation Loss: 0.176178640127182, Validation Accuracy: 0.475\n",
      "Epoch 6784, Training Loss: 0.17384451483526536, Validation Loss: 0.17228796382745107, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 6785, Training Loss: 0.17374901425453923, Validation Loss: 0.17701797584692638, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 6786, Training Loss: 0.1741274744272232, Validation Loss: 0.17418050169944763, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6787, Training Loss: 0.1736227249906909, Validation Loss: 0.17643146614233654, Validation Accuracy: 0.4875\n",
      "Epoch 6788, Training Loss: 0.17442546159990371, Validation Loss: 0.17274997333685557, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 6789, Training Loss: 0.17336528531966672, Validation Loss: 0.17597414453824362, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 6790, Training Loss: 0.17466240688677756, Validation Loss: 0.17361145516236623, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6791, Training Loss: 0.17371047937100934, Validation Loss: 0.17435990969340007, Validation Accuracy: 0.49375\n",
      "Epoch 6792, Training Loss: 0.17425863685146456, Validation Loss: 0.17372983594735464, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 6793, Training Loss: 0.1736319334276261, Validation Loss: 0.1745059053103129, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 6794, Training Loss: 0.17438715119515696, Validation Loss: 0.173950590689977, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 6795, Training Loss: 0.17379353700145597, Validation Loss: 0.17356110016504925, Validation Accuracy: 0.5125\n",
      "Epoch 6796, Training Loss: 0.17419204596550233, Validation Loss: 0.17443856596946716, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 6797, Training Loss: 0.17361143231391907, Validation Loss: 0.17330300509929658, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 6798, Training Loss: 0.17433950593394618, Validation Loss: 0.17395203908284504, Validation Accuracy: 0.48125\n",
      "Epoch 6799, Training Loss: 0.17375037122157314, Validation Loss: 0.17398640314737956, Validation Accuracy: 0.50625\n",
      "Epoch 6800, Training Loss: 0.17426379794074642, Validation Loss: 0.174546679854393, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 6801, Training Loss: 0.1736479531372747, Validation Loss: 0.1720792184273402, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 6802, Training Loss: 0.1743849265959955, Validation Loss: 0.17395546436309814, Validation Accuracy: 0.475\n",
      "Epoch 6803, Training Loss: 0.17375806743098843, Validation Loss: 0.17374114493529003, Validation Accuracy: 0.5125\n",
      "Epoch 6804, Training Loss: 0.17404440574107632, Validation Loss: 0.17484458486239116, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 6805, Training Loss: 0.1736690964429609, Validation Loss: 0.1728467086950938, Validation Accuracy: 0.5375\n",
      "Epoch 6806, Training Loss: 0.17435285352891491, Validation Loss: 0.17367356419563293, Validation Accuracy: 0.4875\n",
      "Epoch 6807, Training Loss: 0.17381849548509043, Validation Loss: 0.17441080510616302, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 6808, Training Loss: 0.1742153460941007, Validation Loss: 0.17406751016775768, Validation Accuracy: 0.475\n",
      "Epoch 6809, Training Loss: 0.17370363541187778, Validation Loss: 0.17183733582496644, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 6810, Training Loss: 0.1743267019910197, Validation Loss: 0.17381737927595775, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 6811, Training Loss: 0.17389228747737023, Validation Loss: 0.17366386850674947, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6812, Training Loss: 0.17404016131354916, Validation Loss: 0.1739963452021281, Validation Accuracy: 0.4875\n",
      "Epoch 6813, Training Loss: 0.1738496321824289, Validation Loss: 0.17285894950230915, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 6814, Training Loss: 0.17425401797217707, Validation Loss: 0.17340912620226542, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 6815, Training Loss: 0.17392414087249386, Validation Loss: 0.17350125908851624, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6816, Training Loss: 0.17401758028614905, Validation Loss: 0.17379510800043743, Validation Accuracy: 0.49375\n",
      "Epoch 6817, Training Loss: 0.17387239154308073, Validation Loss: 0.1733450710773468, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 6818, Training Loss: 0.17415457194851292, Validation Loss: 0.17326805194218953, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 6819, Training Loss: 0.17399380908858392, Validation Loss: 0.17348573009173077, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 6820, Training Loss: 0.17390480445277307, Validation Loss: 0.1732600728670756, Validation Accuracy: 0.5125\n",
      "Epoch 6821, Training Loss: 0.17395788767645437, Validation Loss: 0.1735166937112808, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 6822, Training Loss: 0.1741477092427592, Validation Loss: 0.1730685422817866, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 6823, Training Loss: 0.17395944268472732, Validation Loss: 0.17354674736658732, Validation Accuracy: 0.48125\n",
      "Epoch 6824, Training Loss: 0.17395171138548082, Validation Loss: 0.17336768706639608, Validation Accuracy: 0.50625\n",
      "Epoch 6825, Training Loss: 0.1739873448687215, Validation Loss: 0.17362567087014516, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 6826, Training Loss: 0.17401894542478746, Validation Loss: 0.17274150550365447, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 6827, Training Loss: 0.1739690351870752, Validation Loss: 0.17372764547665914, Validation Accuracy: 0.475\n",
      "Epoch 6828, Training Loss: 0.1739569532294427, Validation Loss: 0.1732336699962616, Validation Accuracy: 0.5125\n",
      "Epoch 6829, Training Loss: 0.17394476119549043, Validation Loss: 0.17375447849432626, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 6830, Training Loss: 0.17418879126348802, Validation Loss: 0.17303006152311962, Validation Accuracy: 0.5375\n",
      "Epoch 6831, Training Loss: 0.17394721796435694, Validation Loss: 0.17360775768756867, Validation Accuracy: 0.4875\n",
      "Epoch 6832, Training Loss: 0.17401054116987413, Validation Loss: 0.17356175382932026, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 6833, Training Loss: 0.17383037026851408, Validation Loss: 0.17398214141527812, Validation Accuracy: 0.475\n",
      "Epoch 6834, Training Loss: 0.17425281434289872, Validation Loss: 0.17288969258467357, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 6835, Training Loss: 0.17382406900005956, Validation Loss: 0.17398055791854858, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 6836, Training Loss: 0.1741973974051014, Validation Loss: 0.17338358362515768, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6837, Training Loss: 0.17376457923843014, Validation Loss: 0.17370178004105885, Validation Accuracy: 0.4875\n",
      "Epoch 6838, Training Loss: 0.1742723214049493, Validation Loss: 0.17308478951454162, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 6839, Training Loss: 0.17374915124908571, Validation Loss: 0.17370523711045582, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 6840, Training Loss: 0.1742492082618898, Validation Loss: 0.17343154847621917, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6841, Training Loss: 0.1736709254403268, Validation Loss: 0.173728409409523, Validation Accuracy: 0.49375\n",
      "Epoch 6842, Training Loss: 0.17434409212681554, Validation Loss: 0.17328326006730396, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 6843, Training Loss: 0.17381986927601598, Validation Loss: 0.17334217429161072, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 6844, Training Loss: 0.17418213957740414, Validation Loss: 0.17346565226713817, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 6845, Training Loss: 0.17373128716022737, Validation Loss: 0.17325970927874249, Validation Accuracy: 0.5125\n",
      "Epoch 6846, Training Loss: 0.1742923178019062, Validation Loss: 0.17341417868932088, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 6847, Training Loss: 0.17383106966172496, Validation Loss: 0.17290797928969065, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 6848, Training Loss: 0.17417747839804618, Validation Loss: 0.1735117922226588, Validation Accuracy: 0.48125\n",
      "Epoch 6849, Training Loss: 0.1736636507895685, Validation Loss: 0.17348270912965139, Validation Accuracy: 0.50625\n",
      "Epoch 6850, Training Loss: 0.17434675462784305, Validation Loss: 0.17350452542304992, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 6851, Training Loss: 0.17369111939784018, Validation Loss: 0.17235990862051645, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 6852, Training Loss: 0.17392911209214118, Validation Loss: 0.17447057068347932, Validation Accuracy: 0.475\n",
      "Epoch 6853, Training Loss: 0.1737689669093778, Validation Loss: 0.17342093090216318, Validation Accuracy: 0.5125\n",
      "Epoch 6854, Training Loss: 0.174450887307044, Validation Loss: 0.1734437018632889, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 6855, Training Loss: 0.17365995385954458, Validation Loss: 0.1727471838394801, Validation Accuracy: 0.5375\n",
      "Epoch 6856, Training Loss: 0.17439526896322927, Validation Loss: 0.17340254584948223, Validation Accuracy: 0.4875\n",
      "Epoch 6857, Training Loss: 0.1736193150281906, Validation Loss: 0.173803315560023, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 6858, Training Loss: 0.17437990153989485, Validation Loss: 0.17349431614081065, Validation Accuracy: 0.475\n",
      "Epoch 6859, Training Loss: 0.1736922538088214, Validation Loss: 0.17189495464166005, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 6860, Training Loss: 0.17427640047765547, Validation Loss: 0.17361710866292318, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 6861, Training Loss: 0.17365134627588333, Validation Loss: 0.1736177404721578, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6862, Training Loss: 0.17437914061930873, Validation Loss: 0.173384424050649, Validation Accuracy: 0.4875\n",
      "Epoch 6863, Training Loss: 0.1737545281648636, Validation Loss: 0.17272830804189046, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 6864, Training Loss: 0.17420696587331833, Validation Loss: 0.17337558468182881, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 6865, Training Loss: 0.17372667693322705, Validation Loss: 0.1739255040884018, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6866, Training Loss: 0.17435245504302363, Validation Loss: 0.17332666019598644, Validation Accuracy: 0.49375\n",
      "Epoch 6867, Training Loss: 0.17373363289140886, Validation Loss: 0.17341556151707968, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 6868, Training Loss: 0.17389759036802477, Validation Loss: 0.17326343655586243, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 6869, Training Loss: 0.1737489282123504, Validation Loss: 0.1741061528523763, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 6870, Training Loss: 0.17439739309972332, Validation Loss: 0.1732730875412623, Validation Accuracy: 0.5125\n",
      "Epoch 6871, Training Loss: 0.1737823991044875, Validation Loss: 0.17470762630303702, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 6872, Training Loss: 0.17423394899214467, Validation Loss: 0.1731496622165044, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 6873, Training Loss: 0.17366492027236569, Validation Loss: 0.17473686039447783, Validation Accuracy: 0.48125\n",
      "Epoch 6874, Training Loss: 0.17439012133306073, Validation Loss: 0.17327563563982645, Validation Accuracy: 0.50625\n",
      "Epoch 6875, Training Loss: 0.1735497376611156, Validation Loss: 0.17577194372812907, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 6876, Training Loss: 0.17449194577432448, Validation Loss: 0.1728448619445165, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 6877, Training Loss: 0.17347699692172389, Validation Loss: 0.17495660483837128, Validation Accuracy: 0.475\n",
      "Epoch 6878, Training Loss: 0.17448026807077469, Validation Loss: 0.17324196100234984, Validation Accuracy: 0.5125\n",
      "Epoch 6879, Training Loss: 0.1735058287459035, Validation Loss: 0.17564152677853903, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 6880, Training Loss: 0.17447735465341999, Validation Loss: 0.17279801070690154, Validation Accuracy: 0.5375\n",
      "Epoch 6881, Training Loss: 0.17348499740323714, Validation Loss: 0.17489973306655884, Validation Accuracy: 0.4875\n",
      "Epoch 6882, Training Loss: 0.17457331044058647, Validation Loss: 0.17360986471176149, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 6883, Training Loss: 0.17359159165813076, Validation Loss: 0.17550897399584453, Validation Accuracy: 0.475\n",
      "Epoch 6884, Training Loss: 0.17437944248799356, Validation Loss: 0.17252053717772167, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 6885, Training Loss: 0.17362582347085398, Validation Loss: 0.17542936305205029, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 6886, Training Loss: 0.17442971371835278, Validation Loss: 0.17370955049991607, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6887, Training Loss: 0.17351149262920504, Validation Loss: 0.1749285747607549, Validation Accuracy: 0.4875\n",
      "Epoch 6888, Training Loss: 0.1744478638133695, Validation Loss: 0.17275754511356353, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 6889, Training Loss: 0.17350607533608714, Validation Loss: 0.1746440827846527, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 6890, Training Loss: 0.1743845824272402, Validation Loss: 0.17403627435366312, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6891, Training Loss: 0.1736181200511994, Validation Loss: 0.17475388646125795, Validation Accuracy: 0.49375\n",
      "Epoch 6892, Training Loss: 0.1744211931382456, Validation Loss: 0.17370444337526958, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 6893, Training Loss: 0.17356056695984257, Validation Loss: 0.17394782503445944, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 6894, Training Loss: 0.17430963150916562, Validation Loss: 0.1744662602742513, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 6895, Training Loss: 0.17357565414521, Validation Loss: 0.1737858792146047, Validation Accuracy: 0.5125\n",
      "Epoch 6896, Training Loss: 0.17434419451221342, Validation Loss: 0.17473597725232443, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 6897, Training Loss: 0.1737661645297081, Validation Loss: 0.17303845385710398, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 6898, Training Loss: 0.17429566287225293, Validation Loss: 0.17496904730796814, Validation Accuracy: 0.48125\n",
      "Epoch 6899, Training Loss: 0.17359412052939016, Validation Loss: 0.17389818727970124, Validation Accuracy: 0.50625\n",
      "Epoch 6900, Training Loss: 0.1744863126547106, Validation Loss: 0.17562116583188375, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 6901, Training Loss: 0.173705592751503, Validation Loss: 0.17222546835740407, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 6902, Training Loss: 0.17429014559715025, Validation Loss: 0.17584745287895204, Validation Accuracy: 0.475\n",
      "Epoch 6903, Training Loss: 0.17380406058603717, Validation Loss: 0.17344856162865957, Validation Accuracy: 0.5125\n",
      "Epoch 6904, Training Loss: 0.1740443605569101, Validation Loss: 0.17613376379013063, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 6905, Training Loss: 0.17397279508652225, Validation Loss: 0.17265918453534443, Validation Accuracy: 0.5375\n",
      "Epoch 6906, Training Loss: 0.17388329246351797, Validation Loss: 0.17577221989631653, Validation Accuracy: 0.4875\n",
      "Epoch 6907, Training Loss: 0.17399170658280771, Validation Loss: 0.1741575241088867, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 6908, Training Loss: 0.17397835466169542, Validation Loss: 0.1756509304046631, Validation Accuracy: 0.475\n",
      "Epoch 6909, Training Loss: 0.17409317435756808, Validation Loss: 0.17184512416521708, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 6910, Training Loss: 0.17377623531126207, Validation Loss: 0.17641891340414684, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 6911, Training Loss: 0.17424220423544606, Validation Loss: 0.17394169370333354, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6912, Training Loss: 0.1736739585476537, Validation Loss: 0.17570542097091674, Validation Accuracy: 0.4875\n",
      "Epoch 6913, Training Loss: 0.17444844640070392, Validation Loss: 0.17273538211981457, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 6914, Training Loss: 0.173337931594541, Validation Loss: 0.17587358554204305, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 6915, Training Loss: 0.17466638886159466, Validation Loss: 0.17367594043413798, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6916, Training Loss: 0.17363220933944948, Validation Loss: 0.17498282194137574, Validation Accuracy: 0.49375\n",
      "Epoch 6917, Training Loss: 0.174330337874351, Validation Loss: 0.17355348666508993, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 6918, Training Loss: 0.17363735456620494, Validation Loss: 0.17460493048032125, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 6919, Training Loss: 0.17438067399686383, Validation Loss: 0.17394381364186604, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 6920, Training Loss: 0.1737583899690259, Validation Loss: 0.173915163675944, Validation Accuracy: 0.5125\n",
      "Epoch 6921, Training Loss: 0.17426923398048647, Validation Loss: 0.174220472574234, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 6922, Training Loss: 0.1736240242758105, Validation Loss: 0.17314826051394144, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 6923, Training Loss: 0.1743044617675966, Validation Loss: 0.17402928272883098, Validation Accuracy: 0.48125\n",
      "Epoch 6924, Training Loss: 0.173769764361843, Validation Loss: 0.1738811453183492, Validation Accuracy: 0.50625\n",
      "Epoch 6925, Training Loss: 0.17423833618240972, Validation Loss: 0.17460335294405618, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 6926, Training Loss: 0.17362930361301668, Validation Loss: 0.17209689716498058, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 6927, Training Loss: 0.17428128805852705, Validation Loss: 0.1743158757686615, Validation Accuracy: 0.475\n",
      "Epoch 6928, Training Loss: 0.17379148640940267, Validation Loss: 0.17370782593886058, Validation Accuracy: 0.5125\n",
      "Epoch 6929, Training Loss: 0.17432302717239626, Validation Loss: 0.17423161665598552, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 6930, Training Loss: 0.17361326371469804, Validation Loss: 0.1727179636557897, Validation Accuracy: 0.5375\n",
      "Epoch 6931, Training Loss: 0.17434235782392563, Validation Loss: 0.17378415366013844, Validation Accuracy: 0.4875\n",
      "Epoch 6932, Training Loss: 0.1738073364380867, Validation Loss: 0.17428877353668212, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 6933, Training Loss: 0.17420908039616, Validation Loss: 0.17430472870667776, Validation Accuracy: 0.475\n",
      "Epoch 6934, Training Loss: 0.17371905234552198, Validation Loss: 0.17180485427379608, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 6935, Training Loss: 0.1743297653813516, Validation Loss: 0.1738185207049052, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 6936, Training Loss: 0.17387586447500414, Validation Loss: 0.17371469338734943, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6937, Training Loss: 0.17407466711536532, Validation Loss: 0.17394379874070484, Validation Accuracy: 0.4875\n",
      "Epoch 6938, Training Loss: 0.17382880612727133, Validation Loss: 0.17286298672358194, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 6939, Training Loss: 0.1742560834653916, Validation Loss: 0.17340513666470844, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 6940, Training Loss: 0.17393348438124503, Validation Loss: 0.17350654006004335, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6941, Training Loss: 0.17401525426295497, Validation Loss: 0.17371476590633392, Validation Accuracy: 0.49375\n",
      "Epoch 6942, Training Loss: 0.17385111701103947, Validation Loss: 0.17330376704533895, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 6943, Training Loss: 0.17414168532817595, Validation Loss: 0.1732815146446228, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 6944, Training Loss: 0.1739681617867562, Validation Loss: 0.17345958650112153, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 6945, Training Loss: 0.17393866710124478, Validation Loss: 0.1732602576414744, Validation Accuracy: 0.5125\n",
      "Epoch 6946, Training Loss: 0.17398390173912048, Validation Loss: 0.1735381990671158, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 6947, Training Loss: 0.17387899564158532, Validation Loss: 0.1729205479224523, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 6948, Training Loss: 0.17404294879205764, Validation Loss: 0.17369563778241476, Validation Accuracy: 0.48125\n",
      "Epoch 6949, Training Loss: 0.1738771430907711, Validation Loss: 0.17338524460792543, Validation Accuracy: 0.50625\n",
      "Epoch 6950, Training Loss: 0.1739093118136929, Validation Loss: 0.17344529926776886, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 6951, Training Loss: 0.17419214931226545, Validation Loss: 0.17296079993247987, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 6952, Training Loss: 0.17398216695554794, Validation Loss: 0.173686878879865, Validation Accuracy: 0.475\n",
      "Epoch 6953, Training Loss: 0.1739439796055517, Validation Loss: 0.17323117852210998, Validation Accuracy: 0.5125\n",
      "Epoch 6954, Training Loss: 0.1739003989965685, Validation Loss: 0.17367680470148722, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 6955, Training Loss: 0.1741814406648759, Validation Loss: 0.17302484611670177, Validation Accuracy: 0.5375\n",
      "Epoch 6956, Training Loss: 0.1739027778948507, Validation Loss: 0.17356500426928204, Validation Accuracy: 0.4875\n",
      "Epoch 6957, Training Loss: 0.1741008061555124, Validation Loss: 0.17345691919326783, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 6958, Training Loss: 0.17379849908813352, Validation Loss: 0.1738886257012685, Validation Accuracy: 0.475\n",
      "Epoch 6959, Training Loss: 0.17424864778595586, Validation Loss: 0.17286645571390788, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 6960, Training Loss: 0.17383207669181208, Validation Loss: 0.1739673376083374, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 6961, Training Loss: 0.17417214282097354, Validation Loss: 0.17339617908000945, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6962, Training Loss: 0.1737957957290834, Validation Loss: 0.1736631651719411, Validation Accuracy: 0.4875\n",
      "Epoch 6963, Training Loss: 0.1742299473093402, Validation Loss: 0.17305638094743092, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 6964, Training Loss: 0.17375852600220712, Validation Loss: 0.17361359496911366, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 6965, Training Loss: 0.1742939785603554, Validation Loss: 0.17339968880017598, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6966, Training Loss: 0.17365620741921087, Validation Loss: 0.1737239569425583, Validation Accuracy: 0.49375\n",
      "Epoch 6967, Training Loss: 0.17435028331895028, Validation Loss: 0.17328174610932667, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 6968, Training Loss: 0.17383590004136484, Validation Loss: 0.1733983745177587, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 6969, Training Loss: 0.17413076469975133, Validation Loss: 0.17353381017843883, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 6970, Training Loss: 0.17378049560131564, Validation Loss: 0.1732936143875122, Validation Accuracy: 0.5125\n",
      "Epoch 6971, Training Loss: 0.1742688628935045, Validation Loss: 0.1734414388736089, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 6972, Training Loss: 0.17388027618008275, Validation Loss: 0.17291076680024464, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 6973, Training Loss: 0.17405920643960276, Validation Loss: 0.17366004983584085, Validation Accuracy: 0.48125\n",
      "Epoch 6974, Training Loss: 0.17365569020471266, Validation Loss: 0.1734859675168991, Validation Accuracy: 0.50625\n",
      "Epoch 6975, Training Loss: 0.17442559330694138, Validation Loss: 0.17348915934562684, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 6976, Training Loss: 0.17369148712004384, Validation Loss: 0.17227565546830495, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 6977, Training Loss: 0.174327768145069, Validation Loss: 0.17350963950157167, Validation Accuracy: 0.475\n",
      "Epoch 6978, Training Loss: 0.1736694040798372, Validation Loss: 0.17328179279963177, Validation Accuracy: 0.5125\n",
      "Epoch 6979, Training Loss: 0.1743179218422982, Validation Loss: 0.17349591255187988, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 6980, Training Loss: 0.17373343388880452, Validation Loss: 0.17266098260879517, Validation Accuracy: 0.5375\n",
      "Epoch 6981, Training Loss: 0.17426031251107493, Validation Loss: 0.17348745763301848, Validation Accuracy: 0.4875\n",
      "Epoch 6982, Training Loss: 0.17365983753435074, Validation Loss: 0.17369807461897532, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 6983, Training Loss: 0.17436880353958376, Validation Loss: 0.1734564503033956, Validation Accuracy: 0.475\n",
      "Epoch 6984, Training Loss: 0.17369071418239224, Validation Loss: 0.17190862596035003, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 6985, Training Loss: 0.1742993655704683, Validation Loss: 0.17356795072555542, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 6986, Training Loss: 0.17363543087436306, Validation Loss: 0.17359999815622965, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6987, Training Loss: 0.17438663590338924, Validation Loss: 0.17336995402971903, Validation Accuracy: 0.4875\n",
      "Epoch 6988, Training Loss: 0.17370111567358817, Validation Loss: 0.17278597752253214, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 6989, Training Loss: 0.1742308255164854, Validation Loss: 0.1733328729867935, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 6990, Training Loss: 0.17369701304743368, Validation Loss: 0.17390332023302715, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 6991, Training Loss: 0.1744073768777232, Validation Loss: 0.17334143916765848, Validation Accuracy: 0.49375\n",
      "Epoch 6992, Training Loss: 0.17376663463730965, Validation Loss: 0.1738883525133133, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 6993, Training Loss: 0.17420148128463375, Validation Loss: 0.17326205472151437, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 6994, Training Loss: 0.17362132620426915, Validation Loss: 0.17443670630455016, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 6995, Training Loss: 0.17440451248999564, Validation Loss: 0.17323368887106577, Validation Accuracy: 0.5125\n",
      "Epoch 6996, Training Loss: 0.17371117203466355, Validation Loss: 0.1749082406361898, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 6997, Training Loss: 0.17426738960127677, Validation Loss: 0.17304825286070505, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 6998, Training Loss: 0.17364880682960634, Validation Loss: 0.17495849430561067, Validation Accuracy: 0.48125\n",
      "Epoch 6999, Training Loss: 0.17437858687293145, Validation Loss: 0.17329457998275757, Validation Accuracy: 0.50625\n",
      "Epoch 7000, Training Loss: 0.17355450939747594, Validation Loss: 0.1757013976573944, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 7001, Training Loss: 0.174486052124731, Validation Loss: 0.17268989781538646, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 7002, Training Loss: 0.17347432817182235, Validation Loss: 0.17531483272711437, Validation Accuracy: 0.475\n",
      "Epoch 7003, Training Loss: 0.17451863952221408, Validation Loss: 0.17321711679299673, Validation Accuracy: 0.5125\n",
      "Epoch 7004, Training Loss: 0.1734697453437313, Validation Loss: 0.1756031443675359, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 7005, Training Loss: 0.174517257559684, Validation Loss: 0.17291449904441833, Validation Accuracy: 0.5375\n",
      "Epoch 7006, Training Loss: 0.1734668948957997, Validation Loss: 0.17506032784779865, Validation Accuracy: 0.4875\n",
      "Epoch 7007, Training Loss: 0.17458654411377444, Validation Loss: 0.17360174258550007, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 7008, Training Loss: 0.17357297193619511, Validation Loss: 0.1753466119368871, Validation Accuracy: 0.475\n",
      "Epoch 7009, Training Loss: 0.1744326723198737, Validation Loss: 0.17262257734934489, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 7010, Training Loss: 0.17358130264666774, Validation Loss: 0.17556237876415254, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 7011, Training Loss: 0.174439680672461, Validation Loss: 0.17373823523521423, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7012, Training Loss: 0.17351433202143637, Validation Loss: 0.17497633596261342, Validation Accuracy: 0.4875\n",
      "Epoch 7013, Training Loss: 0.17414629459381104, Validation Loss: 0.17317264874776203, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 7014, Training Loss: 0.1735590946289801, Validation Loss: 0.1740131100018819, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 7015, Training Loss: 0.17443836167935403, Validation Loss: 0.17382384836673737, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7016, Training Loss: 0.1735678824686235, Validation Loss: 0.17480281194051106, Validation Accuracy: 0.49375\n",
      "Epoch 7017, Training Loss: 0.1744145534692272, Validation Loss: 0.17371268471082052, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 7018, Training Loss: 0.1735597224004807, Validation Loss: 0.1740452249844869, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 7019, Training Loss: 0.17428022719198658, Validation Loss: 0.17459857265154521, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 7020, Training Loss: 0.17362948915650767, Validation Loss: 0.17381053765614826, Validation Accuracy: 0.5125\n",
      "Epoch 7021, Training Loss: 0.1743428260087967, Validation Loss: 0.17475979328155516, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 7022, Training Loss: 0.17376653225191177, Validation Loss: 0.1730161021153132, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 7023, Training Loss: 0.17431126102324454, Validation Loss: 0.17479987939198813, Validation Accuracy: 0.48125\n",
      "Epoch 7024, Training Loss: 0.17354509522837977, Validation Loss: 0.1738890419403712, Validation Accuracy: 0.50625\n",
      "Epoch 7025, Training Loss: 0.17445034173227125, Validation Loss: 0.17555548548698424, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 7026, Training Loss: 0.17372504645778286, Validation Loss: 0.17227587401866912, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 7027, Training Loss: 0.17427109278017475, Validation Loss: 0.1757918268442154, Validation Accuracy: 0.475\n",
      "Epoch 7028, Training Loss: 0.17383010108624736, Validation Loss: 0.17348275383313497, Validation Accuracy: 0.5125\n",
      "Epoch 7029, Training Loss: 0.17397496873332607, Validation Loss: 0.1755413979291916, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 7030, Training Loss: 0.17398655270376512, Validation Loss: 0.1726692348718643, Validation Accuracy: 0.5375\n",
      "Epoch 7031, Training Loss: 0.1738861135898098, Validation Loss: 0.17573627432187397, Validation Accuracy: 0.4875\n",
      "Epoch 7032, Training Loss: 0.17401949436433853, Validation Loss: 0.17410872181256612, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 7033, Training Loss: 0.17395552656342905, Validation Loss: 0.17651304602622986, Validation Accuracy: 0.475\n",
      "Epoch 7034, Training Loss: 0.17400686250578973, Validation Loss: 0.17227409879366556, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 7035, Training Loss: 0.173791735883682, Validation Loss: 0.17729490995407104, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 7036, Training Loss: 0.17423752382878335, Validation Loss: 0.17387016117572784, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7037, Training Loss: 0.17375671623214597, Validation Loss: 0.17488425572713215, Validation Accuracy: 0.4875\n",
      "Epoch 7038, Training Loss: 0.1743585395236169, Validation Loss: 0.17272990047931672, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 7039, Training Loss: 0.17337237634966451, Validation Loss: 0.17562355399131774, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 7040, Training Loss: 0.17466950464633205, Validation Loss: 0.17378352085749307, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7041, Training Loss: 0.17366171075451758, Validation Loss: 0.17452080647150675, Validation Accuracy: 0.49375\n",
      "Epoch 7042, Training Loss: 0.17421751589544357, Validation Loss: 0.17360473275184632, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 7043, Training Loss: 0.17364391972941737, Validation Loss: 0.1746339440345764, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 7044, Training Loss: 0.17433793362109892, Validation Loss: 0.17393898864587148, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 7045, Training Loss: 0.17379154889814316, Validation Loss: 0.17368430296579998, Validation Accuracy: 0.5125\n",
      "Epoch 7046, Training Loss: 0.17414419160735223, Validation Loss: 0.17500371634960174, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 7047, Training Loss: 0.1735849029594852, Validation Loss: 0.17335252066453297, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 7048, Training Loss: 0.17427982053449076, Validation Loss: 0.17403206030527751, Validation Accuracy: 0.48125\n",
      "Epoch 7049, Training Loss: 0.17377283400104893, Validation Loss: 0.17393427391846975, Validation Accuracy: 0.50625\n",
      "Epoch 7050, Training Loss: 0.17424415917165817, Validation Loss: 0.17469558517138165, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 7051, Training Loss: 0.17367303852112062, Validation Loss: 0.17207548518975577, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 7052, Training Loss: 0.1743439104287855, Validation Loss: 0.1740286459525426, Validation Accuracy: 0.475\n",
      "Epoch 7053, Training Loss: 0.17384853189991367, Validation Loss: 0.17337244153022766, Validation Accuracy: 0.5125\n",
      "Epoch 7054, Training Loss: 0.1741668365655407, Validation Loss: 0.17463123699029287, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 7055, Training Loss: 0.17367305198023397, Validation Loss: 0.17274468143781027, Validation Accuracy: 0.5375\n",
      "Epoch 7056, Training Loss: 0.17435305781902805, Validation Loss: 0.17365918656190235, Validation Accuracy: 0.4875\n",
      "Epoch 7057, Training Loss: 0.17376882510800515, Validation Loss: 0.17433939079443614, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 7058, Training Loss: 0.17423177967148443, Validation Loss: 0.17417242924372356, Validation Accuracy: 0.475\n",
      "Epoch 7059, Training Loss: 0.17369245617620407, Validation Loss: 0.17176800668239595, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 7060, Training Loss: 0.17436931979271672, Validation Loss: 0.17375409205754597, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 7061, Training Loss: 0.17380075733507833, Validation Loss: 0.1738732655843099, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7062, Training Loss: 0.17421637667763618, Validation Loss: 0.1736818273862203, Validation Accuracy: 0.4875\n",
      "Epoch 7063, Training Loss: 0.17383267033484676, Validation Loss: 0.1728401154279709, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 7064, Training Loss: 0.17422627729754295, Validation Loss: 0.17345928351084391, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 7065, Training Loss: 0.1738439360933919, Validation Loss: 0.17350507179896038, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7066, Training Loss: 0.17418094700382603, Validation Loss: 0.17350453635056814, Validation Accuracy: 0.49375\n",
      "Epoch 7067, Training Loss: 0.17381977506222263, Validation Loss: 0.17330752313137054, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 7068, Training Loss: 0.17418063456012356, Validation Loss: 0.17326840857664744, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 7069, Training Loss: 0.17395286742717989, Validation Loss: 0.1734706073999405, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 7070, Training Loss: 0.17400904624692856, Validation Loss: 0.17322891851266226, Validation Accuracy: 0.5125\n",
      "Epoch 7071, Training Loss: 0.17391163447210867, Validation Loss: 0.17353109419345855, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 7072, Training Loss: 0.17403817897842777, Validation Loss: 0.17299768229325613, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 7073, Training Loss: 0.17408478308108546, Validation Loss: 0.17354420522848765, Validation Accuracy: 0.48125\n",
      "Epoch 7074, Training Loss: 0.17383787660829483, Validation Loss: 0.17348837753136953, Validation Accuracy: 0.50625\n",
      "Epoch 7075, Training Loss: 0.17399354951996956, Validation Loss: 0.17363723913828533, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 7076, Training Loss: 0.17414487417667143, Validation Loss: 0.17288862665494284, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 7077, Training Loss: 0.17397280229676154, Validation Loss: 0.17365872959295908, Validation Accuracy: 0.475\n",
      "Epoch 7078, Training Loss: 0.17398185691525858, Validation Loss: 0.1732247273127238, Validation Accuracy: 0.5125\n",
      "Epoch 7079, Training Loss: 0.17389746731327427, Validation Loss: 0.17369691332181295, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 7080, Training Loss: 0.1741307637383861, Validation Loss: 0.17295653820037843, Validation Accuracy: 0.5375\n",
      "Epoch 7081, Training Loss: 0.17392846845811413, Validation Loss: 0.1735899806022644, Validation Accuracy: 0.4875\n",
      "Epoch 7082, Training Loss: 0.17394749339549773, Validation Loss: 0.1736994981765747, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 7083, Training Loss: 0.1738634123917549, Validation Loss: 0.1739306648572286, Validation Accuracy: 0.475\n",
      "Epoch 7084, Training Loss: 0.17425718374790683, Validation Loss: 0.1729147881269455, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 7085, Training Loss: 0.1738370205125501, Validation Loss: 0.17389160494009653, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 7086, Training Loss: 0.17418140365231422, Validation Loss: 0.1733946233987808, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7087, Training Loss: 0.17377030272637645, Validation Loss: 0.17368463973204296, Validation Accuracy: 0.4875\n",
      "Epoch 7088, Training Loss: 0.17422361912265902, Validation Loss: 0.17304388483365377, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 7089, Training Loss: 0.17379696667194366, Validation Loss: 0.17368173897266387, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 7090, Training Loss: 0.17422626239638175, Validation Loss: 0.1734522094329198, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7091, Training Loss: 0.17368453356527513, Validation Loss: 0.17370184361934662, Validation Accuracy: 0.49375\n",
      "Epoch 7092, Training Loss: 0.17434420460654843, Validation Loss: 0.173281462987264, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 7093, Training Loss: 0.17383686861684244, Validation Loss: 0.1733604649702708, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 7094, Training Loss: 0.17415092500948137, Validation Loss: 0.17349949081738789, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 7095, Training Loss: 0.1737637096835721, Validation Loss: 0.17326082388559977, Validation Accuracy: 0.5125\n",
      "Epoch 7096, Training Loss: 0.17423922159979421, Validation Loss: 0.173447322845459, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 7097, Training Loss: 0.1738356577773248, Validation Loss: 0.17292317350705463, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 7098, Training Loss: 0.17420465715469852, Validation Loss: 0.17346383134524027, Validation Accuracy: 0.48125\n",
      "Epoch 7099, Training Loss: 0.1736482136672543, Validation Loss: 0.17346083223819733, Validation Accuracy: 0.50625\n",
      "Epoch 7100, Training Loss: 0.1743591139393468, Validation Loss: 0.17348480522632598, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 7101, Training Loss: 0.17370232170627964, Validation Loss: 0.17229396402835845, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 7102, Training Loss: 0.17431608226991469, Validation Loss: 0.173505499958992, Validation Accuracy: 0.475\n",
      "Epoch 7103, Training Loss: 0.17368322658923366, Validation Loss: 0.17332856059074403, Validation Accuracy: 0.5125\n",
      "Epoch 7104, Training Loss: 0.17433317486316927, Validation Loss: 0.17347415983676912, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 7105, Training Loss: 0.1736908963611049, Validation Loss: 0.17268208762009937, Validation Accuracy: 0.5375\n",
      "Epoch 7106, Training Loss: 0.17416164855803212, Validation Loss: 0.17352109551429748, Validation Accuracy: 0.4875\n",
      "Epoch 7107, Training Loss: 0.17369734135366255, Validation Loss: 0.17388301293055217, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 7108, Training Loss: 0.17442164305717714, Validation Loss: 0.17344364921251934, Validation Accuracy: 0.475\n",
      "Epoch 7109, Training Loss: 0.17365640594113257, Validation Loss: 0.171857155362765, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 7110, Training Loss: 0.17432683802420093, Validation Loss: 0.17355124255021412, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 7111, Training Loss: 0.1736444778019382, Validation Loss: 0.17363138496875763, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7112, Training Loss: 0.17438212806178677, Validation Loss: 0.1733651558558146, Validation Accuracy: 0.4875\n",
      "Epoch 7113, Training Loss: 0.17370457514639823, Validation Loss: 0.17273686230182647, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 7114, Training Loss: 0.17429021673817788, Validation Loss: 0.17333699464797975, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 7115, Training Loss: 0.17371014289317593, Validation Loss: 0.17393526037534077, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7116, Training Loss: 0.1742344613998167, Validation Loss: 0.17331042289733886, Validation Accuracy: 0.49375\n",
      "Epoch 7117, Training Loss: 0.17381670974916028, Validation Loss: 0.17354245185852052, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 7118, Training Loss: 0.17425934249354946, Validation Loss: 0.17325649956862132, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 7119, Training Loss: 0.17358392525103786, Validation Loss: 0.17434325019518535, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 7120, Training Loss: 0.17445859841762051, Validation Loss: 0.173222283522288, Validation Accuracy: 0.5125\n",
      "Epoch 7121, Training Loss: 0.17366255819797516, Validation Loss: 0.1749642829100291, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 7122, Training Loss: 0.17429688572883606, Validation Loss: 0.17302635113398235, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 7123, Training Loss: 0.17362058354962256, Validation Loss: 0.17460648814837137, Validation Accuracy: 0.48125\n",
      "Epoch 7124, Training Loss: 0.17436424666835415, Validation Loss: 0.17326986292997995, Validation Accuracy: 0.50625\n",
      "Epoch 7125, Training Loss: 0.17359864183010593, Validation Loss: 0.1757829397916794, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 7126, Training Loss: 0.17445630700357498, Validation Loss: 0.17273537615935008, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 7127, Training Loss: 0.17348950236074387, Validation Loss: 0.1750868300596873, Validation Accuracy: 0.475\n",
      "Epoch 7128, Training Loss: 0.17451745848501882, Validation Loss: 0.17321802377700807, Validation Accuracy: 0.5125\n",
      "Epoch 7129, Training Loss: 0.17345774894760502, Validation Loss: 0.1754593312740326, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 7130, Training Loss: 0.1744828478943917, Validation Loss: 0.17308326760927836, Validation Accuracy: 0.5375\n",
      "Epoch 7131, Training Loss: 0.17345611126192154, Validation Loss: 0.17502866685390472, Validation Accuracy: 0.4875\n",
      "Epoch 7132, Training Loss: 0.1745891167271522, Validation Loss: 0.1735955794652303, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 7133, Training Loss: 0.1735717687875994, Validation Loss: 0.17553851902484893, Validation Accuracy: 0.475\n",
      "Epoch 7134, Training Loss: 0.17427298907310732, Validation Loss: 0.17290641069412233, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 7135, Training Loss: 0.1736536761445384, Validation Loss: 0.17495102683703104, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 7136, Training Loss: 0.17441712704397017, Validation Loss: 0.1737369567155838, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7137, Training Loss: 0.17352720566334262, Validation Loss: 0.17506755193074544, Validation Accuracy: 0.4875\n",
      "Epoch 7138, Training Loss: 0.17432352900505066, Validation Loss: 0.17273884117603303, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 7139, Training Loss: 0.17359111337892472, Validation Loss: 0.1745019555091858, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 7140, Training Loss: 0.17440076172351837, Validation Loss: 0.17396148840586345, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7141, Training Loss: 0.1735795385414554, Validation Loss: 0.17476009726524352, Validation Accuracy: 0.49375\n",
      "Epoch 7142, Training Loss: 0.17439697202174895, Validation Loss: 0.1736242691675822, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 7143, Training Loss: 0.17353509799126657, Validation Loss: 0.17407833735148112, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 7144, Training Loss: 0.17428012817136704, Validation Loss: 0.17444108724594115, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 7145, Training Loss: 0.17358002835704434, Validation Loss: 0.17383691569169363, Validation Accuracy: 0.5125\n",
      "Epoch 7146, Training Loss: 0.17438245829074614, Validation Loss: 0.174083078900973, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 7147, Training Loss: 0.17363950562092564, Validation Loss: 0.1729097455739975, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 7148, Training Loss: 0.1743025976803995, Validation Loss: 0.17489152451356252, Validation Accuracy: 0.48125\n",
      "Epoch 7149, Training Loss: 0.17358436267222127, Validation Loss: 0.1739016701777776, Validation Accuracy: 0.50625\n",
      "Epoch 7150, Training Loss: 0.17440142362348496, Validation Loss: 0.1753530611594518, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 7151, Training Loss: 0.17380409807928146, Validation Loss: 0.17222022712230683, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 7152, Training Loss: 0.1742529498953973, Validation Loss: 0.17561781605084736, Validation Accuracy: 0.475\n",
      "Epoch 7153, Training Loss: 0.17378951032315532, Validation Loss: 0.17348969678084056, Validation Accuracy: 0.5125\n",
      "Epoch 7154, Training Loss: 0.17399156189733936, Validation Loss: 0.1758121023575465, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 7155, Training Loss: 0.17400626549797674, Validation Loss: 0.17265969514846802, Validation Accuracy: 0.5375\n",
      "Epoch 7156, Training Loss: 0.17388967400596989, Validation Loss: 0.17577949861685435, Validation Accuracy: 0.4875\n",
      "Epoch 7157, Training Loss: 0.17397183083718823, Validation Loss: 0.17414191663265227, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 7158, Training Loss: 0.1739815886943571, Validation Loss: 0.17561022639274598, Validation Accuracy: 0.475\n",
      "Epoch 7159, Training Loss: 0.1740972226665866, Validation Loss: 0.17191469768683115, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 7160, Training Loss: 0.1737814781165892, Validation Loss: 0.17691734631856282, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 7161, Training Loss: 0.17424158079008903, Validation Loss: 0.17389492193857828, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7162, Training Loss: 0.17369437602258497, Validation Loss: 0.17558761239051818, Validation Accuracy: 0.4875\n",
      "Epoch 7163, Training Loss: 0.174430241027186, Validation Loss: 0.1727312962214152, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 7164, Training Loss: 0.17335086003426584, Validation Loss: 0.17572097579638163, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 7165, Training Loss: 0.17469514762201616, Validation Loss: 0.1737682064374288, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7166, Training Loss: 0.17361292435276893, Validation Loss: 0.175128639737765, Validation Accuracy: 0.49375\n",
      "Epoch 7167, Training Loss: 0.17413974817722075, Validation Loss: 0.17357236941655477, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 7168, Training Loss: 0.1736515236477698, Validation Loss: 0.17439085841178895, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 7169, Training Loss: 0.17433542541919217, Validation Loss: 0.17403560876846313, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 7170, Training Loss: 0.17365340263612808, Validation Loss: 0.1747692992289861, Validation Accuracy: 0.5125\n",
      "Epoch 7171, Training Loss: 0.17430851488344132, Validation Loss: 0.17393847306569418, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 7172, Training Loss: 0.17377648766963713, Validation Loss: 0.17293555438518524, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 7173, Training Loss: 0.1741121800676469, Validation Loss: 0.1744418462117513, Validation Accuracy: 0.48125\n",
      "Epoch 7174, Training Loss: 0.17379088363339823, Validation Loss: 0.1736846387386322, Validation Accuracy: 0.50625\n",
      "Epoch 7175, Training Loss: 0.17412964951607487, Validation Loss: 0.17500172257423402, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 7176, Training Loss: 0.17368558529884584, Validation Loss: 0.1721212238073349, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 7177, Training Loss: 0.17432946351266676, Validation Loss: 0.1740640103816986, Validation Accuracy: 0.475\n",
      "Epoch 7178, Training Loss: 0.1738474061412196, Validation Loss: 0.1733969291051229, Validation Accuracy: 0.5125\n",
      "Epoch 7179, Training Loss: 0.1741571911881047, Validation Loss: 0.17483425835768382, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 7180, Training Loss: 0.17365338965769736, Validation Loss: 0.17279059092203777, Validation Accuracy: 0.5375\n",
      "Epoch 7181, Training Loss: 0.1743158741343406, Validation Loss: 0.1737286388874054, Validation Accuracy: 0.4875\n",
      "Epoch 7182, Training Loss: 0.17381243071248453, Validation Loss: 0.17412928342819214, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 7183, Training Loss: 0.17421212984669593, Validation Loss: 0.17416056295235952, Validation Accuracy: 0.475\n",
      "Epoch 7184, Training Loss: 0.1737211909024946, Validation Loss: 0.1718709498643875, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 7185, Training Loss: 0.17431355243729008, Validation Loss: 0.17383739252885183, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 7186, Training Loss: 0.17380389090507262, Validation Loss: 0.1738849848508835, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7187, Training Loss: 0.17424554978647538, Validation Loss: 0.17363744378089904, Validation Accuracy: 0.4875\n",
      "Epoch 7188, Training Loss: 0.1738009073080555, Validation Loss: 0.1727977971235911, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 7189, Training Loss: 0.1742644771452873, Validation Loss: 0.17341649532318115, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 7190, Training Loss: 0.17383106966172496, Validation Loss: 0.17352177302042643, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7191, Training Loss: 0.1741071992343472, Validation Loss: 0.17368912398815156, Validation Accuracy: 0.49375\n",
      "Epoch 7192, Training Loss: 0.17385201011934587, Validation Loss: 0.17335329751173656, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 7193, Training Loss: 0.1741842959196337, Validation Loss: 0.17326010763645172, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 7194, Training Loss: 0.17401192169035634, Validation Loss: 0.17347688376903533, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 7195, Training Loss: 0.1738640098802505, Validation Loss: 0.17327486177285512, Validation Accuracy: 0.5125\n",
      "Epoch 7196, Training Loss: 0.1739747432931777, Validation Loss: 0.1734930713971456, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 7197, Training Loss: 0.17410639745573844, Validation Loss: 0.17304314474264781, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 7198, Training Loss: 0.17401128959271214, Validation Loss: 0.17351142863432567, Validation Accuracy: 0.48125\n",
      "Epoch 7199, Training Loss: 0.1740029978175317, Validation Loss: 0.17332588334878285, Validation Accuracy: 0.50625\n",
      "Epoch 7200, Training Loss: 0.173923215558452, Validation Loss: 0.17357089420159658, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 7201, Training Loss: 0.1741636481977278, Validation Loss: 0.172835906346639, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 7202, Training Loss: 0.1739063916667815, Validation Loss: 0.17360094686349234, Validation Accuracy: 0.475\n",
      "Epoch 7203, Training Loss: 0.17397006384788022, Validation Loss: 0.1732378661632538, Validation Accuracy: 0.5125\n",
      "Epoch 7204, Training Loss: 0.1739525766141953, Validation Loss: 0.17375076512495677, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 7205, Training Loss: 0.17416019785788753, Validation Loss: 0.1730116347471873, Validation Accuracy: 0.5375\n",
      "Epoch 7206, Training Loss: 0.17394062876701355, Validation Loss: 0.17358789443969727, Validation Accuracy: 0.4875\n",
      "Epoch 7207, Training Loss: 0.174048864072369, Validation Loss: 0.17351932128270467, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 7208, Training Loss: 0.17381722792502372, Validation Loss: 0.17391047577063243, Validation Accuracy: 0.475\n",
      "Epoch 7209, Training Loss: 0.17423704410752944, Validation Loss: 0.17281495432058971, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 7210, Training Loss: 0.1738390278431677, Validation Loss: 0.17401349544525146, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 7211, Training Loss: 0.17419286697141587, Validation Loss: 0.17338245312372844, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7212, Training Loss: 0.17376665146120132, Validation Loss: 0.17369484404722849, Validation Accuracy: 0.4875\n",
      "Epoch 7213, Training Loss: 0.17426864706700848, Validation Loss: 0.17308524946371714, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 7214, Training Loss: 0.1737376211151, Validation Loss: 0.17366127570470175, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 7215, Training Loss: 0.17415090434012875, Validation Loss: 0.17354988058408102, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7216, Training Loss: 0.17372968023823154, Validation Loss: 0.1737941821416219, Validation Accuracy: 0.49375\n",
      "Epoch 7217, Training Loss: 0.17430289281952766, Validation Loss: 0.17329190572102865, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 7218, Training Loss: 0.1738411000659389, Validation Loss: 0.1733129898707072, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 7219, Training Loss: 0.17396066265721474, Validation Loss: 0.1739120642344157, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 7220, Training Loss: 0.17381441016351024, Validation Loss: 0.17331452965736388, Validation Accuracy: 0.5125\n",
      "Epoch 7221, Training Loss: 0.17419294484200015, Validation Loss: 0.17356552680333456, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 7222, Training Loss: 0.17380431150236436, Validation Loss: 0.17297120094299318, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 7223, Training Loss: 0.17416807288123715, Validation Loss: 0.17356480956077575, Validation Accuracy: 0.48125\n",
      "Epoch 7224, Training Loss: 0.17364144661734182, Validation Loss: 0.17354055047035216, Validation Accuracy: 0.50625\n",
      "Epoch 7225, Training Loss: 0.17417137805492647, Validation Loss: 0.17387646039326984, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 7226, Training Loss: 0.17371260014272505, Validation Loss: 0.17252139747142792, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 7227, Training Loss: 0.174158874538637, Validation Loss: 0.17367800076802573, Validation Accuracy: 0.475\n",
      "Epoch 7228, Training Loss: 0.17363241987843667, Validation Loss: 0.17328676382700603, Validation Accuracy: 0.5125\n",
      "Epoch 7229, Training Loss: 0.17432326559097536, Validation Loss: 0.17345112760861714, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 7230, Training Loss: 0.1736366282547674, Validation Loss: 0.17283715109030406, Validation Accuracy: 0.5375\n",
      "Epoch 7231, Training Loss: 0.17414571008374613, Validation Loss: 0.17337350845336913, Validation Accuracy: 0.4875\n",
      "Epoch 7232, Training Loss: 0.1736789047718048, Validation Loss: 0.17373212377230327, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 7233, Training Loss: 0.17446767995434423, Validation Loss: 0.17344140509764353, Validation Accuracy: 0.475\n",
      "Epoch 7234, Training Loss: 0.17363014913374378, Validation Loss: 0.17193093597888948, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 7235, Training Loss: 0.17437763848612386, Validation Loss: 0.1735413610935211, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 7236, Training Loss: 0.17366608640839976, Validation Loss: 0.17380189498265583, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7237, Training Loss: 0.1743753994664838, Validation Loss: 0.1734048585096995, Validation Accuracy: 0.4875\n",
      "Epoch 7238, Training Loss: 0.17370264136022137, Validation Loss: 0.1727288047472636, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 7239, Training Loss: 0.174253755519467, Validation Loss: 0.17334112723668416, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 7240, Training Loss: 0.1736807640521757, Validation Loss: 0.17367195785045625, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7241, Training Loss: 0.17442045817452093, Validation Loss: 0.1733443945646286, Validation Accuracy: 0.49375\n",
      "Epoch 7242, Training Loss: 0.17377418664193922, Validation Loss: 0.17390735844771069, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 7243, Training Loss: 0.1741996931452905, Validation Loss: 0.17325807909170787, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 7244, Training Loss: 0.17360333906066033, Validation Loss: 0.17404977877934774, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 7245, Training Loss: 0.1744914319246046, Validation Loss: 0.17322572867075603, Validation Accuracy: 0.5125\n",
      "Epoch 7246, Training Loss: 0.1736606652698209, Validation Loss: 0.17469266057014465, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 7247, Training Loss: 0.17430478190222093, Validation Loss: 0.17316735188166302, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 7248, Training Loss: 0.17364927453379478, Validation Loss: 0.1749238779147466, Validation Accuracy: 0.48125\n",
      "Epoch 7249, Training Loss: 0.17441554079132696, Validation Loss: 0.17328001360098522, Validation Accuracy: 0.50625\n",
      "Epoch 7250, Training Loss: 0.17352429801417935, Validation Loss: 0.17550158500671387, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 7251, Training Loss: 0.17456002437299298, Validation Loss: 0.17280942897001902, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 7252, Training Loss: 0.17344583907435018, Validation Loss: 0.1755904108285904, Validation Accuracy: 0.475\n",
      "Epoch 7253, Training Loss: 0.17447804347161325, Validation Loss: 0.1732382317384084, Validation Accuracy: 0.5125\n",
      "Epoch 7254, Training Loss: 0.17353335840086784, Validation Loss: 0.1752702921628952, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 7255, Training Loss: 0.17445345607496077, Validation Loss: 0.17304816941420237, Validation Accuracy: 0.5375\n",
      "Epoch 7256, Training Loss: 0.17347466416897311, Validation Loss: 0.1746783047914505, Validation Accuracy: 0.4875\n",
      "Epoch 7257, Training Loss: 0.174550358806887, Validation Loss: 0.17357296546300252, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 7258, Training Loss: 0.17357818397783464, Validation Loss: 0.17541466355323793, Validation Accuracy: 0.475\n",
      "Epoch 7259, Training Loss: 0.1743687968100271, Validation Loss: 0.17290405829747518, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 7260, Training Loss: 0.17359746704178472, Validation Loss: 0.17504659394423167, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 7261, Training Loss: 0.17443710132952658, Validation Loss: 0.17368237574895223, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7262, Training Loss: 0.1735122050008466, Validation Loss: 0.17501920064290363, Validation Accuracy: 0.4875\n",
      "Epoch 7263, Training Loss: 0.1743462686577151, Validation Loss: 0.1727424611647924, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 7264, Training Loss: 0.17358306194505385, Validation Loss: 0.17469955384731292, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 7265, Training Loss: 0.1744019643914315, Validation Loss: 0.17390257120132446, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7266, Training Loss: 0.17358268557056303, Validation Loss: 0.17485562364260357, Validation Accuracy: 0.49375\n",
      "Epoch 7267, Training Loss: 0.17434900806796166, Validation Loss: 0.17373568614323934, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 7268, Training Loss: 0.17361776723015693, Validation Loss: 0.17399531503518423, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 7269, Training Loss: 0.17427256559171983, Validation Loss: 0.17453768948713938, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 7270, Training Loss: 0.1736172192519711, Validation Loss: 0.17379716436068218, Validation Accuracy: 0.5125\n",
      "Epoch 7271, Training Loss: 0.17437149343952055, Validation Loss: 0.17479754388332366, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 7272, Training Loss: 0.17374708479450596, Validation Loss: 0.17302094201246898, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 7273, Training Loss: 0.17432056800011667, Validation Loss: 0.17491462032000224, Validation Accuracy: 0.48125\n",
      "Epoch 7274, Training Loss: 0.17355838177665586, Validation Loss: 0.17389598886171978, Validation Accuracy: 0.50625\n",
      "Epoch 7275, Training Loss: 0.17448854206069822, Validation Loss: 0.17566307485103608, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 7276, Training Loss: 0.1737441377293679, Validation Loss: 0.1721253345410029, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 7277, Training Loss: 0.1741959995800449, Validation Loss: 0.1756049931049347, Validation Accuracy: 0.475\n",
      "Epoch 7278, Training Loss: 0.1738799637363803, Validation Loss: 0.17353647351264953, Validation Accuracy: 0.5125\n",
      "Epoch 7279, Training Loss: 0.17396548150047178, Validation Loss: 0.17581077615420024, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 7280, Training Loss: 0.17401278547702298, Validation Loss: 0.17266093691190085, Validation Accuracy: 0.5375\n",
      "Epoch 7281, Training Loss: 0.17387508528847848, Validation Loss: 0.17577725350856782, Validation Accuracy: 0.4875\n",
      "Epoch 7282, Training Loss: 0.17398843553758436, Validation Loss: 0.17413703203201295, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 7283, Training Loss: 0.17397966356046737, Validation Loss: 0.17601861655712128, Validation Accuracy: 0.475\n",
      "Epoch 7284, Training Loss: 0.17406232943457942, Validation Loss: 0.1719847470521927, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 7285, Training Loss: 0.1737957385278517, Validation Loss: 0.1772329439719518, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 7286, Training Loss: 0.17419834242713067, Validation Loss: 0.17380871872107187, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7287, Training Loss: 0.17375472476405482, Validation Loss: 0.17468492090702056, Validation Accuracy: 0.4875\n",
      "Epoch 7288, Training Loss: 0.17433343395110099, Validation Loss: 0.1727424144744873, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 7289, Training Loss: 0.1733788506638619, Validation Loss: 0.1755183885494868, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 7290, Training Loss: 0.1746859064986629, Validation Loss: 0.17379949887593588, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7291, Training Loss: 0.17363596731616604, Validation Loss: 0.17473842998345693, Validation Accuracy: 0.49375\n",
      "Epoch 7292, Training Loss: 0.1742595011188138, Validation Loss: 0.17378726402918498, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 7293, Training Loss: 0.17362370269913827, Validation Loss: 0.1747901111841202, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 7294, Training Loss: 0.17435273672303847, Validation Loss: 0.17398665547370912, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 7295, Training Loss: 0.17376581988027018, Validation Loss: 0.17407483259836834, Validation Accuracy: 0.5125\n",
      "Epoch 7296, Training Loss: 0.17423621348796353, Validation Loss: 0.17423575222492219, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 7297, Training Loss: 0.1736132118009752, Validation Loss: 0.1733033816019694, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 7298, Training Loss: 0.17431644085914857, Validation Loss: 0.17404016156991323, Validation Accuracy: 0.48125\n",
      "Epoch 7299, Training Loss: 0.17372567519064872, Validation Loss: 0.1741529901822408, Validation Accuracy: 0.50625\n",
      "Epoch 7300, Training Loss: 0.1743161827325821, Validation Loss: 0.17442208031813303, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 7301, Training Loss: 0.1736278557969678, Validation Loss: 0.1720782409111659, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 7302, Training Loss: 0.17439870776668673, Validation Loss: 0.17393235365549722, Validation Accuracy: 0.475\n",
      "Epoch 7303, Training Loss: 0.17368175185495807, Validation Loss: 0.1739872415860494, Validation Accuracy: 0.5125\n",
      "Epoch 7304, Training Loss: 0.17429488608914037, Validation Loss: 0.17437813679377237, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 7305, Training Loss: 0.1735809959711567, Validation Loss: 0.17282537122567496, Validation Accuracy: 0.5375\n",
      "Epoch 7306, Training Loss: 0.1744885718630206, Validation Loss: 0.17359738051891327, Validation Accuracy: 0.4875\n",
      "Epoch 7307, Training Loss: 0.17378666179795418, Validation Loss: 0.17421034971872965, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 7308, Training Loss: 0.1742295738189451, Validation Loss: 0.17410366435845692, Validation Accuracy: 0.475\n",
      "Epoch 7309, Training Loss: 0.1737048952810226, Validation Loss: 0.17172731161117555, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 7310, Training Loss: 0.1743178593535577, Validation Loss: 0.17379102408885955, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 7311, Training Loss: 0.17380827569192456, Validation Loss: 0.17384734352429707, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7312, Training Loss: 0.17419304434330232, Validation Loss: 0.17374107241630554, Validation Accuracy: 0.4875\n",
      "Epoch 7313, Training Loss: 0.17383671335635648, Validation Loss: 0.1728100130955378, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 7314, Training Loss: 0.1742357212689615, Validation Loss: 0.17344677050908405, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 7315, Training Loss: 0.17383499924213655, Validation Loss: 0.17352755665779113, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7316, Training Loss: 0.1742004458942721, Validation Loss: 0.17349160313606263, Validation Accuracy: 0.49375\n",
      "Epoch 7317, Training Loss: 0.17380550551799037, Validation Loss: 0.17331533829371135, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 7318, Training Loss: 0.17420077131640527, Validation Loss: 0.17326047023137411, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 7319, Training Loss: 0.17393420828926948, Validation Loss: 0.17346316675345103, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 7320, Training Loss: 0.17396501619969645, Validation Loss: 0.17324535846710204, Validation Accuracy: 0.5125\n",
      "Epoch 7321, Training Loss: 0.17400156874810496, Validation Loss: 0.1735272059837977, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 7322, Training Loss: 0.1740487765881323, Validation Loss: 0.17299485703309378, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 7323, Training Loss: 0.17402313072835246, Validation Loss: 0.17352010409037272, Validation Accuracy: 0.48125\n",
      "Epoch 7324, Training Loss: 0.17399129752189882, Validation Loss: 0.1733449826637904, Validation Accuracy: 0.50625\n",
      "Epoch 7325, Training Loss: 0.17394931325989385, Validation Loss: 0.1735907773176829, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 7326, Training Loss: 0.1741792078941099, Validation Loss: 0.17285841902097066, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 7327, Training Loss: 0.17388230946756178, Validation Loss: 0.1736307869354884, Validation Accuracy: 0.475\n",
      "Epoch 7328, Training Loss: 0.17413682514621365, Validation Loss: 0.17321982781092327, Validation Accuracy: 0.5125\n",
      "Epoch 7329, Training Loss: 0.1738366412539636, Validation Loss: 0.17364479800065358, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 7330, Training Loss: 0.17418781788118423, Validation Loss: 0.1730169286330541, Validation Accuracy: 0.5375\n",
      "Epoch 7331, Training Loss: 0.17388398464648955, Validation Loss: 0.17355085810025533, Validation Accuracy: 0.4875\n",
      "Epoch 7332, Training Loss: 0.17413815663706872, Validation Loss: 0.17344152927398682, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 7333, Training Loss: 0.1737824361170492, Validation Loss: 0.1738314598798752, Validation Accuracy: 0.475\n",
      "Epoch 7334, Training Loss: 0.1742604120123771, Validation Loss: 0.17287167012691498, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 7335, Training Loss: 0.17381014650867832, Validation Loss: 0.17402426302433013, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 7336, Training Loss: 0.1741802668379199, Validation Loss: 0.173398091395696, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7337, Training Loss: 0.17380430813758604, Validation Loss: 0.17365243832270305, Validation Accuracy: 0.4875\n",
      "Epoch 7338, Training Loss: 0.17424430674122227, Validation Loss: 0.17306176126003264, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 7339, Training Loss: 0.17377435007402975, Validation Loss: 0.1736476351817449, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 7340, Training Loss: 0.17410353979756754, Validation Loss: 0.17364483177661896, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7341, Training Loss: 0.17375124702530523, Validation Loss: 0.1737139642238617, Validation Accuracy: 0.49375\n",
      "Epoch 7342, Training Loss: 0.17433547541018454, Validation Loss: 0.17328340609868367, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 7343, Training Loss: 0.17383506605702062, Validation Loss: 0.1733430157105128, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 7344, Training Loss: 0.17416477251437404, Validation Loss: 0.17348955273628236, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 7345, Training Loss: 0.173741846796005, Validation Loss: 0.17327104310194652, Validation Accuracy: 0.5125\n",
      "Epoch 7346, Training Loss: 0.17429577823608153, Validation Loss: 0.173413943250974, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 7347, Training Loss: 0.1737929673925523, Validation Loss: 0.1729218860467275, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 7348, Training Loss: 0.17416195955968672, Validation Loss: 0.17351629038651784, Validation Accuracy: 0.48125\n",
      "Epoch 7349, Training Loss: 0.17363456276155287, Validation Loss: 0.17355134586493173, Validation Accuracy: 0.50625\n",
      "Epoch 7350, Training Loss: 0.1743904318540327, Validation Loss: 0.1735049198071162, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 7351, Training Loss: 0.17373597718054248, Validation Loss: 0.1722162554661433, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 7352, Training Loss: 0.1742441452318622, Validation Loss: 0.1735082060098648, Validation Accuracy: 0.475\n",
      "Epoch 7353, Training Loss: 0.17362242792883226, Validation Loss: 0.17327335476875305, Validation Accuracy: 0.5125\n",
      "Epoch 7354, Training Loss: 0.1742584830330264, Validation Loss: 0.17361527681350708, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 7355, Training Loss: 0.1737021452957584, Validation Loss: 0.17273698449134828, Validation Accuracy: 0.5375\n",
      "Epoch 7356, Training Loss: 0.17417068731400273, Validation Loss: 0.17349469165007272, Validation Accuracy: 0.4875\n",
      "Epoch 7357, Training Loss: 0.1736721247434616, Validation Loss: 0.17367707788944245, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 7358, Training Loss: 0.17445915168331516, Validation Loss: 0.17341700494289397, Validation Accuracy: 0.475\n",
      "Epoch 7359, Training Loss: 0.1736421964822277, Validation Loss: 0.17187414765357972, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 7360, Training Loss: 0.1743245389192335, Validation Loss: 0.17360086143016815, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 7361, Training Loss: 0.17364399423522334, Validation Loss: 0.17361042996247608, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7362, Training Loss: 0.17438976274382684, Validation Loss: 0.1733660141626994, Validation Accuracy: 0.4875\n",
      "Epoch 7363, Training Loss: 0.17371401575303846, Validation Loss: 0.172740971048673, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 7364, Training Loss: 0.1742896500133699, Validation Loss: 0.17335199217001598, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 7365, Training Loss: 0.1737064310619908, Validation Loss: 0.17413157721360525, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7366, Training Loss: 0.17434955652683012, Validation Loss: 0.1733493059873581, Validation Accuracy: 0.49375\n",
      "Epoch 7367, Training Loss: 0.1737641865207303, Validation Loss: 0.17365409731864928, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 7368, Training Loss: 0.17424604537025576, Validation Loss: 0.17325629492600758, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 7369, Training Loss: 0.17360957784037437, Validation Loss: 0.17442646423975627, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 7370, Training Loss: 0.17443801799128134, Validation Loss: 0.1732398360967636, Validation Accuracy: 0.5125\n",
      "Epoch 7371, Training Loss: 0.1736698559214992, Validation Loss: 0.17451670666535696, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 7372, Training Loss: 0.17431852798308095, Validation Loss: 0.17314814825852712, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 7373, Training Loss: 0.17362844463317625, Validation Loss: 0.17486697634061177, Validation Accuracy: 0.48125\n",
      "Epoch 7374, Training Loss: 0.17442373546861833, Validation Loss: 0.1732809950908025, Validation Accuracy: 0.50625\n",
      "Epoch 7375, Training Loss: 0.17352166627683946, Validation Loss: 0.1757702132066091, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 7376, Training Loss: 0.1745319231863945, Validation Loss: 0.17265043159325918, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 7377, Training Loss: 0.17345905784637697, Validation Loss: 0.17546712160110473, Validation Accuracy: 0.475\n",
      "Epoch 7378, Training Loss: 0.17449585660811393, Validation Loss: 0.17321725090344747, Validation Accuracy: 0.5125\n",
      "Epoch 7379, Training Loss: 0.17349394146473177, Validation Loss: 0.17547838985919953, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 7380, Training Loss: 0.17445674682817153, Validation Loss: 0.17312100927035015, Validation Accuracy: 0.5375\n",
      "Epoch 7381, Training Loss: 0.17346338687404508, Validation Loss: 0.17485495507717133, Validation Accuracy: 0.4875\n",
      "Epoch 7382, Training Loss: 0.17442207471016916, Validation Loss: 0.1733164370059967, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 7383, Training Loss: 0.1736707870037325, Validation Loss: 0.17518607278664908, Validation Accuracy: 0.475\n",
      "Epoch 7384, Training Loss: 0.17440825460418577, Validation Loss: 0.17239776253700256, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 7385, Training Loss: 0.1735805340351597, Validation Loss: 0.17516601085662842, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 7386, Training Loss: 0.17442322738708987, Validation Loss: 0.17344728211561838, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7387, Training Loss: 0.17354711409538023, Validation Loss: 0.1750170648097992, Validation Accuracy: 0.4875\n",
      "Epoch 7388, Training Loss: 0.17420482395156736, Validation Loss: 0.1731150637070338, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 7389, Training Loss: 0.17356162542296993, Validation Loss: 0.17399793366591135, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 7390, Training Loss: 0.17439057365540536, Validation Loss: 0.17386878033479056, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7391, Training Loss: 0.17359551643171617, Validation Loss: 0.1749716450770696, Validation Accuracy: 0.49375\n",
      "Epoch 7392, Training Loss: 0.17428522148439962, Validation Loss: 0.17372419238090514, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 7393, Training Loss: 0.1736558190276546, Validation Loss: 0.17392786542574565, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 7394, Training Loss: 0.17426259190805496, Validation Loss: 0.1745204011599223, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 7395, Training Loss: 0.1736185493007783, Validation Loss: 0.1738212674856186, Validation Accuracy: 0.5125\n",
      "Epoch 7396, Training Loss: 0.17441341232868932, Validation Loss: 0.17483471234639486, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 7397, Training Loss: 0.17371003858504758, Validation Loss: 0.1730237493912379, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 7398, Training Loss: 0.17431301263070875, Validation Loss: 0.17497812310854594, Validation Accuracy: 0.48125\n",
      "Epoch 7399, Training Loss: 0.17358233467225107, Validation Loss: 0.17385536034901936, Validation Accuracy: 0.50625\n",
      "Epoch 7400, Training Loss: 0.174451750613028, Validation Loss: 0.1743469754854838, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 7401, Training Loss: 0.1736113679024481, Validation Loss: 0.17241060634454092, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 7402, Training Loss: 0.1742738466108999, Validation Loss: 0.1756909082333247, Validation Accuracy: 0.475\n",
      "Epoch 7403, Training Loss: 0.17375511940448515, Validation Loss: 0.17344279785950978, Validation Accuracy: 0.5125\n",
      "Epoch 7404, Training Loss: 0.1740379487314532, Validation Loss: 0.17591687043507895, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 7405, Training Loss: 0.17398225299773679, Validation Loss: 0.17266121009985605, Validation Accuracy: 0.5375\n",
      "Epoch 7406, Training Loss: 0.1739052269727953, Validation Loss: 0.17586565911769866, Validation Accuracy: 0.4875\n",
      "Epoch 7407, Training Loss: 0.17397214183884283, Validation Loss: 0.17409605880578358, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 7408, Training Loss: 0.17398260101195304, Validation Loss: 0.1758227010567983, Validation Accuracy: 0.475\n",
      "Epoch 7409, Training Loss: 0.17408591124319261, Validation Loss: 0.17202508548895518, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 7410, Training Loss: 0.17377883628491433, Validation Loss: 0.1771335482597351, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 7411, Training Loss: 0.17426987809519615, Validation Loss: 0.17385627329349518, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7412, Training Loss: 0.1737049678640981, Validation Loss: 0.1754673997561137, Validation Accuracy: 0.4875\n",
      "Epoch 7413, Training Loss: 0.17442837982408463, Validation Loss: 0.17273162106672924, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 7414, Training Loss: 0.17337193892848107, Validation Loss: 0.1757580131292343, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 7415, Training Loss: 0.17469161604681321, Validation Loss: 0.17379918396472932, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7416, Training Loss: 0.17363467956742934, Validation Loss: 0.17486020227273305, Validation Accuracy: 0.49375\n",
      "Epoch 7417, Training Loss: 0.17428570889657544, Validation Loss: 0.17360023458798726, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 7418, Training Loss: 0.17365624443177255, Validation Loss: 0.17459799846013388, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 7419, Training Loss: 0.17435286266188468, Validation Loss: 0.17396150330702465, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 7420, Training Loss: 0.17381421548704948, Validation Loss: 0.17360303401947022, Validation Accuracy: 0.5125\n",
      "Epoch 7421, Training Loss: 0.17419267517905082, Validation Loss: 0.17443081637223562, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 7422, Training Loss: 0.1736003924762049, Validation Loss: 0.17330629229545594, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 7423, Training Loss: 0.17431097501708614, Validation Loss: 0.17407831052939096, Validation Accuracy: 0.48125\n",
      "Epoch 7424, Training Loss: 0.173743236449457, Validation Loss: 0.1741354485352834, Validation Accuracy: 0.50625\n",
      "Epoch 7425, Training Loss: 0.1743158015512651, Validation Loss: 0.17442905008792878, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 7426, Training Loss: 0.17367067308195175, Validation Loss: 0.17207680841286976, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 7427, Training Loss: 0.17433380359603512, Validation Loss: 0.17403855125109355, Validation Accuracy: 0.475\n",
      "Epoch 7428, Training Loss: 0.17384074243807024, Validation Loss: 0.17338869074980418, Validation Accuracy: 0.5125\n",
      "Epoch 7429, Training Loss: 0.17417261677403603, Validation Loss: 0.17454123894373577, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 7430, Training Loss: 0.1736506478440377, Validation Loss: 0.17276821732521058, Validation Accuracy: 0.5375\n",
      "Epoch 7431, Training Loss: 0.17436714181976934, Validation Loss: 0.17366581062475842, Validation Accuracy: 0.4875\n",
      "Epoch 7432, Training Loss: 0.1737898689123892, Validation Loss: 0.174172846476237, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 7433, Training Loss: 0.1741687044981987, Validation Loss: 0.17449308335781097, Validation Accuracy: 0.475\n",
      "Epoch 7434, Training Loss: 0.17373980822101717, Validation Loss: 0.17177505592505138, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 7435, Training Loss: 0.17434846489660202, Validation Loss: 0.17378085255622863, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 7436, Training Loss: 0.17379289577084203, Validation Loss: 0.17381100356578827, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7437, Training Loss: 0.1742255283940223, Validation Loss: 0.17365654408931733, Validation Accuracy: 0.4875\n",
      "Epoch 7438, Training Loss: 0.17387334281398403, Validation Loss: 0.17288348376750945, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 7439, Training Loss: 0.17417541098210118, Validation Loss: 0.17350825369358064, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 7440, Training Loss: 0.17383946382230328, Validation Loss: 0.17355701526006062, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7441, Training Loss: 0.17416008585883724, Validation Loss: 0.17353756030400594, Validation Accuracy: 0.49375\n",
      "Epoch 7442, Training Loss: 0.17383275012816152, Validation Loss: 0.17331793308258056, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 7443, Training Loss: 0.17419232091596049, Validation Loss: 0.17326030631860098, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 7444, Training Loss: 0.17401287536467275, Validation Loss: 0.17351139783859254, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 7445, Training Loss: 0.17384985137370326, Validation Loss: 0.17327483296394347, Validation Accuracy: 0.5125\n",
      "Epoch 7446, Training Loss: 0.17396386256141047, Validation Loss: 0.17353498737017314, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 7447, Training Loss: 0.17412469992714544, Validation Loss: 0.173058158159256, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 7448, Training Loss: 0.17399593851258677, Validation Loss: 0.17346464991569518, Validation Accuracy: 0.48125\n",
      "Epoch 7449, Training Loss: 0.17402120030695392, Validation Loss: 0.17332649528980254, Validation Accuracy: 0.50625\n",
      "Epoch 7450, Training Loss: 0.1739164360107914, Validation Loss: 0.17352232336997986, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 7451, Training Loss: 0.17402233856339608, Validation Loss: 0.17265855769316354, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 7452, Training Loss: 0.17391362642088243, Validation Loss: 0.1736868917942047, Validation Accuracy: 0.475\n",
      "Epoch 7453, Training Loss: 0.17384742921398533, Validation Loss: 0.17328831553459167, Validation Accuracy: 0.5125\n",
      "Epoch 7454, Training Loss: 0.17386841245235934, Validation Loss: 0.17380489508310953, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 7455, Training Loss: 0.17413601183122204, Validation Loss: 0.17297116617361705, Validation Accuracy: 0.5375\n",
      "Epoch 7456, Training Loss: 0.17398644022403226, Validation Loss: 0.17362707753976186, Validation Accuracy: 0.4875\n",
      "Epoch 7457, Training Loss: 0.174050766133493, Validation Loss: 0.173490575949351, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 7458, Training Loss: 0.173804075967881, Validation Loss: 0.1739254266023636, Validation Accuracy: 0.475\n",
      "Epoch 7459, Training Loss: 0.1742534339427948, Validation Loss: 0.1728842188914617, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 7460, Training Loss: 0.17388055978282804, Validation Loss: 0.1740008294582367, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 7461, Training Loss: 0.17397605988287157, Validation Loss: 0.1735853095849355, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7462, Training Loss: 0.17385008642750402, Validation Loss: 0.173904753724734, Validation Accuracy: 0.4875\n",
      "Epoch 7463, Training Loss: 0.1742310437463945, Validation Loss: 0.17304784655570984, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 7464, Training Loss: 0.17378254475132113, Validation Loss: 0.17366211811701457, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 7465, Training Loss: 0.17419092164885613, Validation Loss: 0.17348107794920603, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7466, Training Loss: 0.173617823950706, Validation Loss: 0.17387800017992655, Validation Accuracy: 0.49375\n",
      "Epoch 7467, Training Loss: 0.1743625090006859, Validation Loss: 0.17329569359620411, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 7468, Training Loss: 0.17390397671730287, Validation Loss: 0.17342170774936677, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 7469, Training Loss: 0.17408897078806354, Validation Loss: 0.1735659162203471, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 7470, Training Loss: 0.17374624696470076, Validation Loss: 0.17327889601389568, Validation Accuracy: 0.5125\n",
      "Epoch 7471, Training Loss: 0.17429958091628167, Validation Loss: 0.17343056400616963, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 7472, Training Loss: 0.17385643047671165, Validation Loss: 0.17290825843811036, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 7473, Training Loss: 0.1741251983950215, Validation Loss: 0.17354335685571035, Validation Accuracy: 0.48125\n",
      "Epoch 7474, Training Loss: 0.17365094923203991, Validation Loss: 0.17347028950850168, Validation Accuracy: 0.50625\n",
      "Epoch 7475, Training Loss: 0.17437666462313745, Validation Loss: 0.17348823348681133, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 7476, Training Loss: 0.17369651602160546, Validation Loss: 0.17234433988730113, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 7477, Training Loss: 0.17408309540440958, Validation Loss: 0.17383053700129192, Validation Accuracy: 0.475\n",
      "Epoch 7478, Training Loss: 0.17378382528981856, Validation Loss: 0.17332886258761088, Validation Accuracy: 0.5125\n",
      "Epoch 7479, Training Loss: 0.17433584601648391, Validation Loss: 0.17355373601118723, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 7480, Training Loss: 0.17373972602428928, Validation Loss: 0.17265919844309488, Validation Accuracy: 0.5375\n",
      "Epoch 7481, Training Loss: 0.17424058241228904, Validation Loss: 0.17350700894991558, Validation Accuracy: 0.4875\n",
      "Epoch 7482, Training Loss: 0.1736645217864744, Validation Loss: 0.17374999821186066, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 7483, Training Loss: 0.1743902458298591, Validation Loss: 0.17341128885746002, Validation Accuracy: 0.475\n",
      "Epoch 7484, Training Loss: 0.17365704813311178, Validation Loss: 0.17215409775575002, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 7485, Training Loss: 0.1743737853342487, Validation Loss: 0.17352477610111236, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 7486, Training Loss: 0.17367021931755927, Validation Loss: 0.1739109754562378, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7487, Training Loss: 0.17434420508723106, Validation Loss: 0.17336323857307434, Validation Accuracy: 0.4875\n",
      "Epoch 7488, Training Loss: 0.17370070661267928, Validation Loss: 0.17274813055992128, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 7489, Training Loss: 0.1741761387355866, Validation Loss: 0.17335827151934305, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 7490, Training Loss: 0.17374192610863717, Validation Loss: 0.17374119361241658, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7491, Training Loss: 0.1743205117602502, Validation Loss: 0.173311581214269, Validation Accuracy: 0.49375\n",
      "Epoch 7492, Training Loss: 0.17383816838264465, Validation Loss: 0.1737227737903595, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 7493, Training Loss: 0.17421805666339013, Validation Loss: 0.17325586279233296, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 7494, Training Loss: 0.17359098119120445, Validation Loss: 0.1740666449069977, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 7495, Training Loss: 0.17445589842334872, Validation Loss: 0.17322988907496134, Validation Accuracy: 0.5125\n",
      "Epoch 7496, Training Loss: 0.17366632915312244, Validation Loss: 0.17464391390482584, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 7497, Training Loss: 0.17433587918358465, Validation Loss: 0.17306223313013713, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 7498, Training Loss: 0.17361506002564583, Validation Loss: 0.17488402823607127, Validation Accuracy: 0.48125\n",
      "Epoch 7499, Training Loss: 0.17439605680204207, Validation Loss: 0.173273961742719, Validation Accuracy: 0.50625\n",
      "Epoch 7500, Training Loss: 0.1735419563708767, Validation Loss: 0.17581122120221457, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 7501, Training Loss: 0.1743746481595501, Validation Loss: 0.17310555080572765, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 7502, Training Loss: 0.17354354791102872, Validation Loss: 0.17517746289571126, Validation Accuracy: 0.475\n",
      "Epoch 7503, Training Loss: 0.17453288359026756, Validation Loss: 0.17321831782658895, Validation Accuracy: 0.5125\n",
      "Epoch 7504, Training Loss: 0.1734465850937751, Validation Loss: 0.17575388848781587, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 7505, Training Loss: 0.17447032034397125, Validation Loss: 0.17290004094441733, Validation Accuracy: 0.5375\n",
      "Epoch 7506, Training Loss: 0.17350270767365733, Validation Loss: 0.17482701341311138, Validation Accuracy: 0.4875\n",
      "Epoch 7507, Training Loss: 0.1746040140428851, Validation Loss: 0.17361087600390115, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 7508, Training Loss: 0.17355906626870554, Validation Loss: 0.17545109192530314, Validation Accuracy: 0.475\n",
      "Epoch 7509, Training Loss: 0.17434354655204282, Validation Loss: 0.17280063728491465, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 7510, Training Loss: 0.17364013483447413, Validation Loss: 0.17485321164131165, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 7511, Training Loss: 0.17440075355191384, Validation Loss: 0.17367558677991232, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7512, Training Loss: 0.17353206969076587, Validation Loss: 0.17509665290514628, Validation Accuracy: 0.4875\n",
      "Epoch 7513, Training Loss: 0.17434556541904325, Validation Loss: 0.17275390426317852, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 7514, Training Loss: 0.17356229309112794, Validation Loss: 0.17442402442296345, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 7515, Training Loss: 0.17438943636032841, Validation Loss: 0.17370675007502237, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7516, Training Loss: 0.17354886906762276, Validation Loss: 0.1748231589794159, Validation Accuracy: 0.49375\n",
      "Epoch 7517, Training Loss: 0.1743949810343404, Validation Loss: 0.1736290117104848, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 7518, Training Loss: 0.17352782334050826, Validation Loss: 0.1740497539440791, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 7519, Training Loss: 0.17432310023615438, Validation Loss: 0.17455763618151346, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 7520, Training Loss: 0.17361453319749526, Validation Loss: 0.1737904796997706, Validation Accuracy: 0.5125\n",
      "Epoch 7521, Training Loss: 0.1743444694626716, Validation Loss: 0.17474316755930583, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 7522, Training Loss: 0.17376905871975806, Validation Loss: 0.17299657563368478, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 7523, Training Loss: 0.17432417023566463, Validation Loss: 0.174841445684433, Validation Accuracy: 0.48125\n",
      "Epoch 7524, Training Loss: 0.17352521804071241, Validation Loss: 0.173906605442365, Validation Accuracy: 0.50625\n",
      "Epoch 7525, Training Loss: 0.17449571865220223, Validation Loss: 0.17401116589705148, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 7526, Training Loss: 0.1735231655259286, Validation Loss: 0.17225845654805502, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 7527, Training Loss: 0.17429660452950385, Validation Loss: 0.17538092136383057, Validation Accuracy: 0.475\n",
      "Epoch 7528, Training Loss: 0.17367512997119658, Validation Loss: 0.1734799822171529, Validation Accuracy: 0.5125\n",
      "Epoch 7529, Training Loss: 0.17401715247861801, Validation Loss: 0.17594118316968282, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 7530, Training Loss: 0.17383611154171727, Validation Loss: 0.17266380389531452, Validation Accuracy: 0.5375\n",
      "Epoch 7531, Training Loss: 0.17389852145025808, Validation Loss: 0.1759847233692805, Validation Accuracy: 0.4875\n",
      "Epoch 7532, Training Loss: 0.17399780644524482, Validation Loss: 0.17404695451259614, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 7533, Training Loss: 0.1739819097903467, Validation Loss: 0.1752448300520579, Validation Accuracy: 0.475\n",
      "Epoch 7534, Training Loss: 0.1740759591902456, Validation Loss: 0.17190912862618765, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 7535, Training Loss: 0.1737894074570748, Validation Loss: 0.17693614562352497, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 7536, Training Loss: 0.1742344416918293, Validation Loss: 0.17393498917420705, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7537, Training Loss: 0.17369816764708487, Validation Loss: 0.17555690705776214, Validation Accuracy: 0.4875\n",
      "Epoch 7538, Training Loss: 0.17440037813878828, Validation Loss: 0.17273900012175242, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 7539, Training Loss: 0.1733429927018381, Validation Loss: 0.17603615125020344, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 7540, Training Loss: 0.1746997198750896, Validation Loss: 0.17373600999514263, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7541, Training Loss: 0.173699309748988, Validation Loss: 0.1742389589548111, Validation Accuracy: 0.49375\n",
      "Epoch 7542, Training Loss: 0.17422924118657265, Validation Loss: 0.1736715277036031, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 7543, Training Loss: 0.173678015989642, Validation Loss: 0.1744663933912913, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 7544, Training Loss: 0.17435014968918217, Validation Loss: 0.17402622898419698, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 7545, Training Loss: 0.1737410113696129, Validation Loss: 0.1741508940855662, Validation Accuracy: 0.5125\n",
      "Epoch 7546, Training Loss: 0.17428591991624526, Validation Loss: 0.17412305275599163, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 7547, Training Loss: 0.1735798894397674, Validation Loss: 0.1733458697795868, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 7548, Training Loss: 0.17436640589467942, Validation Loss: 0.17390580077966053, Validation Accuracy: 0.48125\n",
      "Epoch 7549, Training Loss: 0.1737226036287123, Validation Loss: 0.17416657706101735, Validation Accuracy: 0.50625\n",
      "Epoch 7550, Training Loss: 0.17431192917208518, Validation Loss: 0.17443167865276338, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 7551, Training Loss: 0.1736310153238235, Validation Loss: 0.17208936115105947, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 7552, Training Loss: 0.1743820386548196, Validation Loss: 0.1739354133605957, Validation Accuracy: 0.475\n",
      "Epoch 7553, Training Loss: 0.17368556847495417, Validation Loss: 0.17394304275512695, Validation Accuracy: 0.5125\n",
      "Epoch 7554, Training Loss: 0.1743906731567075, Validation Loss: 0.1740985264380773, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 7555, Training Loss: 0.1737074020408815, Validation Loss: 0.1726593295733134, Validation Accuracy: 0.5375\n",
      "Epoch 7556, Training Loss: 0.17428794022529356, Validation Loss: 0.17377902170022327, Validation Accuracy: 0.4875\n",
      "Epoch 7557, Training Loss: 0.17382666324415513, Validation Loss: 0.17397883037726083, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 7558, Training Loss: 0.1741613745689392, Validation Loss: 0.1742945631345113, Validation Accuracy: 0.475\n",
      "Epoch 7559, Training Loss: 0.17376558001964323, Validation Loss: 0.1717753658692042, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 7560, Training Loss: 0.17429402326383897, Validation Loss: 0.17379990915457408, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 7561, Training Loss: 0.17380403991668456, Validation Loss: 0.17380466262499492, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7562, Training Loss: 0.17422197518810148, Validation Loss: 0.17367255290349323, Validation Accuracy: 0.4875\n",
      "Epoch 7563, Training Loss: 0.17381395351502202, Validation Loss: 0.1728015015522639, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 7564, Training Loss: 0.1742448648137431, Validation Loss: 0.17343155841032665, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 7565, Training Loss: 0.17384981147704587, Validation Loss: 0.17349522213141125, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7566, Training Loss: 0.17416985381034114, Validation Loss: 0.1735394110282262, Validation Accuracy: 0.49375\n",
      "Epoch 7567, Training Loss: 0.17381714140215226, Validation Loss: 0.17331843376159667, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 7568, Training Loss: 0.17419430853859072, Validation Loss: 0.17326615850130717, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 7569, Training Loss: 0.1739261568553986, Validation Loss: 0.1734723210334778, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 7570, Training Loss: 0.17404488738506071, Validation Loss: 0.1732239375511805, Validation Accuracy: 0.5125\n",
      "Epoch 7571, Training Loss: 0.1738975264372364, Validation Loss: 0.17350967725118002, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 7572, Training Loss: 0.17410708050574025, Validation Loss: 0.17301789820194244, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 7573, Training Loss: 0.17398469342339423, Validation Loss: 0.17353543837865193, Validation Accuracy: 0.48125\n",
      "Epoch 7574, Training Loss: 0.17410922915704788, Validation Loss: 0.17328580717245737, Validation Accuracy: 0.50625\n",
      "Epoch 7575, Training Loss: 0.1739191682107987, Validation Loss: 0.17351912359396618, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 7576, Training Loss: 0.1741158885340537, Validation Loss: 0.17274904946486155, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 7577, Training Loss: 0.17392718647756883, Validation Loss: 0.17366012334823608, Validation Accuracy: 0.475\n",
      "Epoch 7578, Training Loss: 0.17408232967699727, Validation Loss: 0.17321734031041464, Validation Accuracy: 0.5125\n",
      "Epoch 7579, Training Loss: 0.17385371846537437, Validation Loss: 0.17365121444066364, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 7580, Training Loss: 0.1741575882319481, Validation Loss: 0.1729761759440104, Validation Accuracy: 0.5375\n",
      "Epoch 7581, Training Loss: 0.17390437760660726, Validation Loss: 0.173544509212176, Validation Accuracy: 0.4875\n",
      "Epoch 7582, Training Loss: 0.17412392458608072, Validation Loss: 0.1734467695156733, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 7583, Training Loss: 0.17378372819192947, Validation Loss: 0.17384506464004518, Validation Accuracy: 0.475\n",
      "Epoch 7584, Training Loss: 0.17425492405891418, Validation Loss: 0.17287305692831675, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 7585, Training Loss: 0.17382593789408285, Validation Loss: 0.17395665049552916, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 7586, Training Loss: 0.17410688679064473, Validation Loss: 0.17344490985075633, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7587, Training Loss: 0.17384015552459225, Validation Loss: 0.17376980980237325, Validation Accuracy: 0.4875\n",
      "Epoch 7588, Training Loss: 0.17422455116625754, Validation Loss: 0.1730389436086019, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 7589, Training Loss: 0.1737604905520716, Validation Loss: 0.17364806830883026, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 7590, Training Loss: 0.1742315027982958, Validation Loss: 0.1734491169452667, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7591, Training Loss: 0.17370624888327815, Validation Loss: 0.1736582746108373, Validation Accuracy: 0.49375\n",
      "Epoch 7592, Training Loss: 0.17420953271850462, Validation Loss: 0.17329399585723876, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 7593, Training Loss: 0.17371531936430162, Validation Loss: 0.1732893188794454, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 7594, Training Loss: 0.17417888343334198, Validation Loss: 0.17359315355618796, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 7595, Training Loss: 0.1737660357067662, Validation Loss: 0.17330661416053772, Validation Accuracy: 0.5125\n",
      "Epoch 7596, Training Loss: 0.17433495338886015, Validation Loss: 0.17344021300474802, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 7597, Training Loss: 0.1738666594028473, Validation Loss: 0.17291944324970246, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 7598, Training Loss: 0.17407726616628708, Validation Loss: 0.17362192670504253, Validation Accuracy: 0.48125\n",
      "Epoch 7599, Training Loss: 0.17367386769863866, Validation Loss: 0.1735108971595764, Validation Accuracy: 0.50625\n",
      "Epoch 7600, Training Loss: 0.17436632562068202, Validation Loss: 0.17351291477680206, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 7601, Training Loss: 0.1737102226864907, Validation Loss: 0.17234268486499787, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 7602, Training Loss: 0.1743538841124504, Validation Loss: 0.1735046237707138, Validation Accuracy: 0.475\n",
      "Epoch 7603, Training Loss: 0.17365672415302646, Validation Loss: 0.1732970247666041, Validation Accuracy: 0.5125\n",
      "Epoch 7604, Training Loss: 0.17436750569651205, Validation Loss: 0.17343002955118816, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 7605, Training Loss: 0.1736753438749621, Validation Loss: 0.17266210714975994, Validation Accuracy: 0.5375\n",
      "Epoch 7606, Training Loss: 0.17432965145957086, Validation Loss: 0.17343075474103292, Validation Accuracy: 0.4875\n",
      "Epoch 7607, Training Loss: 0.17363276500855723, Validation Loss: 0.17366981705029805, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 7608, Training Loss: 0.17440507152388174, Validation Loss: 0.173427485426267, Validation Accuracy: 0.475\n",
      "Epoch 7609, Training Loss: 0.17364273725017423, Validation Loss: 0.1720685362815857, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 7610, Training Loss: 0.17422498522266264, Validation Loss: 0.17356084485848744, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 7611, Training Loss: 0.17368000217022433, Validation Loss: 0.17381411989529927, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7612, Training Loss: 0.17440640013064107, Validation Loss: 0.17338878512382508, Validation Accuracy: 0.4875\n",
      "Epoch 7613, Training Loss: 0.17370647913025272, Validation Loss: 0.1727273424466451, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 7614, Training Loss: 0.17425872770047957, Validation Loss: 0.17335194249947866, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 7615, Training Loss: 0.17368905342394306, Validation Loss: 0.17373703916867575, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7616, Training Loss: 0.17423403839911183, Validation Loss: 0.1732923209667206, Validation Accuracy: 0.49375\n",
      "Epoch 7617, Training Loss: 0.17368275792367996, Validation Loss: 0.17331528862317402, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 7618, Training Loss: 0.17441040613958914, Validation Loss: 0.1732634037733078, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 7619, Training Loss: 0.1735582394946006, Validation Loss: 0.17450926502545674, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 7620, Training Loss: 0.17428545557683514, Validation Loss: 0.17326084276040396, Validation Accuracy: 0.5125\n",
      "Epoch 7621, Training Loss: 0.17377154096480338, Validation Loss: 0.17454627652963003, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 7622, Training Loss: 0.17428479079277284, Validation Loss: 0.17316403090953827, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 7623, Training Loss: 0.17364998113724492, Validation Loss: 0.17481003006299337, Validation Accuracy: 0.48125\n",
      "Epoch 7624, Training Loss: 0.17422501069884147, Validation Loss: 0.17328353822231293, Validation Accuracy: 0.50625\n",
      "Epoch 7625, Training Loss: 0.1736358231113803, Validation Loss: 0.1744937151670456, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 7626, Training Loss: 0.17449376900349894, Validation Loss: 0.1729472666978836, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 7627, Training Loss: 0.17343959500712733, Validation Loss: 0.17571349640687306, Validation Accuracy: 0.475\n",
      "Epoch 7628, Training Loss: 0.17447478732755106, Validation Loss: 0.1732224682966868, Validation Accuracy: 0.5125\n",
      "Epoch 7629, Training Loss: 0.17355224778575282, Validation Loss: 0.17559837301572165, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 7630, Training Loss: 0.17439444315048955, Validation Loss: 0.17284457782904308, Validation Accuracy: 0.5375\n",
      "Epoch 7631, Training Loss: 0.1735123121930707, Validation Loss: 0.17474662760893503, Validation Accuracy: 0.4875\n",
      "Epoch 7632, Training Loss: 0.17458797991275787, Validation Loss: 0.17355984052022297, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 7633, Training Loss: 0.17359122826207068, Validation Loss: 0.1755204051733017, Validation Accuracy: 0.475\n",
      "Epoch 7634, Training Loss: 0.17439085148995923, Validation Loss: 0.1722439875205358, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 7635, Training Loss: 0.17362036916517443, Validation Loss: 0.1752954125404358, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 7636, Training Loss: 0.17441528747158666, Validation Loss: 0.17373100519180298, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7637, Training Loss: 0.17352347989236155, Validation Loss: 0.17498270670572916, Validation Accuracy: 0.4875\n",
      "Epoch 7638, Training Loss: 0.1744198102143503, Validation Loss: 0.17276133398214977, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 7639, Training Loss: 0.17351440844997282, Validation Loss: 0.174700861175855, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 7640, Training Loss: 0.17441789132933463, Validation Loss: 0.17391505142052968, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7641, Training Loss: 0.1735746649003798, Validation Loss: 0.17481489380200704, Validation Accuracy: 0.49375\n",
      "Epoch 7642, Training Loss: 0.17438701083583216, Validation Loss: 0.1737310747305552, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 7643, Training Loss: 0.17359379366520913, Validation Loss: 0.17399287124474844, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 7644, Training Loss: 0.17428528685723582, Validation Loss: 0.17455509901046753, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 7645, Training Loss: 0.17361621366393182, Validation Loss: 0.17378698786099753, Validation Accuracy: 0.5125\n",
      "Epoch 7646, Training Loss: 0.17441106996228617, Validation Loss: 0.1748270740111669, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 7647, Training Loss: 0.17371229346721404, Validation Loss: 0.17303227186203002, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 7648, Training Loss: 0.17431176814340776, Validation Loss: 0.1749954124291738, Validation Accuracy: 0.48125\n",
      "Epoch 7649, Training Loss: 0.17359597163815652, Validation Loss: 0.1738508641719818, Validation Accuracy: 0.50625\n",
      "Epoch 7650, Training Loss: 0.1745050876371322, Validation Loss: 0.1756356954574585, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 7651, Training Loss: 0.17369136839143692, Validation Loss: 0.1722238133351008, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 7652, Training Loss: 0.17430052882240665, Validation Loss: 0.17576550642649333, Validation Accuracy: 0.475\n",
      "Epoch 7653, Training Loss: 0.1737899640875478, Validation Loss: 0.17346435487270356, Validation Accuracy: 0.5125\n",
      "Epoch 7654, Training Loss: 0.17397549171601573, Validation Loss: 0.1754134794076284, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 7655, Training Loss: 0.1740093913770491, Validation Loss: 0.17266274491945902, Validation Accuracy: 0.5375\n",
      "Epoch 7656, Training Loss: 0.17389610746214468, Validation Loss: 0.1756952077150345, Validation Accuracy: 0.4875\n",
      "Epoch 7657, Training Loss: 0.17396199462875242, Validation Loss: 0.17416285673777263, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 7658, Training Loss: 0.17397699865602678, Validation Loss: 0.17600087225437164, Validation Accuracy: 0.475\n",
      "Epoch 7659, Training Loss: 0.17403336013517073, Validation Loss: 0.17212070127328236, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 7660, Training Loss: 0.1737910908076071, Validation Loss: 0.1769038587808609, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 7661, Training Loss: 0.1742640378013734, Validation Loss: 0.1737719178199768, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7662, Training Loss: 0.17373899682875601, Validation Loss: 0.1750747889280319, Validation Accuracy: 0.4875\n",
      "Epoch 7663, Training Loss: 0.17439219643992762, Validation Loss: 0.17272794445355732, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 7664, Training Loss: 0.1733604924332711, Validation Loss: 0.17564679980278014, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 7665, Training Loss: 0.17467639138621668, Validation Loss: 0.1737135907014211, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7666, Training Loss: 0.17361857285422663, Validation Loss: 0.17531401713689168, Validation Accuracy: 0.49375\n",
      "Epoch 7667, Training Loss: 0.1743557861735744, Validation Loss: 0.17355574071407318, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 7668, Training Loss: 0.17361758024461807, Validation Loss: 0.17478762865066527, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 7669, Training Loss: 0.174328766522869, Validation Loss: 0.17388854225476583, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 7670, Training Loss: 0.1737805619355171, Validation Loss: 0.17401835223038992, Validation Accuracy: 0.5125\n",
      "Epoch 7671, Training Loss: 0.17429549271060574, Validation Loss: 0.17417563994725546, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 7672, Training Loss: 0.17359239632083523, Validation Loss: 0.17326488494873046, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 7673, Training Loss: 0.17433878587138268, Validation Loss: 0.17396459678808848, Validation Accuracy: 0.48125\n",
      "Epoch 7674, Training Loss: 0.17372013676551082, Validation Loss: 0.1742440640926361, Validation Accuracy: 0.50625\n",
      "Epoch 7675, Training Loss: 0.174244039481686, Validation Loss: 0.1747358242670695, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 7676, Training Loss: 0.17360912503734713, Validation Loss: 0.1723015636205673, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 7677, Training Loss: 0.1744319599482321, Validation Loss: 0.17391968071460723, Validation Accuracy: 0.475\n",
      "Epoch 7678, Training Loss: 0.17382722372008907, Validation Loss: 0.17344893415768942, Validation Accuracy: 0.5125\n",
      "Epoch 7679, Training Loss: 0.17420001520264533, Validation Loss: 0.1745002716779709, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 7680, Training Loss: 0.17363287172009867, Validation Loss: 0.17270912130673727, Validation Accuracy: 0.5375\n",
      "Epoch 7681, Training Loss: 0.17438250299422972, Validation Loss: 0.17366301715373994, Validation Accuracy: 0.4875\n",
      "Epoch 7682, Training Loss: 0.17383950564169115, Validation Loss: 0.1740648845831553, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 7683, Training Loss: 0.17402156562574447, Validation Loss: 0.17533605595429738, Validation Accuracy: 0.475\n",
      "Epoch 7684, Training Loss: 0.17377960057027877, Validation Loss: 0.17200508217016855, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 7685, Training Loss: 0.17424428462982178, Validation Loss: 0.17393194337685902, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 7686, Training Loss: 0.17386078161578025, Validation Loss: 0.1737578769524892, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7687, Training Loss: 0.1741523286027293, Validation Loss: 0.17377665440241497, Validation Accuracy: 0.4875\n",
      "Epoch 7688, Training Loss: 0.17382746694549436, Validation Loss: 0.1728133052587509, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 7689, Training Loss: 0.17423541699686357, Validation Loss: 0.1734385758638382, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 7690, Training Loss: 0.17388109526326578, Validation Loss: 0.17346616288026173, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7691, Training Loss: 0.17411794633634628, Validation Loss: 0.17358429531256359, Validation Accuracy: 0.49375\n",
      "Epoch 7692, Training Loss: 0.17382007693090745, Validation Loss: 0.17331236898899077, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 7693, Training Loss: 0.17417434386668668, Validation Loss: 0.17326961358388265, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 7694, Training Loss: 0.1739660463025493, Validation Loss: 0.17348097562789916, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 7695, Training Loss: 0.1739644307282663, Validation Loss: 0.1732399880886078, Validation Accuracy: 0.5125\n",
      "Epoch 7696, Training Loss: 0.17394238085516037, Validation Loss: 0.17352184653282166, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 7697, Training Loss: 0.174101096968497, Validation Loss: 0.17304417689641316, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 7698, Training Loss: 0.17395021069434383, Validation Loss: 0.17355800767739613, Validation Accuracy: 0.48125\n",
      "Epoch 7699, Training Loss: 0.17410369025122735, Validation Loss: 0.17328651348749796, Validation Accuracy: 0.50625\n",
      "Epoch 7700, Training Loss: 0.1738790552462301, Validation Loss: 0.17358495593070983, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 7701, Training Loss: 0.17417023499165812, Validation Loss: 0.17287339468797047, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 7702, Training Loss: 0.1739224580026442, Validation Loss: 0.1736063539981842, Validation Accuracy: 0.475\n",
      "Epoch 7703, Training Loss: 0.17400212826267367, Validation Loss: 0.17322670817375183, Validation Accuracy: 0.5125\n",
      "Epoch 7704, Training Loss: 0.17392036895598134, Validation Loss: 0.17378495633602142, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 7705, Training Loss: 0.17415065438516678, Validation Loss: 0.17303065260251363, Validation Accuracy: 0.5375\n",
      "Epoch 7706, Training Loss: 0.17396377988399997, Validation Loss: 0.17366846303145092, Validation Accuracy: 0.4875\n",
      "Epoch 7707, Training Loss: 0.1740150768910685, Validation Loss: 0.17354947626590728, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 7708, Training Loss: 0.17380593140279094, Validation Loss: 0.17400929530461628, Validation Accuracy: 0.475\n",
      "Epoch 7709, Training Loss: 0.17425083056572946, Validation Loss: 0.17287249863147736, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 7710, Training Loss: 0.17382487750822498, Validation Loss: 0.17397141953309378, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 7711, Training Loss: 0.17417219906084, Validation Loss: 0.17338215708732604, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7712, Training Loss: 0.17376891499565494, Validation Loss: 0.1736757000287374, Validation Accuracy: 0.4875\n",
      "Epoch 7713, Training Loss: 0.1741441935300827, Validation Loss: 0.17297201653321584, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 7714, Training Loss: 0.1737897857542961, Validation Loss: 0.17371862332026164, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 7715, Training Loss: 0.17428417551902034, Validation Loss: 0.1734177549680074, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7716, Training Loss: 0.1736553883360278, Validation Loss: 0.1736896852652232, Validation Accuracy: 0.49375\n",
      "Epoch 7717, Training Loss: 0.17428725332983078, Validation Loss: 0.1732875446478526, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 7718, Training Loss: 0.1739155246365455, Validation Loss: 0.17337181170781454, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 7719, Training Loss: 0.1741119488593071, Validation Loss: 0.17354153593381247, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 7720, Training Loss: 0.17374565620576182, Validation Loss: 0.17327966193358105, Validation Accuracy: 0.5125\n",
      "Epoch 7721, Training Loss: 0.17426810629906192, Validation Loss: 0.17344453930854797, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 7722, Training Loss: 0.17382483328542403, Validation Loss: 0.17293330828348796, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 7723, Training Loss: 0.17403304480737256, Validation Loss: 0.17368750671545666, Validation Accuracy: 0.48125\n",
      "Epoch 7724, Training Loss: 0.1737507423085551, Validation Loss: 0.1734882891178131, Validation Accuracy: 0.50625\n",
      "Epoch 7725, Training Loss: 0.17437364593628915, Validation Loss: 0.17349567910035452, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 7726, Training Loss: 0.17369126456399117, Validation Loss: 0.17221846183141074, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 7727, Training Loss: 0.17428774170337186, Validation Loss: 0.1735064446926117, Validation Accuracy: 0.475\n",
      "Epoch 7728, Training Loss: 0.17362486835448973, Validation Loss: 0.1732610454161962, Validation Accuracy: 0.5125\n",
      "Epoch 7729, Training Loss: 0.1743821333492956, Validation Loss: 0.17352436284224193, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 7730, Training Loss: 0.17374214962605508, Validation Loss: 0.17266099651654562, Validation Accuracy: 0.5375\n",
      "Epoch 7731, Training Loss: 0.17426339705144206, Validation Loss: 0.1734817902247111, Validation Accuracy: 0.4875\n",
      "Epoch 7732, Training Loss: 0.17366006826200792, Validation Loss: 0.17381148934364318, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 7733, Training Loss: 0.17437767117254196, Validation Loss: 0.17341842949390412, Validation Accuracy: 0.475\n",
      "Epoch 7734, Training Loss: 0.17366655795804917, Validation Loss: 0.17193079789479573, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 7735, Training Loss: 0.17432363571659212, Validation Loss: 0.17358988722165425, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 7736, Training Loss: 0.17364279541277117, Validation Loss: 0.1736509491999944, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7737, Training Loss: 0.1743791180272256, Validation Loss: 0.17335429390271503, Validation Accuracy: 0.4875\n",
      "Epoch 7738, Training Loss: 0.17369568251794384, Validation Loss: 0.1727910101413727, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 7739, Training Loss: 0.17434757323034347, Validation Loss: 0.17333822747071584, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 7740, Training Loss: 0.17365754900440092, Validation Loss: 0.1739278276761373, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7741, Training Loss: 0.17437685401208938, Validation Loss: 0.1733243703842163, Validation Accuracy: 0.49375\n",
      "Epoch 7742, Training Loss: 0.17373922995982632, Validation Loss: 0.17361323436101278, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 7743, Training Loss: 0.17429792111919773, Validation Loss: 0.17325587272644044, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 7744, Training Loss: 0.17357448320234975, Validation Loss: 0.17447798450787863, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 7745, Training Loss: 0.1742522192578162, Validation Loss: 0.17326628665129343, Validation Accuracy: 0.5125\n",
      "Epoch 7746, Training Loss: 0.17377167074911057, Validation Loss: 0.1743925561507543, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 7747, Training Loss: 0.17405520235338517, Validation Loss: 0.1732002764940262, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 7748, Training Loss: 0.17368126973029105, Validation Loss: 0.17440339227517446, Validation Accuracy: 0.48125\n",
      "Epoch 7749, Training Loss: 0.17440321464692393, Validation Loss: 0.17327825725078583, Validation Accuracy: 0.50625\n",
      "Epoch 7750, Training Loss: 0.17356716240606002, Validation Loss: 0.17572825153668722, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 7751, Training Loss: 0.17449325082763548, Validation Loss: 0.17263887623945873, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 7752, Training Loss: 0.17346936223968382, Validation Loss: 0.1753492385149002, Validation Accuracy: 0.475\n",
      "Epoch 7753, Training Loss: 0.17450011353338918, Validation Loss: 0.17321737408638, Validation Accuracy: 0.5125\n",
      "Epoch 7754, Training Loss: 0.17347438873783236, Validation Loss: 0.17550030251344045, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 7755, Training Loss: 0.17452758118029563, Validation Loss: 0.17284711400667827, Validation Accuracy: 0.5375\n",
      "Epoch 7756, Training Loss: 0.17345740814362803, Validation Loss: 0.174954887231191, Validation Accuracy: 0.4875\n",
      "Epoch 7757, Training Loss: 0.17437528554470308, Validation Loss: 0.17331192096074421, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 7758, Training Loss: 0.17369744950725186, Validation Loss: 0.17505683600902558, Validation Accuracy: 0.475\n",
      "Epoch 7759, Training Loss: 0.17435174988162133, Validation Loss: 0.172425976395607, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 7760, Training Loss: 0.17358449918608512, Validation Loss: 0.17497867544492085, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 7761, Training Loss: 0.1744574361270474, Validation Loss: 0.17364009122053783, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7762, Training Loss: 0.17351401813568607, Validation Loss: 0.1750425726175308, Validation Accuracy: 0.4875\n",
      "Epoch 7763, Training Loss: 0.17432559065280423, Validation Loss: 0.1727368285258611, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 7764, Training Loss: 0.1735956577524062, Validation Loss: 0.1745759020249049, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 7765, Training Loss: 0.1743520349264145, Validation Loss: 0.17401321331659952, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7766, Training Loss: 0.17360718211820048, Validation Loss: 0.17474915981292724, Validation Accuracy: 0.49375\n",
      "Epoch 7767, Training Loss: 0.17436390874847288, Validation Loss: 0.17334401806195576, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 7768, Training Loss: 0.17350601092461618, Validation Loss: 0.17381094694137572, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 7769, Training Loss: 0.17427157730825485, Validation Loss: 0.17446500261624653, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 7770, Training Loss: 0.17358685597296683, Validation Loss: 0.17379671533902485, Validation Accuracy: 0.5125\n",
      "Epoch 7771, Training Loss: 0.17435214788682998, Validation Loss: 0.17473240892092387, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 7772, Training Loss: 0.17376554252639895, Validation Loss: 0.17302356660366058, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 7773, Training Loss: 0.17431258001635153, Validation Loss: 0.17491600016752878, Validation Accuracy: 0.48125\n",
      "Epoch 7774, Training Loss: 0.173566771130408, Validation Loss: 0.17387339174747468, Validation Accuracy: 0.50625\n",
      "Epoch 7775, Training Loss: 0.17444554788451042, Validation Loss: 0.1754355122645696, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 7776, Training Loss: 0.17378756115513463, Validation Loss: 0.1721231440703074, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 7777, Training Loss: 0.17421840900374996, Validation Loss: 0.17571108043193817, Validation Accuracy: 0.475\n",
      "Epoch 7778, Training Loss: 0.17382408197849028, Validation Loss: 0.17346751789251963, Validation Accuracy: 0.5125\n",
      "Epoch 7779, Training Loss: 0.17402876480933158, Validation Loss: 0.1760148455699285, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 7780, Training Loss: 0.17397302100735326, Validation Loss: 0.17265920639038085, Validation Accuracy: 0.5375\n",
      "Epoch 7781, Training Loss: 0.17388270699208783, Validation Loss: 0.17582628428936004, Validation Accuracy: 0.4875\n",
      "Epoch 7782, Training Loss: 0.1739964259247626, Validation Loss: 0.1741349518299103, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 7783, Training Loss: 0.17397510620855516, Validation Loss: 0.17592395544052125, Validation Accuracy: 0.475\n",
      "Epoch 7784, Training Loss: 0.17410980020799943, Validation Loss: 0.1718982477982839, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 7785, Training Loss: 0.1737697975289437, Validation Loss: 0.17703558305899303, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 7786, Training Loss: 0.1742296786077561, Validation Loss: 0.1738387982050578, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7787, Training Loss: 0.17374207608161435, Validation Loss: 0.17523089349269866, Validation Accuracy: 0.4875\n",
      "Epoch 7788, Training Loss: 0.1742553686903369, Validation Loss: 0.17284743785858153, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 7789, Training Loss: 0.1733868049998437, Validation Loss: 0.17590344349543255, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 7790, Training Loss: 0.174670958711255, Validation Loss: 0.17373926440874735, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7791, Training Loss: 0.17367738581472827, Validation Loss: 0.17454456587632497, Validation Accuracy: 0.49375\n",
      "Epoch 7792, Training Loss: 0.17418352730812564, Validation Loss: 0.1734894633293152, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 7793, Training Loss: 0.1736512472552638, Validation Loss: 0.17483316858609518, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 7794, Training Loss: 0.17438986512922472, Validation Loss: 0.17393133242925007, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 7795, Training Loss: 0.17380160381717066, Validation Loss: 0.1734911153713862, Validation Accuracy: 0.5125\n",
      "Epoch 7796, Training Loss: 0.17417217598807427, Validation Loss: 0.17453433672587076, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 7797, Training Loss: 0.17362021678878414, Validation Loss: 0.17331556578477222, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 7798, Training Loss: 0.17413817682573873, Validation Loss: 0.17460441986719769, Validation Accuracy: 0.48125\n",
      "Epoch 7799, Training Loss: 0.17371368215930078, Validation Loss: 0.17464469770590466, Validation Accuracy: 0.50625\n",
      "Epoch 7800, Training Loss: 0.17431931149575017, Validation Loss: 0.17447256247202556, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 7801, Training Loss: 0.1736116894791203, Validation Loss: 0.1721629649400711, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 7802, Training Loss: 0.17441321621018072, Validation Loss: 0.17387320001920065, Validation Accuracy: 0.475\n",
      "Epoch 7803, Training Loss: 0.17383998728567554, Validation Loss: 0.17336325347423553, Validation Accuracy: 0.5125\n",
      "Epoch 7804, Training Loss: 0.17414517171921268, Validation Loss: 0.1746846963961919, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 7805, Training Loss: 0.17366844463732936, Validation Loss: 0.17275843918323516, Validation Accuracy: 0.5375\n",
      "Epoch 7806, Training Loss: 0.17434567164990208, Validation Loss: 0.17368378043174743, Validation Accuracy: 0.4875\n",
      "Epoch 7807, Training Loss: 0.17379115714180854, Validation Loss: 0.17418834567070007, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 7808, Training Loss: 0.17425307871833925, Validation Loss: 0.17407461007436117, Validation Accuracy: 0.475\n",
      "Epoch 7809, Training Loss: 0.17370939350897266, Validation Loss: 0.17177469929059347, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 7810, Training Loss: 0.17433322148938332, Validation Loss: 0.17378042936325072, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 7811, Training Loss: 0.17388416538315435, Validation Loss: 0.17363735636075336, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7812, Training Loss: 0.1740760519619911, Validation Loss: 0.17388946811358133, Validation Accuracy: 0.4875\n",
      "Epoch 7813, Training Loss: 0.17384178359662333, Validation Loss: 0.17283775905768076, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 7814, Training Loss: 0.17423714793497516, Validation Loss: 0.17344354887803395, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 7815, Training Loss: 0.17385070362398702, Validation Loss: 0.17350754936536153, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7816, Training Loss: 0.1741530962528721, Validation Loss: 0.17357943654060365, Validation Accuracy: 0.49375\n",
      "Epoch 7817, Training Loss: 0.1738417148590088, Validation Loss: 0.17332820693651835, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 7818, Training Loss: 0.17419412059168662, Validation Loss: 0.17326470017433165, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 7819, Training Loss: 0.17397911654364678, Validation Loss: 0.17351144750912983, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 7820, Training Loss: 0.17392900682264759, Validation Loss: 0.1732423226038615, Validation Accuracy: 0.5125\n",
      "Epoch 7821, Training Loss: 0.17393831235747184, Validation Loss: 0.1735197365283966, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 7822, Training Loss: 0.1741187221580936, Validation Loss: 0.1730365922053655, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 7823, Training Loss: 0.1740344036971369, Validation Loss: 0.1735086500644684, Validation Accuracy: 0.48125\n",
      "Epoch 7824, Training Loss: 0.1739594066335309, Validation Loss: 0.17335108915964761, Validation Accuracy: 0.50625\n",
      "Epoch 7825, Training Loss: 0.17393803211950487, Validation Loss: 0.17357133130232494, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 7826, Training Loss: 0.1740837957589857, Validation Loss: 0.17273022433121998, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 7827, Training Loss: 0.17398196122338694, Validation Loss: 0.17365456720193226, Validation Accuracy: 0.475\n",
      "Epoch 7828, Training Loss: 0.17405696261313655, Validation Loss: 0.17321752806504567, Validation Accuracy: 0.5125\n",
      "Epoch 7829, Training Loss: 0.17388701486972072, Validation Loss: 0.17363060613473255, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 7830, Training Loss: 0.17415075148305587, Validation Loss: 0.17296937505404156, Validation Accuracy: 0.5375\n",
      "Epoch 7831, Training Loss: 0.17392610301894526, Validation Loss: 0.1735997498035431, Validation Accuracy: 0.4875\n",
      "Epoch 7832, Training Loss: 0.17408229122238775, Validation Loss: 0.17347247898578644, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 7833, Training Loss: 0.17379928163943753, Validation Loss: 0.17385491331418354, Validation Accuracy: 0.475\n",
      "Epoch 7834, Training Loss: 0.17421856859037954, Validation Loss: 0.17280872563521069, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 7835, Training Loss: 0.17387758820287644, Validation Loss: 0.1739039848248164, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 7836, Training Loss: 0.17413108723778878, Validation Loss: 0.17343002955118816, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7837, Training Loss: 0.17375389750926726, Validation Loss: 0.17380911906560262, Validation Accuracy: 0.4875\n",
      "Epoch 7838, Training Loss: 0.17429177222713346, Validation Loss: 0.17309912045796713, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 7839, Training Loss: 0.17371105859356542, Validation Loss: 0.17368079523245494, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 7840, Training Loss: 0.1743085172868544, Validation Loss: 0.17338865101337433, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7841, Training Loss: 0.17369663475021238, Validation Loss: 0.1736463874578476, Validation Accuracy: 0.49375\n",
      "Epoch 7842, Training Loss: 0.17434122341294442, Validation Loss: 0.17328187028566996, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 7843, Training Loss: 0.17378880179697467, Validation Loss: 0.17332861224810284, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 7844, Training Loss: 0.17423550976860908, Validation Loss: 0.17343843181927998, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 7845, Training Loss: 0.17375944747078803, Validation Loss: 0.17325990398724875, Validation Accuracy: 0.5125\n",
      "Epoch 7846, Training Loss: 0.17423686144813413, Validation Loss: 0.173442538579305, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 7847, Training Loss: 0.17379093843121682, Validation Loss: 0.17292661170164744, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 7848, Training Loss: 0.17425985153644316, Validation Loss: 0.17343554099400837, Validation Accuracy: 0.48125\n",
      "Epoch 7849, Training Loss: 0.17363888505966432, Validation Loss: 0.1734924683968226, Validation Accuracy: 0.50625\n",
      "Epoch 7850, Training Loss: 0.17436932844500388, Validation Loss: 0.17347867389520008, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 7851, Training Loss: 0.17368956727366294, Validation Loss: 0.1722633421421051, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 7852, Training Loss: 0.1743206271240788, Validation Loss: 0.17350452542304992, Validation Accuracy: 0.475\n",
      "Epoch 7853, Training Loss: 0.17366688962905638, Validation Loss: 0.1732983609040578, Validation Accuracy: 0.5125\n",
      "Epoch 7854, Training Loss: 0.1743620778283765, Validation Loss: 0.17342759370803834, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 7855, Training Loss: 0.17365956258389256, Validation Loss: 0.17272393107414247, Validation Accuracy: 0.5375\n",
      "Epoch 7856, Training Loss: 0.17438777560187924, Validation Loss: 0.17338157196839651, Validation Accuracy: 0.4875\n",
      "Epoch 7857, Training Loss: 0.173638419758889, Validation Loss: 0.17380188902219137, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 7858, Training Loss: 0.1742815980988164, Validation Loss: 0.1734671801328659, Validation Accuracy: 0.475\n",
      "Epoch 7859, Training Loss: 0.17375508575670182, Validation Loss: 0.172262242436409, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 7860, Training Loss: 0.1741359959686956, Validation Loss: 0.1735502988100052, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 7861, Training Loss: 0.17373568829028838, Validation Loss: 0.17364346385002136, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7862, Training Loss: 0.17435540306952693, Validation Loss: 0.1734139531850815, Validation Accuracy: 0.4875\n",
      "Epoch 7863, Training Loss: 0.17369986013058694, Validation Loss: 0.17272995809714, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 7864, Training Loss: 0.1742634460810692, Validation Loss: 0.17334822714328765, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 7865, Training Loss: 0.17365084252049845, Validation Loss: 0.17366078694661458, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7866, Training Loss: 0.1744150101177154, Validation Loss: 0.17334660689036052, Validation Accuracy: 0.49375\n",
      "Epoch 7867, Training Loss: 0.17378165981461924, Validation Loss: 0.17388724486033122, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 7868, Training Loss: 0.17417763365853217, Validation Loss: 0.17325584987799328, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 7869, Training Loss: 0.17362693865453044, Validation Loss: 0.17431939740975697, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 7870, Training Loss: 0.17441339694684552, Validation Loss: 0.17325560748577118, Validation Accuracy: 0.5125\n",
      "Epoch 7871, Training Loss: 0.1737282843359055, Validation Loss: 0.17462864518165588, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 7872, Training Loss: 0.17432246909987542, Validation Loss: 0.173011780778567, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 7873, Training Loss: 0.17362332103713865, Validation Loss: 0.17497896353403727, Validation Accuracy: 0.48125\n",
      "Epoch 7874, Training Loss: 0.17437711934889516, Validation Loss: 0.17329575618108115, Validation Accuracy: 0.50625\n",
      "Epoch 7875, Training Loss: 0.17356089574675407, Validation Loss: 0.1756712665160497, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 7876, Training Loss: 0.17448323340185226, Validation Loss: 0.1727058082818985, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 7877, Training Loss: 0.17347820103168488, Validation Loss: 0.17550378541151682, Validation Accuracy: 0.475\n",
      "Epoch 7878, Training Loss: 0.17448621844091722, Validation Loss: 0.17322672704855602, Validation Accuracy: 0.5125\n",
      "Epoch 7879, Training Loss: 0.1734967476898624, Validation Loss: 0.17558830281098683, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 7880, Training Loss: 0.17447933843058924, Validation Loss: 0.1728731393814087, Validation Accuracy: 0.5375\n",
      "Epoch 7881, Training Loss: 0.17348419802804146, Validation Loss: 0.17507395148277283, Validation Accuracy: 0.4875\n",
      "Epoch 7882, Training Loss: 0.17444157119720213, Validation Loss: 0.1733289361000061, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 7883, Training Loss: 0.1736833986736113, Validation Loss: 0.1751001864671707, Validation Accuracy: 0.475\n",
      "Epoch 7884, Training Loss: 0.17437701311803633, Validation Loss: 0.17229965130488079, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 7885, Training Loss: 0.17359543471567093, Validation Loss: 0.17531211376190187, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 7886, Training Loss: 0.17439049770755152, Validation Loss: 0.17352254887421925, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7887, Training Loss: 0.1735577626574424, Validation Loss: 0.17509929339090982, Validation Accuracy: 0.4875\n",
      "Epoch 7888, Training Loss: 0.1741670903659636, Validation Loss: 0.1731202612320582, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 7889, Training Loss: 0.1736152796976028, Validation Loss: 0.17389500339825947, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 7890, Training Loss: 0.17435737434894807, Validation Loss: 0.17374757528305054, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7891, Training Loss: 0.17358626329129742, Validation Loss: 0.1748277097940445, Validation Accuracy: 0.49375\n",
      "Epoch 7892, Training Loss: 0.17440359727028878, Validation Loss: 0.17341529130935668, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 7893, Training Loss: 0.17344690667044732, Validation Loss: 0.17389092445373536, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 7894, Training Loss: 0.17432163415416593, Validation Loss: 0.17441545228163402, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 7895, Training Loss: 0.17355706903242296, Validation Loss: 0.1737467388312022, Validation Accuracy: 0.5125\n",
      "Epoch 7896, Training Loss: 0.17430434736513323, Validation Loss: 0.17447471618652344, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 7897, Training Loss: 0.1737509326588723, Validation Loss: 0.1729150265455246, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 7898, Training Loss: 0.17421345556935958, Validation Loss: 0.17487788399060566, Validation Accuracy: 0.48125\n",
      "Epoch 7899, Training Loss: 0.17359490452274198, Validation Loss: 0.17398767471313475, Validation Accuracy: 0.50625\n",
      "Epoch 7900, Training Loss: 0.1744113160717872, Validation Loss: 0.17548022170861563, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 7901, Training Loss: 0.17379820539105323, Validation Loss: 0.17216380834579467, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 7902, Training Loss: 0.17424417936032818, Validation Loss: 0.17570938368638356, Validation Accuracy: 0.475\n",
      "Epoch 7903, Training Loss: 0.17382531156463008, Validation Loss: 0.17349294622739156, Validation Accuracy: 0.5125\n",
      "Epoch 7904, Training Loss: 0.17400117939518345, Validation Loss: 0.17500255008538565, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 7905, Training Loss: 0.17378644020326675, Validation Loss: 0.1727733463048935, Validation Accuracy: 0.5375\n",
      "Epoch 7906, Training Loss: 0.17390205206409579, Validation Loss: 0.17572926779588063, Validation Accuracy: 0.4875\n",
      "Epoch 7907, Training Loss: 0.17396554350852966, Validation Loss: 0.17412663698196412, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 7908, Training Loss: 0.17398095515466505, Validation Loss: 0.1755266269048055, Validation Accuracy: 0.475\n",
      "Epoch 7909, Training Loss: 0.1741004591026614, Validation Loss: 0.17189518809318544, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 7910, Training Loss: 0.17378450016821584, Validation Loss: 0.177089191476504, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 7911, Training Loss: 0.17421821528865444, Validation Loss: 0.17383474707603455, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7912, Training Loss: 0.1737477611149511, Validation Loss: 0.17504550516605377, Validation Accuracy: 0.4875\n",
      "Epoch 7913, Training Loss: 0.17430449878015825, Validation Loss: 0.17274785538514456, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 7914, Training Loss: 0.17335468963269265, Validation Loss: 0.17538216412067414, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 7915, Training Loss: 0.17464543109939945, Validation Loss: 0.17381067673365275, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7916, Training Loss: 0.17367367061876482, Validation Loss: 0.1743073175350825, Validation Accuracy: 0.49375\n",
      "Epoch 7917, Training Loss: 0.17425123962663835, Validation Loss: 0.17372449437777202, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 7918, Training Loss: 0.17368711483094, Validation Loss: 0.17452193399270374, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 7919, Training Loss: 0.17433892046251603, Validation Loss: 0.17399998406569164, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 7920, Training Loss: 0.17377755382368643, Validation Loss: 0.17370330691337585, Validation Accuracy: 0.5125\n",
      "Epoch 7921, Training Loss: 0.17420456534431827, Validation Loss: 0.1743610233068466, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 7922, Training Loss: 0.17358943531590124, Validation Loss: 0.1733930100997289, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 7923, Training Loss: 0.17438034857473067, Validation Loss: 0.17388766606648762, Validation Accuracy: 0.48125\n",
      "Epoch 7924, Training Loss: 0.173708543662102, Validation Loss: 0.17428726553916932, Validation Accuracy: 0.50625\n",
      "Epoch 7925, Training Loss: 0.17432190477848053, Validation Loss: 0.1743794729312261, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 7926, Training Loss: 0.17361409721835966, Validation Loss: 0.1720967044432958, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 7927, Training Loss: 0.1744144030155674, Validation Loss: 0.1739012171824773, Validation Accuracy: 0.475\n",
      "Epoch 7928, Training Loss: 0.17379483292179723, Validation Loss: 0.17350427607695262, Validation Accuracy: 0.5125\n",
      "Epoch 7929, Training Loss: 0.17418209150914224, Validation Loss: 0.17483955025672912, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 7930, Training Loss: 0.1736583815466973, Validation Loss: 0.1728232055902481, Validation Accuracy: 0.5375\n",
      "Epoch 7931, Training Loss: 0.17440920491372386, Validation Loss: 0.17363198101520538, Validation Accuracy: 0.4875\n",
      "Epoch 7932, Training Loss: 0.17385156500724055, Validation Loss: 0.1739061266183853, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 7933, Training Loss: 0.17413371032284153, Validation Loss: 0.17433245480060577, Validation Accuracy: 0.475\n",
      "Epoch 7934, Training Loss: 0.1737572536353142, Validation Loss: 0.17179640432198842, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 7935, Training Loss: 0.1742804136968428, Validation Loss: 0.1738363415002823, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 7936, Training Loss: 0.17382355370829183, Validation Loss: 0.17380038599173228, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7937, Training Loss: 0.1741997782261141, Validation Loss: 0.1737057646115621, Validation Accuracy: 0.4875\n",
      "Epoch 7938, Training Loss: 0.17381892569603458, Validation Loss: 0.1727832833925883, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 7939, Training Loss: 0.1742270867670736, Validation Loss: 0.17344342470169066, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 7940, Training Loss: 0.1738441288471222, Validation Loss: 0.1735254685084025, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7941, Training Loss: 0.17418665943607206, Validation Loss: 0.1735039750734965, Validation Accuracy: 0.49375\n",
      "Epoch 7942, Training Loss: 0.17381198944584017, Validation Loss: 0.1733134259780248, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 7943, Training Loss: 0.17418985357207636, Validation Loss: 0.1732597271601359, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 7944, Training Loss: 0.17404427691813437, Validation Loss: 0.17363034983476003, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 7945, Training Loss: 0.17376164370967495, Validation Loss: 0.17331529359022776, Validation Accuracy: 0.5125\n",
      "Epoch 7946, Training Loss: 0.17403077310131443, Validation Loss: 0.17352712055047353, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 7947, Training Loss: 0.17409712556869752, Validation Loss: 0.1730205923318863, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 7948, Training Loss: 0.17398765058286728, Validation Loss: 0.17352313796679178, Validation Accuracy: 0.48125\n",
      "Epoch 7949, Training Loss: 0.1740726016221508, Validation Loss: 0.17330231567223867, Validation Accuracy: 0.50625\n",
      "Epoch 7950, Training Loss: 0.17390632485189744, Validation Loss: 0.17357223927974702, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 7951, Training Loss: 0.17418669837136422, Validation Loss: 0.1728944420814514, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 7952, Training Loss: 0.1739174593840876, Validation Loss: 0.17357913454373677, Validation Accuracy: 0.475\n",
      "Epoch 7953, Training Loss: 0.17407795931062392, Validation Loss: 0.1732174426317215, Validation Accuracy: 0.5125\n",
      "Epoch 7954, Training Loss: 0.17385044693946838, Validation Loss: 0.17373967170715332, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 7955, Training Loss: 0.17417694532102154, Validation Loss: 0.17301037510236103, Validation Accuracy: 0.5375\n",
      "Epoch 7956, Training Loss: 0.17389891657137102, Validation Loss: 0.17358137170473734, Validation Accuracy: 0.4875\n",
      "Epoch 7957, Training Loss: 0.1741144791726143, Validation Loss: 0.1734450529019038, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 7958, Training Loss: 0.1738035794227354, Validation Loss: 0.17375900546709697, Validation Accuracy: 0.475\n",
      "Epoch 7959, Training Loss: 0.17422207228599057, Validation Loss: 0.17280290027459463, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 7960, Training Loss: 0.17383052360626958, Validation Loss: 0.1740016589562098, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 7961, Training Loss: 0.17391739112715568, Validation Loss: 0.17368543247381846, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7962, Training Loss: 0.1738818629134086, Validation Loss: 0.17400498787562052, Validation Accuracy: 0.4875\n",
      "Epoch 7963, Training Loss: 0.17420779745424947, Validation Loss: 0.17302492558956145, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 7964, Training Loss: 0.1738105401877434, Validation Loss: 0.17369200189908346, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 7965, Training Loss: 0.17419709793982968, Validation Loss: 0.17351266940434773, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7966, Training Loss: 0.17370253849414088, Validation Loss: 0.1737086405356725, Validation Accuracy: 0.49375\n",
      "Epoch 7967, Training Loss: 0.17434693248041214, Validation Loss: 0.17328231334686278, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 7968, Training Loss: 0.1737913066341031, Validation Loss: 0.1733130673567454, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 7969, Training Loss: 0.1742411712484975, Validation Loss: 0.17343000173568726, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 7970, Training Loss: 0.1737421553942465, Validation Loss: 0.17325258751710257, Validation Accuracy: 0.5125\n",
      "Epoch 7971, Training Loss: 0.17427080148650753, Validation Loss: 0.17342283924420673, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 7972, Training Loss: 0.1737881398970081, Validation Loss: 0.17292143007119495, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 7973, Training Loss: 0.17413056185168604, Validation Loss: 0.1735119173924128, Validation Accuracy: 0.48125\n",
      "Epoch 7974, Training Loss: 0.17364699850159307, Validation Loss: 0.17357102731863658, Validation Accuracy: 0.50625\n",
      "Epoch 7975, Training Loss: 0.17438733097045653, Validation Loss: 0.17350653310616812, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 7976, Training Loss: 0.17372198210608575, Validation Loss: 0.17220814526081085, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 7977, Training Loss: 0.17427045491433912, Validation Loss: 0.17359943091869354, Validation Accuracy: 0.475\n",
      "Epoch 7978, Training Loss: 0.17368424996252982, Validation Loss: 0.17328461805979412, Validation Accuracy: 0.5125\n",
      "Epoch 7979, Training Loss: 0.17435795597491727, Validation Loss: 0.1734347254037857, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 7980, Training Loss: 0.1736755294184531, Validation Loss: 0.17276658415794371, Validation Accuracy: 0.5375\n",
      "Epoch 7981, Training Loss: 0.174281713462645, Validation Loss: 0.17341470022996266, Validation Accuracy: 0.4875\n",
      "Epoch 7982, Training Loss: 0.1736309802339923, Validation Loss: 0.17389311095078785, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 7983, Training Loss: 0.1744289686602931, Validation Loss: 0.1733584523200989, Validation Accuracy: 0.475\n",
      "Epoch 7984, Training Loss: 0.1736538395766289, Validation Loss: 0.1720173865556717, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 7985, Training Loss: 0.1743822491938068, Validation Loss: 0.1735498607158661, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 7986, Training Loss: 0.17365994040043123, Validation Loss: 0.1740535944700241, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7987, Training Loss: 0.1743362843990326, Validation Loss: 0.17338407039642334, Validation Accuracy: 0.4875\n",
      "Epoch 7988, Training Loss: 0.17371358650345955, Validation Loss: 0.17274262110392252, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 7989, Training Loss: 0.17431096444206853, Validation Loss: 0.17335522969563802, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 7990, Training Loss: 0.17365169332873437, Validation Loss: 0.1737761229276657, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 7991, Training Loss: 0.17436468985772902, Validation Loss: 0.17333194017410278, Validation Accuracy: 0.49375\n",
      "Epoch 7992, Training Loss: 0.17376538149772153, Validation Loss: 0.17357839743296305, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 7993, Training Loss: 0.17407165371602581, Validation Loss: 0.17326388855775196, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 7994, Training Loss: 0.17363729448087753, Validation Loss: 0.1742265284061432, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 7995, Training Loss: 0.17442658880064565, Validation Loss: 0.17323574622472127, Validation Accuracy: 0.5125\n",
      "Epoch 7996, Training Loss: 0.17371450028111857, Validation Loss: 0.1746909201145172, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 7997, Training Loss: 0.17416665775160636, Validation Loss: 0.17320600549379986, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 7998, Training Loss: 0.17369883243114717, Validation Loss: 0.1747590740521749, Validation Accuracy: 0.48125\n",
      "Epoch 7999, Training Loss: 0.17442723387672054, Validation Loss: 0.1732862710952759, Validation Accuracy: 0.50625\n",
      "Epoch 8000, Training Loss: 0.173517202658038, Validation Loss: 0.1754771778980891, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 8001, Training Loss: 0.17457256490184414, Validation Loss: 0.17273954749107362, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 8002, Training Loss: 0.17343478962298362, Validation Loss: 0.17558190325895945, Validation Accuracy: 0.475\n",
      "Epoch 8003, Training Loss: 0.17448399288039054, Validation Loss: 0.17322410146395364, Validation Accuracy: 0.5125\n",
      "Epoch 8004, Training Loss: 0.1735531851168602, Validation Loss: 0.17565674384435018, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 8005, Training Loss: 0.17442237369475827, Validation Loss: 0.1728520731131236, Validation Accuracy: 0.5375\n",
      "Epoch 8006, Training Loss: 0.17350805094165186, Validation Loss: 0.17498511175314585, Validation Accuracy: 0.4875\n",
      "Epoch 8007, Training Loss: 0.17457068014529445, Validation Loss: 0.17358749210834504, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 8008, Training Loss: 0.17359119173019164, Validation Loss: 0.17540352940559387, Validation Accuracy: 0.475\n",
      "Epoch 8009, Training Loss: 0.1743964086617193, Validation Loss: 0.17269179622332256, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 8010, Training Loss: 0.17360261274922278, Validation Loss: 0.1753785341978073, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 8011, Training Loss: 0.17444542627180776, Validation Loss: 0.17370132406552632, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8012, Training Loss: 0.17350310423681814, Validation Loss: 0.17495996057987212, Validation Accuracy: 0.4875\n",
      "Epoch 8013, Training Loss: 0.17439121777011501, Validation Loss: 0.17282287180423736, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 8014, Training Loss: 0.17350357578646752, Validation Loss: 0.17456164360046386, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 8015, Training Loss: 0.1744239931145022, Validation Loss: 0.17390375236670177, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8016, Training Loss: 0.17357760042913498, Validation Loss: 0.17474598288536072, Validation Accuracy: 0.49375\n",
      "Epoch 8017, Training Loss: 0.17430644842886156, Validation Loss: 0.17335793177286785, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 8018, Training Loss: 0.17362454725850013, Validation Loss: 0.17363379299640655, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 8019, Training Loss: 0.1742089525345833, Validation Loss: 0.17457727591196695, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 8020, Training Loss: 0.17362403437014548, Validation Loss: 0.17382201055685678, Validation Accuracy: 0.5125\n",
      "Epoch 8021, Training Loss: 0.17439423741832857, Validation Loss: 0.17459887762864432, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 8022, Training Loss: 0.17367153831066623, Validation Loss: 0.17294960419336955, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 8023, Training Loss: 0.174302390025508, Validation Loss: 0.17482545375823974, Validation Accuracy: 0.48125\n",
      "Epoch 8024, Training Loss: 0.17355751077974996, Validation Loss: 0.17393976350625356, Validation Accuracy: 0.50625\n",
      "Epoch 8025, Training Loss: 0.1744824643096616, Validation Loss: 0.17563678522904713, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 8026, Training Loss: 0.17375603318214417, Validation Loss: 0.17213595807552337, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 8027, Training Loss: 0.17424927459609124, Validation Loss: 0.17573790152867635, Validation Accuracy: 0.475\n",
      "Epoch 8028, Training Loss: 0.17380837375117886, Validation Loss: 0.1734538545211156, Validation Accuracy: 0.5125\n",
      "Epoch 8029, Training Loss: 0.17402482946072856, Validation Loss: 0.17569289108117422, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 8030, Training Loss: 0.17396273536066856, Validation Loss: 0.17266077995300294, Validation Accuracy: 0.5375\n",
      "Epoch 8031, Training Loss: 0.17386190112560027, Validation Loss: 0.1757290095090866, Validation Accuracy: 0.4875\n",
      "Epoch 8032, Training Loss: 0.17398959254064866, Validation Loss: 0.17421922584374747, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 8033, Training Loss: 0.17396522962277935, Validation Loss: 0.17589566707611085, Validation Accuracy: 0.475\n",
      "Epoch 8034, Training Loss: 0.17412005316826604, Validation Loss: 0.17196463346481322, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 8035, Training Loss: 0.17377822485662275, Validation Loss: 0.17711053291956583, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 8036, Training Loss: 0.17423888896742173, Validation Loss: 0.17390071054299672, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8037, Training Loss: 0.17373205481037016, Validation Loss: 0.17509018580118815, Validation Accuracy: 0.4875\n",
      "Epoch 8038, Training Loss: 0.17437722461838875, Validation Loss: 0.17274834613005322, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 8039, Training Loss: 0.17337205621504015, Validation Loss: 0.17575805981953938, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 8040, Training Loss: 0.17468172023373266, Validation Loss: 0.17371295789877575, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8041, Training Loss: 0.17365921505035892, Validation Loss: 0.17467645704746246, Validation Accuracy: 0.49375\n",
      "Epoch 8042, Training Loss: 0.1742931955283688, Validation Loss: 0.17360982696215313, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 8043, Training Loss: 0.1736268578998504, Validation Loss: 0.1745907743771871, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 8044, Training Loss: 0.1743923089196605, Validation Loss: 0.17392901380856832, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 8045, Training Loss: 0.1738029819342398, Validation Loss: 0.17358529369036357, Validation Accuracy: 0.5125\n",
      "Epoch 8046, Training Loss: 0.17419374758197415, Validation Loss: 0.1745030085245768, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 8047, Training Loss: 0.17361207114111993, Validation Loss: 0.17344412207603455, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 8048, Training Loss: 0.17430161564580857, Validation Loss: 0.17393572628498077, Validation Accuracy: 0.48125\n",
      "Epoch 8049, Training Loss: 0.17378567447585444, Validation Loss: 0.17380238672097523, Validation Accuracy: 0.50625\n",
      "Epoch 8050, Training Loss: 0.17417965637099359, Validation Loss: 0.17491323252518973, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 8051, Training Loss: 0.17363422291894112, Validation Loss: 0.17210619946320851, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 8052, Training Loss: 0.17444281616518575, Validation Loss: 0.17387841045856475, Validation Accuracy: 0.475\n",
      "Epoch 8053, Training Loss: 0.17370573887901922, Validation Loss: 0.17383007407188417, Validation Accuracy: 0.5125\n",
      "Epoch 8054, Training Loss: 0.17427780743568175, Validation Loss: 0.17457448343435925, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 8055, Training Loss: 0.1735412218878346, Validation Loss: 0.17308656573295594, Validation Accuracy: 0.5375\n",
      "Epoch 8056, Training Loss: 0.1744608792566484, Validation Loss: 0.17366632521152497, Validation Accuracy: 0.4875\n",
      "Epoch 8057, Training Loss: 0.17381209519601637, Validation Loss: 0.1742484947045644, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 8058, Training Loss: 0.17426742469110795, Validation Loss: 0.17405642569065094, Validation Accuracy: 0.475\n",
      "Epoch 8059, Training Loss: 0.1737002581357956, Validation Loss: 0.17173573474089304, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 8060, Training Loss: 0.1743436744136195, Validation Loss: 0.17376720110575358, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 8061, Training Loss: 0.17380385966070236, Validation Loss: 0.17386161287625632, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8062, Training Loss: 0.17421928192338637, Validation Loss: 0.17367615401744843, Validation Accuracy: 0.4875\n",
      "Epoch 8063, Training Loss: 0.173799172524483, Validation Loss: 0.17280276119709015, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 8064, Training Loss: 0.17425277781101964, Validation Loss: 0.1734079450368881, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 8065, Training Loss: 0.17388180427012906, Validation Loss: 0.17344879607359567, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8066, Training Loss: 0.1740698290448035, Validation Loss: 0.17374807000160217, Validation Accuracy: 0.49375\n",
      "Epoch 8067, Training Loss: 0.1738722430121514, Validation Loss: 0.17331516643365225, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 8068, Training Loss: 0.1741832951384206, Validation Loss: 0.17326499025026956, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 8069, Training Loss: 0.17398906427045022, Validation Loss: 0.17348024547100066, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 8070, Training Loss: 0.17390536012188082, Validation Loss: 0.1732545604308446, Validation Accuracy: 0.5125\n",
      "Epoch 8071, Training Loss: 0.17394792600985495, Validation Loss: 0.1735342542330424, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 8072, Training Loss: 0.17411863948068312, Validation Loss: 0.17303663690884907, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 8073, Training Loss: 0.1740275986732975, Validation Loss: 0.17352713445822399, Validation Accuracy: 0.48125\n",
      "Epoch 8074, Training Loss: 0.17387755311304523, Validation Loss: 0.17344427108764648, Validation Accuracy: 0.50625\n",
      "Epoch 8075, Training Loss: 0.17399810831392964, Validation Loss: 0.17362066706021625, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 8076, Training Loss: 0.1741694663801501, Validation Loss: 0.17288943727811176, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 8077, Training Loss: 0.17392036318778992, Validation Loss: 0.17356974681218465, Validation Accuracy: 0.475\n",
      "Epoch 8078, Training Loss: 0.17400072034328215, Validation Loss: 0.17323068181673687, Validation Accuracy: 0.5125\n",
      "Epoch 8079, Training Loss: 0.17390825238920027, Validation Loss: 0.1737879693508148, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 8080, Training Loss: 0.17416373904674284, Validation Loss: 0.1730447550614675, Validation Accuracy: 0.5375\n",
      "Epoch 8081, Training Loss: 0.17396276708572142, Validation Loss: 0.17368096113204956, Validation Accuracy: 0.4875\n",
      "Epoch 8082, Training Loss: 0.17399648024189857, Validation Loss: 0.17356655498345694, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 8083, Training Loss: 0.17380763734540633, Validation Loss: 0.17398413519064584, Validation Accuracy: 0.475\n",
      "Epoch 8084, Training Loss: 0.17420051415120402, Validation Loss: 0.17280956904093425, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 8085, Training Loss: 0.1738094081801753, Validation Loss: 0.17420979340871176, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 8086, Training Loss: 0.17419083224188897, Validation Loss: 0.17338670194149017, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8087, Training Loss: 0.17380496955687, Validation Loss: 0.17365722556908925, Validation Accuracy: 0.4875\n",
      "Epoch 8088, Training Loss: 0.17415960902167904, Validation Loss: 0.17298568288485208, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 8089, Training Loss: 0.17381037339087455, Validation Loss: 0.17361384431521099, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 8090, Training Loss: 0.17427269633739226, Validation Loss: 0.17340365648269654, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8091, Training Loss: 0.1736627177846047, Validation Loss: 0.17372686862945558, Validation Accuracy: 0.49375\n",
      "Epoch 8092, Training Loss: 0.17434481267006166, Validation Loss: 0.17328212757905323, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 8093, Training Loss: 0.17382363542433707, Validation Loss: 0.1733382244904836, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 8094, Training Loss: 0.17408657025906346, Validation Loss: 0.17360429962476095, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 8095, Training Loss: 0.17378549421987227, Validation Loss: 0.17333365678787233, Validation Accuracy: 0.5125\n",
      "Epoch 8096, Training Loss: 0.17414040815445683, Validation Loss: 0.17352330883344014, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 8097, Training Loss: 0.17374835283525528, Validation Loss: 0.17294610540072122, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 8098, Training Loss: 0.1743397121467898, Validation Loss: 0.17344420552253723, Validation Accuracy: 0.48125\n",
      "Epoch 8099, Training Loss: 0.1736249654523788, Validation Loss: 0.17345752120018004, Validation Accuracy: 0.50625\n",
      "Epoch 8100, Training Loss: 0.17438751699463015, Validation Loss: 0.1734909286101659, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 8101, Training Loss: 0.1737048154877078, Validation Loss: 0.1722455491622289, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 8102, Training Loss: 0.17433083922632278, Validation Loss: 0.17349960605303447, Validation Accuracy: 0.475\n",
      "Epoch 8103, Training Loss: 0.17363230932143428, Validation Loss: 0.17326216101646424, Validation Accuracy: 0.5125\n",
      "Epoch 8104, Training Loss: 0.1743811551601656, Validation Loss: 0.1734420696894328, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 8105, Training Loss: 0.17368879433601134, Validation Loss: 0.1726840833822886, Validation Accuracy: 0.5375\n",
      "Epoch 8106, Training Loss: 0.17380931396638194, Validation Loss: 0.17448168496290842, Validation Accuracy: 0.4875\n",
      "Epoch 8107, Training Loss: 0.17381781531918433, Validation Loss: 0.1738789588212967, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 8108, Training Loss: 0.17438729924540367, Validation Loss: 0.17335843443870544, Validation Accuracy: 0.475\n",
      "Epoch 8109, Training Loss: 0.17361664868170215, Validation Loss: 0.17236977219581603, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 8110, Training Loss: 0.17435141484583577, Validation Loss: 0.17339075605074564, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 8111, Training Loss: 0.17365473941449197, Validation Loss: 0.17367057204246522, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8112, Training Loss: 0.17439429510024287, Validation Loss: 0.17337733010450998, Validation Accuracy: 0.4875\n",
      "Epoch 8113, Training Loss: 0.1737142368670433, Validation Loss: 0.17272894481817883, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 8114, Training Loss: 0.1742618771330003, Validation Loss: 0.17334726750850676, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 8115, Training Loss: 0.1736841615169279, Validation Loss: 0.17371445099512736, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8116, Training Loss: 0.1744042279258851, Validation Loss: 0.1733468294143677, Validation Accuracy: 0.49375\n",
      "Epoch 8117, Training Loss: 0.1737740554155842, Validation Loss: 0.17388741473356883, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 8118, Training Loss: 0.17418810100324691, Validation Loss: 0.17325785557428997, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 8119, Training Loss: 0.17361086751184157, Validation Loss: 0.17399702668190004, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 8120, Training Loss: 0.17448508643334912, Validation Loss: 0.17323070069154103, Validation Accuracy: 0.5125\n",
      "Epoch 8121, Training Loss: 0.17366070805057401, Validation Loss: 0.17473671237627666, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 8122, Training Loss: 0.17431315347071616, Validation Loss: 0.17313390771547954, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 8123, Training Loss: 0.17364933702253527, Validation Loss: 0.1750053028265635, Validation Accuracy: 0.48125\n",
      "Epoch 8124, Training Loss: 0.17434650323083323, Validation Loss: 0.17327061295509338, Validation Accuracy: 0.50625\n",
      "Epoch 8125, Training Loss: 0.17362520723573624, Validation Loss: 0.17578838765621185, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 8126, Training Loss: 0.17444726728623913, Validation Loss: 0.1726811001698176, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 8127, Training Loss: 0.17348253678890965, Validation Loss: 0.17509700059890748, Validation Accuracy: 0.475\n",
      "Epoch 8128, Training Loss: 0.17453060611601798, Validation Loss: 0.17321710189183553, Validation Accuracy: 0.5125\n",
      "Epoch 8129, Training Loss: 0.17346832156181335, Validation Loss: 0.17576179107030232, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 8130, Training Loss: 0.17442826494093863, Validation Loss: 0.17279095351696014, Validation Accuracy: 0.5375\n",
      "Epoch 8131, Training Loss: 0.17353478122142055, Validation Loss: 0.1745745062828064, Validation Accuracy: 0.4875\n",
      "Epoch 8132, Training Loss: 0.17455275212564775, Validation Loss: 0.17360739608605702, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 8133, Training Loss: 0.17358220392657864, Validation Loss: 0.17553041875362396, Validation Accuracy: 0.475\n",
      "Epoch 8134, Training Loss: 0.17439260405878867, Validation Loss: 0.17225364744663238, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 8135, Training Loss: 0.173623489756738, Validation Loss: 0.17546185652414958, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 8136, Training Loss: 0.17439137687606196, Validation Loss: 0.17368706862131755, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8137, Training Loss: 0.1735404845206968, Validation Loss: 0.17511184116204578, Validation Accuracy: 0.4875\n",
      "Epoch 8138, Training Loss: 0.17429222310743026, Validation Loss: 0.17273703515529631, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 8139, Training Loss: 0.17359700606715295, Validation Loss: 0.1746022015810013, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 8140, Training Loss: 0.17440260850614117, Validation Loss: 0.1739603728055954, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8141, Training Loss: 0.173575994949187, Validation Loss: 0.17472534974416096, Validation Accuracy: 0.49375\n",
      "Epoch 8142, Training Loss: 0.17444775710182805, Validation Loss: 0.17368771235148112, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 8143, Training Loss: 0.17354410598354955, Validation Loss: 0.17398889164129894, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 8144, Training Loss: 0.17424459226669803, Validation Loss: 0.17461443543434144, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 8145, Training Loss: 0.1736572120458849, Validation Loss: 0.17385006546974183, Validation Accuracy: 0.5125\n",
      "Epoch 8146, Training Loss: 0.17437057437435274, Validation Loss: 0.17482029100259144, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 8147, Training Loss: 0.17373939146918635, Validation Loss: 0.17303438584009806, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 8148, Training Loss: 0.174306113393076, Validation Loss: 0.17497076193491617, Validation Accuracy: 0.48125\n",
      "Epoch 8149, Training Loss: 0.17358555476511678, Validation Loss: 0.17387248774369557, Validation Accuracy: 0.50625\n",
      "Epoch 8150, Training Loss: 0.17451580493680893, Validation Loss: 0.1756379852692286, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 8151, Training Loss: 0.17368744794399507, Validation Loss: 0.17219039698441824, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 8152, Training Loss: 0.17426631239152723, Validation Loss: 0.17575660347938538, Validation Accuracy: 0.475\n",
      "Epoch 8153, Training Loss: 0.17380438552748773, Validation Loss: 0.17348447938760123, Validation Accuracy: 0.5125\n",
      "Epoch 8154, Training Loss: 0.17396497774508693, Validation Loss: 0.17543621957302094, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 8155, Training Loss: 0.174016535282135, Validation Loss: 0.17266060610612233, Validation Accuracy: 0.5375\n",
      "Epoch 8156, Training Loss: 0.17387864041712978, Validation Loss: 0.17569198509057363, Validation Accuracy: 0.4875\n",
      "Epoch 8157, Training Loss: 0.17397822007056205, Validation Loss: 0.17417609691619873, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 8158, Training Loss: 0.17400705045269382, Validation Loss: 0.17554946541786193, Validation Accuracy: 0.475\n",
      "Epoch 8159, Training Loss: 0.1739345755307905, Validation Loss: 0.17221468885739644, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 8160, Training Loss: 0.17378928776710265, Validation Loss: 0.17713609238465627, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 8161, Training Loss: 0.1744841880375339, Validation Loss: 0.17346317370732625, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8162, Training Loss: 0.1735011988109158, Validation Loss: 0.17509986360867819, Validation Accuracy: 0.4875\n",
      "Epoch 8163, Training Loss: 0.1733544151629171, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.46458333333333335\n",
      "Epoch 8164, Training Loss: 0.17361869206351618, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 8165, Training Loss: 0.17487815214741614, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 8166, Training Loss: 0.23986862215303606, Validation Loss: 0.36650826533635456, Validation Accuracy: 0.49375\n",
      "Epoch 8167, Training Loss: 0.34605677666202667, Validation Loss: 0.17328591446081798, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 8168, Training Loss: 0.1929472574303227, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8169, Training Loss: 0.1737842934746896, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5166666666666667\n",
      "Epoch 8170, Training Loss: 0.17346590180550853, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.4875\n",
      "Epoch 8171, Training Loss: 0.17471769019480674, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5208333333333334\n",
      "Epoch 8172, Training Loss: 0.18475352804506978, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 8173, Training Loss: 0.17471087411526712, Validation Loss: 0.18659826318422953, Validation Accuracy: 0.48125\n",
      "Epoch 8174, Training Loss: 0.17433899160354369, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.49375\n",
      "Epoch 8175, Training Loss: 0.17326118148142292, Validation Loss: 0.21814387341340383, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 8176, Training Loss: 0.17603841423988342, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.4479166666666667\n",
      "Epoch 8177, Training Loss: 0.17572539756374975, Validation Loss: 0.1756450355052948, Validation Accuracy: 0.475\n",
      "Epoch 8178, Training Loss: 0.17361380592469247, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.4875\n",
      "Epoch 8179, Training Loss: 0.1731222959295396, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 8180, Training Loss: 0.1733208615933695, Validation Loss: 0.17328675190607706, Validation Accuracy: 0.5375\n",
      "Epoch 8181, Training Loss: 0.17740257709257065, Validation Loss: 0.1733148992061615, Validation Accuracy: 0.4875\n",
      "Epoch 8182, Training Loss: 0.17333179375817698, Validation Loss: 0.17328682442506155, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 8183, Training Loss: 0.17483946248408286, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.525\n",
      "Epoch 8184, Training Loss: 0.1733923424636164, Validation Loss: 0.1716652403275172, Validation Accuracy: 0.5604166666666667\n",
      "New best validation loss, checkpoint saved\n",
      "Epoch 8185, Training Loss: 0.17408447256011347, Validation Loss: 0.17389993667602538, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 8186, Training Loss: 0.17358513512919027, Validation Loss: 0.17394082446893055, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8187, Training Loss: 0.17383374033435697, Validation Loss: 0.1745568871498108, Validation Accuracy: 0.4875\n",
      "Epoch 8188, Training Loss: 0.17367912492444437, Validation Loss: 0.17307139535744984, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 8189, Training Loss: 0.17385789175187388, Validation Loss: 0.17363335192203522, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 8190, Training Loss: 0.1737111609789633, Validation Loss: 0.17347403168678283, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8191, Training Loss: 0.1736807111770876, Validation Loss: 0.1739270528157552, Validation Accuracy: 0.49375\n",
      "Epoch 8192, Training Loss: 0.17370436460741104, Validation Loss: 0.1733184576034546, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 8193, Training Loss: 0.17364646686661628, Validation Loss: 0.1733215461174647, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 8194, Training Loss: 0.17382967231735105, Validation Loss: 0.17352055112520853, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 8195, Training Loss: 0.17353324592113495, Validation Loss: 0.17340327699979147, Validation Accuracy: 0.5125\n",
      "Epoch 8196, Training Loss: 0.17390624265516957, Validation Loss: 0.17360471785068513, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 8197, Training Loss: 0.17352123125906913, Validation Loss: 0.1729080448547999, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 8198, Training Loss: 0.17390818461295096, Validation Loss: 0.1735224852959315, Validation Accuracy: 0.48125\n",
      "Epoch 8199, Training Loss: 0.17349985049616906, Validation Loss: 0.17354971766471863, Validation Accuracy: 0.50625\n",
      "Epoch 8200, Training Loss: 0.1739042309984084, Validation Loss: 0.1737400323152542, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 8201, Training Loss: 0.1737502827759712, Validation Loss: 0.17274039288361867, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 8202, Training Loss: 0.17385535663174045, Validation Loss: 0.17374857068061828, Validation Accuracy: 0.475\n",
      "Epoch 8203, Training Loss: 0.17373339495351237, Validation Loss: 0.17322051425774893, Validation Accuracy: 0.5125\n",
      "Epoch 8204, Training Loss: 0.1738262383207198, Validation Loss: 0.1739608625570933, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 8205, Training Loss: 0.17377750671678974, Validation Loss: 0.17293482820192974, Validation Accuracy: 0.5375\n",
      "Epoch 8206, Training Loss: 0.17385449188370858, Validation Loss: 0.1736128936211268, Validation Accuracy: 0.4875\n",
      "Epoch 8207, Training Loss: 0.17360879000156157, Validation Loss: 0.17418505847454072, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 8208, Training Loss: 0.1737489402294159, Validation Loss: 0.17408990363279978, Validation Accuracy: 0.475\n",
      "Epoch 8209, Training Loss: 0.17378481501533138, Validation Loss: 0.17237945993741352, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 8210, Training Loss: 0.17375322791837877, Validation Loss: 0.17402672171592712, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 8211, Training Loss: 0.17367146572759073, Validation Loss: 0.17377940118312835, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8212, Training Loss: 0.17377632952505542, Validation Loss: 0.17391563455263773, Validation Accuracy: 0.4875\n",
      "Epoch 8213, Training Loss: 0.17385645787562093, Validation Loss: 0.17291782796382904, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 8214, Training Loss: 0.17372101064651244, Validation Loss: 0.1735634634892146, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 8215, Training Loss: 0.1740433564109187, Validation Loss: 0.17337305347124735, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8216, Training Loss: 0.17363759634956236, Validation Loss: 0.17367636859416963, Validation Accuracy: 0.49375\n",
      "Epoch 8217, Training Loss: 0.1740114217804324, Validation Loss: 0.1732863376537959, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 8218, Training Loss: 0.17376649091320653, Validation Loss: 0.17331692079703012, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 8219, Training Loss: 0.17393943667411804, Validation Loss: 0.17344334920247395, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 8220, Training Loss: 0.17373181831452153, Validation Loss: 0.17328524192174274, Validation Accuracy: 0.5125\n",
      "Epoch 8221, Training Loss: 0.17381438324528356, Validation Loss: 0.17376995484034222, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 8222, Training Loss: 0.17378187371838477, Validation Loss: 0.17293387254079182, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 8223, Training Loss: 0.17394192757145052, Validation Loss: 0.17347408731778463, Validation Accuracy: 0.48125\n",
      "Epoch 8224, Training Loss: 0.1736316829919815, Validation Loss: 0.1734465628862381, Validation Accuracy: 0.50625\n",
      "Epoch 8225, Training Loss: 0.17412509456757577, Validation Loss: 0.17345817784468334, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 8226, Training Loss: 0.17367212282073113, Validation Loss: 0.1723711222410202, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 8227, Training Loss: 0.17386399401772407, Validation Loss: 0.17380970120429992, Validation Accuracy: 0.475\n",
      "Epoch 8228, Training Loss: 0.17372436629187676, Validation Loss: 0.17331919968128204, Validation Accuracy: 0.5125\n",
      "Epoch 8229, Training Loss: 0.17399508193615945, Validation Loss: 0.17357397278149922, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 8230, Training Loss: 0.17372360056446445, Validation Loss: 0.1727605591217677, Validation Accuracy: 0.5375\n",
      "Epoch 8231, Training Loss: 0.17405931218977896, Validation Loss: 0.1734117329120636, Validation Accuracy: 0.4875\n",
      "Epoch 8232, Training Loss: 0.17361926599856345, Validation Loss: 0.17390728096167246, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 8233, Training Loss: 0.17408769697912277, Validation Loss: 0.17346063653628033, Validation Accuracy: 0.475\n",
      "Epoch 8234, Training Loss: 0.1736490140038152, Validation Loss: 0.17217648029327393, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 8235, Training Loss: 0.17408071506407954, Validation Loss: 0.1735189328591029, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 8236, Training Loss: 0.17360475995848257, Validation Loss: 0.1737995574871699, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8237, Training Loss: 0.17409373098804104, Validation Loss: 0.1733714868625005, Validation Accuracy: 0.4875\n",
      "Epoch 8238, Training Loss: 0.17368642024455533, Validation Loss: 0.1727573186159134, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 8239, Training Loss: 0.17402014232450916, Validation Loss: 0.17334494988123575, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 8240, Training Loss: 0.17364967350036867, Validation Loss: 0.17392532726128895, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8241, Training Loss: 0.1739645537830168, Validation Loss: 0.17332232594490052, Validation Accuracy: 0.49375\n",
      "Epoch 8242, Training Loss: 0.1737584601486883, Validation Loss: 0.1734510123729706, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 8243, Training Loss: 0.17375435559980332, Validation Loss: 0.17325634956359864, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 8244, Training Loss: 0.1736094682447372, Validation Loss: 0.1741925944884618, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 8245, Training Loss: 0.17385183130541154, Validation Loss: 0.17325629194577535, Validation Accuracy: 0.5125\n",
      "Epoch 8246, Training Loss: 0.1737205982208252, Validation Loss: 0.17393679122130076, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 8247, Training Loss: 0.17382924018367643, Validation Loss: 0.17315137684345244, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 8248, Training Loss: 0.1736251312878824, Validation Loss: 0.17418718139330547, Validation Accuracy: 0.48125\n",
      "Epoch 8249, Training Loss: 0.1741398447944272, Validation Loss: 0.17326936821142833, Validation Accuracy: 0.50625\n",
      "Epoch 8250, Training Loss: 0.17356187393588404, Validation Loss: 0.17531010409196218, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 8251, Training Loss: 0.17408321557506437, Validation Loss: 0.1731196492910385, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 8252, Training Loss: 0.17352350344580988, Validation Loss: 0.17467523217201233, Validation Accuracy: 0.475\n",
      "Epoch 8253, Training Loss: 0.17411531027286284, Validation Loss: 0.17327662805716196, Validation Accuracy: 0.5125\n",
      "Epoch 8254, Training Loss: 0.17359515111292562, Validation Loss: 0.17501750886440276, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 8255, Training Loss: 0.17404166585014713, Validation Loss: 0.17320699195067088, Validation Accuracy: 0.5375\n",
      "Epoch 8256, Training Loss: 0.17348594290594901, Validation Loss: 0.17476637264092762, Validation Accuracy: 0.4875\n",
      "Epoch 8257, Training Loss: 0.17417839121433995, Validation Loss: 0.17330586910247803, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 8258, Training Loss: 0.17367720267465037, Validation Loss: 0.17429717481136323, Validation Accuracy: 0.475\n",
      "Epoch 8259, Training Loss: 0.17383096631496184, Validation Loss: 0.173126815756162, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 8260, Training Loss: 0.17361651120647306, Validation Loss: 0.1743948797384898, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 8261, Training Loss: 0.17410963966000464, Validation Loss: 0.17342452804247538, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8262, Training Loss: 0.1736026233242404, Validation Loss: 0.1749170631170273, Validation Accuracy: 0.4875\n",
      "Epoch 8263, Training Loss: 0.1740922591378612, Validation Loss: 0.17283053894837697, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 8264, Training Loss: 0.17348377118187566, Validation Loss: 0.17462531526883443, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 8265, Training Loss: 0.1741614692634152, Validation Loss: 0.17371304134527843, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8266, Training Loss: 0.17354080657805165, Validation Loss: 0.17489821712176004, Validation Accuracy: 0.49375\n",
      "Epoch 8267, Training Loss: 0.17408428701662249, Validation Loss: 0.17329903244972228, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 8268, Training Loss: 0.17350282784431212, Validation Loss: 0.17356129586696625, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 8269, Training Loss: 0.17397709671528108, Validation Loss: 0.17415977319081624, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 8270, Training Loss: 0.17355919605301273, Validation Loss: 0.17400914827982586, Validation Accuracy: 0.5125\n",
      "Epoch 8271, Training Loss: 0.17417180970791848, Validation Loss: 0.17366015215714772, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 8272, Training Loss: 0.17348794879451876, Validation Loss: 0.17294365167617798, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 8273, Training Loss: 0.17405224134845118, Validation Loss: 0.17454291184743245, Validation Accuracy: 0.48125\n",
      "Epoch 8274, Training Loss: 0.17350433526500578, Validation Loss: 0.1740043083826701, Validation Accuracy: 0.50625\n",
      "Epoch 8275, Training Loss: 0.1742545808515241, Validation Loss: 0.1740297685066859, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 8276, Training Loss: 0.17353043969600432, Validation Loss: 0.17233327726523082, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 8277, Training Loss: 0.17409088871171396, Validation Loss: 0.17508240342140197, Validation Accuracy: 0.475\n",
      "Epoch 8278, Training Loss: 0.1736335167961736, Validation Loss: 0.17339083154996235, Validation Accuracy: 0.5125\n",
      "Epoch 8279, Training Loss: 0.17385524030654662, Validation Loss: 0.1754782925049464, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 8280, Training Loss: 0.1737803787954392, Validation Loss: 0.17267994383970897, Validation Accuracy: 0.5375\n",
      "Epoch 8281, Training Loss: 0.17374672812800254, Validation Loss: 0.1748522768417994, Validation Accuracy: 0.4875\n",
      "Epoch 8282, Training Loss: 0.17387017415415856, Validation Loss: 0.17412833074728648, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 8283, Training Loss: 0.17384186723539907, Validation Loss: 0.17578058044115702, Validation Accuracy: 0.475\n",
      "Epoch 8284, Training Loss: 0.17382736456009648, Validation Loss: 0.1720807284116745, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 8285, Training Loss: 0.17369693517684937, Validation Loss: 0.17644150753815968, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 8286, Training Loss: 0.17399838951326185, Validation Loss: 0.1740007181962331, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8287, Training Loss: 0.17362366616725922, Validation Loss: 0.1748311251401901, Validation Accuracy: 0.4875\n",
      "Epoch 8288, Training Loss: 0.17415407924882828, Validation Loss: 0.1727388044198354, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 8289, Training Loss: 0.1733620407119874, Validation Loss: 0.17476107279459635, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 8290, Training Loss: 0.17441996787824937, Validation Loss: 0.17378466725349426, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8291, Training Loss: 0.17350776830027181, Validation Loss: 0.17483139832814534, Validation Accuracy: 0.49375\n",
      "Epoch 8292, Training Loss: 0.17404967065780394, Validation Loss: 0.1735444873571396, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 8293, Training Loss: 0.17356597223589498, Validation Loss: 0.17366324762503307, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 8294, Training Loss: 0.17408999271931186, Validation Loss: 0.17437148292859395, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 8295, Training Loss: 0.17363485597795056, Validation Loss: 0.17358001867930095, Validation Accuracy: 0.5125\n",
      "Epoch 8296, Training Loss: 0.17403802996681583, Validation Loss: 0.17445440093676248, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 8297, Training Loss: 0.17356145766473585, Validation Loss: 0.17298594216505686, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 8298, Training Loss: 0.17397923094611015, Validation Loss: 0.17444434861342112, Validation Accuracy: 0.48125\n",
      "Epoch 8299, Training Loss: 0.17370939062487695, Validation Loss: 0.17372150719165802, Validation Accuracy: 0.50625\n",
      "Epoch 8300, Training Loss: 0.1741033148381018, Validation Loss: 0.17435217003027598, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 8301, Training Loss: 0.17363261311284958, Validation Loss: 0.17215743958950042, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 8302, Training Loss: 0.17405262637522914, Validation Loss: 0.1741065522034963, Validation Accuracy: 0.475\n",
      "Epoch 8303, Training Loss: 0.17372981675209537, Validation Loss: 0.1735648234685262, Validation Accuracy: 0.5125\n",
      "Epoch 8304, Training Loss: 0.1740421647987058, Validation Loss: 0.17470718920230865, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 8305, Training Loss: 0.17361504175970632, Validation Loss: 0.17266972462336222, Validation Accuracy: 0.5375\n",
      "Epoch 8306, Training Loss: 0.17413842101250926, Validation Loss: 0.17356268763542176, Validation Accuracy: 0.4875\n",
      "Epoch 8307, Training Loss: 0.17377786867080197, Validation Loss: 0.17383882502714793, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 8308, Training Loss: 0.1738618299845726, Validation Loss: 0.1749106635649999, Validation Accuracy: 0.475\n",
      "Epoch 8309, Training Loss: 0.17367390903734392, Validation Loss: 0.1722364862759908, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 8310, Training Loss: 0.17399890384366434, Validation Loss: 0.1739009827375412, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 8311, Training Loss: 0.17382019373678392, Validation Loss: 0.17364209691683452, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8312, Training Loss: 0.17378571052705089, Validation Loss: 0.1745113601287206, Validation Accuracy: 0.4875\n",
      "Epoch 8313, Training Loss: 0.17379647253021116, Validation Loss: 0.1728848805030187, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 8314, Training Loss: 0.1739327061560846, Validation Loss: 0.17346899807453156, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 8315, Training Loss: 0.1738340417223592, Validation Loss: 0.17349894245465597, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8316, Training Loss: 0.17387463777296006, Validation Loss: 0.1736464411020279, Validation Accuracy: 0.49375\n",
      "Epoch 8317, Training Loss: 0.1738165318965912, Validation Loss: 0.17334661384423575, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 8318, Training Loss: 0.17387667490590003, Validation Loss: 0.17327639758586882, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 8319, Training Loss: 0.17394894697973806, Validation Loss: 0.1736027439435323, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 8320, Training Loss: 0.1735589715742296, Validation Loss: 0.17382324238618216, Validation Accuracy: 0.5125\n",
      "Epoch 8321, Training Loss: 0.17404748499393463, Validation Loss: 0.17369983990987142, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 8322, Training Loss: 0.17373345167406143, Validation Loss: 0.17297306756178538, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 8323, Training Loss: 0.17397846089255425, Validation Loss: 0.17360844214757284, Validation Accuracy: 0.48125\n",
      "Epoch 8324, Training Loss: 0.17367845965969947, Validation Loss: 0.1734718769788742, Validation Accuracy: 0.50625\n",
      "Epoch 8325, Training Loss: 0.17395739593813497, Validation Loss: 0.17376708388328552, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 8326, Training Loss: 0.17382949879092555, Validation Loss: 0.17278442084789275, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 8327, Training Loss: 0.17391735507595923, Validation Loss: 0.1736871749162674, Validation Accuracy: 0.475\n",
      "Epoch 8328, Training Loss: 0.173812527329691, Validation Loss: 0.17321723798910776, Validation Accuracy: 0.5125\n",
      "Epoch 8329, Training Loss: 0.17387266072534746, Validation Loss: 0.17396779557069142, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 8330, Training Loss: 0.1738396325419026, Validation Loss: 0.17297973930835725, Validation Accuracy: 0.5375\n",
      "Epoch 8331, Training Loss: 0.17389367328536126, Validation Loss: 0.17357316116491953, Validation Accuracy: 0.4875\n",
      "Epoch 8332, Training Loss: 0.1737210068010515, Validation Loss: 0.17379563848177593, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 8333, Training Loss: 0.1738336725581077, Validation Loss: 0.17381569345792133, Validation Accuracy: 0.475\n",
      "Epoch 8334, Training Loss: 0.17392850114453223, Validation Loss: 0.17282355924447376, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 8335, Training Loss: 0.17382826343659433, Validation Loss: 0.17388196388880411, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 8336, Training Loss: 0.173724357158907, Validation Loss: 0.1737111488978068, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8337, Training Loss: 0.17383616105202707, Validation Loss: 0.17366479734579723, Validation Accuracy: 0.4875\n",
      "Epoch 8338, Training Loss: 0.17397674677833433, Validation Loss: 0.17308996518452963, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 8339, Training Loss: 0.17374185448692692, Validation Loss: 0.17355220913887023, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 8340, Training Loss: 0.17386558363514562, Validation Loss: 0.1742234657208125, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8341, Training Loss: 0.1735758170966179, Validation Loss: 0.1738174170255661, Validation Accuracy: 0.49375\n",
      "Epoch 8342, Training Loss: 0.1741202281367394, Validation Loss: 0.1732793758312861, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 8343, Training Loss: 0.17379449307918549, Validation Loss: 0.17331044177214305, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 8344, Training Loss: 0.17372473689817614, Validation Loss: 0.1739767422278722, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 8345, Training Loss: 0.17382304081993719, Validation Loss: 0.17328725556532543, Validation Accuracy: 0.5125\n",
      "Epoch 8346, Training Loss: 0.17395970946358097, Validation Loss: 0.17343920965989432, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 8347, Training Loss: 0.17384885491863375, Validation Loss: 0.17294126749038696, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 8348, Training Loss: 0.17375666527978836, Validation Loss: 0.17383595903714497, Validation Accuracy: 0.48125\n",
      "Epoch 8349, Training Loss: 0.1736745156588093, Validation Loss: 0.17351650794347126, Validation Accuracy: 0.50625\n",
      "Epoch 8350, Training Loss: 0.17410868310159253, Validation Loss: 0.17346267700195311, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 8351, Training Loss: 0.17370787743599184, Validation Loss: 0.17228666146596272, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 8352, Training Loss: 0.1737903279642905, Validation Loss: 0.17421779036521912, Validation Accuracy: 0.475\n",
      "Epoch 8353, Training Loss: 0.17375001743916543, Validation Loss: 0.1733335018157959, Validation Accuracy: 0.5125\n",
      "Epoch 8354, Training Loss: 0.17402721604993265, Validation Loss: 0.17355602184931437, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 8355, Training Loss: 0.17375329761735855, Validation Loss: 0.17276380360126495, Validation Accuracy: 0.5375\n",
      "Epoch 8356, Training Loss: 0.17385868487819547, Validation Loss: 0.17352243562539418, Validation Accuracy: 0.4875\n",
      "Epoch 8357, Training Loss: 0.17366391516500904, Validation Loss: 0.17374246617158254, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 8358, Training Loss: 0.1741698610205804, Validation Loss: 0.1733692983786265, Validation Accuracy: 0.475\n",
      "Epoch 8359, Training Loss: 0.17361389052483342, Validation Loss: 0.17256935934225717, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 8360, Training Loss: 0.17399359662686625, Validation Loss: 0.17363213499387106, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 8361, Training Loss: 0.1737181895202206, Validation Loss: 0.17386905948321024, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8362, Training Loss: 0.17388192780556216, Validation Loss: 0.17349566121896107, Validation Accuracy: 0.4875\n",
      "Epoch 8363, Training Loss: 0.17380618568389647, Validation Loss: 0.172893754641215, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 8364, Training Loss: 0.17397739377713972, Validation Loss: 0.1733113984266917, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 8365, Training Loss: 0.17364582130985876, Validation Loss: 0.17360356748104094, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8366, Training Loss: 0.17419155999537436, Validation Loss: 0.17331224183241525, Validation Accuracy: 0.49375\n",
      "Epoch 8367, Training Loss: 0.1736530036695542, Validation Loss: 0.17328459819157918, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 8368, Training Loss: 0.1739689775051609, Validation Loss: 0.17326403558254241, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 8369, Training Loss: 0.1736479281417785, Validation Loss: 0.17422293325265248, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 8370, Training Loss: 0.1741295971216694, Validation Loss: 0.17326673865318298, Validation Accuracy: 0.5125\n",
      "Epoch 8371, Training Loss: 0.1737579280330289, Validation Loss: 0.174025430281957, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 8372, Training Loss: 0.17384948749696055, Validation Loss: 0.17311131755510967, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 8373, Training Loss: 0.17371974933531978, Validation Loss: 0.17439673046271006, Validation Accuracy: 0.48125\n",
      "Epoch 8374, Training Loss: 0.17404486911912118, Validation Loss: 0.1732791006565094, Validation Accuracy: 0.50625\n",
      "Epoch 8375, Training Loss: 0.17366423385758553, Validation Loss: 0.17467691600322724, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 8376, Training Loss: 0.17412398467140813, Validation Loss: 0.1731571763753891, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 8377, Training Loss: 0.17353949335313612, Validation Loss: 0.17496682206789652, Validation Accuracy: 0.475\n",
      "Epoch 8378, Training Loss: 0.17423068419579538, Validation Loss: 0.1732371926307678, Validation Accuracy: 0.5125\n",
      "Epoch 8379, Training Loss: 0.1735529875563037, Validation Loss: 0.17524482707182568, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 8380, Training Loss: 0.17424914913792763, Validation Loss: 0.17304375469684602, Validation Accuracy: 0.5375\n",
      "Epoch 8381, Training Loss: 0.17347716900610155, Validation Loss: 0.17466486791769664, Validation Accuracy: 0.4875\n",
      "Epoch 8382, Training Loss: 0.17431044818893557, Validation Loss: 0.17336052159468332, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 8383, Training Loss: 0.17365269170653436, Validation Loss: 0.1751401275396347, Validation Accuracy: 0.475\n",
      "Epoch 8384, Training Loss: 0.17409799416219035, Validation Loss: 0.17307943503061932, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 8385, Training Loss: 0.17361052574649935, Validation Loss: 0.17516177296638488, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 8386, Training Loss: 0.17409541962608213, Validation Loss: 0.17334739863872528, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8387, Training Loss: 0.17364439175974938, Validation Loss: 0.17489874760309856, Validation Accuracy: 0.4875\n",
      "Epoch 8388, Training Loss: 0.17409920644375584, Validation Loss: 0.17308058142662047, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 8389, Training Loss: 0.17349222638914663, Validation Loss: 0.17482425967852275, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 8390, Training Loss: 0.17422390801291313, Validation Loss: 0.17369055946667988, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8391, Training Loss: 0.17354263269132184, Validation Loss: 0.17507813572883607, Validation Accuracy: 0.49375\n",
      "Epoch 8392, Training Loss: 0.1741538187188487, Validation Loss: 0.17330465118090313, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 8393, Training Loss: 0.17349316035547563, Validation Loss: 0.1738381455341975, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 8394, Training Loss: 0.17411016841088572, Validation Loss: 0.1741008092959722, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 8395, Training Loss: 0.1735232631045003, Validation Loss: 0.1741200457016627, Validation Accuracy: 0.5125\n",
      "Epoch 8396, Training Loss: 0.17425305372284305, Validation Loss: 0.17388053238391876, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 8397, Training Loss: 0.17358244042242726, Validation Loss: 0.17291220724582673, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 8398, Training Loss: 0.17408082033357314, Validation Loss: 0.1744939108689626, Validation Accuracy: 0.48125\n",
      "Epoch 8399, Training Loss: 0.1734930315325337, Validation Loss: 0.1741231252749761, Validation Accuracy: 0.50625\n",
      "Epoch 8400, Training Loss: 0.1743335320103553, Validation Loss: 0.17456170419851938, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 8401, Training Loss: 0.17358060133072636, Validation Loss: 0.17238614857196807, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 8402, Training Loss: 0.1741015406385545, Validation Loss: 0.17530007561047872, Validation Accuracy: 0.475\n",
      "Epoch 8403, Training Loss: 0.1736928911939744, Validation Loss: 0.1735515018304189, Validation Accuracy: 0.5125\n",
      "Epoch 8404, Training Loss: 0.17391654993257216, Validation Loss: 0.17577372789382933, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 8405, Training Loss: 0.17380379428786616, Validation Loss: 0.1726612110932668, Validation Accuracy: 0.5375\n",
      "Epoch 8406, Training Loss: 0.17380112121182104, Validation Loss: 0.17534153759479523, Validation Accuracy: 0.4875\n",
      "Epoch 8407, Training Loss: 0.17383275878044865, Validation Loss: 0.17445642550786336, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 8408, Training Loss: 0.1739020371629346, Validation Loss: 0.1759571462869644, Validation Accuracy: 0.475\n",
      "Epoch 8409, Training Loss: 0.17397916605395655, Validation Loss: 0.17187251547972363, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 8410, Training Loss: 0.17374486163739236, Validation Loss: 0.1762813836336136, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 8411, Training Loss: 0.1740559228966313, Validation Loss: 0.17407689491907755, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8412, Training Loss: 0.17364243153602846, Validation Loss: 0.17518352667490641, Validation Accuracy: 0.4875\n",
      "Epoch 8413, Training Loss: 0.17420475232985713, Validation Loss: 0.17275082270304362, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 8414, Training Loss: 0.17331941906482942, Validation Loss: 0.17481387158234915, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 8415, Training Loss: 0.17442694594783167, Validation Loss: 0.17374013165632884, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8416, Training Loss: 0.17354194098903286, Validation Loss: 0.17457432548205057, Validation Accuracy: 0.49375\n",
      "Epoch 8417, Training Loss: 0.17406223041395988, Validation Loss: 0.17352519035339356, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 8418, Training Loss: 0.17354618830065574, Validation Loss: 0.17385981480280557, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 8419, Training Loss: 0.17412768929235398, Validation Loss: 0.17420655886332195, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 8420, Training Loss: 0.1737065142200839, Validation Loss: 0.17363901933034262, Validation Accuracy: 0.5125\n",
      "Epoch 8421, Training Loss: 0.17403469595216936, Validation Loss: 0.1745224098364512, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 8422, Training Loss: 0.17355853895987233, Validation Loss: 0.17296862403551738, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 8423, Training Loss: 0.17401785139114626, Validation Loss: 0.17464512089888254, Validation Accuracy: 0.48125\n",
      "Epoch 8424, Training Loss: 0.17372585736936139, Validation Loss: 0.17386894126733143, Validation Accuracy: 0.50625\n",
      "Epoch 8425, Training Loss: 0.1740122567261419, Validation Loss: 0.1751253565152486, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 8426, Training Loss: 0.1736386158773976, Validation Loss: 0.17208513617515564, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 8427, Training Loss: 0.17414325139214915, Validation Loss: 0.17399330139160157, Validation Accuracy: 0.475\n",
      "Epoch 8428, Training Loss: 0.17379084710151918, Validation Loss: 0.17340046167373657, Validation Accuracy: 0.5125\n",
      "Epoch 8429, Training Loss: 0.17408276277203713, Validation Loss: 0.17454966604709626, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 8430, Training Loss: 0.17366660266153275, Validation Loss: 0.17265912691752117, Validation Accuracy: 0.5375\n",
      "Epoch 8431, Training Loss: 0.1741288698488666, Validation Loss: 0.1736967315276464, Validation Accuracy: 0.4875\n",
      "Epoch 8432, Training Loss: 0.1737679757418171, Validation Loss: 0.1739818811416626, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 8433, Training Loss: 0.17397501535954013, Validation Loss: 0.1746991455554962, Validation Accuracy: 0.475\n",
      "Epoch 8434, Training Loss: 0.1737327229592108, Validation Loss: 0.17220645348230998, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 8435, Training Loss: 0.17402997084202304, Validation Loss: 0.17384244898955029, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 8436, Training Loss: 0.17381109777958162, Validation Loss: 0.1737235466639201, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8437, Training Loss: 0.17386483136684663, Validation Loss: 0.17438324789206186, Validation Accuracy: 0.4875\n",
      "Epoch 8438, Training Loss: 0.1738475186209525, Validation Loss: 0.17285265723864238, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 8439, Training Loss: 0.1739603728055954, Validation Loss: 0.17346031268437703, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 8440, Training Loss: 0.17386604268704692, Validation Loss: 0.17351974447568258, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8441, Training Loss: 0.17391380187003844, Validation Loss: 0.1740065336227417, Validation Accuracy: 0.49375\n",
      "Epoch 8442, Training Loss: 0.1737736237625922, Validation Loss: 0.17333078583081563, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 8443, Training Loss: 0.1739653358536382, Validation Loss: 0.17325756053129832, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 8444, Training Loss: 0.17395305970022756, Validation Loss: 0.17353574732939403, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 8445, Training Loss: 0.1735776936815631, Validation Loss: 0.17345823148886363, Validation Accuracy: 0.5125\n",
      "Epoch 8446, Training Loss: 0.17401243650144146, Validation Loss: 0.17356000343958536, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 8447, Training Loss: 0.17387463344681647, Validation Loss: 0.17305954893430073, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 8448, Training Loss: 0.17397469378286792, Validation Loss: 0.17354440689086914, Validation Accuracy: 0.48125\n",
      "Epoch 8449, Training Loss: 0.17369743412540806, Validation Loss: 0.173490575949351, Validation Accuracy: 0.50625\n",
      "Epoch 8450, Training Loss: 0.17397045079738863, Validation Loss: 0.17359736065069833, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 8451, Training Loss: 0.17390688628919662, Validation Loss: 0.1729465126991272, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 8452, Training Loss: 0.17393112615231546, Validation Loss: 0.1737212876478831, Validation Accuracy: 0.475\n",
      "Epoch 8453, Training Loss: 0.17362897722951828, Validation Loss: 0.17341831028461457, Validation Accuracy: 0.5125\n",
      "Epoch 8454, Training Loss: 0.1738727626300627, Validation Loss: 0.17375636100769043, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 8455, Training Loss: 0.17386737658131507, Validation Loss: 0.17299766540527345, Validation Accuracy: 0.5375\n",
      "Epoch 8456, Training Loss: 0.17391193730215873, Validation Loss: 0.1735015203555425, Validation Accuracy: 0.4875\n",
      "Epoch 8457, Training Loss: 0.17371069856228366, Validation Loss: 0.17393038868904115, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 8458, Training Loss: 0.1738296905832906, Validation Loss: 0.17393046021461486, Validation Accuracy: 0.475\n",
      "Epoch 8459, Training Loss: 0.17397862961215357, Validation Loss: 0.17294013301531475, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 8460, Training Loss: 0.1738683639034148, Validation Loss: 0.17382065455118814, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 8461, Training Loss: 0.17371590291300126, Validation Loss: 0.17380153139432272, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8462, Training Loss: 0.17383706810012942, Validation Loss: 0.1738435834646225, Validation Accuracy: 0.4875\n",
      "Epoch 8463, Training Loss: 0.17397014364119498, Validation Loss: 0.17307423253854115, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 8464, Training Loss: 0.17378685118690615, Validation Loss: 0.17353250881036122, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 8465, Training Loss: 0.1738860184146512, Validation Loss: 0.17374927997589112, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8466, Training Loss: 0.1737065137394013, Validation Loss: 0.17365898887316386, Validation Accuracy: 0.49375\n",
      "Epoch 8467, Training Loss: 0.17400097462438768, Validation Loss: 0.17329023778438568, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 8468, Training Loss: 0.17385129149883025, Validation Loss: 0.17329259713490805, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 8469, Training Loss: 0.1737829307394643, Validation Loss: 0.1739512731631597, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 8470, Training Loss: 0.17380683220201923, Validation Loss: 0.17327178915341696, Validation Accuracy: 0.5125\n",
      "Epoch 8471, Training Loss: 0.17404806998468214, Validation Loss: 0.17337435682614644, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 8472, Training Loss: 0.17385501198230252, Validation Loss: 0.17293420533339182, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 8473, Training Loss: 0.17381849356235995, Validation Loss: 0.1736942410469055, Validation Accuracy: 0.48125\n",
      "Epoch 8474, Training Loss: 0.17371979211607286, Validation Loss: 0.1734353999296824, Validation Accuracy: 0.50625\n",
      "Epoch 8475, Training Loss: 0.1740463270295051, Validation Loss: 0.17352491120497385, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 8476, Training Loss: 0.1737548526256315, Validation Loss: 0.17238714496294658, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 8477, Training Loss: 0.1738234450740199, Validation Loss: 0.17398948868115743, Validation Accuracy: 0.475\n",
      "Epoch 8478, Training Loss: 0.17375619805628253, Validation Loss: 0.1733217974503835, Validation Accuracy: 0.5125\n",
      "Epoch 8479, Training Loss: 0.17409561718663863, Validation Loss: 0.17340712348620096, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 8480, Training Loss: 0.17377056565976912, Validation Loss: 0.17273285786310832, Validation Accuracy: 0.5375\n",
      "Epoch 8481, Training Loss: 0.1740567102547615, Validation Loss: 0.17338265875975292, Validation Accuracy: 0.4875\n",
      "Epoch 8482, Training Loss: 0.17366123247531154, Validation Loss: 0.17358351250489554, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 8483, Training Loss: 0.1741374735870669, Validation Loss: 0.17340145806471507, Validation Accuracy: 0.475\n",
      "Epoch 8484, Training Loss: 0.17375905427240557, Validation Loss: 0.17224046488602957, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 8485, Training Loss: 0.1740359389974225, Validation Loss: 0.17348902821540832, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 8486, Training Loss: 0.17367808376589128, Validation Loss: 0.17378941774368287, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8487, Training Loss: 0.17411854767030285, Validation Loss: 0.17333846688270568, Validation Accuracy: 0.4875\n",
      "Epoch 8488, Training Loss: 0.17376637506869533, Validation Loss: 0.17282860080401102, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 8489, Training Loss: 0.17408375249754998, Validation Loss: 0.17331176896890005, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 8490, Training Loss: 0.1736412005078408, Validation Loss: 0.17354816198349, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8491, Training Loss: 0.174119274462423, Validation Loss: 0.17329952716827393, Validation Accuracy: 0.49375\n",
      "Epoch 8492, Training Loss: 0.17385766054353408, Validation Loss: 0.17333414256572724, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 8493, Training Loss: 0.17393071757208917, Validation Loss: 0.17326919337113697, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 8494, Training Loss: 0.1736464947462082, Validation Loss: 0.17394108374913533, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 8495, Training Loss: 0.1742209614284577, Validation Loss: 0.17326800326506298, Validation Accuracy: 0.5125\n",
      "Epoch 8496, Training Loss: 0.1737671254142638, Validation Loss: 0.1741682787736257, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 8497, Training Loss: 0.1740298319247461, Validation Loss: 0.17322146395842233, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 8498, Training Loss: 0.17369155345424528, Validation Loss: 0.17423204481601715, Validation Accuracy: 0.48125\n",
      "Epoch 8499, Training Loss: 0.1740478406990728, Validation Loss: 0.17328273355960847, Validation Accuracy: 0.50625\n",
      "Epoch 8500, Training Loss: 0.1736590785364951, Validation Loss: 0.17469141781330108, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 8501, Training Loss: 0.17402954111176153, Validation Loss: 0.1731390784184138, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 8502, Training Loss: 0.17358597103626497, Validation Loss: 0.17472850481669108, Validation Accuracy: 0.475\n",
      "Epoch 8503, Training Loss: 0.17416367175117617, Validation Loss: 0.17327075699965158, Validation Accuracy: 0.5125\n",
      "Epoch 8504, Training Loss: 0.17363360908723646, Validation Loss: 0.17496540943781536, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 8505, Training Loss: 0.1741973094401821, Validation Loss: 0.17320277988910676, Validation Accuracy: 0.5375\n",
      "Epoch 8506, Training Loss: 0.1740597039461136, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5125\n",
      "Epoch 8507, Training Loss: 0.1733292245095776, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5104166666666666\n",
      "Epoch 8508, Training Loss: 0.17350291965469236, Validation Loss: 0.1733144164085388, Validation Accuracy: 0.475\n",
      "Epoch 8509, Training Loss: 0.17374927382315358, Validation Loss: 0.17324764728546144, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 8510, Training Loss: 0.17335700940701268, Validation Loss: 0.17328768571217854, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 8511, Training Loss: 0.17500836041665846, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 8512, Training Loss: 0.17625367497244188, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5125\n",
      "Epoch 8513, Training Loss: 0.18275739204499028, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.46458333333333335\n",
      "Epoch 8514, Training Loss: 0.1732427506677566, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 8515, Training Loss: 0.17279823460886556, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 8516, Training Loss: 0.17336001944157384, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.50625\n",
      "Epoch 8517, Training Loss: 0.17621179934470885, Validation Loss: 0.1732834388812383, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 8518, Training Loss: 0.17341390877000748, Validation Loss: 0.1740836868683497, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 8519, Training Loss: 0.17383133884399168, Validation Loss: 0.17328769167264302, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 8520, Training Loss: 0.17347666813481238, Validation Loss: 0.1732177644968033, Validation Accuracy: 0.5125\n",
      "Epoch 8521, Training Loss: 0.17424934958257982, Validation Loss: 0.1733375757932663, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 8522, Training Loss: 0.1735054672725739, Validation Loss: 0.17293238739172617, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 8523, Training Loss: 0.1742237070875783, Validation Loss: 0.17349433799584707, Validation Accuracy: 0.48125\n",
      "Epoch 8524, Training Loss: 0.17364109860312554, Validation Loss: 0.17327348093191783, Validation Accuracy: 0.50625\n",
      "Epoch 8525, Training Loss: 0.17376049247480208, Validation Loss: 0.1734991749127706, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 8526, Training Loss: 0.17354085080085263, Validation Loss: 0.17256803611914318, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 8527, Training Loss: 0.17397027630959788, Validation Loss: 0.1737872252861659, Validation Accuracy: 0.475\n",
      "Epoch 8528, Training Loss: 0.17365187598812964, Validation Loss: 0.17321712176005047, Validation Accuracy: 0.5125\n",
      "Epoch 8529, Training Loss: 0.17372464268438279, Validation Loss: 0.1738142361243566, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 8530, Training Loss: 0.17357332043109402, Validation Loss: 0.17277482748031617, Validation Accuracy: 0.5375\n",
      "Epoch 8531, Training Loss: 0.17377248021864122, Validation Loss: 0.17448909680048624, Validation Accuracy: 0.4875\n",
      "Epoch 8532, Training Loss: 0.1737345601281812, Validation Loss: 0.17376720110575358, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 8533, Training Loss: 0.17370334507957583, Validation Loss: 0.17593544721603394, Validation Accuracy: 0.475\n",
      "Epoch 8534, Training Loss: 0.17382320040656674, Validation Loss: 0.17175847192605337, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 8535, Training Loss: 0.17368268485992186, Validation Loss: 0.17714225252469382, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 8536, Training Loss: 0.17399263718435842, Validation Loss: 0.1741936484972636, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8537, Training Loss: 0.17352389424077927, Validation Loss: 0.17553093135356904, Validation Accuracy: 0.4875\n",
      "Epoch 8538, Training Loss: 0.17415710226182016, Validation Loss: 0.17276520629723865, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 8539, Training Loss: 0.17329176347101888, Validation Loss: 0.1753941943248113, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 8540, Training Loss: 0.17445679249302035, Validation Loss: 0.1740603228410085, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8541, Training Loss: 0.17344603711558926, Validation Loss: 0.1748996118704478, Validation Accuracy: 0.49375\n",
      "Epoch 8542, Training Loss: 0.17409169337441843, Validation Loss: 0.1738313486178716, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 8543, Training Loss: 0.1734604388475418, Validation Loss: 0.173973215619723, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 8544, Training Loss: 0.17412634338102034, Validation Loss: 0.1745879014333089, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 8545, Training Loss: 0.17359631340349874, Validation Loss: 0.17371331850687663, Validation Accuracy: 0.5125\n",
      "Epoch 8546, Training Loss: 0.17408180140679883, Validation Loss: 0.174572417140007, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 8547, Training Loss: 0.17352440039957723, Validation Loss: 0.17305188477039338, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 8548, Training Loss: 0.1741064013011994, Validation Loss: 0.17404206693172455, Validation Accuracy: 0.48125\n",
      "Epoch 8549, Training Loss: 0.17367769441296976, Validation Loss: 0.17373810410499574, Validation Accuracy: 0.50625\n",
      "Epoch 8550, Training Loss: 0.1740659999270593, Validation Loss: 0.17481123010317484, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 8551, Training Loss: 0.17362239235831844, Validation Loss: 0.17217000623544057, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 8552, Training Loss: 0.17410950026204508, Validation Loss: 0.17402343153953553, Validation Accuracy: 0.475\n",
      "Epoch 8553, Training Loss: 0.173720984689651, Validation Loss: 0.17336247861385345, Validation Accuracy: 0.5125\n",
      "Epoch 8554, Training Loss: 0.17396041943180945, Validation Loss: 0.1752256214618683, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 8555, Training Loss: 0.17358228227784556, Validation Loss: 0.17268413305282593, Validation Accuracy: 0.5375\n",
      "Epoch 8556, Training Loss: 0.17403423113207664, Validation Loss: 0.1737595558166504, Validation Accuracy: 0.4875\n",
      "Epoch 8557, Training Loss: 0.17373555562188547, Validation Loss: 0.17382195393244426, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 8558, Training Loss: 0.1739468079420828, Validation Loss: 0.17448097864786785, Validation Accuracy: 0.475\n",
      "Epoch 8559, Training Loss: 0.17370586241445235, Validation Loss: 0.17207420170307158, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 8560, Training Loss: 0.1740444105479025, Validation Loss: 0.17383074363072712, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 8561, Training Loss: 0.17376102699387458, Validation Loss: 0.17364956835905712, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8562, Training Loss: 0.17390864126143918, Validation Loss: 0.17402266959349313, Validation Accuracy: 0.4875\n",
      "Epoch 8563, Training Loss: 0.17382023988231535, Validation Loss: 0.1728417823712031, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 8564, Training Loss: 0.1739471996984174, Validation Loss: 0.1734421968460083, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 8565, Training Loss: 0.17379317697017424, Validation Loss: 0.17360811531543732, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8566, Training Loss: 0.17380153556023875, Validation Loss: 0.17421062191327413, Validation Accuracy: 0.49375\n",
      "Epoch 8567, Training Loss: 0.17381754757896548, Validation Loss: 0.17335673371950786, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 8568, Training Loss: 0.1737708487818318, Validation Loss: 0.17335578600565593, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 8569, Training Loss: 0.17397047915766317, Validation Loss: 0.173717924952507, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 8570, Training Loss: 0.17372920532380381, Validation Loss: 0.1732232322295507, Validation Accuracy: 0.5125\n",
      "Epoch 8571, Training Loss: 0.1738824926076397, Validation Loss: 0.17374204993247985, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 8572, Training Loss: 0.17385652036436142, Validation Loss: 0.17306666672229767, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 8573, Training Loss: 0.1739458186972526, Validation Loss: 0.17369105418523154, Validation Accuracy: 0.48125\n",
      "Epoch 8574, Training Loss: 0.1736123946405226, Validation Loss: 0.17357096274693806, Validation Accuracy: 0.50625\n",
      "Epoch 8575, Training Loss: 0.17398041823217947, Validation Loss: 0.1738439033428828, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 8576, Training Loss: 0.17377199713260896, Validation Loss: 0.17263003289699555, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 8577, Training Loss: 0.17392362942618708, Validation Loss: 0.17374257246653238, Validation Accuracy: 0.475\n",
      "Epoch 8578, Training Loss: 0.17385493651513131, Validation Loss: 0.17321807543436687, Validation Accuracy: 0.5125\n",
      "Epoch 8579, Training Loss: 0.17383544291219405, Validation Loss: 0.17391105790932973, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 8580, Training Loss: 0.17387787132493912, Validation Loss: 0.17300909757614136, Validation Accuracy: 0.5375\n",
      "Epoch 8581, Training Loss: 0.17386746839169534, Validation Loss: 0.1736077070236206, Validation Accuracy: 0.4875\n",
      "Epoch 8582, Training Loss: 0.17373461204190407, Validation Loss: 0.17372028827667235, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 8583, Training Loss: 0.17377041857088765, Validation Loss: 0.1740882118542989, Validation Accuracy: 0.475\n",
      "Epoch 8584, Training Loss: 0.17394423965484865, Validation Loss: 0.17286049127578734, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 8585, Training Loss: 0.17382062010226712, Validation Loss: 0.1738465130329132, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 8586, Training Loss: 0.17389814026894107, Validation Loss: 0.17340076565742493, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8587, Training Loss: 0.17375098745669088, Validation Loss: 0.1737793654203415, Validation Accuracy: 0.4875\n",
      "Epoch 8588, Training Loss: 0.17395394223351632, Validation Loss: 0.17303561667601267, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 8589, Training Loss: 0.17375885382775338, Validation Loss: 0.17355613708496093, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 8590, Training Loss: 0.17393959241528664, Validation Loss: 0.17350695033868155, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8591, Training Loss: 0.17369793595806246, Validation Loss: 0.1736483484506607, Validation Accuracy: 0.49375\n",
      "Epoch 8592, Training Loss: 0.1739182924070666, Validation Loss: 0.17335155606269836, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 8593, Training Loss: 0.1738422166916632, Validation Loss: 0.17336666882038115, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 8594, Training Loss: 0.17373582961097842, Validation Loss: 0.17399417261282604, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 8595, Training Loss: 0.17378396132299978, Validation Loss: 0.17331900596618652, Validation Accuracy: 0.5125\n",
      "Epoch 8596, Training Loss: 0.17380428073867674, Validation Loss: 0.17365334431330362, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 8597, Training Loss: 0.1738872854940353, Validation Loss: 0.17291295826435088, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 8598, Training Loss: 0.17378845714753674, Validation Loss: 0.17371303141117095, Validation Accuracy: 0.48125\n",
      "Epoch 8599, Training Loss: 0.1737220061402167, Validation Loss: 0.17339134414990742, Validation Accuracy: 0.50625\n",
      "Epoch 8600, Training Loss: 0.17408238687822897, Validation Loss: 0.17347088158130647, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 8601, Training Loss: 0.17369681260278147, Validation Loss: 0.17243767380714417, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 8602, Training Loss: 0.17394183720311812, Validation Loss: 0.17360540827115375, Validation Accuracy: 0.475\n",
      "Epoch 8603, Training Loss: 0.17368464460296015, Validation Loss: 0.17329057256380717, Validation Accuracy: 0.5125\n",
      "Epoch 8604, Training Loss: 0.17406238279035013, Validation Loss: 0.1734606981277466, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 8605, Training Loss: 0.17366644259422057, Validation Loss: 0.17272863189379375, Validation Accuracy: 0.5375\n",
      "Epoch 8606, Training Loss: 0.17390855041242415, Validation Loss: 0.17355062166849772, Validation Accuracy: 0.4875\n",
      "Epoch 8607, Training Loss: 0.17362796250850923, Validation Loss: 0.17386521100997926, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 8608, Training Loss: 0.17413208849968448, Validation Loss: 0.1734041303396225, Validation Accuracy: 0.475\n",
      "Epoch 8609, Training Loss: 0.17368453741073608, Validation Loss: 0.17254327833652497, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 8610, Training Loss: 0.17401391844595632, Validation Loss: 0.17352963089942933, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 8611, Training Loss: 0.1736617790114495, Validation Loss: 0.17370407183965048, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8612, Training Loss: 0.17401657758220548, Validation Loss: 0.17335989077885947, Validation Accuracy: 0.4875\n",
      "Epoch 8613, Training Loss: 0.17376289060038905, Validation Loss: 0.17284784615039825, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 8614, Training Loss: 0.17375524966947495, Validation Loss: 0.17352179686228433, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 8615, Training Loss: 0.17371513189808016, Validation Loss: 0.1740102857351303, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8616, Training Loss: 0.17396646209301486, Validation Loss: 0.17333449125289918, Validation Accuracy: 0.49375\n",
      "Epoch 8617, Training Loss: 0.17383288375792966, Validation Loss: 0.17331800858179727, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 8618, Training Loss: 0.17384774646451395, Validation Loss: 0.173264283935229, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 8619, Training Loss: 0.17361746872625045, Validation Loss: 0.1742879052956899, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 8620, Training Loss: 0.17410451317987136, Validation Loss: 0.17325808008511862, Validation Accuracy: 0.5125\n",
      "Epoch 8621, Training Loss: 0.1737439920825343, Validation Loss: 0.1742241621017456, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 8622, Training Loss: 0.17383149122038194, Validation Loss: 0.1731614222129186, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 8623, Training Loss: 0.1736736831165129, Validation Loss: 0.17444321314493816, Validation Accuracy: 0.48125\n",
      "Epoch 8624, Training Loss: 0.1739523857831955, Validation Loss: 0.17327875991662342, Validation Accuracy: 0.50625\n",
      "Epoch 8625, Training Loss: 0.1736943366066102, Validation Loss: 0.17462134261926016, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 8626, Training Loss: 0.1739813454689518, Validation Loss: 0.17322331964969634, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 8627, Training Loss: 0.17356982971391371, Validation Loss: 0.17472777962684632, Validation Accuracy: 0.475\n",
      "Epoch 8628, Training Loss: 0.17408033388276253, Validation Loss: 0.17327265242735546, Validation Accuracy: 0.5125\n",
      "Epoch 8629, Training Loss: 0.17359201562020085, Validation Loss: 0.1749097466468811, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 8630, Training Loss: 0.17408750470607512, Validation Loss: 0.1732617179552714, Validation Accuracy: 0.5375\n",
      "Epoch 8631, Training Loss: 0.17350474528727994, Validation Loss: 0.17463290691375732, Validation Accuracy: 0.4875\n",
      "Epoch 8632, Training Loss: 0.17425417323266307, Validation Loss: 0.17344589034716287, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 8633, Training Loss: 0.1735909576377561, Validation Loss: 0.17439541220664978, Validation Accuracy: 0.475\n",
      "Epoch 8634, Training Loss: 0.17404797336747568, Validation Loss: 0.1731845458348592, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 8635, Training Loss: 0.17363157339634433, Validation Loss: 0.17481103142102558, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 8636, Training Loss: 0.1739894348767496, Validation Loss: 0.17331605553627014, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8637, Training Loss: 0.17361786528941123, Validation Loss: 0.1741814374923706, Validation Accuracy: 0.4875\n",
      "Epoch 8638, Training Loss: 0.17400759554678394, Validation Loss: 0.17322070101896922, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 8639, Training Loss: 0.17349503982451656, Validation Loss: 0.17477956414222717, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 8640, Training Loss: 0.1741551891449959, Validation Loss: 0.17375049293041228, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8641, Training Loss: 0.17356571795478945, Validation Loss: 0.17490984896818798, Validation Accuracy: 0.49375\n",
      "Epoch 8642, Training Loss: 0.17409457458603766, Validation Loss: 0.17328818539778393, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 8643, Training Loss: 0.17348549923589152, Validation Loss: 0.17371441423892975, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 8644, Training Loss: 0.17404599391645, Validation Loss: 0.17419821321964263, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 8645, Training Loss: 0.17352560787431656, Validation Loss: 0.17401218911012015, Validation Accuracy: 0.5125\n",
      "Epoch 8646, Training Loss: 0.17421616661933162, Validation Loss: 0.17439091702302298, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 8647, Training Loss: 0.17356691485451115, Validation Loss: 0.1731005330880483, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 8648, Training Loss: 0.1741267567680728, Validation Loss: 0.17461043695608774, Validation Accuracy: 0.48125\n",
      "Epoch 8649, Training Loss: 0.1735042199011772, Validation Loss: 0.1740663299957911, Validation Accuracy: 0.50625\n",
      "Epoch 8650, Training Loss: 0.17431004008939188, Validation Loss: 0.17511752545833587, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 8651, Training Loss: 0.17365106026972493, Validation Loss: 0.17214763462543486, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 8652, Training Loss: 0.1740777583852891, Validation Loss: 0.17514742116133372, Validation Accuracy: 0.475\n",
      "Epoch 8653, Training Loss: 0.173726454857857, Validation Loss: 0.17360552549362182, Validation Accuracy: 0.5125\n",
      "Epoch 8654, Training Loss: 0.1738215805061402, Validation Loss: 0.17552486956119537, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 8655, Training Loss: 0.17381798451946628, Validation Loss: 0.1726602166891098, Validation Accuracy: 0.5375\n",
      "Epoch 8656, Training Loss: 0.1737800178027922, Validation Loss: 0.17534503042697908, Validation Accuracy: 0.4875\n",
      "Epoch 8657, Training Loss: 0.173821410344493, Validation Loss: 0.17420938114325205, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 8658, Training Loss: 0.1739008484348174, Validation Loss: 0.1753472864627838, Validation Accuracy: 0.475\n",
      "Epoch 8659, Training Loss: 0.17389666505398288, Validation Loss: 0.17217321197191873, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 8660, Training Loss: 0.17364554299462226, Validation Loss: 0.17605070074399312, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 8661, Training Loss: 0.17403768627874314, Validation Loss: 0.17392649352550507, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8662, Training Loss: 0.17363265973906364, Validation Loss: 0.1750248044729233, Validation Accuracy: 0.4875\n",
      "Epoch 8663, Training Loss: 0.17417202793782757, Validation Loss: 0.17279768387476604, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 8664, Training Loss: 0.17333367995677457, Validation Loss: 0.17503471473852794, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 8665, Training Loss: 0.17440890304503903, Validation Loss: 0.1736609309911728, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8666, Training Loss: 0.17356434993205533, Validation Loss: 0.17457386255264282, Validation Accuracy: 0.49375\n",
      "Epoch 8667, Training Loss: 0.174082844968765, Validation Loss: 0.1735221823056539, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 8668, Training Loss: 0.17359069710777653, Validation Loss: 0.17397924661636352, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 8669, Training Loss: 0.174160094991807, Validation Loss: 0.17402397791544597, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 8670, Training Loss: 0.1737068199342297, Validation Loss: 0.17354365984598796, Validation Accuracy: 0.5125\n",
      "Epoch 8671, Training Loss: 0.17398797504363522, Validation Loss: 0.1744564155737559, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 8672, Training Loss: 0.17352412016161026, Validation Loss: 0.17301616370677947, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 8673, Training Loss: 0.1740856228336211, Validation Loss: 0.17397945125897726, Validation Accuracy: 0.48125\n",
      "Epoch 8674, Training Loss: 0.17371936334717658, Validation Loss: 0.17361024022102356, Validation Accuracy: 0.50625\n",
      "Epoch 8675, Training Loss: 0.17398897149870474, Validation Loss: 0.17472463548183442, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 8676, Training Loss: 0.17367696906289748, Validation Loss: 0.1722029636303584, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 8677, Training Loss: 0.17408722639083862, Validation Loss: 0.17405424614747364, Validation Accuracy: 0.475\n",
      "Epoch 8678, Training Loss: 0.1737528318359006, Validation Loss: 0.1733466198047002, Validation Accuracy: 0.5125\n",
      "Epoch 8679, Training Loss: 0.1740508641927473, Validation Loss: 0.1742975115776062, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 8680, Training Loss: 0.17365665685745976, Validation Loss: 0.17267307539780935, Validation Accuracy: 0.5375\n",
      "Epoch 8681, Training Loss: 0.17411016648815525, Validation Loss: 0.17365239262580873, Validation Accuracy: 0.4875\n",
      "Epoch 8682, Training Loss: 0.17375424071665732, Validation Loss: 0.17377258241176605, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 8683, Training Loss: 0.17392536709385534, Validation Loss: 0.17483541866143545, Validation Accuracy: 0.475\n",
      "Epoch 8684, Training Loss: 0.1737106120394122, Validation Loss: 0.17225774228572846, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 8685, Training Loss: 0.17395873367786407, Validation Loss: 0.1739065686861674, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 8686, Training Loss: 0.17384510174874337, Validation Loss: 0.17368154227733612, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8687, Training Loss: 0.1737947444761953, Validation Loss: 0.17453629771868387, Validation Accuracy: 0.4875\n",
      "Epoch 8688, Training Loss: 0.17378193524576002, Validation Loss: 0.17285554707050324, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 8689, Training Loss: 0.1739460426953531, Validation Loss: 0.17341959079106647, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 8690, Training Loss: 0.17384396060820548, Validation Loss: 0.1735352595647176, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8691, Training Loss: 0.17384305067600742, Validation Loss: 0.1739572525024414, Validation Accuracy: 0.49375\n",
      "Epoch 8692, Training Loss: 0.17382467610220756, Validation Loss: 0.17333522140979768, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 8693, Training Loss: 0.17376068811262807, Validation Loss: 0.17355293532212576, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 8694, Training Loss: 0.17391213678544568, Validation Loss: 0.1735835035641988, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 8695, Training Loss: 0.1738129416781087, Validation Loss: 0.173217111825943, Validation Accuracy: 0.5125\n",
      "Epoch 8696, Training Loss: 0.17390904263142618, Validation Loss: 0.17365740636984509, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 8697, Training Loss: 0.17380824781233264, Validation Loss: 0.17300627529621124, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 8698, Training Loss: 0.1739806955860507, Validation Loss: 0.17355148394902548, Validation Accuracy: 0.48125\n",
      "Epoch 8699, Training Loss: 0.17372945912422671, Validation Loss: 0.173407448331515, Validation Accuracy: 0.50625\n",
      "Epoch 8700, Training Loss: 0.1739486523212925, Validation Loss: 0.17366341054439544, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 8701, Training Loss: 0.17390329895480985, Validation Loss: 0.1729411820570628, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 8702, Training Loss: 0.17390842014743435, Validation Loss: 0.1736988971630732, Validation Accuracy: 0.475\n",
      "Epoch 8703, Training Loss: 0.1738174052969102, Validation Loss: 0.17321718533833821, Validation Accuracy: 0.5125\n",
      "Epoch 8704, Training Loss: 0.17388758976613322, Validation Loss: 0.1739146590232849, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 8705, Training Loss: 0.1739134697183486, Validation Loss: 0.17305376032988232, Validation Accuracy: 0.5375\n",
      "Epoch 8706, Training Loss: 0.17389825178730872, Validation Loss: 0.1735907554626465, Validation Accuracy: 0.4875\n",
      "Epoch 8707, Training Loss: 0.17379047745658505, Validation Loss: 0.17359937926133473, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 8708, Training Loss: 0.17384076983697952, Validation Loss: 0.17385090192159017, Validation Accuracy: 0.475\n",
      "Epoch 8709, Training Loss: 0.17389306810594374, Validation Loss: 0.17267732421557108, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 8710, Training Loss: 0.1738721747552195, Validation Loss: 0.17384004692236582, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 8711, Training Loss: 0.17386577590819327, Validation Loss: 0.17344293395678204, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8712, Training Loss: 0.17382550960586918, Validation Loss: 0.17371022899945576, Validation Accuracy: 0.4875\n",
      "Epoch 8713, Training Loss: 0.1738996712430831, Validation Loss: 0.17296788096427917, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 8714, Training Loss: 0.17381740962305375, Validation Loss: 0.17351297438144683, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 8715, Training Loss: 0.17393537490598618, Validation Loss: 0.17362764179706575, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8716, Training Loss: 0.17365103863900708, Validation Loss: 0.1737548142671585, Validation Accuracy: 0.49375\n",
      "Epoch 8717, Training Loss: 0.1741186495750181, Validation Loss: 0.17327911655108133, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 8718, Training Loss: 0.17383203631447208, Validation Loss: 0.17334732214609783, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 8719, Training Loss: 0.17380571173083398, Validation Loss: 0.1737124055624008, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 8720, Training Loss: 0.17379992238936887, Validation Loss: 0.17328179975350697, Validation Accuracy: 0.5125\n",
      "Epoch 8721, Training Loss: 0.17399204402200638, Validation Loss: 0.17340315183003743, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 8722, Training Loss: 0.17383177770722297, Validation Loss: 0.1729693591594696, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 8723, Training Loss: 0.17401513649571326, Validation Loss: 0.1733901490767797, Validation Accuracy: 0.48125\n",
      "Epoch 8724, Training Loss: 0.17363500931570608, Validation Loss: 0.17341562112172446, Validation Accuracy: 0.50625\n",
      "Epoch 8725, Training Loss: 0.17415160421402223, Validation Loss: 0.17342238823572795, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 8726, Training Loss: 0.17372671827193228, Validation Loss: 0.17243869403998058, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 8727, Training Loss: 0.17383304142182873, Validation Loss: 0.17390914658705395, Validation Accuracy: 0.475\n",
      "Epoch 8728, Training Loss: 0.17379456470089574, Validation Loss: 0.17328804632027944, Validation Accuracy: 0.5125\n",
      "Epoch 8729, Training Loss: 0.17393606180144894, Validation Loss: 0.17359753847122192, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 8730, Training Loss: 0.17413755818720786, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.4625\n",
      "Epoch 8731, Training Loss: 0.19555034897019785, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5125\n",
      "Epoch 8732, Training Loss: 0.17366636953046244, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.5104166666666666\n",
      "Epoch 8733, Training Loss: 0.18131887383999362, Validation Loss: 0.1732867956161499, Validation Accuracy: 0.475\n",
      "Epoch 8734, Training Loss: 0.1750277530762457, Validation Loss: 0.1721989740928014, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 8735, Training Loss: 0.17395227426482784, Validation Loss: 0.1743382255236308, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 8736, Training Loss: 0.17381140781987098, Validation Loss: 0.17378867367903392, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8737, Training Loss: 0.1743680695372243, Validation Loss: 0.17333735922972363, Validation Accuracy: 0.4875\n",
      "Epoch 8738, Training Loss: 0.17384878425828873, Validation Loss: 0.17288462221622466, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 8739, Training Loss: 0.1740276385699549, Validation Loss: 0.17357332706451417, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 8740, Training Loss: 0.17379466083741957, Validation Loss: 0.1737034261226654, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8741, Training Loss: 0.17430671520771518, Validation Loss: 0.17331585387388865, Validation Accuracy: 0.49375\n",
      "Epoch 8742, Training Loss: 0.17386209580206102, Validation Loss: 0.1734476089477539, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 8743, Training Loss: 0.1741590682537325, Validation Loss: 0.1732707550128301, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 8744, Training Loss: 0.1736494437340767, Validation Loss: 0.17395031154155732, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 8745, Training Loss: 0.17446283227013004, Validation Loss: 0.1732401023308436, Validation Accuracy: 0.5125\n",
      "Epoch 8746, Training Loss: 0.1737895555073215, Validation Loss: 0.1747368574142456, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 8747, Training Loss: 0.1742573082447052, Validation Loss: 0.17306806643803915, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 8748, Training Loss: 0.17367070096154366, Validation Loss: 0.17438991169134777, Validation Accuracy: 0.48125\n",
      "Epoch 8749, Training Loss: 0.17437283165993228, Validation Loss: 0.17327002187569937, Validation Accuracy: 0.50625\n",
      "Epoch 8750, Training Loss: 0.1736405530283528, Validation Loss: 0.17531515260537464, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 8751, Training Loss: 0.17446252415257116, Validation Loss: 0.17291452785332997, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 8752, Training Loss: 0.17352105100308696, Validation Loss: 0.1751895874738693, Validation Accuracy: 0.475\n",
      "Epoch 8753, Training Loss: 0.17451685042150558, Validation Loss: 0.17321761151154835, Validation Accuracy: 0.5125\n",
      "Epoch 8754, Training Loss: 0.1735503149609412, Validation Loss: 0.1759005864461263, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 8755, Training Loss: 0.17439767958656435, Validation Loss: 0.17279815375804902, Validation Accuracy: 0.5375\n",
      "Epoch 8756, Training Loss: 0.17356140286691726, Validation Loss: 0.17472012142340343, Validation Accuracy: 0.4875\n",
      "Epoch 8757, Training Loss: 0.17452022144871374, Validation Loss: 0.17348023056983947, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 8758, Training Loss: 0.17372883327545657, Validation Loss: 0.17568539083003998, Validation Accuracy: 0.475\n",
      "Epoch 8759, Training Loss: 0.1743493229150772, Validation Loss: 0.17234049638112386, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 8760, Training Loss: 0.17365791624592197, Validation Loss: 0.17548385163148245, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 8761, Training Loss: 0.17438271016843856, Validation Loss: 0.17366871237754822, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8762, Training Loss: 0.1736044196351882, Validation Loss: 0.1753307948509852, Validation Accuracy: 0.4875\n",
      "Epoch 8763, Training Loss: 0.17440232394203062, Validation Loss: 0.17277458409468333, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 8764, Training Loss: 0.17353723318346084, Validation Loss: 0.1748998949925105, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 8765, Training Loss: 0.17440919193529314, Validation Loss: 0.17390553057193756, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8766, Training Loss: 0.17361376698940031, Validation Loss: 0.17523016929626464, Validation Accuracy: 0.49375\n",
      "Epoch 8767, Training Loss: 0.17436830170692935, Validation Loss: 0.1737128883600235, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 8768, Training Loss: 0.1736335398689393, Validation Loss: 0.17415561278661093, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 8769, Training Loss: 0.17424890398979187, Validation Loss: 0.17452005545298258, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 8770, Training Loss: 0.1736239141994907, Validation Loss: 0.1741636037826538, Validation Accuracy: 0.5125\n",
      "Epoch 8771, Training Loss: 0.17439111346198666, Validation Loss: 0.17472872932751973, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 8772, Training Loss: 0.1737522031030347, Validation Loss: 0.17294881641864776, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 8773, Training Loss: 0.17433865031888407, Validation Loss: 0.17467415432135264, Validation Accuracy: 0.48125\n",
      "Epoch 8774, Training Loss: 0.17348130431867415, Validation Loss: 0.1742422769467036, Validation Accuracy: 0.50625\n",
      "Epoch 8775, Training Loss: 0.17453292973579898, Validation Loss: 0.17551663517951965, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 8776, Training Loss: 0.17377973371936428, Validation Loss: 0.17209310630957286, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 8777, Training Loss: 0.17426791402601427, Validation Loss: 0.17561994989713034, Validation Accuracy: 0.475\n",
      "Epoch 8778, Training Loss: 0.1738168130959234, Validation Loss: 0.17367592056592304, Validation Accuracy: 0.5125\n",
      "Epoch 8779, Training Loss: 0.17395231848762882, Validation Loss: 0.17567041118939716, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 8780, Training Loss: 0.17404816996666692, Validation Loss: 0.1726741204659144, Validation Accuracy: 0.5375\n",
      "Epoch 8781, Training Loss: 0.17392091260802361, Validation Loss: 0.17573123276233674, Validation Accuracy: 0.4875\n",
      "Epoch 8782, Training Loss: 0.17392741528249556, Validation Loss: 0.1744804084300995, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 8783, Training Loss: 0.17402998333977115, Validation Loss: 0.17654753824075062, Validation Accuracy: 0.475\n",
      "Epoch 8784, Training Loss: 0.17410884893709613, Validation Loss: 0.1718500703573227, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 8785, Training Loss: 0.17381984283847193, Validation Loss: 0.17678276399771373, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 8786, Training Loss: 0.17422168870126048, Validation Loss: 0.17418566544850667, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8787, Training Loss: 0.1737366299475393, Validation Loss: 0.17488760352134705, Validation Accuracy: 0.4875\n",
      "Epoch 8788, Training Loss: 0.17440292864076554, Validation Loss: 0.17273826996485392, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 8789, Training Loss: 0.1733775576276164, Validation Loss: 0.17544316947460176, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 8790, Training Loss: 0.17466603652123483, Validation Loss: 0.17404175301392874, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8791, Training Loss: 0.17354636471117696, Validation Loss: 0.17563709020614623, Validation Accuracy: 0.49375\n",
      "Epoch 8792, Training Loss: 0.17436928662561602, Validation Loss: 0.17356468637784322, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 8793, Training Loss: 0.17366722658757242, Validation Loss: 0.17460968792438508, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 8794, Training Loss: 0.17438790154072545, Validation Loss: 0.17410006721814472, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 8795, Training Loss: 0.1738051824992703, Validation Loss: 0.173503119746844, Validation Accuracy: 0.5125\n",
      "Epoch 8796, Training Loss: 0.17419187628453778, Validation Loss: 0.17485186060269672, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 8797, Training Loss: 0.1736351833228142, Validation Loss: 0.1732511341571808, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 8798, Training Loss: 0.17428810942557552, Validation Loss: 0.1740592877070109, Validation Accuracy: 0.48125\n",
      "Epoch 8799, Training Loss: 0.17377218652156093, Validation Loss: 0.1739283323287964, Validation Accuracy: 0.50625\n",
      "Epoch 8800, Training Loss: 0.17425942180618162, Validation Loss: 0.17465961178143818, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 8801, Training Loss: 0.1737163331239454, Validation Loss: 0.17209727466106414, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 8802, Training Loss: 0.17430506646633148, Validation Loss: 0.17410963575045268, Validation Accuracy: 0.475\n",
      "Epoch 8803, Training Loss: 0.17381227256790285, Validation Loss: 0.17347319523493449, Validation Accuracy: 0.5125\n",
      "Epoch 8804, Training Loss: 0.1742524254706598, Validation Loss: 0.1744755725065867, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 8805, Training Loss: 0.17366189197186502, Validation Loss: 0.1727248917023341, Validation Accuracy: 0.5375\n",
      "Epoch 8806, Training Loss: 0.174382726030965, Validation Loss: 0.17362652818361918, Validation Accuracy: 0.4875\n",
      "Epoch 8807, Training Loss: 0.17384682691866352, Validation Loss: 0.1739342192808787, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 8808, Training Loss: 0.17415915429592133, Validation Loss: 0.17428966760635375, Validation Accuracy: 0.475\n",
      "Epoch 8809, Training Loss: 0.17374677283148612, Validation Loss: 0.17181101838747662, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 8810, Training Loss: 0.17429844602461783, Validation Loss: 0.17382220029830933, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 8811, Training Loss: 0.17387894036308413, Validation Loss: 0.17367105881373088, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8812, Training Loss: 0.17408934235572815, Validation Loss: 0.1738871842622757, Validation Accuracy: 0.4875\n",
      "Epoch 8813, Training Loss: 0.17388356741397612, Validation Loss: 0.17279095947742462, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 8814, Training Loss: 0.1741818896224422, Validation Loss: 0.17347337206204733, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 8815, Training Loss: 0.1738612267278856, Validation Loss: 0.17356565097967783, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8816, Training Loss: 0.1741808436570629, Validation Loss: 0.17350060443083445, Validation Accuracy: 0.49375\n",
      "Epoch 8817, Training Loss: 0.17382988477906874, Validation Loss: 0.1733124852180481, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 8818, Training Loss: 0.17414150026536757, Validation Loss: 0.17328479786713918, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 8819, Training Loss: 0.17395634708865995, Validation Loss: 0.17352200051148733, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 8820, Training Loss: 0.1738675553952494, Validation Loss: 0.17329870065053304, Validation Accuracy: 0.5125\n",
      "Epoch 8821, Training Loss: 0.17398047399136327, Validation Loss: 0.17363113164901733, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 8822, Training Loss: 0.1741783147858035, Validation Loss: 0.17307419180870057, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 8823, Training Loss: 0.17405345170728623, Validation Loss: 0.17359654208024342, Validation Accuracy: 0.48125\n",
      "Epoch 8824, Training Loss: 0.173885878536009, Validation Loss: 0.17337730924288433, Validation Accuracy: 0.50625\n",
      "Epoch 8825, Training Loss: 0.17396211095394626, Validation Loss: 0.17365738650163015, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 8826, Training Loss: 0.17414919791683073, Validation Loss: 0.17289004425207774, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 8827, Training Loss: 0.17402322686487628, Validation Loss: 0.173857186237971, Validation Accuracy: 0.475\n",
      "Epoch 8828, Training Loss: 0.1738679769539064, Validation Loss: 0.17325804034868877, Validation Accuracy: 0.5125\n",
      "Epoch 8829, Training Loss: 0.17395873560059455, Validation Loss: 0.173887966076533, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 8830, Training Loss: 0.17410437330122916, Validation Loss: 0.17297585209210714, Validation Accuracy: 0.5375\n",
      "Epoch 8831, Training Loss: 0.17399160179399675, Validation Loss: 0.17371334234873453, Validation Accuracy: 0.4875\n",
      "Epoch 8832, Training Loss: 0.17394966175479273, Validation Loss: 0.1736500432093938, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 8833, Training Loss: 0.17384566510877303, Validation Loss: 0.17396044135093688, Validation Accuracy: 0.475\n",
      "Epoch 8834, Training Loss: 0.17422133972567896, Validation Loss: 0.17290170590082804, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 8835, Training Loss: 0.17390436270544607, Validation Loss: 0.17419325908025104, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 8836, Training Loss: 0.1739071444157631, Validation Loss: 0.17369333803653716, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8837, Training Loss: 0.17382495393676142, Validation Loss: 0.1739039182662964, Validation Accuracy: 0.4875\n",
      "Epoch 8838, Training Loss: 0.1742558955184875, Validation Loss: 0.17303432325522106, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 8839, Training Loss: 0.17380221140000127, Validation Loss: 0.173707511027654, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 8840, Training Loss: 0.17422536400056654, Validation Loss: 0.1734632839759191, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8841, Training Loss: 0.17367095331991872, Validation Loss: 0.17376035551230112, Validation Accuracy: 0.49375\n",
      "Epoch 8842, Training Loss: 0.17434441754894872, Validation Loss: 0.17328283389409382, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 8843, Training Loss: 0.17384890779372184, Validation Loss: 0.17333187858263652, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 8844, Training Loss: 0.17418267073169832, Validation Loss: 0.17346672813097636, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 8845, Training Loss: 0.17373025321191357, Validation Loss: 0.17326457500457765, Validation Accuracy: 0.5125\n",
      "Epoch 8846, Training Loss: 0.17430036394826828, Validation Loss: 0.17341022292772929, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 8847, Training Loss: 0.17378701750309236, Validation Loss: 0.1729249119758606, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 8848, Training Loss: 0.17414145988802757, Validation Loss: 0.1734962781270345, Validation Accuracy: 0.48125\n",
      "Epoch 8849, Training Loss: 0.1736782572923168, Validation Loss: 0.17347371180852253, Validation Accuracy: 0.50625\n",
      "Epoch 8850, Training Loss: 0.17435994407823008, Validation Loss: 0.1734973539908727, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 8851, Training Loss: 0.1736943269929578, Validation Loss: 0.17237456738948823, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 8852, Training Loss: 0.1743265813396823, Validation Loss: 0.17349672317504883, Validation Accuracy: 0.475\n",
      "Epoch 8853, Training Loss: 0.17365557724429714, Validation Loss: 0.17329673568407694, Validation Accuracy: 0.5125\n",
      "Epoch 8854, Training Loss: 0.17440624871561605, Validation Loss: 0.17340704500675203, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 8855, Training Loss: 0.17362965162723296, Validation Loss: 0.17273414134979248, Validation Accuracy: 0.5375\n",
      "Epoch 8856, Training Loss: 0.17402608163895145, Validation Loss: 0.1735880603392919, Validation Accuracy: 0.4875\n",
      "Epoch 8857, Training Loss: 0.17372277955855092, Validation Loss: 0.17388330797354382, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 8858, Training Loss: 0.17443000212792428, Validation Loss: 0.1734842300415039, Validation Accuracy: 0.475\n",
      "Epoch 8859, Training Loss: 0.1736540102189587, Validation Loss: 0.1718658705552419, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 8860, Training Loss: 0.17428140870986447, Validation Loss: 0.1735251933336258, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 8861, Training Loss: 0.17367577168249315, Validation Loss: 0.17374456028143564, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8862, Training Loss: 0.17427417972395498, Validation Loss: 0.17330535252888998, Validation Accuracy: 0.4875\n",
      "Epoch 8863, Training Loss: 0.1736951571318411, Validation Loss: 0.17292358974615732, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 8864, Training Loss: 0.17423326930692118, Validation Loss: 0.17333789269129435, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 8865, Training Loss: 0.173690929047523, Validation Loss: 0.17378955483436584, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8866, Training Loss: 0.17435854769522144, Validation Loss: 0.17330937683582306, Validation Accuracy: 0.49375\n",
      "Epoch 8867, Training Loss: 0.17382861625763676, Validation Loss: 0.17383470833301545, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 8868, Training Loss: 0.17421303833684615, Validation Loss: 0.1732611119747162, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 8869, Training Loss: 0.17360676873114803, Validation Loss: 0.17444194555282594, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 8870, Training Loss: 0.17437333301190408, Validation Loss: 0.17326059341430664, Validation Accuracy: 0.5125\n",
      "Epoch 8871, Training Loss: 0.17368648609807413, Validation Loss: 0.17425116896629333, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 8872, Training Loss: 0.17435077938341326, Validation Loss: 0.17313540875911712, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 8873, Training Loss: 0.1736205268290735, Validation Loss: 0.17512094875176748, Validation Accuracy: 0.48125\n",
      "Epoch 8874, Training Loss: 0.17438824522879817, Validation Loss: 0.17326940695444742, Validation Accuracy: 0.50625\n",
      "Epoch 8875, Training Loss: 0.17357999615130887, Validation Loss: 0.17532068689664204, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 8876, Training Loss: 0.1744340129436985, Validation Loss: 0.17308625280857087, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 8877, Training Loss: 0.17351585963080007, Validation Loss: 0.17555715243021647, Validation Accuracy: 0.475\n",
      "Epoch 8878, Training Loss: 0.17454935706430866, Validation Loss: 0.17321996688842772, Validation Accuracy: 0.5125\n",
      "Epoch 8879, Training Loss: 0.17344398940763167, Validation Loss: 0.17577340205510458, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 8880, Training Loss: 0.174410427770307, Validation Loss: 0.17296020984649657, Validation Accuracy: 0.5375\n",
      "Epoch 8881, Training Loss: 0.17352143170372133, Validation Loss: 0.1748194009065628, Validation Accuracy: 0.4875\n",
      "Epoch 8882, Training Loss: 0.17455938891057046, Validation Loss: 0.17362180252869924, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 8883, Training Loss: 0.17359322790176637, Validation Loss: 0.17555511395136517, Validation Accuracy: 0.475\n",
      "Epoch 8884, Training Loss: 0.17429770865748007, Validation Loss: 0.17228500843048095, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 8885, Training Loss: 0.17365665685745976, Validation Loss: 0.17501582105954488, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 8886, Training Loss: 0.17441035182245315, Validation Loss: 0.1737123241027196, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8887, Training Loss: 0.17352808435117045, Validation Loss: 0.17502229611078898, Validation Accuracy: 0.4875\n",
      "Epoch 8888, Training Loss: 0.1743738805094073, Validation Loss: 0.172846848766009, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 8889, Training Loss: 0.17350975736494986, Validation Loss: 0.1744679480791092, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 8890, Training Loss: 0.17442342206355063, Validation Loss: 0.17385567724704742, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8891, Training Loss: 0.17356578909581707, Validation Loss: 0.17475147147973377, Validation Accuracy: 0.49375\n",
      "Epoch 8892, Training Loss: 0.17437074357463467, Validation Loss: 0.17371890544891358, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 8893, Training Loss: 0.17361881896372763, Validation Loss: 0.17401502231756846, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 8894, Training Loss: 0.17426803467735166, Validation Loss: 0.17455374499162038, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 8895, Training Loss: 0.17362368924002494, Validation Loss: 0.17379995584487914, Validation Accuracy: 0.5125\n",
      "Epoch 8896, Training Loss: 0.1744368355120382, Validation Loss: 0.17453602453072867, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 8897, Training Loss: 0.17358751354678983, Validation Loss: 0.17304721772670745, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 8898, Training Loss: 0.17434421422020083, Validation Loss: 0.1748695880174637, Validation Accuracy: 0.48125\n",
      "Epoch 8899, Training Loss: 0.1735365770516857, Validation Loss: 0.1740235596895218, Validation Accuracy: 0.50625\n",
      "Epoch 8900, Training Loss: 0.17452512296938127, Validation Loss: 0.1757325917482376, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 8901, Training Loss: 0.17364333618071773, Validation Loss: 0.17217741509278614, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 8902, Training Loss: 0.17427059815775964, Validation Loss: 0.1757948060830434, Validation Accuracy: 0.475\n",
      "Epoch 8903, Training Loss: 0.17380936732215266, Validation Loss: 0.1734686185916265, Validation Accuracy: 0.5125\n",
      "Epoch 8904, Training Loss: 0.1739897636636611, Validation Loss: 0.17561104198296865, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 8905, Training Loss: 0.17400974035263062, Validation Loss: 0.17266585032145182, Validation Accuracy: 0.5375\n",
      "Epoch 8906, Training Loss: 0.17385862911901168, Validation Loss: 0.17568990389506023, Validation Accuracy: 0.4875\n",
      "Epoch 8907, Training Loss: 0.1739989374914477, Validation Loss: 0.1741649071375529, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 8908, Training Loss: 0.17396127745028464, Validation Loss: 0.17618393103281657, Validation Accuracy: 0.475\n",
      "Epoch 8909, Training Loss: 0.17412185668945312, Validation Loss: 0.17195530434449513, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 8910, Training Loss: 0.17376687305588875, Validation Loss: 0.17695045471191406, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 8911, Training Loss: 0.17425655165026266, Validation Loss: 0.17390711903572081, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8912, Training Loss: 0.17369605312424322, Validation Loss: 0.17560970385869343, Validation Accuracy: 0.4875\n",
      "Epoch 8913, Training Loss: 0.17420515418052673, Validation Loss: 0.17289401292800904, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 8914, Training Loss: 0.17341560894443142, Validation Loss: 0.17581499814987184, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 8915, Training Loss: 0.174674853682518, Validation Loss: 0.17377808094024658, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8916, Training Loss: 0.17364361882209778, Validation Loss: 0.17481252451737722, Validation Accuracy: 0.49375\n",
      "Epoch 8917, Training Loss: 0.17429104351228283, Validation Loss: 0.17369559804598492, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 8918, Training Loss: 0.17363202091186278, Validation Loss: 0.17486045956611634, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 8919, Training Loss: 0.17435599286710063, Validation Loss: 0.1739611009756724, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 8920, Training Loss: 0.17379283376278415, Validation Loss: 0.17345545490582784, Validation Accuracy: 0.5125\n",
      "Epoch 8921, Training Loss: 0.17416285603277146, Validation Loss: 0.17459705074628193, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 8922, Training Loss: 0.1736044374204451, Validation Loss: 0.17343202730019888, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 8923, Training Loss: 0.17431817948818207, Validation Loss: 0.17391481002171835, Validation Accuracy: 0.48125\n",
      "Epoch 8924, Training Loss: 0.1737795053951202, Validation Loss: 0.1738383799791336, Validation Accuracy: 0.50625\n",
      "Epoch 8925, Training Loss: 0.17421090122192137, Validation Loss: 0.17469915747642517, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 8926, Training Loss: 0.17365808592688653, Validation Loss: 0.17207925816377004, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 8927, Training Loss: 0.17436763211604087, Validation Loss: 0.173965318997701, Validation Accuracy: 0.475\n",
      "Epoch 8928, Training Loss: 0.17375982240323098, Validation Loss: 0.17367363472779593, Validation Accuracy: 0.5125\n",
      "Epoch 8929, Training Loss: 0.1741204857826233, Validation Loss: 0.17536083459854127, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 8930, Training Loss: 0.1736996106563076, Validation Loss: 0.1726778119802475, Validation Accuracy: 0.5375\n",
      "Epoch 8931, Training Loss: 0.17436061943731002, Validation Loss: 0.17363167703151702, Validation Accuracy: 0.4875\n",
      "Epoch 8932, Training Loss: 0.1738361519190573, Validation Loss: 0.17390151023864747, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 8933, Training Loss: 0.17412155962759449, Validation Loss: 0.17433266838391623, Validation Accuracy: 0.475\n",
      "Epoch 8934, Training Loss: 0.17373503311987845, Validation Loss: 0.17192977567513784, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 8935, Training Loss: 0.17430292069911957, Validation Loss: 0.17380234201749165, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 8936, Training Loss: 0.17389132034394048, Validation Loss: 0.17372456192970276, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8937, Training Loss: 0.17398379406621378, Validation Loss: 0.17429183423519135, Validation Accuracy: 0.4875\n",
      "Epoch 8938, Training Loss: 0.17390551730509726, Validation Loss: 0.1727802058060964, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 8939, Training Loss: 0.17416346169287159, Validation Loss: 0.1734708160161972, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 8940, Training Loss: 0.17393212308806758, Validation Loss: 0.17361198763052624, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8941, Training Loss: 0.17403150758435648, Validation Loss: 0.1736965795358022, Validation Accuracy: 0.49375\n",
      "Epoch 8942, Training Loss: 0.17384733451950934, Validation Loss: 0.173295862476031, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 8943, Training Loss: 0.17418211986941676, Validation Loss: 0.17326607704162597, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 8944, Training Loss: 0.17399238482598336, Validation Loss: 0.1734634776910146, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 8945, Training Loss: 0.1738987233369581, Validation Loss: 0.17326615552107494, Validation Accuracy: 0.5125\n",
      "Epoch 8946, Training Loss: 0.17399329283545095, Validation Loss: 0.1735020806392034, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 8947, Training Loss: 0.17411243242602195, Validation Loss: 0.17304187814394634, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 8948, Training Loss: 0.17397545758754976, Validation Loss: 0.17349021136760712, Validation Accuracy: 0.48125\n",
      "Epoch 8949, Training Loss: 0.17405918625093275, Validation Loss: 0.17330776453018187, Validation Accuracy: 0.50625\n",
      "Epoch 8950, Training Loss: 0.17390377771469853, Validation Loss: 0.17360795438289642, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 8951, Training Loss: 0.17415681337156602, Validation Loss: 0.17286982834339143, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 8952, Training Loss: 0.17395525305501877, Validation Loss: 0.17362361252307892, Validation Accuracy: 0.475\n",
      "Epoch 8953, Training Loss: 0.17400946059534628, Validation Loss: 0.17322227160135906, Validation Accuracy: 0.5125\n",
      "Epoch 8954, Training Loss: 0.17387785353968221, Validation Loss: 0.1737141102552414, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 8955, Training Loss: 0.17417065510826726, Validation Loss: 0.17298797269662222, Validation Accuracy: 0.5375\n",
      "Epoch 8956, Training Loss: 0.1738869619946326, Validation Loss: 0.17359059453010559, Validation Accuracy: 0.4875\n",
      "Epoch 8957, Training Loss: 0.1741666366015711, Validation Loss: 0.1734148770570755, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 8958, Training Loss: 0.17377444572987094, Validation Loss: 0.17382565538088482, Validation Accuracy: 0.475\n",
      "Epoch 8959, Training Loss: 0.17425761395885098, Validation Loss: 0.17288091083367665, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 8960, Training Loss: 0.1738177970532448, Validation Loss: 0.17398079137007397, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 8961, Training Loss: 0.17406067588636953, Validation Loss: 0.17348980903625488, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8962, Training Loss: 0.17380449416175967, Validation Loss: 0.17388019263744353, Validation Accuracy: 0.4875\n",
      "Epoch 8963, Training Loss: 0.1742525028605615, Validation Loss: 0.1730791469415029, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 8964, Training Loss: 0.1737149651012113, Validation Loss: 0.17365634938081106, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 8965, Training Loss: 0.17413900552257414, Validation Loss: 0.17366236547629038, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8966, Training Loss: 0.17367013664014877, Validation Loss: 0.1738940328359604, Validation Accuracy: 0.49375\n",
      "Epoch 8967, Training Loss: 0.17442865621659062, Validation Loss: 0.17328539391358694, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 8968, Training Loss: 0.17388460184297255, Validation Loss: 0.17348923683166503, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 8969, Training Loss: 0.1740502191166724, Validation Loss: 0.17364347676436107, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 8970, Training Loss: 0.17379185509297154, Validation Loss: 0.17325580219427744, Validation Accuracy: 0.5125\n",
      "Epoch 8971, Training Loss: 0.17425588926961344, Validation Loss: 0.17343841791152953, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 8972, Training Loss: 0.17382361235157137, Validation Loss: 0.1729170282681783, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 8973, Training Loss: 0.17421982605611125, Validation Loss: 0.17346721390883127, Validation Accuracy: 0.48125\n",
      "Epoch 8974, Training Loss: 0.17364423601858078, Validation Loss: 0.17347102761268615, Validation Accuracy: 0.50625\n",
      "Epoch 8975, Training Loss: 0.17437236155233077, Validation Loss: 0.1734870394070943, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 8976, Training Loss: 0.1737022683505089, Validation Loss: 0.17224024335543314, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 8977, Training Loss: 0.17429545377531358, Validation Loss: 0.17356294989585877, Validation Accuracy: 0.475\n",
      "Epoch 8978, Training Loss: 0.17368574776957113, Validation Loss: 0.17328683634599049, Validation Accuracy: 0.5125\n",
      "Epoch 8979, Training Loss: 0.17434921812626622, Validation Loss: 0.1734693557024002, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 8980, Training Loss: 0.1737021275105015, Validation Loss: 0.1726616770029068, Validation Accuracy: 0.5375\n",
      "Epoch 8981, Training Loss: 0.17421057916456653, Validation Loss: 0.17347016433874765, Validation Accuracy: 0.4875\n",
      "Epoch 8982, Training Loss: 0.17369264604583864, Validation Loss: 0.17388602197170258, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 8983, Training Loss: 0.17443883419036865, Validation Loss: 0.17338892817497253, Validation Accuracy: 0.475\n",
      "Epoch 8984, Training Loss: 0.17362555188517417, Validation Loss: 0.1721065789461136, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 8985, Training Loss: 0.17437457990261815, Validation Loss: 0.17348325550556182, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 8986, Training Loss: 0.1736506454406246, Validation Loss: 0.17384359339872996, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8987, Training Loss: 0.1743626339781669, Validation Loss: 0.17338848412036895, Validation Accuracy: 0.4875\n",
      "Epoch 8988, Training Loss: 0.1737118839256225, Validation Loss: 0.17272715071837108, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 8989, Training Loss: 0.17428432212721917, Validation Loss: 0.17335367798805237, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 8990, Training Loss: 0.17370101136545982, Validation Loss: 0.17399664322535197, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 8991, Training Loss: 0.1743547950060137, Validation Loss: 0.17333365678787233, Validation Accuracy: 0.49375\n",
      "Epoch 8992, Training Loss: 0.1737787627404736, Validation Loss: 0.17371293803056082, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 8993, Training Loss: 0.17425220243392453, Validation Loss: 0.17325600385665893, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 8994, Training Loss: 0.1735855379412251, Validation Loss: 0.174198051293691, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 8995, Training Loss: 0.1743063119149977, Validation Loss: 0.17327613433202108, Validation Accuracy: 0.5125\n",
      "Epoch 8996, Training Loss: 0.17369380112617247, Validation Loss: 0.17399019996325174, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 8997, Training Loss: 0.17407337263707193, Validation Loss: 0.17319441040356953, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 8998, Training Loss: 0.17370388392479189, Validation Loss: 0.17448023358980816, Validation Accuracy: 0.48125\n",
      "Epoch 8999, Training Loss: 0.17442730213365248, Validation Loss: 0.17327776551246643, Validation Accuracy: 0.50625\n",
      "Epoch 9000, Training Loss: 0.17352682015588206, Validation Loss: 0.17591366569201153, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 9001, Training Loss: 0.17439490412512132, Validation Loss: 0.1730381041765213, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 9002, Training Loss: 0.17356657068575582, Validation Loss: 0.17502963940302532, Validation Accuracy: 0.475\n",
      "Epoch 9003, Training Loss: 0.1744880522451093, Validation Loss: 0.1732254127661387, Validation Accuracy: 0.5125\n",
      "Epoch 9004, Training Loss: 0.17350091136270954, Validation Loss: 0.17570368150870005, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 9005, Training Loss: 0.174475954905633, Validation Loss: 0.17279483477274576, Validation Accuracy: 0.5375\n",
      "Epoch 9006, Training Loss: 0.17348511324774835, Validation Loss: 0.1748653699954351, Validation Accuracy: 0.4875\n",
      "Epoch 9007, Training Loss: 0.1745763656593138, Validation Loss: 0.17362070182959238, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 9008, Training Loss: 0.1735730517295099, Validation Loss: 0.17535606324672698, Validation Accuracy: 0.475\n",
      "Epoch 9009, Training Loss: 0.17445027491738718, Validation Loss: 0.1724282036225001, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 9010, Training Loss: 0.17358660746005275, Validation Loss: 0.17569348414738972, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 9011, Training Loss: 0.17440163704656786, Validation Loss: 0.173745193084081, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9012, Training Loss: 0.17356451624824154, Validation Loss: 0.17502432962258657, Validation Accuracy: 0.4875\n",
      "Epoch 9013, Training Loss: 0.1743889008798907, Validation Loss: 0.1727472166220347, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 9014, Training Loss: 0.17352333040006698, Validation Loss: 0.1746409922838211, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 9015, Training Loss: 0.1743564259621405, Validation Loss: 0.1740566591421763, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9016, Training Loss: 0.1736501686034664, Validation Loss: 0.17478809952735902, Validation Accuracy: 0.49375\n",
      "Epoch 9017, Training Loss: 0.17435792569191225, Validation Loss: 0.17336517572402954, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 9018, Training Loss: 0.17355000011382565, Validation Loss: 0.17366301616032917, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 9019, Training Loss: 0.1742050407394286, Validation Loss: 0.1745362937450409, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 9020, Training Loss: 0.17361559117994002, Validation Loss: 0.17383919258912403, Validation Accuracy: 0.5125\n",
      "Epoch 9021, Training Loss: 0.17433289943202848, Validation Loss: 0.1747080792983373, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 9022, Training Loss: 0.1737435652363685, Validation Loss: 0.17302574614683788, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 9023, Training Loss: 0.17433162802650082, Validation Loss: 0.17499072353045145, Validation Accuracy: 0.48125\n",
      "Epoch 9024, Training Loss: 0.17359034909356025, Validation Loss: 0.17387896180152893, Validation Accuracy: 0.50625\n",
      "Epoch 9025, Training Loss: 0.17443126151638647, Validation Loss: 0.17543657819430034, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 9026, Training Loss: 0.17379421043780544, Validation Loss: 0.17211326758066814, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 9027, Training Loss: 0.17421236538117932, Validation Loss: 0.1757167398929596, Validation Accuracy: 0.475\n",
      "Epoch 9028, Training Loss: 0.1738343157114521, Validation Loss: 0.17351562480131785, Validation Accuracy: 0.5125\n",
      "Epoch 9029, Training Loss: 0.17397497882766108, Validation Loss: 0.17570091386636097, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 9030, Training Loss: 0.1739823683615654, Validation Loss: 0.17266374627749126, Validation Accuracy: 0.5375\n",
      "Epoch 9031, Training Loss: 0.173894866339622, Validation Loss: 0.1758080542087555, Validation Accuracy: 0.4875\n",
      "Epoch 9032, Training Loss: 0.17400361693674518, Validation Loss: 0.1741527686516444, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 9033, Training Loss: 0.17397563015261003, Validation Loss: 0.1762735664844513, Validation Accuracy: 0.475\n",
      "Epoch 9034, Training Loss: 0.17411881060369552, Validation Loss: 0.17194212873776754, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 9035, Training Loss: 0.17377838011710875, Validation Loss: 0.17678781549135844, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 9036, Training Loss: 0.17424794550864928, Validation Loss: 0.17394426862398785, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9037, Training Loss: 0.1736733038579264, Validation Loss: 0.17582249840100606, Validation Accuracy: 0.4875\n",
      "Epoch 9038, Training Loss: 0.17440560796568472, Validation Loss: 0.17276418209075928, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 9039, Training Loss: 0.1733659549105552, Validation Loss: 0.1758995036284129, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 9040, Training Loss: 0.1746970525672359, Validation Loss: 0.17362117767333984, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9041, Training Loss: 0.17366822063922882, Validation Loss: 0.17494494418303172, Validation Accuracy: 0.49375\n",
      "Epoch 9042, Training Loss: 0.1742847220551583, Validation Loss: 0.1735467900832494, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 9043, Training Loss: 0.17365319017441042, Validation Loss: 0.17478624482949576, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 9044, Training Loss: 0.17431987485577982, Validation Loss: 0.17413395047187805, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 9045, Training Loss: 0.1737732195085095, Validation Loss: 0.17411869565645854, Validation Accuracy: 0.5125\n",
      "Epoch 9046, Training Loss: 0.1742907137640061, Validation Loss: 0.17413664360841116, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 9047, Training Loss: 0.17357815994370368, Validation Loss: 0.1734580139319102, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 9048, Training Loss: 0.1743507505424561, Validation Loss: 0.17391540110111237, Validation Accuracy: 0.48125\n",
      "Epoch 9049, Training Loss: 0.17375866299675358, Validation Loss: 0.17392156024773917, Validation Accuracy: 0.50625\n",
      "Epoch 9050, Training Loss: 0.17422870714818278, Validation Loss: 0.17461393972237904, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 9051, Training Loss: 0.17366648922043462, Validation Loss: 0.1720753530661265, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 9052, Training Loss: 0.17439238294478385, Validation Loss: 0.17395395338535308, Validation Accuracy: 0.475\n",
      "Epoch 9053, Training Loss: 0.17375294383495085, Validation Loss: 0.17365632553895313, Validation Accuracy: 0.5125\n",
      "Epoch 9054, Training Loss: 0.17430579325845164, Validation Loss: 0.17425263126691182, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 9055, Training Loss: 0.17362182515282784, Validation Loss: 0.17270399928092955, Validation Accuracy: 0.5375\n",
      "Epoch 9056, Training Loss: 0.1743940523555202, Validation Loss: 0.17365383505821227, Validation Accuracy: 0.4875\n",
      "Epoch 9057, Training Loss: 0.1737620965127022, Validation Loss: 0.17440374195575714, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 9058, Training Loss: 0.1742668637344914, Validation Loss: 0.1740133802096049, Validation Accuracy: 0.475\n",
      "Epoch 9059, Training Loss: 0.17369327814348282, Validation Loss: 0.17177097300688426, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 9060, Training Loss: 0.17432586944872333, Validation Loss: 0.17380299468835195, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 9061, Training Loss: 0.1738142289461628, Validation Loss: 0.17382336854934693, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9062, Training Loss: 0.17419674800288293, Validation Loss: 0.1737005352973938, Validation Accuracy: 0.4875\n",
      "Epoch 9063, Training Loss: 0.17384272958001784, Validation Loss: 0.17286079426606496, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 9064, Training Loss: 0.1741944440910893, Validation Loss: 0.1734897365172704, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 9065, Training Loss: 0.17384947211511673, Validation Loss: 0.17359772324562073, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9066, Training Loss: 0.1741831071915165, Validation Loss: 0.17350184122721354, Validation Accuracy: 0.49375\n",
      "Epoch 9067, Training Loss: 0.17382406611596385, Validation Loss: 0.1733026643594106, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 9068, Training Loss: 0.17417319936137046, Validation Loss: 0.17327182094256083, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 9069, Training Loss: 0.1739281819712731, Validation Loss: 0.17350120842456818, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 9070, Training Loss: 0.17404785848432971, Validation Loss: 0.17322033445040386, Validation Accuracy: 0.5125\n",
      "Epoch 9071, Training Loss: 0.17390944111731746, Validation Loss: 0.17347807188828787, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 9072, Training Loss: 0.17409428136963997, Validation Loss: 0.17301493187745412, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 9073, Training Loss: 0.17402215446195296, Validation Loss: 0.17349164585272472, Validation Accuracy: 0.48125\n",
      "Epoch 9074, Training Loss: 0.1740024806030335, Validation Loss: 0.17333179612954458, Validation Accuracy: 0.50625\n",
      "Epoch 9075, Training Loss: 0.17392475999170734, Validation Loss: 0.17358562250932058, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 9076, Training Loss: 0.17415712725731633, Validation Loss: 0.1728625625371933, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 9077, Training Loss: 0.17392245511854848, Validation Loss: 0.1735717495282491, Validation Accuracy: 0.475\n",
      "Epoch 9078, Training Loss: 0.1740261306685786, Validation Loss: 0.17322350045045218, Validation Accuracy: 0.5125\n",
      "Epoch 9079, Training Loss: 0.17387913359749702, Validation Loss: 0.17367661893367767, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 9080, Training Loss: 0.17421535474638786, Validation Loss: 0.17304584880669913, Validation Accuracy: 0.5375\n",
      "Epoch 9081, Training Loss: 0.17387755791987142, Validation Loss: 0.17352501451969146, Validation Accuracy: 0.4875\n",
      "Epoch 9082, Training Loss: 0.173782070317576, Validation Loss: 0.17397152483463288, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 9083, Training Loss: 0.17391322793499117, Validation Loss: 0.1738832970460256, Validation Accuracy: 0.475\n",
      "Epoch 9084, Training Loss: 0.17423262855698984, Validation Loss: 0.17278561194737752, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 9085, Training Loss: 0.1738664594388777, Validation Loss: 0.17393114666144052, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 9086, Training Loss: 0.173798501010864, Validation Loss: 0.173878479997317, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9087, Training Loss: 0.17389091801258824, Validation Loss: 0.17375956376393636, Validation Accuracy: 0.4875\n",
      "Epoch 9088, Training Loss: 0.17430987377320567, Validation Loss: 0.17310853997866313, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 9089, Training Loss: 0.1737654920547239, Validation Loss: 0.1738431364297867, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 9090, Training Loss: 0.17419056738576583, Validation Loss: 0.17353487114111582, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9091, Training Loss: 0.17369423566326017, Validation Loss: 0.17375842829545338, Validation Accuracy: 0.49375\n",
      "Epoch 9092, Training Loss: 0.17433734045874688, Validation Loss: 0.17328322529792786, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 9093, Training Loss: 0.17381926842274203, Validation Loss: 0.1733391284942627, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 9094, Training Loss: 0.17376130002160226, Validation Loss: 0.17466493646303813, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 9095, Training Loss: 0.17387531072862686, Validation Loss: 0.17330054342746734, Validation Accuracy: 0.5125\n",
      "Epoch 9096, Training Loss: 0.17431211711898928, Validation Loss: 0.17346120874087015, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 9097, Training Loss: 0.17386125028133392, Validation Loss: 0.1729074647029241, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 9098, Training Loss: 0.17418035047669564, Validation Loss: 0.17352377076943715, Validation Accuracy: 0.48125\n",
      "Epoch 9099, Training Loss: 0.1736783202617399, Validation Loss: 0.1734904666741689, Validation Accuracy: 0.50625\n",
      "Epoch 9100, Training Loss: 0.1743478549103583, Validation Loss: 0.17351636787255606, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 9101, Training Loss: 0.17369018735424166, Validation Loss: 0.1723721275726954, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 9102, Training Loss: 0.17432447787254088, Validation Loss: 0.17349434792995452, Validation Accuracy: 0.475\n",
      "Epoch 9103, Training Loss: 0.17368319486418077, Validation Loss: 0.17326161464055378, Validation Accuracy: 0.5125\n",
      "Epoch 9104, Training Loss: 0.1742703438766541, Validation Loss: 0.1734807401895523, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 9105, Training Loss: 0.17371880623602098, Validation Loss: 0.1727560818195343, Validation Accuracy: 0.5375\n",
      "Epoch 9106, Training Loss: 0.17439170133682988, Validation Loss: 0.17338574230670928, Validation Accuracy: 0.4875\n",
      "Epoch 9107, Training Loss: 0.1736503690481186, Validation Loss: 0.17414467334747313, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 9108, Training Loss: 0.1743534827424634, Validation Loss: 0.17343696355819702, Validation Accuracy: 0.475\n",
      "Epoch 9109, Training Loss: 0.1736585017173521, Validation Loss: 0.17234890162944794, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 9110, Training Loss: 0.17439195177247446, Validation Loss: 0.17350256939729056, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 9111, Training Loss: 0.1736559776529189, Validation Loss: 0.17404114007949828, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9112, Training Loss: 0.17431766996460576, Validation Loss: 0.17334329187870026, Validation Accuracy: 0.4875\n",
      "Epoch 9113, Training Loss: 0.1737663419015946, Validation Loss: 0.1727644036213557, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 9114, Training Loss: 0.17430685460567474, Validation Loss: 0.17335179448127747, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 9115, Training Loss: 0.17370706123690452, Validation Loss: 0.17444482545057932, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9116, Training Loss: 0.17424993361196212, Validation Loss: 0.17336995800336202, Validation Accuracy: 0.49375\n",
      "Epoch 9117, Training Loss: 0.1738608657352386, Validation Loss: 0.17375455697377523, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 9118, Training Loss: 0.1741773885103964, Validation Loss: 0.17325884501139324, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 9119, Training Loss: 0.1736131368144866, Validation Loss: 0.1741002966960271, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 9120, Training Loss: 0.1744742234868388, Validation Loss: 0.17323055267333984, Validation Accuracy: 0.5125\n",
      "Epoch 9121, Training Loss: 0.17367446855191263, Validation Loss: 0.17489310105641684, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 9122, Training Loss: 0.17431489979067155, Validation Loss: 0.17306094666322072, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 9123, Training Loss: 0.17362119305518367, Validation Loss: 0.17468101382255555, Validation Accuracy: 0.48125\n",
      "Epoch 9124, Training Loss: 0.17440864011164633, Validation Loss: 0.1732763369878133, Validation Accuracy: 0.50625\n",
      "Epoch 9125, Training Loss: 0.17352996333952872, Validation Loss: 0.17559762299060822, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 9126, Training Loss: 0.17443261271522892, Validation Loss: 0.17311010360717774, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 9127, Training Loss: 0.17350753420783627, Validation Loss: 0.17519568701585134, Validation Accuracy: 0.475\n",
      "Epoch 9128, Training Loss: 0.17436501960600576, Validation Loss: 0.17327282726764678, Validation Accuracy: 0.5125\n",
      "Epoch 9129, Training Loss: 0.17357309210684993, Validation Loss: 0.17531845470269522, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 9130, Training Loss: 0.17434628452024153, Validation Loss: 0.17318387627601622, Validation Accuracy: 0.5375\n",
      "Epoch 9131, Training Loss: 0.17348724315243383, Validation Loss: 0.17465510467688242, Validation Accuracy: 0.4875\n",
      "Epoch 9132, Training Loss: 0.1742658422839257, Validation Loss: 0.173298708597819, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 9133, Training Loss: 0.1737752701005628, Validation Loss: 0.17474952836831412, Validation Accuracy: 0.475\n",
      "Epoch 9134, Training Loss: 0.17438997616690974, Validation Loss: 0.17232904235521954, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 9135, Training Loss: 0.17356603424395284, Validation Loss: 0.1756167193253835, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 9136, Training Loss: 0.17432392220343312, Validation Loss: 0.17387288212776184, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9137, Training Loss: 0.173632764047192, Validation Loss: 0.1750368575255076, Validation Accuracy: 0.4875\n",
      "Epoch 9138, Training Loss: 0.17425556865430647, Validation Loss: 0.17284186482429503, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 9139, Training Loss: 0.17355915423362486, Validation Loss: 0.1742743452390035, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 9140, Training Loss: 0.17437274081091728, Validation Loss: 0.17390971680482228, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9141, Training Loss: 0.17361070215702057, Validation Loss: 0.17482916216055552, Validation Accuracy: 0.49375\n",
      "Epoch 9142, Training Loss: 0.1743582001616878, Validation Loss: 0.17352038522561392, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 9143, Training Loss: 0.17355398160796012, Validation Loss: 0.1739805221557617, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 9144, Training Loss: 0.17432210858791106, Validation Loss: 0.1744885285695394, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 9145, Training Loss: 0.1735905158904291, Validation Loss: 0.17378147840499877, Validation Accuracy: 0.5125\n",
      "Epoch 9146, Training Loss: 0.17433201209191354, Validation Loss: 0.1747124989827474, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 9147, Training Loss: 0.1737731325049554, Validation Loss: 0.1730274776617686, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 9148, Training Loss: 0.17430323602691775, Validation Loss: 0.17492520908514658, Validation Accuracy: 0.48125\n",
      "Epoch 9149, Training Loss: 0.17357569596459788, Validation Loss: 0.17389591832955678, Validation Accuracy: 0.50625\n",
      "Epoch 9150, Training Loss: 0.17446325430946966, Validation Loss: 0.17555848956108094, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 9151, Training Loss: 0.173766874017254, Validation Loss: 0.1721492737531662, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 9152, Training Loss: 0.17424730572008318, Validation Loss: 0.1757307360569636, Validation Accuracy: 0.475\n",
      "Epoch 9153, Training Loss: 0.1738036217228059, Validation Loss: 0.17348031798998514, Validation Accuracy: 0.5125\n",
      "Epoch 9154, Training Loss: 0.17399636343602212, Validation Loss: 0.17581164836883545, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 9155, Training Loss: 0.17399488822106393, Validation Loss: 0.17265920837720236, Validation Accuracy: 0.5375\n",
      "Epoch 9156, Training Loss: 0.17388023436069489, Validation Loss: 0.1757510483264923, Validation Accuracy: 0.4875\n",
      "Epoch 9157, Training Loss: 0.173993214484184, Validation Loss: 0.17417073051134746, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 9158, Training Loss: 0.17398039756282682, Validation Loss: 0.17625826001167297, Validation Accuracy: 0.475\n",
      "Epoch 9159, Training Loss: 0.17407075195543228, Validation Loss: 0.17205886443456014, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 9160, Training Loss: 0.17379287173671107, Validation Loss: 0.17715842127799988, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 9161, Training Loss: 0.1742455776660673, Validation Loss: 0.17380673090616863, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9162, Training Loss: 0.1737604881486585, Validation Loss: 0.17483025590578716, Validation Accuracy: 0.4875\n",
      "Epoch 9163, Training Loss: 0.1743661871840877, Validation Loss: 0.17272963027159374, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 9164, Training Loss: 0.17334309700996645, Validation Loss: 0.17563528617223104, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 9165, Training Loss: 0.1746786304058567, Validation Loss: 0.1738326499859492, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9166, Training Loss: 0.1736496739810513, Validation Loss: 0.17468608021736146, Validation Accuracy: 0.49375\n",
      "Epoch 9167, Training Loss: 0.17415486852968892, Validation Loss: 0.17365524570147198, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 9168, Training Loss: 0.17363939794801897, Validation Loss: 0.1744793524344762, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 9169, Training Loss: 0.17433324696556216, Validation Loss: 0.1739615172147751, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 9170, Training Loss: 0.17380721963221027, Validation Loss: 0.17349802652994792, Validation Accuracy: 0.5125\n",
      "Epoch 9171, Training Loss: 0.17418165216522832, Validation Loss: 0.17459222674369812, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 9172, Training Loss: 0.17364090248461692, Validation Loss: 0.17331796487172443, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 9173, Training Loss: 0.1743024770290621, Validation Loss: 0.17396779755751293, Validation Accuracy: 0.48125\n",
      "Epoch 9174, Training Loss: 0.17373006526500948, Validation Loss: 0.17410237888495128, Validation Accuracy: 0.50625\n",
      "Epoch 9175, Training Loss: 0.1742391543042275, Validation Loss: 0.1747763713200887, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 9176, Training Loss: 0.17364193835566122, Validation Loss: 0.1721338083346685, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 9177, Training Loss: 0.17440679092561046, Validation Loss: 0.17391514281431833, Validation Accuracy: 0.475\n",
      "Epoch 9178, Training Loss: 0.17374821103388263, Validation Loss: 0.17380790412425995, Validation Accuracy: 0.5125\n",
      "Epoch 9179, Training Loss: 0.1742742878775443, Validation Loss: 0.17460734446843465, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 9180, Training Loss: 0.17356723931527906, Validation Loss: 0.17314742902914684, Validation Accuracy: 0.5375\n",
      "Epoch 9181, Training Loss: 0.17446062593690811, Validation Loss: 0.1736145834128062, Validation Accuracy: 0.4875\n",
      "Epoch 9182, Training Loss: 0.1738360341518156, Validation Loss: 0.17397740483283997, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 9183, Training Loss: 0.17416716679450003, Validation Loss: 0.17421819070974986, Validation Accuracy: 0.475\n",
      "Epoch 9184, Training Loss: 0.17372849968171888, Validation Loss: 0.1718689888715744, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 9185, Training Loss: 0.1743123190056893, Validation Loss: 0.17382382651170095, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 9186, Training Loss: 0.17381716639764846, Validation Loss: 0.17383843064308166, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9187, Training Loss: 0.17421003022501547, Validation Loss: 0.17368089656035104, Validation Accuracy: 0.4875\n",
      "Epoch 9188, Training Loss: 0.17380586843336782, Validation Loss: 0.17276708384354908, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 9189, Training Loss: 0.1742439414224317, Validation Loss: 0.17342168788115184, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 9190, Training Loss: 0.1738610815617346, Validation Loss: 0.17346790532271067, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9191, Training Loss: 0.17408579684072925, Validation Loss: 0.1737042138973872, Validation Accuracy: 0.49375\n",
      "Epoch 9192, Training Loss: 0.17387461325814646, Validation Loss: 0.17335772514343262, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 9193, Training Loss: 0.1741501684150388, Validation Loss: 0.1732689638932546, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 9194, Training Loss: 0.1739706728727587, Validation Loss: 0.17349518636862438, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 9195, Training Loss: 0.1739751369722428, Validation Loss: 0.17323550780614216, Validation Accuracy: 0.5125\n",
      "Epoch 9196, Training Loss: 0.17396724512500147, Validation Loss: 0.17352027495702108, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 9197, Training Loss: 0.1740743080454488, Validation Loss: 0.17301283677419027, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 9198, Training Loss: 0.17401114394587855, Validation Loss: 0.17349897027015687, Validation Accuracy: 0.48125\n",
      "Epoch 9199, Training Loss: 0.17405200389123732, Validation Loss: 0.1733085145552953, Validation Accuracy: 0.50625\n",
      "Epoch 9200, Training Loss: 0.17389706882738298, Validation Loss: 0.1735916405916214, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 9201, Training Loss: 0.1741729801700961, Validation Loss: 0.1728467434644699, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 9202, Training Loss: 0.17391463873847837, Validation Loss: 0.17359488209088644, Validation Accuracy: 0.475\n",
      "Epoch 9203, Training Loss: 0.1740920707102745, Validation Loss: 0.1732171247402827, Validation Accuracy: 0.5125\n",
      "Epoch 9204, Training Loss: 0.17384251856034802, Validation Loss: 0.1737016409635544, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 9205, Training Loss: 0.17416502391138383, Validation Loss: 0.1730089028676351, Validation Accuracy: 0.5375\n",
      "Epoch 9206, Training Loss: 0.17393675927192934, Validation Loss: 0.1735567718744278, Validation Accuracy: 0.4875\n",
      "Epoch 9207, Training Loss: 0.17407287753397419, Validation Loss: 0.17349392672379813, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 9208, Training Loss: 0.1737992080949968, Validation Loss: 0.1739191383123398, Validation Accuracy: 0.475\n",
      "Epoch 9209, Training Loss: 0.1741447256457421, Validation Loss: 0.1727166106303533, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 9210, Training Loss: 0.1738305788847708, Validation Loss: 0.17408572435379027, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 9211, Training Loss: 0.17419364711930674, Validation Loss: 0.17338483730951945, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9212, Training Loss: 0.17379818856716156, Validation Loss: 0.1736761917670568, Validation Accuracy: 0.4875\n",
      "Epoch 9213, Training Loss: 0.1741938663105811, Validation Loss: 0.17302758196989695, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 9214, Training Loss: 0.17375276838579484, Validation Loss: 0.17363748053709666, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 9215, Training Loss: 0.17427944319863473, Validation Loss: 0.1734033981959025, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9216, Training Loss: 0.17371016788867213, Validation Loss: 0.17363617122173308, Validation Accuracy: 0.49375\n",
      "Epoch 9217, Training Loss: 0.17429317870447714, Validation Loss: 0.17328768372535705, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 9218, Training Loss: 0.17379500933231845, Validation Loss: 0.17330731252829235, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 9219, Training Loss: 0.17424902560249453, Validation Loss: 0.17344331741333008, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 9220, Training Loss: 0.17372419949500792, Validation Loss: 0.17325371404488882, Validation Accuracy: 0.5125\n",
      "Epoch 9221, Training Loss: 0.17428816326202884, Validation Loss: 0.17340900003910065, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 9222, Training Loss: 0.17380382120609283, Validation Loss: 0.17291269501050313, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 9223, Training Loss: 0.17421847918341238, Validation Loss: 0.1734494646390279, Validation Accuracy: 0.48125\n",
      "Epoch 9224, Training Loss: 0.17366844896347292, Validation Loss: 0.1735466778278351, Validation Accuracy: 0.50625\n",
      "Epoch 9225, Training Loss: 0.17431055009365082, Validation Loss: 0.1735616554816564, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 9226, Training Loss: 0.1737209620975679, Validation Loss: 0.1723691552877426, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 9227, Training Loss: 0.17431654901273788, Validation Loss: 0.1734951615333557, Validation Accuracy: 0.475\n",
      "Epoch 9228, Training Loss: 0.1736692464159381, Validation Loss: 0.17326642274856568, Validation Accuracy: 0.5125\n",
      "Epoch 9229, Training Loss: 0.1743667317974952, Validation Loss: 0.17342461546262106, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 9230, Training Loss: 0.17365751247252187, Validation Loss: 0.17270978490511577, Validation Accuracy: 0.5375\n",
      "Epoch 9231, Training Loss: 0.17434056680048665, Validation Loss: 0.17340282400449117, Validation Accuracy: 0.4875\n",
      "Epoch 9232, Training Loss: 0.173650459416451, Validation Loss: 0.17385757068792979, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 9233, Training Loss: 0.17440056993115333, Validation Loss: 0.17341030637423197, Validation Accuracy: 0.475\n",
      "Epoch 9234, Training Loss: 0.17365110833798686, Validation Loss: 0.17213110625743866, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 9235, Training Loss: 0.17430597111102072, Validation Loss: 0.17353914280732471, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 9236, Training Loss: 0.17368407018723026, Validation Loss: 0.17379287282625835, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9237, Training Loss: 0.17438571107002995, Validation Loss: 0.17337065935134888, Validation Accuracy: 0.4875\n",
      "Epoch 9238, Training Loss: 0.173688986609059, Validation Loss: 0.1727283388376236, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 9239, Training Loss: 0.17430266737937927, Validation Loss: 0.17335311472415924, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 9240, Training Loss: 0.17365976447059261, Validation Loss: 0.17368753552436828, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9241, Training Loss: 0.17440493164523954, Validation Loss: 0.17334188024202982, Validation Accuracy: 0.49375\n",
      "Epoch 9242, Training Loss: 0.17373775234145503, Validation Loss: 0.17355717619260153, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 9243, Training Loss: 0.17417303929405828, Validation Loss: 0.1732623815536499, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 9244, Training Loss: 0.1736754669297126, Validation Loss: 0.17447658876578012, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 9245, Training Loss: 0.17445815570892825, Validation Loss: 0.17322551608085632, Validation Accuracy: 0.5125\n",
      "Epoch 9246, Training Loss: 0.17366168960448233, Validation Loss: 0.17489197254180908, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 9247, Training Loss: 0.17423094857123592, Validation Loss: 0.173198397954305, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 9248, Training Loss: 0.1736582334964506, Validation Loss: 0.17462666233380636, Validation Accuracy: 0.48125\n",
      "Epoch 9249, Training Loss: 0.17441200537066306, Validation Loss: 0.17327372133731841, Validation Accuracy: 0.50625\n",
      "Epoch 9250, Training Loss: 0.17352998785434232, Validation Loss: 0.1757337858279546, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 9251, Training Loss: 0.17446868890716183, Validation Loss: 0.17308149735132852, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 9252, Training Loss: 0.17352427782550936, Validation Loss: 0.17555913031101228, Validation Accuracy: 0.475\n",
      "Epoch 9253, Training Loss: 0.17444621651403366, Validation Loss: 0.1732539931933085, Validation Accuracy: 0.5125\n",
      "Epoch 9254, Training Loss: 0.173539636115874, Validation Loss: 0.1756041834751765, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 9255, Training Loss: 0.17432150917668496, Validation Loss: 0.1731811950604121, Validation Accuracy: 0.5375\n",
      "Epoch 9256, Training Loss: 0.17355208050820134, Validation Loss: 0.17432497143745423, Validation Accuracy: 0.4875\n",
      "Epoch 9257, Training Loss: 0.17450892300375045, Validation Loss: 0.1735717455546061, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 9258, Training Loss: 0.17362263366099326, Validation Loss: 0.1755319893360138, Validation Accuracy: 0.475\n",
      "Epoch 9259, Training Loss: 0.17436315744153916, Validation Loss: 0.17222030858198803, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 9260, Training Loss: 0.17362003364870626, Validation Loss: 0.1751678635676702, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 9261, Training Loss: 0.17441568643816055, Validation Loss: 0.1737196922302246, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9262, Training Loss: 0.173520008402486, Validation Loss: 0.17499187390009563, Validation Accuracy: 0.4875\n",
      "Epoch 9263, Training Loss: 0.17412569686289756, Validation Loss: 0.17317871550718944, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 9264, Training Loss: 0.17362668677683799, Validation Loss: 0.17399117251237234, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 9265, Training Loss: 0.174400792487206, Validation Loss: 0.17380449970563253, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9266, Training Loss: 0.17355692771173292, Validation Loss: 0.17475309371948242, Validation Accuracy: 0.49375\n",
      "Epoch 9267, Training Loss: 0.17443616928592806, Validation Loss: 0.17353690266609192, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 9268, Training Loss: 0.173461411749163, Validation Loss: 0.1740004022916158, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 9269, Training Loss: 0.1743200243480744, Validation Loss: 0.174504554271698, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 9270, Training Loss: 0.1735940167019444, Validation Loss: 0.17382358511288962, Validation Accuracy: 0.5125\n",
      "Epoch 9271, Training Loss: 0.17433301816063543, Validation Loss: 0.1747374633948008, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 9272, Training Loss: 0.17377298253197823, Validation Loss: 0.1729677160580953, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 9273, Training Loss: 0.17432809981607622, Validation Loss: 0.17466014623641968, Validation Accuracy: 0.48125\n",
      "Epoch 9274, Training Loss: 0.17349023924719903, Validation Loss: 0.1740002234776815, Validation Accuracy: 0.50625\n",
      "Epoch 9275, Training Loss: 0.1744794456228133, Validation Loss: 0.17535718977451326, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 9276, Training Loss: 0.17363754059037856, Validation Loss: 0.17219017644723256, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 9277, Training Loss: 0.17429102861112164, Validation Loss: 0.17557655175526937, Validation Accuracy: 0.475\n",
      "Epoch 9278, Training Loss: 0.1737498915003192, Validation Loss: 0.1734109620253245, Validation Accuracy: 0.5125\n",
      "Epoch 9279, Training Loss: 0.17397766728555003, Validation Loss: 0.1752963642279307, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 9280, Training Loss: 0.17401920931954537, Validation Loss: 0.17265921235084533, Validation Accuracy: 0.5375\n",
      "Epoch 9281, Training Loss: 0.17388407068867837, Validation Loss: 0.1757194568713506, Validation Accuracy: 0.4875\n",
      "Epoch 9282, Training Loss: 0.17396863718186656, Validation Loss: 0.17417312562465667, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 9283, Training Loss: 0.1739802538387237, Validation Loss: 0.17592920263608297, Validation Accuracy: 0.475\n",
      "Epoch 9284, Training Loss: 0.17410770347041468, Validation Loss: 0.17187928259372712, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 9285, Training Loss: 0.17377781867980957, Validation Loss: 0.17664845585823058, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 9286, Training Loss: 0.17424630830364843, Validation Loss: 0.17395233114560446, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9287, Training Loss: 0.17367502470170298, Validation Loss: 0.17583104570706684, Validation Accuracy: 0.4875\n",
      "Epoch 9288, Training Loss: 0.17442383785401622, Validation Loss: 0.17276795009771984, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 9289, Training Loss: 0.17340259830797872, Validation Loss: 0.1755154291788737, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 9290, Training Loss: 0.17467556220869865, Validation Loss: 0.17362785240014394, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9291, Training Loss: 0.17368753110208818, Validation Loss: 0.17457494735717774, Validation Accuracy: 0.49375\n",
      "Epoch 9292, Training Loss: 0.17429192892966733, Validation Loss: 0.17368070483207704, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 9293, Training Loss: 0.1736545644460186, Validation Loss: 0.17464636663595837, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 9294, Training Loss: 0.17437426938164619, Validation Loss: 0.17394895553588868, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 9295, Training Loss: 0.17380105824239792, Validation Loss: 0.17363850275675455, Validation Accuracy: 0.5125\n",
      "Epoch 9296, Training Loss: 0.1742011337511001, Validation Loss: 0.17445445557435355, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 9297, Training Loss: 0.1735960918088113, Validation Loss: 0.17337650259335835, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 9298, Training Loss: 0.17432055550236855, Validation Loss: 0.17395184437433878, Validation Accuracy: 0.48125\n",
      "Epoch 9299, Training Loss: 0.173739553459229, Validation Loss: 0.17403002480665844, Validation Accuracy: 0.50625\n",
      "Epoch 9300, Training Loss: 0.1742752670280395, Validation Loss: 0.17451900442441304, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 9301, Training Loss: 0.17364856937239248, Validation Loss: 0.17207967738310495, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 9302, Training Loss: 0.1743839253340998, Validation Loss: 0.17394593556722004, Validation Accuracy: 0.475\n",
      "Epoch 9303, Training Loss: 0.1737519795856168, Validation Loss: 0.17366225918134054, Validation Accuracy: 0.5125\n",
      "Epoch 9304, Training Loss: 0.17431535691984237, Validation Loss: 0.1742344299952189, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 9305, Training Loss: 0.1735926664644672, Validation Loss: 0.17276085714499156, Validation Accuracy: 0.5375\n",
      "Epoch 9306, Training Loss: 0.17441010138680857, Validation Loss: 0.17362432181835175, Validation Accuracy: 0.4875\n",
      "Epoch 9307, Training Loss: 0.1738185070214733, Validation Loss: 0.1740387737751007, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 9308, Training Loss: 0.1741701292414819, Validation Loss: 0.17426028847694397, Validation Accuracy: 0.475\n",
      "Epoch 9309, Training Loss: 0.17374130410532798, Validation Loss: 0.17190921207269033, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 9310, Training Loss: 0.17430855574146395, Validation Loss: 0.17387021481990814, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 9311, Training Loss: 0.1739404119791523, Validation Loss: 0.17367160717646282, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9312, Training Loss: 0.1740676289604556, Validation Loss: 0.17391068736712137, Validation Accuracy: 0.4875\n",
      "Epoch 9313, Training Loss: 0.17384953556522245, Validation Loss: 0.17285727262496947, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 9314, Training Loss: 0.17423097308604948, Validation Loss: 0.1734370837608973, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 9315, Training Loss: 0.17387202622429018, Validation Loss: 0.17347346941630046, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9316, Training Loss: 0.17413007732360594, Validation Loss: 0.17358020544052125, Validation Accuracy: 0.49375\n",
      "Epoch 9317, Training Loss: 0.1738366393312331, Validation Loss: 0.17331043481826783, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 9318, Training Loss: 0.17417529994441616, Validation Loss: 0.17326709230740864, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 9319, Training Loss: 0.1739265005434713, Validation Loss: 0.1734941263993581, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 9320, Training Loss: 0.17404295071478812, Validation Loss: 0.17322102387746174, Validation Accuracy: 0.5125\n",
      "Epoch 9321, Training Loss: 0.17394142141265254, Validation Loss: 0.17345958451430002, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 9322, Training Loss: 0.17396288341091526, Validation Loss: 0.17293883562088014, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 9323, Training Loss: 0.1741055005019711, Validation Loss: 0.1735602209965388, Validation Accuracy: 0.48125\n",
      "Epoch 9324, Training Loss: 0.17404090300683053, Validation Loss: 0.1733064572016398, Validation Accuracy: 0.50625\n",
      "Epoch 9325, Training Loss: 0.17390072345733643, Validation Loss: 0.17357171475887298, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 9326, Training Loss: 0.1740777511750498, Validation Loss: 0.17266480425993602, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 9327, Training Loss: 0.17398803849374095, Validation Loss: 0.1736965924501419, Validation Accuracy: 0.475\n",
      "Epoch 9328, Training Loss: 0.17402126808320323, Validation Loss: 0.17321988542874653, Validation Accuracy: 0.5125\n",
      "Epoch 9329, Training Loss: 0.1739082052823036, Validation Loss: 0.1737050106128057, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 9330, Training Loss: 0.1741184332678395, Validation Loss: 0.17294218838214875, Validation Accuracy: 0.5375\n",
      "Epoch 9331, Training Loss: 0.17398061338932283, Validation Loss: 0.17364811499913532, Validation Accuracy: 0.4875\n",
      "Epoch 9332, Training Loss: 0.17404919622405882, Validation Loss: 0.17351721028486888, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 9333, Training Loss: 0.17379451759399905, Validation Loss: 0.17390210628509523, Validation Accuracy: 0.475\n",
      "Epoch 9334, Training Loss: 0.17425412324167067, Validation Loss: 0.17288456161816915, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 9335, Training Loss: 0.17389111076631852, Validation Loss: 0.1740920752286911, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 9336, Training Loss: 0.17405653384424025, Validation Loss: 0.1734703799088796, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9337, Training Loss: 0.17380754841912177, Validation Loss: 0.1737206737200419, Validation Accuracy: 0.4875\n",
      "Epoch 9338, Training Loss: 0.1742413692897366, Validation Loss: 0.17306828896204632, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 9339, Training Loss: 0.17376910486528951, Validation Loss: 0.1737662027279536, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 9340, Training Loss: 0.174202757016305, Validation Loss: 0.17348924676577251, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9341, Training Loss: 0.17370888302403112, Validation Loss: 0.17369431654612225, Validation Accuracy: 0.49375\n",
      "Epoch 9342, Training Loss: 0.1743182886031366, Validation Loss: 0.17328668236732483, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 9343, Training Loss: 0.1738115183768734, Validation Loss: 0.17333897054195405, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 9344, Training Loss: 0.17375991950112005, Validation Loss: 0.17454141676425933, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 9345, Training Loss: 0.17392702112274785, Validation Loss: 0.1733212113380432, Validation Accuracy: 0.5125\n",
      "Epoch 9346, Training Loss: 0.17419162921367154, Validation Loss: 0.17347495754559836, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 9347, Training Loss: 0.17378972614965132, Validation Loss: 0.17296362121899922, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 9348, Training Loss: 0.17384996673753184, Validation Loss: 0.17436327636241913, Validation Accuracy: 0.48125\n",
      "Epoch 9349, Training Loss: 0.1736828194510552, Validation Loss: 0.1736846387386322, Validation Accuracy: 0.50625\n",
      "Epoch 9350, Training Loss: 0.17451157973658654, Validation Loss: 0.17353830138842266, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 9351, Training Loss: 0.17371864040051738, Validation Loss: 0.17219939529895784, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 9352, Training Loss: 0.1742483930241677, Validation Loss: 0.17363909284273785, Validation Accuracy: 0.475\n",
      "Epoch 9353, Training Loss: 0.17368040930840276, Validation Loss: 0.17326091527938842, Validation Accuracy: 0.5125\n",
      "Epoch 9354, Training Loss: 0.174388290893647, Validation Loss: 0.1734752396742503, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 9355, Training Loss: 0.1736820205565422, Validation Loss: 0.1726591517527898, Validation Accuracy: 0.5375\n",
      "Epoch 9356, Training Loss: 0.17427550160115765, Validation Loss: 0.17347775995731354, Validation Accuracy: 0.4875\n",
      "Epoch 9357, Training Loss: 0.17367051157259172, Validation Loss: 0.1737152059872945, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 9358, Training Loss: 0.174401234234533, Validation Loss: 0.17340083718299865, Validation Accuracy: 0.475\n",
      "Epoch 9359, Training Loss: 0.17365288590231248, Validation Loss: 0.17210500439008078, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 9360, Training Loss: 0.17425728180716116, Validation Loss: 0.17351656357447307, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 9361, Training Loss: 0.17366813363567477, Validation Loss: 0.1737967014312744, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9362, Training Loss: 0.17439082168763684, Validation Loss: 0.17337754766146343, Validation Accuracy: 0.4875\n",
      "Epoch 9363, Training Loss: 0.17370609554552263, Validation Loss: 0.17272765735785167, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 9364, Training Loss: 0.17423995608283627, Validation Loss: 0.17334752082824706, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 9365, Training Loss: 0.17373996588491625, Validation Loss: 0.17383694152037302, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9366, Training Loss: 0.1743640976567422, Validation Loss: 0.17331518431504567, Validation Accuracy: 0.49375\n",
      "Epoch 9367, Training Loss: 0.17375573996574648, Validation Loss: 0.17357519368330637, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 9368, Training Loss: 0.17427287755473966, Validation Loss: 0.17325969735781352, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 9369, Training Loss: 0.17361943087270182, Validation Loss: 0.174452010790507, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 9370, Training Loss: 0.17443124949932098, Validation Loss: 0.1732292910416921, Validation Accuracy: 0.5125\n",
      "Epoch 9371, Training Loss: 0.1736679365558009, Validation Loss: 0.17480368812878927, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 9372, Training Loss: 0.17432930200330674, Validation Loss: 0.1730328063170115, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 9373, Training Loss: 0.17362681704182778, Validation Loss: 0.17508811950683595, Validation Accuracy: 0.48125\n",
      "Epoch 9374, Training Loss: 0.17434710120001146, Validation Loss: 0.17327728768189748, Validation Accuracy: 0.50625\n",
      "Epoch 9375, Training Loss: 0.17361690344349032, Validation Loss: 0.17553177376588186, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 9376, Training Loss: 0.1744695137585363, Validation Loss: 0.1728439062833786, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 9377, Training Loss: 0.17348366062487325, Validation Loss: 0.17530250151952106, Validation Accuracy: 0.475\n",
      "Epoch 9378, Training Loss: 0.17450997233390808, Validation Loss: 0.1732179860273997, Validation Accuracy: 0.5125\n",
      "Epoch 9379, Training Loss: 0.17346439246208437, Validation Loss: 0.1756239116191864, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 9380, Training Loss: 0.1745233997221916, Validation Loss: 0.17286307513713836, Validation Accuracy: 0.5375\n",
      "Epoch 9381, Training Loss: 0.17346090366763453, Validation Loss: 0.1749936819076538, Validation Accuracy: 0.4875\n",
      "Epoch 9382, Training Loss: 0.17458477183695761, Validation Loss: 0.17359077036380768, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 9383, Training Loss: 0.17357204710283586, Validation Loss: 0.17530590891838074, Validation Accuracy: 0.475\n",
      "Epoch 9384, Training Loss: 0.17439763536376338, Validation Loss: 0.1728778858979543, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 9385, Training Loss: 0.17357604542086202, Validation Loss: 0.17518201569716135, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 9386, Training Loss: 0.17443851886257047, Validation Loss: 0.17367680867513022, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9387, Training Loss: 0.17350266297017375, Validation Loss: 0.17496577401955923, Validation Accuracy: 0.4875\n",
      "Epoch 9388, Training Loss: 0.17439656632561837, Validation Loss: 0.17274072964986165, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 9389, Training Loss: 0.17355636290965543, Validation Loss: 0.17461799482504528, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 9390, Training Loss: 0.17437311189789925, Validation Loss: 0.17401937544345855, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9391, Training Loss: 0.1736075810847744, Validation Loss: 0.17472194135189056, Validation Accuracy: 0.49375\n",
      "Epoch 9392, Training Loss: 0.17444442452922945, Validation Loss: 0.17367711663246155, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 9393, Training Loss: 0.173536263646618, Validation Loss: 0.17400341629981994, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 9394, Training Loss: 0.1742821624202113, Validation Loss: 0.17457721034685772, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 9395, Training Loss: 0.17362302445596264, Validation Loss: 0.17374715705712637, Validation Accuracy: 0.5125\n",
      "Epoch 9396, Training Loss: 0.17435016747443907, Validation Loss: 0.17346703509489694, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 9397, Training Loss: 0.17355445940648356, Validation Loss: 0.17295375963052115, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 9398, Training Loss: 0.17434106142290176, Validation Loss: 0.17496968905131022, Validation Accuracy: 0.48125\n",
      "Epoch 9399, Training Loss: 0.1735691096513502, Validation Loss: 0.17386413514614105, Validation Accuracy: 0.50625\n",
      "Epoch 9400, Training Loss: 0.17439774015257437, Validation Loss: 0.17527646124362944, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 9401, Training Loss: 0.17381111604552116, Validation Loss: 0.17217417856057485, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 9402, Training Loss: 0.1742473162951008, Validation Loss: 0.17562843561172486, Validation Accuracy: 0.475\n",
      "Epoch 9403, Training Loss: 0.17376433745507272, Validation Loss: 0.1734236756960551, Validation Accuracy: 0.5125\n",
      "Epoch 9404, Training Loss: 0.1739664149861182, Validation Loss: 0.17535121142864227, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 9405, Training Loss: 0.17398866914933728, Validation Loss: 0.1726792405049006, Validation Accuracy: 0.5375\n",
      "Epoch 9406, Training Loss: 0.17387301162365945, Validation Loss: 0.17578217486540476, Validation Accuracy: 0.4875\n",
      "Epoch 9407, Training Loss: 0.17398608596094192, Validation Loss: 0.17421221733093262, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 9408, Training Loss: 0.1739737372244558, Validation Loss: 0.1757712115844091, Validation Accuracy: 0.475\n",
      "Epoch 9409, Training Loss: 0.17409210916488402, Validation Loss: 0.17203888595104216, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 9410, Training Loss: 0.17378081237116166, Validation Loss: 0.17667962114016214, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 9411, Training Loss: 0.17423587364535179, Validation Loss: 0.17396568059921264, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9412, Training Loss: 0.17373304069042206, Validation Loss: 0.1747406780719757, Validation Accuracy: 0.4875\n",
      "Epoch 9413, Training Loss: 0.1743465546638735, Validation Loss: 0.17273111045360565, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 9414, Training Loss: 0.1733760973138194, Validation Loss: 0.17550231417020162, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 9415, Training Loss: 0.17467429512931454, Validation Loss: 0.17374971210956575, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9416, Training Loss: 0.1736240074519188, Validation Loss: 0.17465144395828247, Validation Accuracy: 0.49375\n",
      "Epoch 9417, Training Loss: 0.17430365325943117, Validation Loss: 0.17361507217089336, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 9418, Training Loss: 0.1736431429463048, Validation Loss: 0.1745968669652939, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 9419, Training Loss: 0.1743949637297661, Validation Loss: 0.17391194701194762, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 9420, Training Loss: 0.17371774921494146, Validation Loss: 0.1742874244848887, Validation Accuracy: 0.5125\n",
      "Epoch 9421, Training Loss: 0.17430379313807334, Validation Loss: 0.17407476902008057, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 9422, Training Loss: 0.17359967866251547, Validation Loss: 0.17332164148489634, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 9423, Training Loss: 0.17434159257719595, Validation Loss: 0.1739510029554367, Validation Accuracy: 0.48125\n",
      "Epoch 9424, Training Loss: 0.17381177794548772, Validation Loss: 0.17367158035437266, Validation Accuracy: 0.50625\n",
      "Epoch 9425, Training Loss: 0.17414588553290214, Validation Loss: 0.17486797670523327, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 9426, Training Loss: 0.1736670107610764, Validation Loss: 0.17207627296447753, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 9427, Training Loss: 0.17435676580475223, Validation Loss: 0.1739837149779002, Validation Accuracy: 0.475\n",
      "Epoch 9428, Training Loss: 0.1738471249418874, Validation Loss: 0.1733778178691864, Validation Accuracy: 0.5125\n",
      "Epoch 9429, Training Loss: 0.17416411782464675, Validation Loss: 0.17459292113780975, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 9430, Training Loss: 0.17365006189192495, Validation Loss: 0.17276959717273713, Validation Accuracy: 0.5375\n",
      "Epoch 9431, Training Loss: 0.17420523253179365, Validation Loss: 0.17413809796174368, Validation Accuracy: 0.4875\n",
      "Epoch 9432, Training Loss: 0.17370341333650774, Validation Loss: 0.1752021759748459, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 9433, Training Loss: 0.1743784676636419, Validation Loss: 0.1737881600856781, Validation Accuracy: 0.475\n",
      "Epoch 9434, Training Loss: 0.17378364407247113, Validation Loss: 0.17213545739650726, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 9435, Training Loss: 0.17420857808282297, Validation Loss: 0.1740081826845805, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 9436, Training Loss: 0.17381461685703647, Validation Loss: 0.17388730744520822, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9437, Training Loss: 0.17410303556150006, Validation Loss: 0.174033655722936, Validation Accuracy: 0.4875\n",
      "Epoch 9438, Training Loss: 0.17387066589247796, Validation Loss: 0.17274081607659658, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 9439, Training Loss: 0.17421539800782357, Validation Loss: 0.1734193334976832, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 9440, Training Loss: 0.1739102477027524, Validation Loss: 0.17346404989560446, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9441, Training Loss: 0.1740704486446996, Validation Loss: 0.17367979685465496, Validation Accuracy: 0.49375\n",
      "Epoch 9442, Training Loss: 0.17385423904465092, Validation Loss: 0.17329728802045186, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 9443, Training Loss: 0.17419008478041617, Validation Loss: 0.17326682607332866, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 9444, Training Loss: 0.1739217004468364, Validation Loss: 0.17348570227622986, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 9445, Training Loss: 0.17405806001155608, Validation Loss: 0.17322210768858592, Validation Accuracy: 0.5125\n",
      "Epoch 9446, Training Loss: 0.17389917998544632, Validation Loss: 0.17351808647314707, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 9447, Training Loss: 0.17414708579740218, Validation Loss: 0.17305177549521128, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 9448, Training Loss: 0.1739484513959577, Validation Loss: 0.17351489166418713, Validation Accuracy: 0.48125\n",
      "Epoch 9449, Training Loss: 0.1741000610974527, Validation Loss: 0.17329197824001313, Validation Accuracy: 0.50625\n",
      "Epoch 9450, Training Loss: 0.17389091512849253, Validation Loss: 0.1735689600308736, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 9451, Training Loss: 0.17417099687360948, Validation Loss: 0.17284885744253795, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 9452, Training Loss: 0.17390960118462961, Validation Loss: 0.1735822727282842, Validation Accuracy: 0.475\n",
      "Epoch 9453, Training Loss: 0.17400952356476937, Validation Loss: 0.17322694559892018, Validation Accuracy: 0.5125\n",
      "Epoch 9454, Training Loss: 0.1738951446548585, Validation Loss: 0.17370552321275076, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 9455, Training Loss: 0.17415731808831614, Validation Loss: 0.17303702235221863, Validation Accuracy: 0.5375\n",
      "Epoch 9456, Training Loss: 0.1739190485208265, Validation Loss: 0.17355136076609293, Validation Accuracy: 0.4875\n",
      "Epoch 9457, Training Loss: 0.1741011570538244, Validation Loss: 0.17346473038196564, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 9458, Training Loss: 0.17380027136495035, Validation Loss: 0.17380279898643494, Validation Accuracy: 0.475\n",
      "Epoch 9459, Training Loss: 0.17417426166995878, Validation Loss: 0.17270829379558564, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 9460, Training Loss: 0.173886691370318, Validation Loss: 0.17393136024475098, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 9461, Training Loss: 0.17400335784881346, Validation Loss: 0.1735627661148707, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9462, Training Loss: 0.1738212074964277, Validation Loss: 0.1739241103331248, Validation Accuracy: 0.4875\n",
      "Epoch 9463, Training Loss: 0.1742399344521184, Validation Loss: 0.1730511059363683, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 9464, Training Loss: 0.1737890277178057, Validation Loss: 0.17369409004847208, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 9465, Training Loss: 0.17420250513861257, Validation Loss: 0.17349290649096172, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9466, Training Loss: 0.1737201790655813, Validation Loss: 0.17368203401565552, Validation Accuracy: 0.49375\n",
      "Epoch 9467, Training Loss: 0.17434095134658198, Validation Loss: 0.17328192392985026, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 9468, Training Loss: 0.17382008894797293, Validation Loss: 0.17334524989128114, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 9469, Training Loss: 0.17418547551478109, Validation Loss: 0.17346365948518117, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 9470, Training Loss: 0.17373763938103953, Validation Loss: 0.17326043744881947, Validation Accuracy: 0.5125\n",
      "Epoch 9471, Training Loss: 0.1742832468402001, Validation Loss: 0.17341754237810772, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 9472, Training Loss: 0.1738542789413083, Validation Loss: 0.1729105681180954, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 9473, Training Loss: 0.17415020975374407, Validation Loss: 0.17353771726290385, Validation Accuracy: 0.48125\n",
      "Epoch 9474, Training Loss: 0.17363715700564847, Validation Loss: 0.1734948992729187, Validation Accuracy: 0.50625\n",
      "Epoch 9475, Training Loss: 0.17440573053975258, Validation Loss: 0.17349437872568765, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 9476, Training Loss: 0.17368898805110686, Validation Loss: 0.17229648033777872, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 9477, Training Loss: 0.17433078154440848, Validation Loss: 0.1735196868578593, Validation Accuracy: 0.475\n",
      "Epoch 9478, Training Loss: 0.17366980929528514, Validation Loss: 0.1733075976371765, Validation Accuracy: 0.5125\n",
      "Epoch 9479, Training Loss: 0.1743478097261921, Validation Loss: 0.17344372868537902, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 9480, Training Loss: 0.17369341225393356, Validation Loss: 0.1726735572020213, Validation Accuracy: 0.5375\n",
      "Epoch 9481, Training Loss: 0.1743153521130162, Validation Loss: 0.1734169473250707, Validation Accuracy: 0.4875\n",
      "Epoch 9482, Training Loss: 0.17366720976368075, Validation Loss: 0.17372574905554453, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 9483, Training Loss: 0.1744006973120474, Validation Loss: 0.1733920474847158, Validation Accuracy: 0.475\n",
      "Epoch 9484, Training Loss: 0.17363435414529615, Validation Loss: 0.17230438987414043, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 9485, Training Loss: 0.1743597792040917, Validation Loss: 0.1734549323717753, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 9486, Training Loss: 0.17365876224733168, Validation Loss: 0.17379315793514252, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9487, Training Loss: 0.17439841262755856, Validation Loss: 0.17335256735483806, Validation Accuracy: 0.4875\n",
      "Epoch 9488, Training Loss: 0.17367301304494182, Validation Loss: 0.17278137107690175, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 9489, Training Loss: 0.1742754506488, Validation Loss: 0.17332898080348969, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 9490, Training Loss: 0.1736691584510188, Validation Loss: 0.17387849986553192, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9491, Training Loss: 0.17437518171725735, Validation Loss: 0.17331263522307078, Validation Accuracy: 0.49375\n",
      "Epoch 9492, Training Loss: 0.17380915918657858, Validation Loss: 0.17382298906644186, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 9493, Training Loss: 0.17423724311013375, Validation Loss: 0.173261026541392, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 9494, Training Loss: 0.17358765919362346, Validation Loss: 0.17429250876108807, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 9495, Training Loss: 0.17444431204949656, Validation Loss: 0.17322581609090168, Validation Accuracy: 0.5125\n",
      "Epoch 9496, Training Loss: 0.1736526854576603, Validation Loss: 0.17457574903964995, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 9497, Training Loss: 0.17385456638951455, Validation Loss: 0.17311578889687856, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 9498, Training Loss: 0.17380984175589778, Validation Loss: 0.17390118837356566, Validation Accuracy: 0.48125\n",
      "Epoch 9499, Training Loss: 0.17442326632238203, Validation Loss: 0.17327339748541515, Validation Accuracy: 0.50625\n",
      "Epoch 9500, Training Loss: 0.1735812516943101, Validation Loss: 0.1750609467426936, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 9501, Training Loss: 0.1740777454068584, Validation Loss: 0.1731408009926478, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 9502, Training Loss: 0.17362139398051846, Validation Loss: 0.17460626761118572, Validation Accuracy: 0.475\n",
      "Epoch 9503, Training Loss: 0.17459281750263705, Validation Loss: 0.17323090334733326, Validation Accuracy: 0.5125\n",
      "Epoch 9504, Training Loss: 0.17348027902264748, Validation Loss: 0.17570840418338776, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 9505, Training Loss: 0.1745055111185197, Validation Loss: 0.17281394402186076, Validation Accuracy: 0.5375\n",
      "Epoch 9506, Training Loss: 0.17348545164831222, Validation Loss: 0.17485431730747222, Validation Accuracy: 0.4875\n",
      "Epoch 9507, Training Loss: 0.17459191910682187, Validation Loss: 0.17361184159914653, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 9508, Training Loss: 0.17357657801720403, Validation Loss: 0.1754612296819687, Validation Accuracy: 0.475\n",
      "Epoch 9509, Training Loss: 0.1743890239346412, Validation Loss: 0.1726597934961319, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 9510, Training Loss: 0.17360765078375417, Validation Loss: 0.1752021650473277, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 9511, Training Loss: 0.1744042654191294, Validation Loss: 0.17348660230636598, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9512, Training Loss: 0.1735532485669659, Validation Loss: 0.17508675654729208, Validation Accuracy: 0.4875\n",
      "Epoch 9513, Training Loss: 0.174354943536943, Validation Loss: 0.17275118430455524, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 9514, Training Loss: 0.17355734638629422, Validation Loss: 0.17466973662376403, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 9515, Training Loss: 0.1744209946163239, Validation Loss: 0.17395716905593872, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9516, Training Loss: 0.1735722936930195, Validation Loss: 0.17479410568873088, Validation Accuracy: 0.49375\n",
      "Epoch 9517, Training Loss: 0.17439837561499688, Validation Loss: 0.1737218677997589, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 9518, Training Loss: 0.1735853442261296, Validation Loss: 0.17401506702105204, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 9519, Training Loss: 0.17419620194742758, Validation Loss: 0.1746318260828654, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 9520, Training Loss: 0.17369812438564916, Validation Loss: 0.17390571037928262, Validation Accuracy: 0.5125\n",
      "Epoch 9521, Training Loss: 0.1743367814248608, Validation Loss: 0.17483569880326588, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 9522, Training Loss: 0.17374690309647592, Validation Loss: 0.17300294935703278, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 9523, Training Loss: 0.1743438022751962, Validation Loss: 0.17485590974489848, Validation Accuracy: 0.48125\n",
      "Epoch 9524, Training Loss: 0.1735352494062916, Validation Loss: 0.17388198375701905, Validation Accuracy: 0.50625\n",
      "Epoch 9525, Training Loss: 0.1744714658106527, Validation Loss: 0.17536517182985942, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 9526, Training Loss: 0.17375797177514724, Validation Loss: 0.17220496932665508, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 9527, Training Loss: 0.17423106008960354, Validation Loss: 0.1756949841976166, Validation Accuracy: 0.475\n",
      "Epoch 9528, Training Loss: 0.17380529257559008, Validation Loss: 0.173516845703125, Validation Accuracy: 0.5125\n",
      "Epoch 9529, Training Loss: 0.17400480566486234, Validation Loss: 0.1760077933470408, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 9530, Training Loss: 0.17399441474868405, Validation Loss: 0.17265909314155578, Validation Accuracy: 0.5375\n",
      "Epoch 9531, Training Loss: 0.17387910908268345, Validation Loss: 0.17561804056167601, Validation Accuracy: 0.4875\n",
      "Epoch 9532, Training Loss: 0.17401024122391978, Validation Loss: 0.17419542570908864, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 9533, Training Loss: 0.17397641078118356, Validation Loss: 0.17550070583820343, Validation Accuracy: 0.475\n",
      "Epoch 9534, Training Loss: 0.17410241211614302, Validation Loss: 0.172047358751297, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 9535, Training Loss: 0.17380259931087494, Validation Loss: 0.1770076404015223, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 9536, Training Loss: 0.17420050501823425, Validation Loss: 0.17387530505657195, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9537, Training Loss: 0.17369369826009196, Validation Loss: 0.17550089557965595, Validation Accuracy: 0.4875\n",
      "Epoch 9538, Training Loss: 0.17440653712518753, Validation Loss: 0.17274593810240427, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 9539, Training Loss: 0.17331404503314726, Validation Loss: 0.1762579083442688, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 9540, Training Loss: 0.17474506603133294, Validation Loss: 0.1736431618531545, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9541, Training Loss: 0.17362856047768746, Validation Loss: 0.1752353399991989, Validation Accuracy: 0.49375\n",
      "Epoch 9542, Training Loss: 0.17434487708153262, Validation Loss: 0.17349993288517, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 9543, Training Loss: 0.1736491923370669, Validation Loss: 0.17476050158341724, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 9544, Training Loss: 0.17432062087520475, Validation Loss: 0.1739057828982671, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 9545, Training Loss: 0.1737810084896703, Validation Loss: 0.17397832373778024, Validation Accuracy: 0.5125\n",
      "Epoch 9546, Training Loss: 0.17423701286315918, Validation Loss: 0.17434049050013226, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 9547, Training Loss: 0.1736230787730986, Validation Loss: 0.17360683381557465, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 9548, Training Loss: 0.17436494846497813, Validation Loss: 0.17386272350947063, Validation Accuracy: 0.48125\n",
      "Epoch 9549, Training Loss: 0.1738178898249903, Validation Loss: 0.17360579073429108, Validation Accuracy: 0.50625\n",
      "Epoch 9550, Training Loss: 0.17411662013300003, Validation Loss: 0.17495011587937673, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 9551, Training Loss: 0.17367259725447623, Validation Loss: 0.17207484940687814, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 9552, Training Loss: 0.17435316981807833, Validation Loss: 0.17400285303592683, Validation Accuracy: 0.475\n",
      "Epoch 9553, Training Loss: 0.1738180628707332, Validation Loss: 0.17345567444960278, Validation Accuracy: 0.5125\n",
      "Epoch 9554, Training Loss: 0.17420788253507308, Validation Loss: 0.17444309095541635, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 9555, Training Loss: 0.1736392479750418, Validation Loss: 0.17271700203418733, Validation Accuracy: 0.5375\n",
      "Epoch 9556, Training Loss: 0.17439475703623988, Validation Loss: 0.17364784181118012, Validation Accuracy: 0.4875\n",
      "Epoch 9557, Training Loss: 0.17375035920450765, Validation Loss: 0.174440731604894, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 9558, Training Loss: 0.17429021145066909, Validation Loss: 0.1739781359831492, Validation Accuracy: 0.475\n",
      "Epoch 9559, Training Loss: 0.17368956583161507, Validation Loss: 0.17177704870700836, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 9560, Training Loss: 0.17433544320444908, Validation Loss: 0.17377887864907582, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 9561, Training Loss: 0.17383645378774212, Validation Loss: 0.17370515565077463, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9562, Training Loss: 0.17415304914597543, Validation Loss: 0.17375853061676025, Validation Accuracy: 0.4875\n",
      "Epoch 9563, Training Loss: 0.17382634743567435, Validation Loss: 0.17283565004666646, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 9564, Training Loss: 0.17420327951831202, Validation Loss: 0.1734965781370799, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 9565, Training Loss: 0.1739004542750697, Validation Loss: 0.1735059291124344, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9566, Training Loss: 0.1741412729024887, Validation Loss: 0.173568927248319, Validation Accuracy: 0.49375\n",
      "Epoch 9567, Training Loss: 0.1738237916461883, Validation Loss: 0.17331360777219137, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 9568, Training Loss: 0.17417165396674986, Validation Loss: 0.17326753040154774, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 9569, Training Loss: 0.1739627185367769, Validation Loss: 0.1734713037808736, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 9570, Training Loss: 0.17394043889737898, Validation Loss: 0.1732565293709437, Validation Accuracy: 0.5125\n",
      "Epoch 9571, Training Loss: 0.17397125401804525, Validation Loss: 0.17352534333864847, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 9572, Training Loss: 0.17413445682294906, Validation Loss: 0.17304407556851706, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 9573, Training Loss: 0.17398608980640287, Validation Loss: 0.17350292205810547, Validation Accuracy: 0.48125\n",
      "Epoch 9574, Training Loss: 0.17402943391953746, Validation Loss: 0.17331381738185883, Validation Accuracy: 0.50625\n",
      "Epoch 9575, Training Loss: 0.17390758135626394, Validation Loss: 0.17358084321022033, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 9576, Training Loss: 0.17416775178524754, Validation Loss: 0.1728416363398234, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 9577, Training Loss: 0.17389898530898557, Validation Loss: 0.17363352278868358, Validation Accuracy: 0.475\n",
      "Epoch 9578, Training Loss: 0.17411522471135663, Validation Loss: 0.17321885923544567, Validation Accuracy: 0.5125\n",
      "Epoch 9579, Training Loss: 0.17382948581249483, Validation Loss: 0.1736575017372767, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 9580, Training Loss: 0.17419763005548908, Validation Loss: 0.17301833033561706, Validation Accuracy: 0.5375\n",
      "Epoch 9581, Training Loss: 0.17387806648208248, Validation Loss: 0.17356918851534525, Validation Accuracy: 0.4875\n",
      "Epoch 9582, Training Loss: 0.17414363834165758, Validation Loss: 0.17344147662321727, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 9583, Training Loss: 0.17376926445191906, Validation Loss: 0.1738004942735036, Validation Accuracy: 0.475\n",
      "Epoch 9584, Training Loss: 0.17414944210360128, Validation Loss: 0.1726704200108846, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 9585, Training Loss: 0.1738977691819591, Validation Loss: 0.17409000595410665, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 9586, Training Loss: 0.17415305683689733, Validation Loss: 0.17341407934824626, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9587, Training Loss: 0.1737601968549913, Validation Loss: 0.17376425862312317, Validation Accuracy: 0.4875\n",
      "Epoch 9588, Training Loss: 0.17428042186844733, Validation Loss: 0.17307871878147124, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 9589, Training Loss: 0.17372230848958414, Validation Loss: 0.1736467222372691, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 9590, Training Loss: 0.17431344091892242, Validation Loss: 0.17338297565778096, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9591, Training Loss: 0.17368242721403798, Validation Loss: 0.17363458077112834, Validation Accuracy: 0.49375\n",
      "Epoch 9592, Training Loss: 0.1742701453547324, Validation Loss: 0.17329074343045553, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 9593, Training Loss: 0.17384360922921088, Validation Loss: 0.17330816288789114, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 9594, Training Loss: 0.17421498558213633, Validation Loss: 0.1734595239162445, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 9595, Training Loss: 0.1737487921791692, Validation Loss: 0.17324995199839274, Validation Accuracy: 0.5125\n",
      "Epoch 9596, Training Loss: 0.17428001328822104, Validation Loss: 0.17341290016969044, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 9597, Training Loss: 0.17381145540745027, Validation Loss: 0.172911869486173, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 9598, Training Loss: 0.17421308736647328, Validation Loss: 0.17345188756783803, Validation Accuracy: 0.48125\n",
      "Epoch 9599, Training Loss: 0.17364080298331477, Validation Loss: 0.17345533271630606, Validation Accuracy: 0.50625\n",
      "Epoch 9600, Training Loss: 0.17436032333681661, Validation Loss: 0.17348460455735523, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 9601, Training Loss: 0.1736951268488361, Validation Loss: 0.17231281101703644, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 9602, Training Loss: 0.17420831899489125, Validation Loss: 0.17361243863900502, Validation Accuracy: 0.475\n",
      "Epoch 9603, Training Loss: 0.17374800145626068, Validation Loss: 0.1732785741488139, Validation Accuracy: 0.5125\n",
      "Epoch 9604, Training Loss: 0.17431383027184394, Validation Loss: 0.17348494331041972, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 9605, Training Loss: 0.17373104345413945, Validation Loss: 0.17273178895314534, Validation Accuracy: 0.5375\n",
      "Epoch 9606, Training Loss: 0.1743251162190591, Validation Loss: 0.17338718771934508, Validation Accuracy: 0.4875\n",
      "Epoch 9607, Training Loss: 0.17361980484377953, Validation Loss: 0.17375565866629283, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 9608, Training Loss: 0.17444050936929642, Validation Loss: 0.17340677479902902, Validation Accuracy: 0.475\n",
      "Epoch 9609, Training Loss: 0.1736090745656721, Validation Loss: 0.17226994236310322, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 9610, Training Loss: 0.1744314759008346, Validation Loss: 0.17351695398489633, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 9611, Training Loss: 0.17364763252196774, Validation Loss: 0.17426960468292235, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9612, Training Loss: 0.17431568282265816, Validation Loss: 0.1734165757894516, Validation Accuracy: 0.4875\n",
      "Epoch 9613, Training Loss: 0.17374682138043065, Validation Loss: 0.17272949417432149, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 9614, Training Loss: 0.17426386139085215, Validation Loss: 0.17334775229295094, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 9615, Training Loss: 0.17364541561372818, Validation Loss: 0.1736533264319102, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9616, Training Loss: 0.17432750328894583, Validation Loss: 0.17331922054290771, Validation Accuracy: 0.49375\n",
      "Epoch 9617, Training Loss: 0.17381164527708484, Validation Loss: 0.17350458403428395, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 9618, Training Loss: 0.1742566910482222, Validation Loss: 0.17325633267561594, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 9619, Training Loss: 0.17359227711154568, Validation Loss: 0.17444032828013104, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 9620, Training Loss: 0.17445302970947757, Validation Loss: 0.17324173152446748, Validation Accuracy: 0.5125\n",
      "Epoch 9621, Training Loss: 0.17367535012383614, Validation Loss: 0.1748543083667755, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 9622, Training Loss: 0.17424265463506022, Validation Loss: 0.1732065310080846, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 9623, Training Loss: 0.1736689027278654, Validation Loss: 0.1744691660006841, Validation Accuracy: 0.48125\n",
      "Epoch 9624, Training Loss: 0.17442346147952542, Validation Loss: 0.17327255010604858, Validation Accuracy: 0.50625\n",
      "Epoch 9625, Training Loss: 0.17352045639868705, Validation Loss: 0.1758211225271225, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 9626, Training Loss: 0.17453582969404036, Validation Loss: 0.1726624717315038, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 9627, Training Loss: 0.17345854736143543, Validation Loss: 0.17532150745391845, Validation Accuracy: 0.475\n",
      "Epoch 9628, Training Loss: 0.17452060647549167, Validation Loss: 0.17322068214416503, Validation Accuracy: 0.5125\n",
      "Epoch 9629, Training Loss: 0.17345096267038776, Validation Loss: 0.1757262796163559, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 9630, Training Loss: 0.17446561974863853, Validation Loss: 0.1727778673171997, Validation Accuracy: 0.5375\n",
      "Epoch 9631, Training Loss: 0.17351263905725173, Validation Loss: 0.17484064300855, Validation Accuracy: 0.4875\n",
      "Epoch 9632, Training Loss: 0.1745408037977834, Validation Loss: 0.17354004482428234, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 9633, Training Loss: 0.17360073808700807, Validation Loss: 0.17540411154429117, Validation Accuracy: 0.475\n",
      "Epoch 9634, Training Loss: 0.17405511438846588, Validation Loss: 0.17314433455467224, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 9635, Training Loss: 0.17371611008721013, Validation Loss: 0.1743601163228353, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 9636, Training Loss: 0.17440714663074863, Validation Loss: 0.17358453671137491, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9637, Training Loss: 0.17358524232141434, Validation Loss: 0.1751544137795766, Validation Accuracy: 0.4875\n",
      "Epoch 9638, Training Loss: 0.17427132975670598, Validation Loss: 0.17274967630704244, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 9639, Training Loss: 0.17358115748051675, Validation Loss: 0.17462441722551983, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 9640, Training Loss: 0.17439549872952123, Validation Loss: 0.17400135099887848, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9641, Training Loss: 0.17358306146437122, Validation Loss: 0.17474708755811055, Validation Accuracy: 0.49375\n",
      "Epoch 9642, Training Loss: 0.17436918808567908, Validation Loss: 0.1737077832221985, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 9643, Training Loss: 0.17360758781433105, Validation Loss: 0.17401834925015766, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 9644, Training Loss: 0.1743053356485982, Validation Loss: 0.174510324994723, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 9645, Training Loss: 0.17359781121054002, Validation Loss: 0.1737902581691742, Validation Accuracy: 0.5125\n",
      "Epoch 9646, Training Loss: 0.17435895291066938, Validation Loss: 0.17476836840311685, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 9647, Training Loss: 0.1737516354168615, Validation Loss: 0.17303496996561687, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 9648, Training Loss: 0.17430364797192235, Validation Loss: 0.17495455841223398, Validation Accuracy: 0.48125\n",
      "Epoch 9649, Training Loss: 0.17358907095847592, Validation Loss: 0.17389114101727804, Validation Accuracy: 0.50625\n",
      "Epoch 9650, Training Loss: 0.17446084512818244, Validation Loss: 0.1755842496951421, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 9651, Training Loss: 0.1737657823870259, Validation Loss: 0.172159676750501, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 9652, Training Loss: 0.17425682083252939, Validation Loss: 0.17570875783761342, Validation Accuracy: 0.475\n",
      "Epoch 9653, Training Loss: 0.17379502855962323, Validation Loss: 0.17348963618278504, Validation Accuracy: 0.5125\n",
      "Epoch 9654, Training Loss: 0.1739990182461277, Validation Loss: 0.17596415082613628, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 9655, Training Loss: 0.17395986520474957, Validation Loss: 0.17267063061396282, Validation Accuracy: 0.5375\n",
      "Epoch 9656, Training Loss: 0.17390905368712642, Validation Loss: 0.175791131456693, Validation Accuracy: 0.4875\n",
      "Epoch 9657, Training Loss: 0.17395411047243303, Validation Loss: 0.17412635087966918, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 9658, Training Loss: 0.17398475543145211, Validation Loss: 0.17573561370372773, Validation Accuracy: 0.475\n",
      "Epoch 9659, Training Loss: 0.17410816348368122, Validation Loss: 0.17196464240550996, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 9660, Training Loss: 0.17380830020673813, Validation Loss: 0.17711127797762552, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 9661, Training Loss: 0.1742219155834567, Validation Loss: 0.17388768196105958, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9662, Training Loss: 0.1737679252701421, Validation Loss: 0.17456754247347514, Validation Accuracy: 0.4875\n",
      "Epoch 9663, Training Loss: 0.17431525501512712, Validation Loss: 0.17272728184858957, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 9664, Training Loss: 0.17335986081630952, Validation Loss: 0.17549157043298086, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 9665, Training Loss: 0.17466667919389664, Validation Loss: 0.17382263044516247, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9666, Training Loss: 0.17362390314379045, Validation Loss: 0.17488015393416087, Validation Accuracy: 0.49375\n",
      "Epoch 9667, Training Loss: 0.17426711465081862, Validation Loss: 0.17388198177019756, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 9668, Training Loss: 0.17362252743013443, Validation Loss: 0.17459670205911001, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 9669, Training Loss: 0.1743302725015148, Validation Loss: 0.17395898699760437, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 9670, Training Loss: 0.1738197087280212, Validation Loss: 0.17365766068299612, Validation Accuracy: 0.5125\n",
      "Epoch 9671, Training Loss: 0.1741450765440541, Validation Loss: 0.17499305804570517, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 9672, Training Loss: 0.17358888349225443, Validation Loss: 0.17318174342314402, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 9673, Training Loss: 0.1742610566077694, Validation Loss: 0.17413786351680755, Validation Accuracy: 0.48125\n",
      "Epoch 9674, Training Loss: 0.1737797889978655, Validation Loss: 0.1738706996043523, Validation Accuracy: 0.50625\n",
      "Epoch 9675, Training Loss: 0.17414039613739138, Validation Loss: 0.17494911054770151, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 9676, Training Loss: 0.17369035270906263, Validation Loss: 0.17207984924316405, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 9677, Training Loss: 0.1743803471326828, Validation Loss: 0.17399719953536988, Validation Accuracy: 0.475\n",
      "Epoch 9678, Training Loss: 0.17377693470447295, Validation Loss: 0.1736302117506663, Validation Accuracy: 0.5125\n",
      "Epoch 9679, Training Loss: 0.17430612925560243, Validation Loss: 0.1742664873600006, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 9680, Training Loss: 0.17361060650117935, Validation Loss: 0.1727590501308441, Validation Accuracy: 0.5375\n",
      "Epoch 9681, Training Loss: 0.174368919384095, Validation Loss: 0.17372143665949505, Validation Accuracy: 0.4875\n",
      "Epoch 9682, Training Loss: 0.17378764863937132, Validation Loss: 0.17444397509098053, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 9683, Training Loss: 0.17428486914403976, Validation Loss: 0.17398292422294617, Validation Accuracy: 0.475\n",
      "Epoch 9684, Training Loss: 0.17368766377049108, Validation Loss: 0.17179469267527261, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 9685, Training Loss: 0.174338061001993, Validation Loss: 0.17378458480040232, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 9686, Training Loss: 0.17380219265337912, Validation Loss: 0.17387723326683044, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9687, Training Loss: 0.17408523732616055, Validation Loss: 0.17407242059707642, Validation Accuracy: 0.4875\n",
      "Epoch 9688, Training Loss: 0.17387553136194905, Validation Loss: 0.17276179095109304, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 9689, Training Loss: 0.17421612191584804, Validation Loss: 0.17342515985171, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 9690, Training Loss: 0.17394833026393766, Validation Loss: 0.1735019048055013, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9691, Training Loss: 0.1740004026120709, Validation Loss: 0.17379537026087444, Validation Accuracy: 0.49375\n",
      "Epoch 9692, Training Loss: 0.17386580715256353, Validation Loss: 0.17332645654678344, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 9693, Training Loss: 0.17418436706066132, Validation Loss: 0.17326597174008687, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 9694, Training Loss: 0.17393972748710262, Validation Loss: 0.17349877655506135, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 9695, Training Loss: 0.1740399411609096, Validation Loss: 0.17322172025839488, Validation Accuracy: 0.5125\n",
      "Epoch 9696, Training Loss: 0.17393882476514386, Validation Loss: 0.17345891892910004, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 9697, Training Loss: 0.17406244335636015, Validation Loss: 0.17299875418345134, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 9698, Training Loss: 0.174059031951812, Validation Loss: 0.17354849576950074, Validation Accuracy: 0.48125\n",
      "Epoch 9699, Training Loss: 0.1738284311948284, Validation Loss: 0.17353534698486328, Validation Accuracy: 0.50625\n",
      "Epoch 9700, Training Loss: 0.17403249538713886, Validation Loss: 0.17365620930989584, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 9701, Training Loss: 0.17409609402379683, Validation Loss: 0.17279817660649618, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 9702, Training Loss: 0.1739757142720684, Validation Loss: 0.1736175219217936, Validation Accuracy: 0.475\n",
      "Epoch 9703, Training Loss: 0.17391118070771616, Validation Loss: 0.1732759565114975, Validation Accuracy: 0.5125\n",
      "Epoch 9704, Training Loss: 0.17393026861452288, Validation Loss: 0.1737696756919225, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 9705, Training Loss: 0.1741567571316996, Validation Loss: 0.17303219834963482, Validation Accuracy: 0.5375\n",
      "Epoch 9706, Training Loss: 0.1739210048990865, Validation Loss: 0.17355955342451732, Validation Accuracy: 0.4875\n",
      "Epoch 9707, Training Loss: 0.17411635527687688, Validation Loss: 0.17344783941904704, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 9708, Training Loss: 0.17380028145928536, Validation Loss: 0.1738742450873057, Validation Accuracy: 0.475\n",
      "Epoch 9709, Training Loss: 0.17398254044594302, Validation Loss: 0.1721676230430603, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 9710, Training Loss: 0.17390755155394155, Validation Loss: 0.1742337723573049, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 9711, Training Loss: 0.17413508795922802, Validation Loss: 0.17343457738558452, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9712, Training Loss: 0.17376637891415628, Validation Loss: 0.17378006478150684, Validation Accuracy: 0.4875\n",
      "Epoch 9713, Training Loss: 0.17428296227608958, Validation Loss: 0.1730828215678533, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 9714, Training Loss: 0.17371007079078304, Validation Loss: 0.17367529571056367, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 9715, Training Loss: 0.17401460870619742, Validation Loss: 0.1738420436779658, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9716, Training Loss: 0.1737239509820938, Validation Loss: 0.17391284306844076, Validation Accuracy: 0.49375\n",
      "Epoch 9717, Training Loss: 0.17437941701181472, Validation Loss: 0.17328758736451466, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 9718, Training Loss: 0.17384117745584057, Validation Loss: 0.1733560472726822, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 9719, Training Loss: 0.17411674174570269, Validation Loss: 0.17356161574522655, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 9720, Training Loss: 0.1737931986008921, Validation Loss: 0.17326313157876333, Validation Accuracy: 0.5125\n",
      "Epoch 9721, Training Loss: 0.174258794034681, Validation Loss: 0.17343901097774506, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 9722, Training Loss: 0.17383384704589844, Validation Loss: 0.17291186849276224, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 9723, Training Loss: 0.17405698760863272, Validation Loss: 0.17362420161565145, Validation Accuracy: 0.48125\n",
      "Epoch 9724, Training Loss: 0.17365672799848741, Validation Loss: 0.17361170053482056, Validation Accuracy: 0.50625\n",
      "Epoch 9725, Training Loss: 0.1744727453877849, Validation Loss: 0.173455548286438, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 9726, Training Loss: 0.1736831227617879, Validation Loss: 0.17220844328403473, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 9727, Training Loss: 0.17430922533235244, Validation Loss: 0.17354018092155457, Validation Accuracy: 0.475\n",
      "Epoch 9728, Training Loss: 0.17367165896200365, Validation Loss: 0.17328025102615358, Validation Accuracy: 0.5125\n",
      "Epoch 9729, Training Loss: 0.17436753021132562, Validation Loss: 0.17343762417634329, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 9730, Training Loss: 0.17368381061861593, Validation Loss: 0.17268275221188864, Validation Accuracy: 0.5375\n",
      "Epoch 9731, Training Loss: 0.17436080738421408, Validation Loss: 0.17339377403259276, Validation Accuracy: 0.4875\n",
      "Epoch 9732, Training Loss: 0.17362761209087987, Validation Loss: 0.1737522085507711, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 9733, Training Loss: 0.17440856464447513, Validation Loss: 0.1733986794948578, Validation Accuracy: 0.475\n",
      "Epoch 9734, Training Loss: 0.1736416446585809, Validation Loss: 0.172218257188797, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 9735, Training Loss: 0.17410927241848362, Validation Loss: 0.17374468545118968, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 9736, Training Loss: 0.17370847540517007, Validation Loss: 0.17393995722134908, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9737, Training Loss: 0.17440710433067813, Validation Loss: 0.17335768938064575, Validation Accuracy: 0.4875\n",
      "Epoch 9738, Training Loss: 0.1737771471661906, Validation Loss: 0.17273056805133818, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 9739, Training Loss: 0.17422485543835547, Validation Loss: 0.17336884240309397, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 9740, Training Loss: 0.1736893581767236, Validation Loss: 0.17369155089060465, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9741, Training Loss: 0.1743931794358838, Validation Loss: 0.17332378029823303, Validation Accuracy: 0.49375\n",
      "Epoch 9742, Training Loss: 0.173719338832363, Validation Loss: 0.17342531085014343, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 9743, Training Loss: 0.1743087047530759, Validation Loss: 0.17325871288776398, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 9744, Training Loss: 0.17359704596381034, Validation Loss: 0.17451550563176474, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 9745, Training Loss: 0.17446193050953648, Validation Loss: 0.1732411434253057, Validation Accuracy: 0.5125\n",
      "Epoch 9746, Training Loss: 0.17366987178402563, Validation Loss: 0.17456316550572712, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 9747, Training Loss: 0.17437262208231033, Validation Loss: 0.17306722501913707, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 9748, Training Loss: 0.17360013723373413, Validation Loss: 0.1749698281288147, Validation Accuracy: 0.48125\n",
      "Epoch 9749, Training Loss: 0.1744098735432471, Validation Loss: 0.17327500879764557, Validation Accuracy: 0.50625\n",
      "Epoch 9750, Training Loss: 0.17354913873057212, Validation Loss: 0.17584406932195026, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 9751, Training Loss: 0.1743315996662263, Validation Loss: 0.1731305629014969, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 9752, Training Loss: 0.1735753854436259, Validation Loss: 0.17516736388206483, Validation Accuracy: 0.475\n",
      "Epoch 9753, Training Loss: 0.1745016344131962, Validation Loss: 0.17321709791819254, Validation Accuracy: 0.5125\n",
      "Epoch 9754, Training Loss: 0.17346338639336248, Validation Loss: 0.17570808827877044, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 9755, Training Loss: 0.17450990311561093, Validation Loss: 0.17284264862537385, Validation Accuracy: 0.5375\n",
      "Epoch 9756, Training Loss: 0.1734849839441238, Validation Loss: 0.17484071453412373, Validation Accuracy: 0.4875\n",
      "Epoch 9757, Training Loss: 0.17458004480408085, Validation Loss: 0.1735969771941503, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 9758, Training Loss: 0.17357074974044676, Validation Loss: 0.17536763449509937, Validation Accuracy: 0.475\n",
      "Epoch 9759, Training Loss: 0.173994017224158, Validation Loss: 0.17314562400182087, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 9760, Training Loss: 0.1737446241801785, Validation Loss: 0.17376738289992014, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 9761, Training Loss: 0.1741085292831544, Validation Loss: 0.1732895811398824, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9762, Training Loss: 0.17376854679276865, Validation Loss: 0.17429392635822297, Validation Accuracy: 0.4875\n",
      "Epoch 9763, Training Loss: 0.17436001954540128, Validation Loss: 0.1727894345919291, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 9764, Training Loss: 0.17348724411379907, Validation Loss: 0.17452120582262676, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 9765, Training Loss: 0.1744622890987704, Validation Loss: 0.17384633123874665, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9766, Training Loss: 0.1735483201280717, Validation Loss: 0.17476491630077362, Validation Accuracy: 0.49375\n",
      "Epoch 9767, Training Loss: 0.17437910072265134, Validation Loss: 0.17353431383768717, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 9768, Training Loss: 0.17359159358086124, Validation Loss: 0.17373869816462198, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 9769, Training Loss: 0.1742280856255562, Validation Loss: 0.17450391252835593, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 9770, Training Loss: 0.17361811476369057, Validation Loss: 0.17384809652964275, Validation Accuracy: 0.5125\n",
      "Epoch 9771, Training Loss: 0.17442098019584532, Validation Loss: 0.1748417615890503, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 9772, Training Loss: 0.17370742078750365, Validation Loss: 0.1730264186859131, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 9773, Training Loss: 0.17432041225894804, Validation Loss: 0.1749800165494283, Validation Accuracy: 0.48125\n",
      "Epoch 9774, Training Loss: 0.17358332776254223, Validation Loss: 0.17386611700057983, Validation Accuracy: 0.50625\n",
      "Epoch 9775, Training Loss: 0.17452903428385336, Validation Loss: 0.17570996880531312, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 9776, Training Loss: 0.17371061780760366, Validation Loss: 0.17214281062285106, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 9777, Training Loss: 0.17424390585191787, Validation Loss: 0.17575931350390117, Validation Accuracy: 0.475\n",
      "Epoch 9778, Training Loss: 0.1738283278480653, Validation Loss: 0.1734746237595876, Validation Accuracy: 0.5125\n",
      "Epoch 9779, Training Loss: 0.1740328804139168, Validation Loss: 0.17615210314591725, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 9780, Training Loss: 0.1739769640468782, Validation Loss: 0.172659170627594, Validation Accuracy: 0.5375\n",
      "Epoch 9781, Training Loss: 0.17387755119031476, Validation Loss: 0.17542886634667715, Validation Accuracy: 0.4875\n",
      "Epoch 9782, Training Loss: 0.1740100989418645, Validation Loss: 0.17422581613063812, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 9783, Training Loss: 0.17397009797634616, Validation Loss: 0.1760042428970337, Validation Accuracy: 0.475\n",
      "Epoch 9784, Training Loss: 0.17411824435957016, Validation Loss: 0.1718879650036494, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 9785, Training Loss: 0.1737878163976054, Validation Loss: 0.17706103920936583, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 9786, Training Loss: 0.17423571646213531, Validation Loss: 0.17391715049743653, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9787, Training Loss: 0.17369535180830187, Validation Loss: 0.17549905478954314, Validation Accuracy: 0.4875\n",
      "Epoch 9788, Training Loss: 0.17441161601774155, Validation Loss: 0.17274515827496847, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 9789, Training Loss: 0.1733927938245958, Validation Loss: 0.17545845111211142, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 9790, Training Loss: 0.17469415837718594, Validation Loss: 0.17382722596327463, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9791, Training Loss: 0.1736293338960217, Validation Loss: 0.17476815581321717, Validation Accuracy: 0.49375\n",
      "Epoch 9792, Training Loss: 0.17431010882700643, Validation Loss: 0.17365587254365286, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 9793, Training Loss: 0.17363567602249882, Validation Loss: 0.17456547021865845, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 9794, Training Loss: 0.17438716801904863, Validation Loss: 0.1739715059598287, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 9795, Training Loss: 0.17379124318399736, Validation Loss: 0.17361453374226887, Validation Accuracy: 0.5125\n",
      "Epoch 9796, Training Loss: 0.17419696959757036, Validation Loss: 0.17446961204210917, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 9797, Training Loss: 0.17363963396318496, Validation Loss: 0.1730646292368571, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 9798, Training Loss: 0.17426178868739836, Validation Loss: 0.17411410907904307, Validation Accuracy: 0.48125\n",
      "Epoch 9799, Training Loss: 0.17377086848981918, Validation Loss: 0.17397364576657612, Validation Accuracy: 0.50625\n",
      "Epoch 9800, Training Loss: 0.1742699545237326, Validation Loss: 0.17455724875132242, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 9801, Training Loss: 0.17360530985939887, Validation Loss: 0.1721593677997589, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 9802, Training Loss: 0.17440135632791826, Validation Loss: 0.17392718891302744, Validation Accuracy: 0.475\n",
      "Epoch 9803, Training Loss: 0.17371671863140598, Validation Loss: 0.17384529809157054, Validation Accuracy: 0.5125\n",
      "Epoch 9804, Training Loss: 0.17435356253577816, Validation Loss: 0.17412614425023396, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 9805, Training Loss: 0.17366842541002458, Validation Loss: 0.17267606457074483, Validation Accuracy: 0.5375\n",
      "Epoch 9806, Training Loss: 0.17422949114153463, Validation Loss: 0.17400423288345337, Validation Accuracy: 0.4875\n",
      "Epoch 9807, Training Loss: 0.17380182589254073, Validation Loss: 0.17439673840999603, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 9808, Training Loss: 0.1742675208276318, Validation Loss: 0.17401733597119648, Validation Accuracy: 0.475\n",
      "Epoch 9809, Training Loss: 0.17371000061112066, Validation Loss: 0.17196670770645142, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 9810, Training Loss: 0.17428345497577422, Validation Loss: 0.17387796739737194, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 9811, Training Loss: 0.17387494877461465, Validation Loss: 0.17370874385039012, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9812, Training Loss: 0.17404648757749988, Validation Loss: 0.17416722774505616, Validation Accuracy: 0.4875\n",
      "Epoch 9813, Training Loss: 0.17386973529092728, Validation Loss: 0.1727456013361613, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 9814, Training Loss: 0.1742054997913299, Validation Loss: 0.17342172861099242, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 9815, Training Loss: 0.17389893003048434, Validation Loss: 0.1734942485888799, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9816, Training Loss: 0.1741115325881589, Validation Loss: 0.17360971570014955, Validation Accuracy: 0.49375\n",
      "Epoch 9817, Training Loss: 0.17383218148062307, Validation Loss: 0.17331944207350414, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 9818, Training Loss: 0.17417224520637142, Validation Loss: 0.17327088018258413, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 9819, Training Loss: 0.1739729166992249, Validation Loss: 0.17351025938987732, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 9820, Training Loss: 0.17396949568102438, Validation Loss: 0.17323432366053262, Validation Accuracy: 0.5125\n",
      "Epoch 9821, Training Loss: 0.17393260184795625, Validation Loss: 0.17350614070892334, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 9822, Training Loss: 0.17412741193848272, Validation Loss: 0.17303570707639057, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 9823, Training Loss: 0.17396357270979113, Validation Loss: 0.17352381547292073, Validation Accuracy: 0.48125\n",
      "Epoch 9824, Training Loss: 0.17391722240755636, Validation Loss: 0.17341811855634054, Validation Accuracy: 0.50625\n",
      "Epoch 9825, Training Loss: 0.17399229109287262, Validation Loss: 0.17361738085746764, Validation Accuracy: 0.4666666666666667\n",
      "Epoch 9826, Training Loss: 0.17416483932925808, Validation Loss: 0.1729069322347641, Validation Accuracy: 0.5520833333333334\n",
      "Epoch 9827, Training Loss: 0.17395321448003093, Validation Loss: 0.17358842889467876, Validation Accuracy: 0.475\n",
      "Epoch 9828, Training Loss: 0.17401392133005203, Validation Loss: 0.17322386006514232, Validation Accuracy: 0.5125\n",
      "Epoch 9829, Training Loss: 0.17386578744457615, Validation Loss: 0.17377393941084543, Validation Accuracy: 0.4708333333333333\n",
      "Epoch 9830, Training Loss: 0.17415689460692868, Validation Loss: 0.17299013038476307, Validation Accuracy: 0.5375\n",
      "Epoch 9831, Training Loss: 0.17393498843716038, Validation Loss: 0.17357712388038635, Validation Accuracy: 0.4875\n",
      "Epoch 9832, Training Loss: 0.17406113109280985, Validation Loss: 0.17349450290203094, Validation Accuracy: 0.4895833333333333\n",
      "Epoch 9833, Training Loss: 0.17382005433882436, Validation Loss: 0.17383070687452953, Validation Accuracy: 0.475\n",
      "Epoch 9834, Training Loss: 0.1742003305304435, Validation Loss: 0.172831325729688, Validation Accuracy: 0.5604166666666667\n",
      "Epoch 9835, Training Loss: 0.17390980499406014, Validation Loss: 0.17402058243751525, Validation Accuracy: 0.47291666666666665\n",
      "Epoch 9836, Training Loss: 0.1740743859160331, Validation Loss: 0.1734721561272939, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9837, Training Loss: 0.17378873594345584, Validation Loss: 0.17373491923014323, Validation Accuracy: 0.4875\n",
      "Epoch 9838, Training Loss: 0.17426268179570475, Validation Loss: 0.17308167616526285, Validation Accuracy: 0.5354166666666667\n",
      "Epoch 9839, Training Loss: 0.17374069892591046, Validation Loss: 0.17364198863506317, Validation Accuracy: 0.49583333333333335\n",
      "Epoch 9840, Training Loss: 0.17430488909444503, Validation Loss: 0.17339080969492596, Validation Accuracy: 0.49166666666666664\n",
      "Epoch 9841, Training Loss: 0.17364817473196215, Validation Loss: 0.17371499439080557, Validation Accuracy: 0.49375\n",
      "Epoch 9842, Training Loss: 0.17431778580911697, Validation Loss: 0.17328397234280904, Validation Accuracy: 0.5041666666666667\n",
      "Epoch 9843, Training Loss: 0.17385010709685664, Validation Loss: 0.1733272612094879, Validation Accuracy: 0.5083333333333333\n",
      "Epoch 9844, Training Loss: 0.17418668154747255, Validation Loss: 0.17346887290477753, Validation Accuracy: 0.48333333333333334\n",
      "Epoch 9845, Training Loss: 0.17376186434299715, Validation Loss: 0.17325140635172526, Validation Accuracy: 0.5125\n",
      "Epoch 9846, Training Loss: 0.1739857864956702, Validation Loss: 0.17379711071650186, Validation Accuracy: 0.4791666666666667\n",
      "Epoch 9847, Training Loss: 0.1739147992864732, Validation Loss: 0.17290982007980346, Validation Accuracy: 0.5291666666666667\n",
      "Epoch 9848, Training Loss: 0.1741458470782926, Validation Loss: 0.17356797258059184, Validation Accuracy: 0.48125\n",
      "Epoch 9849, Training Loss: 0.17362234284800868, Validation Loss: 0.17345882852872213, Validation Accuracy: 0.50625\n",
      "Epoch 9850, Training Loss: 0.1744378165852639, Validation Loss: 0.1734963595867157, Validation Accuracy: 0.4666666666666667\n"
     ]
    }
   ],
   "source": [
    "def main(do_train = True):\n",
    "    # Initiate the two SGN models\n",
    "    num_classes = 1 # Is the same or not the same\n",
    "    SGN_Encoder1 = SGN(num_classes, dataset, seg, batch_size, do_train).cuda()\n",
    "    # SGN_Encoder2 = SGN(num_classes, dataset, seg, batch_size, do_train).cuda()\n",
    "\n",
    "    pretrained = torch.load('C:\\\\Users\\\\Carrt\\\\OneDrive\\\\Code\\\\Motion Privacy\\\\Attacking Models\\\\SGN Attack Model\\\\results\\\\NTU\\\\SGN\\\\0_best.pth')['state_dict']\n",
    "    del pretrained['fc.weight']\n",
    "    del pretrained['fc.bias']\n",
    "    SGN_Encoder1.load_state_dict(pretrained)\n",
    "    \n",
    "    # Combine the two SGN Models\n",
    "    # model = SGN_Linkage_Attack(SGN_Encoder1, SGN_Encoder2, num_classes).cuda()\n",
    "    model = SGN_Embedding_Model().cuda()\n",
    "\n",
    "    # Load the data and create dataloaders\n",
    "    num_actors = len(set(int(file[9:12]) for file in X))\n",
    "    samples_per_actor = same_samples_per_actor + diff_samples_per_actor\n",
    "    if per_actor:\n",
    "        train_len = int(samples_per_actor * num_actors * 0.5)\n",
    "        val_len = int(samples_per_actor * num_actors * 0.25)\n",
    "        test_len = int(samples_per_actor * num_actors * 0.25)\n",
    "    else:\n",
    "        train_len = int(samples_per_actor * 0.5)\n",
    "        val_len = int(samples_per_actor * 0.25)\n",
    "        test_len = int(samples_per_actor * 0.25)\n",
    "\n",
    "    train_dataset = SGN_Linkage_Dataset(train_gen, train_len)\n",
    "    val_dataset = SGN_Linkage_Dataset(val_gen, val_len)\n",
    "    test_dataset = SGN_Linkage_Dataset(test_gen, test_len)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "    validation_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "    # Set up checkpoint director\n",
    "    checkpoint_dir = 'models'\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "    # Load the model if specified\n",
    "    if load_model:\n",
    "        # Load the model\n",
    "        model.load_state_dict(torch.load(f'{checkpoint_dir}/{load_model}.pt'))\n",
    "        print('Model loaded')\n",
    "\n",
    "    # Initialize variables for tracking loss\n",
    "    best_loss = float('inf')\n",
    "    best_epoch = 0\n",
    "\n",
    "    # Train the model\n",
    "    # criterion = LabelSmoothingLoss(num_classes, smoothing=0.1).cuda()\n",
    "    # criterion = nn.BCELoss().cuda()\n",
    "    criterion = FocalLoss().cuda()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    # optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
    "\n",
    "    if do_train:\n",
    "        for epoch in tqdm(range(max_epochs), desc='Epochs'):\n",
    "            # Train\n",
    "            model.train(True)\n",
    "            total_train_loss = 0  # Add this line to store total training loss\n",
    "\n",
    "            # for i, (x_a, x_b, y) in enumerate(tqdm(train_loader, leave=True, desc='Training Batch', position=1)):\n",
    "            for i, (x_a, x_b, y) in enumerate(train_loader):\n",
    "                x_a = x_a.squeeze(1).cuda()\n",
    "                x_b = x_b.squeeze(1).cuda()\n",
    "                y = y.float().cuda()\n",
    "\n",
    "                x_a = x_a.reshape(x_a.shape[0], -1)\n",
    "                x_b = x_b.reshape(x_b.shape[0], -1)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # x_a = SGN_Encoder1(x_a)\n",
    "                # x_b = SGN_Encoder1(x_b)\n",
    "\n",
    "                x = torch.cat((x_a, x_b), dim=1)\n",
    "\n",
    "                # output = model(x_a, x_b)\n",
    "                output = model(x)\n",
    "                loss = criterion(output.squeeze(), y)\n",
    "\n",
    "                total_train_loss += loss.item()  # Update total training loss\n",
    "                loss.backward()\n",
    "\n",
    "                # torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "\n",
    "                optimizer.step()\n",
    "\n",
    "            avg_train_loss = total_train_loss / len(train_loader)  # Calculate average training loss\n",
    "\n",
    "            # Evaluate\n",
    "            val_loss, val_acc = evaluate(model, criterion, validation_loader, encoder=SGN_Encoder1)\n",
    "            print(f'Epoch {epoch+1}, Training Loss: {avg_train_loss}, Validation Loss: {val_loss}, Validation Accuracy: {val_acc}')\n",
    "\n",
    "            # Save the best model\n",
    "            if val_loss < best_loss:\n",
    "                best_loss = val_loss\n",
    "                best_epoch = epoch\n",
    "                torch.save(model.state_dict(), os.path.join(checkpoint_dir, 'best_model.pt'))\n",
    "                print(f'New best validation loss, checkpoint saved')\n",
    "\n",
    "    # Load the best model\n",
    "    model.load_state_dict(torch.load(os.path.join(checkpoint_dir, 'best_model.pt')))\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy, loss, cm, precision, recall, f1 = evaluate_metrics(model, criterion, test_loader, encoder=SGN_Encoder1)\n",
    "    print(f'Accuracy: {accuracy}')\n",
    "    print(f'Loss: {loss}')\n",
    "    print(f'Confusion Matrix: {cm}')\n",
    "    print(f'Precision: {precision}')\n",
    "    print(f'Recall: {recall}')\n",
    "    print(f'F1: {f1}')\n",
    "\n",
    "main(do_train=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "063dd9079dbbbc7ce9a24508feb60cfa7f5aa9bc9e0c912b3996301118c4566f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
