{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "import shutil\n",
    "import os\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = '1'\n",
    "import os.path as osp\n",
    "import csv\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, MultiStepLR\n",
    "from model import SGN\n",
    "from data import NTUDataLoaders, AverageMeter\n",
    "from util import make_dir, get_num_classes\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
    "import random\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pickle.load(open('data/X.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = 5000\n",
    "train_videos = {}\n",
    "test_videos = {}\n",
    "\n",
    "for video in X.keys():\n",
    "    actor = int(video[9:12])\n",
    "    action = int(video[17:20])\n",
    "    \n",
    "    if len(X[video]) == 0: continue\n",
    "    if action > 60:\n",
    "        if actor not in test_videos:\n",
    "            test_videos[actor] = []\n",
    "        test_videos[actor].append(X[video])    \n",
    "    else:\n",
    "        if actor not in train_videos:\n",
    "            train_videos[actor] = []\n",
    "        train_videos[actor].append(X[video])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.zeros((samples*2, 300, 150), dtype=np.float32)\n",
    "val_x = np.zeros((samples*2, 300, 150), dtype=np.float32)\n",
    "test_x = np.zeros((samples*2, 300, 150), dtype=np.float32)\n",
    "\n",
    "train_y = np.concatenate((np.ones(samples), np.zeros(samples)))\n",
    "val_y = np.concatenate((np.ones(samples), np.zeros(samples)))\n",
    "test_y = np.concatenate((np.ones(samples), np.zeros(samples)))\n",
    "\n",
    "train_y = np.eye(2)[train_y.astype('int32')]\n",
    "val_y = np.eye(2)[val_y.astype('int32')]\n",
    "test_y = np.eye(2)[test_y.astype('int32')]\n",
    "\n",
    "# Same\n",
    "for i in range(samples):\n",
    "    actor = random.choice(list(train_videos.keys()))\n",
    "    vid1 = random.choice(train_videos[actor])\n",
    "    vid2 = random.choice(train_videos[actor])\n",
    "    train_x[i] = np.concatenate((vid1, vid2), axis=1)\n",
    "\n",
    "    actor = random.choice(list(test_videos.keys()))\n",
    "    vid1 = random.choice(test_videos[actor])\n",
    "    vid2 = random.choice(test_videos[actor])\n",
    "    val_x[i] = np.concatenate((vid1, vid2), axis=1)\n",
    "\n",
    "    actor = random.choice(list(test_videos.keys()))\n",
    "    vid1 = random.choice(test_videos[actor])\n",
    "    vid2 = random.choice(test_videos[actor])\n",
    "    test_x[i] = np.concatenate((vid1, vid2), axis=1)\n",
    "    \n",
    "\n",
    "# Diff\n",
    "for i in range(samples):\n",
    "    actor = random.choice(list(train_videos.keys()))\n",
    "    vid1 = random.choice(train_videos[actor])\n",
    "    actor2 = random.choice(list(train_videos.keys()))\n",
    "    while actor != actor2:\n",
    "        actor2 = random.choice(list(train_videos.keys()))\n",
    "    vid2 = random.choice(train_videos[actor2])\n",
    "    train_x[i+samples] = np.concatenate((vid1, vid2), axis=1)   \n",
    "\n",
    "    actor = random.choice(list(test_videos.keys()))\n",
    "    vid1 = random.choice(test_videos[actor])\n",
    "    actor2 = random.choice(list(test_videos.keys()))\n",
    "    while actor != actor2:\n",
    "        actor2 = random.choice(list(test_videos.keys()))\n",
    "    vid2 = random.choice(test_videos[actor2])\n",
    "    val_x[i+samples] = np.concatenate((vid1, vid2), axis=1)\n",
    "\n",
    "    actor = random.choice(list(test_videos.keys()))\n",
    "    vid1 = random.choice(test_videos[actor])\n",
    "    actor2 = random.choice(list(test_videos.keys()))\n",
    "    while actor != actor2:\n",
    "        actor2 = random.choice(list(test_videos.keys()))\n",
    "    vid2 = random.choice(test_videos[actor2])\n",
    "    test_x[i+samples] = np.concatenate((vid1, vid2), axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SGN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import shutil\n",
    "import os\n",
    "import os.path as osp\n",
    "import csv\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from model2 import SGN\n",
    "from data import NTUDataLoaders, AverageMeter\n",
    "from util import make_dir, get_num_classes\n",
    "\n",
    "# Hyperparameters/Tuning Parameters\n",
    "network='SGN'\n",
    "dataset='NTU'\n",
    "start_epoch=0\n",
    "case=0\n",
    "batch_size=64\n",
    "max_epochs=500\n",
    "monitor='val_acc'\n",
    "lr=0.001\n",
    "weight_decay=0.0001\n",
    "lr_factor=0.1\n",
    "workers=16\n",
    "print_freq = 20\n",
    "do_train=1\n",
    "seg=20\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    losses = AverageMeter()\n",
    "    acces = AverageMeter()\n",
    "    model.train()\n",
    "\n",
    "    for i, (inputs, target) in enumerate(train_loader):\n",
    "\n",
    "        output = model(inputs.cuda())\n",
    "        target = target.cuda()\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc = accuracy(output.data, target)\n",
    "        losses.update(loss.item(), inputs.size(0))\n",
    "        acces.update(acc[0], inputs.size(0))\n",
    "\n",
    "        # backward\n",
    "        optimizer.zero_grad()  # clear gradients out before each mini-batch\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % print_freq == 0:\n",
    "            print('Epoch-{:<3d} {:3d} batches\\t'\n",
    "                  'loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'accu {acc.val:.3f} ({acc.avg:.3f})'.format(\n",
    "                      epoch + 1, i + 1, loss=losses, acc=acces))\n",
    "\n",
    "    return losses.avg, acces.avg\n",
    "\n",
    "\n",
    "def validate(val_loader, model, criterion):\n",
    "    losses = AverageMeter()\n",
    "    acces = AverageMeter()\n",
    "    model.eval()\n",
    "\n",
    "    for i, (inputs, target) in enumerate(val_loader):\n",
    "        with torch.no_grad():\n",
    "            output = model(inputs.cuda())\n",
    "        target = target.cuda()\n",
    "        with torch.no_grad():\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        acc = accuracy(output.data, target)\n",
    "        losses.update(loss.item(), inputs.size(0))\n",
    "        acces.update(acc[0], inputs.size(0))\n",
    "\n",
    "    return losses.avg, acces.avg\n",
    "\n",
    "\n",
    "def test(test_loader, model, checkpoint, lable_path, pred_path):\n",
    "    acces = AverageMeter()\n",
    "    # load learnt model that obtained best performance on validation set\n",
    "    model.load_state_dict(torch.load(checkpoint)['state_dict'])\n",
    "    model.eval()\n",
    "\n",
    "    label_output = list()\n",
    "    pred_output = list()\n",
    "\n",
    "    t_start = time.time()\n",
    "    for i, t in enumerate(test_loader):\n",
    "        inputs = t[0]\n",
    "        target = t[1]\n",
    "        with torch.no_grad():\n",
    "            output = model(inputs.cuda())\n",
    "            output = output.view(\n",
    "                (-1, inputs.size(0)//target.size(0), output.size(1)))\n",
    "            output = output.mean(1)\n",
    "\n",
    "        label_output.append(target.cpu().numpy())\n",
    "        pred_output.append(output.cpu().numpy())\n",
    "\n",
    "        acc = accuracy(output.data, target.cuda())\n",
    "        acces.update(acc[0], inputs.size(0))\n",
    "\n",
    "    label_output = np.concatenate(label_output, axis=0)\n",
    "    np.savetxt(lable_path, label_output, fmt='%d')\n",
    "    pred_output = np.concatenate(pred_output, axis=0)\n",
    "    np.savetxt(pred_path, pred_output, fmt='%f')\n",
    "\n",
    "    print('Test: accuracy {:.3f}, time: {:.2f}s'\n",
    "          .format(acces.avg, time.time() - t_start))\n",
    "\n",
    "\n",
    "def accuracy(output, target):\n",
    "    batch_size = target.size(0)\n",
    "    _, pred = output.topk(1, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    target = torch.argmax(target, dim=1)  # Add this line to convert one-hot targets to class indices\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "    correct = correct.view(-1).float().sum(0, keepdim=True)\n",
    "    return correct.mul_(100.0 / batch_size)\n",
    "\n",
    "\n",
    "\n",
    "def save_checkpoint(state, filename='checkpoint.pth.tar', is_best=False):\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, 'model_best.pth.tar')\n",
    "\n",
    "\n",
    "def get_n_params(model):\n",
    "    pp = 0\n",
    "    for p in list(model.parameters()):\n",
    "        nn = 1\n",
    "        for s in list(p.size()):\n",
    "            nn = nn*s\n",
    "        pp += nn\n",
    "    return pp\n",
    "\n",
    "\n",
    "class LabelSmoothingLoss(nn.Module):\n",
    "    def __init__(self, classes, smoothing=0.0, dim=-1):\n",
    "        super(LabelSmoothingLoss, self).__init__()\n",
    "        self.confidence = 1.0 - smoothing\n",
    "        self.smoothing = smoothing\n",
    "        self.cls = classes\n",
    "        self.dim = dim\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        pred = pred.log_softmax(dim=self.dim)\n",
    "        with torch.no_grad():\n",
    "            target = torch.argmax(target, dim=1)  # Add this line to convert one-hot targets to class indices\n",
    "            true_dist = torch.zeros_like(pred)\n",
    "            true_dist.fill_(self.smoothing / (self.cls - 1))\n",
    "            true_dist.scatter_(1, target.data.unsqueeze(1), self.confidence)\n",
    "        return torch.mean(torch.sum(-true_dist * pred, dim=self.dim))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of parameters:  661294\n",
      "The modes is: SGN\n",
      "It is using GPU!\n",
      "Train on 10000 samples, validate on 10000 samples\n",
      "0 0.001\n",
      "Epoch-1    20 batches\tloss 0.8081 (0.8026)\taccu 48.438 (49.766)\n",
      "Epoch-1    40 batches\tloss 0.7620 (0.7862)\taccu 48.438 (49.414)\n",
      "Epoch-1    60 batches\tloss 0.7377 (0.7664)\taccu 50.000 (49.583)\n",
      "Epoch-1    80 batches\tloss 0.7034 (0.7558)\taccu 56.250 (50.039)\n",
      "Epoch-1   100 batches\tloss 0.6902 (0.7503)\taccu 56.250 (49.906)\n",
      "Epoch-1   120 batches\tloss 0.7274 (0.7449)\taccu 45.312 (49.961)\n",
      "Epoch-1   140 batches\tloss 0.7145 (0.7419)\taccu 50.000 (49.587)\n",
      "Epoch-1   49.2s\tTrain: loss 0.7402\taccu 49.5192\tValid: loss 0.7043\taccu 50.3005\n",
      "Epoch 1: val_acc improved from -inf to 50.3005, saving model to ./results/NTU/SGN\\0_best.pth\n",
      "1 0.001\n",
      "Epoch-2    20 batches\tloss 0.7107 (0.7149)\taccu 56.250 (51.250)\n",
      "Epoch-2    40 batches\tloss 0.6791 (0.7175)\taccu 60.938 (49.883)\n",
      "Epoch-2    60 batches\tloss 0.7153 (0.7216)\taccu 48.438 (49.688)\n",
      "Epoch-2    80 batches\tloss 0.7592 (0.7199)\taccu 48.438 (50.312)\n",
      "Epoch-2   100 batches\tloss 0.6944 (0.7218)\taccu 48.438 (50.078)\n",
      "Epoch-2   120 batches\tloss 0.6711 (0.7207)\taccu 57.812 (50.117)\n",
      "Epoch-2   140 batches\tloss 0.7324 (0.7205)\taccu 42.188 (50.167)\n",
      "Epoch-2   46.2s\tTrain: loss 0.7191\taccu 50.0901\tValid: loss 0.6957\taccu 50.7011\n",
      "Epoch 2: val_acc improved from 50.3005 to 50.7011, saving model to ./results/NTU/SGN\\0_best.pth\n",
      "2 0.001\n",
      "Epoch-3    20 batches\tloss 0.7002 (0.7036)\taccu 48.438 (50.703)\n",
      "Epoch-3    40 batches\tloss 0.7184 (0.7041)\taccu 51.562 (50.508)\n",
      "Epoch-3    60 batches\tloss 0.7159 (0.7070)\taccu 45.312 (49.609)\n",
      "Epoch-3    80 batches\tloss 0.6946 (0.7066)\taccu 48.438 (49.395)\n",
      "Epoch-3   100 batches\tloss 0.7032 (0.7061)\taccu 51.562 (49.453)\n",
      "Epoch-3   120 batches\tloss 0.7058 (0.7050)\taccu 46.875 (49.609)\n",
      "Epoch-3   140 batches\tloss 0.6815 (0.7047)\taccu 54.688 (49.721)\n",
      "Epoch-3   44.9s\tTrain: loss 0.7044\taccu 49.6294\tValid: loss 0.6945\taccu 50.3405\n",
      "Epoch 3: val_acc did not improve\n",
      "3 0.001\n",
      "Epoch-4    20 batches\tloss 0.6891 (0.6977)\taccu 57.812 (51.484)\n",
      "Epoch-4    40 batches\tloss 0.7066 (0.6968)\taccu 48.438 (51.641)\n",
      "Epoch-4    60 batches\tloss 0.7113 (0.6988)\taccu 50.000 (51.589)\n",
      "Epoch-4    80 batches\tloss 0.7252 (0.6991)\taccu 45.312 (51.621)\n",
      "Epoch-4   100 batches\tloss 0.6807 (0.7010)\taccu 62.500 (51.047)\n",
      "Epoch-4   120 batches\tloss 0.7049 (0.7000)\taccu 48.438 (51.250)\n",
      "Epoch-4   140 batches\tloss 0.7005 (0.6997)\taccu 48.438 (51.496)\n",
      "Epoch-4   46.3s\tTrain: loss 0.6997\taccu 51.2720\tValid: loss 0.6964\taccu 50.3205\n",
      "Epoch 4: val_acc did not improve\n",
      "4 0.001\n",
      "Epoch-5    20 batches\tloss 0.6879 (0.7004)\taccu 62.500 (50.703)\n",
      "Epoch-5    40 batches\tloss 0.6896 (0.7012)\taccu 53.125 (51.758)\n",
      "Epoch-5    60 batches\tloss 0.6960 (0.6989)\taccu 57.812 (52.188)\n",
      "Epoch-5    80 batches\tloss 0.7001 (0.6987)\taccu 48.438 (51.992)\n",
      "Epoch-5   100 batches\tloss 0.7208 (0.6999)\taccu 45.312 (52.062)\n",
      "Epoch-5   120 batches\tloss 0.7069 (0.7006)\taccu 46.875 (51.732)\n",
      "Epoch-5   140 batches\tloss 0.6941 (0.7000)\taccu 54.688 (51.819)\n",
      "Epoch-5   45.4s\tTrain: loss 0.6995\taccu 51.8029\tValid: loss 0.6946\taccu 49.7696\n",
      "Epoch 5: val_acc did not improve\n",
      "5 0.001\n",
      "Epoch-6    20 batches\tloss 0.6999 (0.6970)\taccu 53.125 (51.797)\n",
      "Epoch-6    40 batches\tloss 0.7098 (0.6962)\taccu 48.438 (51.211)\n",
      "Epoch-6    60 batches\tloss 0.6881 (0.6966)\taccu 56.250 (51.589)\n",
      "Epoch-6    80 batches\tloss 0.7135 (0.6971)\taccu 37.500 (51.055)\n",
      "Epoch-6   100 batches\tloss 0.7473 (0.6999)\taccu 42.188 (50.938)\n",
      "Epoch-6   120 batches\tloss 0.6758 (0.6990)\taccu 60.938 (51.263)\n",
      "Epoch-6   140 batches\tloss 0.7266 (0.6992)\taccu 43.750 (51.283)\n",
      "Epoch-6   46.1s\tTrain: loss 0.6990\taccu 51.0517\tValid: loss 0.6945\taccu 49.9199\n",
      "Epoch 6: val_acc did not improve\n",
      "6 0.001\n",
      "Epoch-7    20 batches\tloss 0.6929 (0.6972)\taccu 53.125 (51.250)\n",
      "Epoch-7    40 batches\tloss 0.6835 (0.6965)\taccu 62.500 (52.109)\n",
      "Epoch-7    60 batches\tloss 0.7164 (0.6970)\taccu 43.750 (51.120)\n",
      "Epoch-7    80 batches\tloss 0.6951 (0.6969)\taccu 53.125 (51.211)\n",
      "Epoch-7   100 batches\tloss 0.6751 (0.6963)\taccu 62.500 (51.453)\n",
      "Epoch-7   120 batches\tloss 0.6986 (0.6968)\taccu 53.125 (51.380)\n",
      "Epoch-7   140 batches\tloss 0.7093 (0.6968)\taccu 54.688 (51.507)\n",
      "Epoch-7   45.6s\tTrain: loss 0.6970\taccu 51.4123\tValid: loss 0.6956\taccu 50.1903\n",
      "Epoch 7: val_acc did not improve\n",
      "7 0.001\n",
      "Epoch-8    20 batches\tloss 0.6918 (0.6960)\taccu 48.438 (50.703)\n",
      "Epoch-8    40 batches\tloss 0.6761 (0.6944)\taccu 62.500 (50.977)\n",
      "Epoch-8    60 batches\tloss 0.6889 (0.6943)\taccu 53.125 (51.458)\n",
      "Epoch-8    80 batches\tloss 0.6662 (0.6947)\taccu 62.500 (51.602)\n",
      "Epoch-8   100 batches\tloss 0.7029 (0.6949)\taccu 48.438 (51.969)\n",
      "Epoch-8   120 batches\tloss 0.7120 (0.6951)\taccu 43.750 (51.914)\n",
      "Epoch-8   140 batches\tloss 0.7438 (0.6957)\taccu 39.062 (51.942)\n",
      "Epoch-8   46.6s\tTrain: loss 0.6968\taccu 51.8029\tValid: loss 0.6944\taccu 50.2404\n",
      "Epoch 8: val_acc did not improve\n",
      "8 0.001\n",
      "Epoch-9    20 batches\tloss 0.6925 (0.6943)\taccu 51.562 (50.391)\n",
      "Epoch-9    40 batches\tloss 0.7061 (0.6977)\taccu 50.000 (50.664)\n",
      "Epoch-9    60 batches\tloss 0.6958 (0.6991)\taccu 51.562 (50.833)\n",
      "Epoch-9    80 batches\tloss 0.6872 (0.6993)\taccu 45.312 (50.762)\n",
      "Epoch-9   100 batches\tloss 0.6933 (0.6988)\taccu 56.250 (50.453)\n",
      "Epoch-9   120 batches\tloss 0.7016 (0.6975)\taccu 51.562 (50.833)\n",
      "Epoch-9   140 batches\tloss 0.7116 (0.6967)\taccu 35.938 (51.038)\n",
      "Epoch-9   47.0s\tTrain: loss 0.6969\taccu 50.9115\tValid: loss 0.6964\taccu 50.0300\n",
      "Epoch 9: val_acc did not improve\n",
      "9 0.001\n",
      "Epoch-10   20 batches\tloss 0.7049 (0.6953)\taccu 50.000 (52.266)\n",
      "Epoch-10   40 batches\tloss 0.6899 (0.6949)\taccu 54.688 (51.641)\n",
      "Epoch-10   60 batches\tloss 0.6906 (0.6943)\taccu 53.125 (51.927)\n",
      "Epoch-10   80 batches\tloss 0.6928 (0.6957)\taccu 53.125 (51.582)\n",
      "Epoch-10  100 batches\tloss 0.7144 (0.6967)\taccu 50.000 (51.406)\n",
      "Epoch-10  120 batches\tloss 0.7011 (0.6961)\taccu 54.688 (51.771)\n",
      "Epoch-10  140 batches\tloss 0.6834 (0.6956)\taccu 51.562 (51.886)\n",
      "Epoch-10  44.7s\tTrain: loss 0.6954\taccu 51.8630\tValid: loss 0.6947\taccu 50.3506\n",
      "Epoch 10: val_acc did not improve\n",
      "10 0.001\n",
      "Epoch-11   20 batches\tloss 0.6935 (0.6940)\taccu 54.688 (52.031)\n",
      "Epoch-11   40 batches\tloss 0.6733 (0.6926)\taccu 56.250 (52.578)\n",
      "Epoch-11   60 batches\tloss 0.6922 (0.6934)\taccu 48.438 (51.979)\n",
      "Epoch-11   80 batches\tloss 0.6863 (0.6941)\taccu 53.125 (51.777)\n",
      "Epoch-11  100 batches\tloss 0.6951 (0.6951)\taccu 45.312 (51.250)\n",
      "Epoch-11  120 batches\tloss 0.6980 (0.6956)\taccu 48.438 (51.081)\n",
      "Epoch-11  140 batches\tloss 0.6965 (0.6962)\taccu 51.562 (50.904)\n",
      "Epoch-11  43.2s\tTrain: loss 0.6961\taccu 50.7812\tValid: loss 0.6932\taccu 50.7212\n",
      "Epoch 11: val_acc improved from 50.7011 to 50.7212, saving model to ./results/NTU/SGN\\0_best.pth\n",
      "11 0.001\n",
      "Epoch-12   20 batches\tloss 0.7029 (0.6931)\taccu 45.312 (51.719)\n",
      "Epoch-12   40 batches\tloss 0.6884 (0.6935)\taccu 53.125 (50.977)\n",
      "Epoch-12   60 batches\tloss 0.6994 (0.6955)\taccu 51.562 (51.016)\n",
      "Epoch-12   80 batches\tloss 0.6896 (0.6947)\taccu 51.562 (51.270)\n",
      "Epoch-12  100 batches\tloss 0.6993 (0.6941)\taccu 48.438 (51.578)\n",
      "Epoch-12  120 batches\tloss 0.6996 (0.6956)\taccu 50.000 (51.250)\n",
      "Epoch-12  140 batches\tloss 0.6885 (0.6963)\taccu 53.125 (51.138)\n",
      "Epoch-12  45.5s\tTrain: loss 0.6963\taccu 50.9615\tValid: loss 0.6937\taccu 49.2188\n",
      "Epoch 12: val_acc did not improve\n",
      "12 0.001\n",
      "Epoch-13   20 batches\tloss 0.6973 (0.6961)\taccu 51.562 (51.094)\n",
      "Epoch-13   40 batches\tloss 0.6902 (0.6979)\taccu 59.375 (50.820)\n",
      "Epoch-13   60 batches\tloss 0.6917 (0.6969)\taccu 48.438 (50.599)\n",
      "Epoch-13   80 batches\tloss 0.6943 (0.6958)\taccu 54.688 (51.055)\n",
      "Epoch-13  100 batches\tloss 0.6915 (0.6956)\taccu 59.375 (50.969)\n",
      "Epoch-13  120 batches\tloss 0.7002 (0.6960)\taccu 53.125 (50.964)\n",
      "Epoch-13  140 batches\tloss 0.6892 (0.6959)\taccu 54.688 (50.960)\n",
      "Epoch-13  48.9s\tTrain: loss 0.6956\taccu 51.1719\tValid: loss 0.6970\taccu 50.3005\n",
      "Epoch 13: val_acc did not improve\n",
      "13 0.001\n",
      "Epoch-14   20 batches\tloss 0.6956 (0.6990)\taccu 54.688 (50.938)\n",
      "Epoch-14   40 batches\tloss 0.6938 (0.6988)\taccu 53.125 (50.312)\n",
      "Epoch-14   60 batches\tloss 0.6938 (0.6974)\taccu 48.438 (51.068)\n",
      "Epoch-14   80 batches\tloss 0.6971 (0.6964)\taccu 48.438 (51.523)\n",
      "Epoch-14  100 batches\tloss 0.6982 (0.6963)\taccu 46.875 (51.328)\n",
      "Epoch-14  120 batches\tloss 0.6829 (0.6959)\taccu 50.000 (51.302)\n",
      "Epoch-14  140 batches\tloss 0.7067 (0.6968)\taccu 43.750 (50.893)\n",
      "Epoch-14  48.7s\tTrain: loss 0.6964\taccu 50.9115\tValid: loss 0.6942\taccu 49.7997\n",
      "Epoch 14: val_acc did not improve\n",
      "14 0.001\n",
      "Epoch-15   20 batches\tloss 0.7107 (0.6980)\taccu 45.312 (53.047)\n",
      "Epoch-15   40 batches\tloss 0.6817 (0.6961)\taccu 57.812 (52.617)\n",
      "Epoch-15   60 batches\tloss 0.6960 (0.6961)\taccu 48.438 (51.667)\n",
      "Epoch-15   80 batches\tloss 0.6966 (0.6959)\taccu 48.438 (51.387)\n",
      "Epoch-15  100 batches\tloss 0.6929 (0.6958)\taccu 56.250 (51.391)\n",
      "Epoch-15  120 batches\tloss 0.6952 (0.6957)\taccu 50.000 (51.432)\n",
      "Epoch-15  140 batches\tloss 0.6979 (0.6955)\taccu 43.750 (51.618)\n",
      "Epoch-15  48.4s\tTrain: loss 0.6955\taccu 51.6627\tValid: loss 0.6962\taccu 50.4107\n",
      "Epoch 15: val_acc did not improve\n",
      "15 0.001\n",
      "Epoch-16   20 batches\tloss 0.6993 (0.6987)\taccu 54.688 (51.797)\n",
      "Epoch-16   40 batches\tloss 0.6904 (0.6979)\taccu 53.125 (51.094)\n",
      "Epoch-16   60 batches\tloss 0.7052 (0.6978)\taccu 43.750 (51.068)\n",
      "Epoch-16   80 batches\tloss 0.6984 (0.6967)\taccu 39.062 (51.504)\n",
      "Epoch-16  100 batches\tloss 0.6901 (0.6959)\taccu 60.938 (51.719)\n",
      "Epoch-16  120 batches\tloss 0.7005 (0.6955)\taccu 46.875 (51.641)\n",
      "Epoch-16  140 batches\tloss 0.6824 (0.6957)\taccu 57.812 (51.473)\n",
      "Epoch-16  48.5s\tTrain: loss 0.6955\taccu 51.7127\tValid: loss 0.6969\taccu 50.0801\n",
      "Epoch 16: val_acc did not improve\n",
      "16 0.001\n",
      "Epoch-17   20 batches\tloss 0.6998 (0.6950)\taccu 48.438 (51.562)\n",
      "Epoch-17   40 batches\tloss 0.6964 (0.6939)\taccu 46.875 (52.148)\n",
      "Epoch-17   60 batches\tloss 0.6895 (0.6946)\taccu 53.125 (51.380)\n",
      "Epoch-17   80 batches\tloss 0.6945 (0.6947)\taccu 48.438 (50.801)\n",
      "Epoch-17  100 batches\tloss 0.6775 (0.6949)\taccu 62.500 (50.938)\n",
      "Epoch-17  120 batches\tloss 0.6963 (0.6948)\taccu 51.562 (51.055)\n",
      "Epoch-17  140 batches\tloss 0.6945 (0.6945)\taccu 46.875 (51.239)\n",
      "Epoch-17  48.3s\tTrain: loss 0.6947\taccu 51.0817\tValid: loss 0.6938\taccu 50.0701\n",
      "Epoch 17: val_acc did not improve\n",
      "17 0.001\n",
      "Epoch-18   20 batches\tloss 0.7097 (0.6952)\taccu 46.875 (53.438)\n",
      "Epoch-18   40 batches\tloss 0.6946 (0.6952)\taccu 53.125 (51.680)\n",
      "Epoch-18   60 batches\tloss 0.6800 (0.6935)\taccu 60.938 (52.292)\n",
      "Epoch-18   80 batches\tloss 0.6892 (0.6937)\taccu 51.562 (51.699)\n",
      "Epoch-18  100 batches\tloss 0.6893 (0.6943)\taccu 46.875 (51.469)\n",
      "Epoch-18  120 batches\tloss 0.6888 (0.6945)\taccu 59.375 (51.393)\n",
      "Epoch-18  140 batches\tloss 0.6978 (0.6943)\taccu 48.438 (51.049)\n",
      "Epoch-18  48.9s\tTrain: loss 0.6944\taccu 51.0116\tValid: loss 0.6939\taccu 49.8297\n",
      "Epoch 18: val_acc did not improve\n",
      "18 0.001\n",
      "Epoch-19   20 batches\tloss 0.6942 (0.6935)\taccu 54.688 (51.797)\n",
      "Epoch-19   40 batches\tloss 0.6904 (0.6958)\taccu 50.000 (50.742)\n",
      "Epoch-19   60 batches\tloss 0.6953 (0.6953)\taccu 53.125 (51.042)\n",
      "Epoch-19   80 batches\tloss 0.6922 (0.6945)\taccu 57.812 (51.445)\n",
      "Epoch-19  100 batches\tloss 0.6859 (0.6945)\taccu 65.625 (51.656)\n",
      "Epoch-19  120 batches\tloss 0.6848 (0.6949)\taccu 62.500 (51.159)\n",
      "Epoch-19  140 batches\tloss 0.6961 (0.6948)\taccu 54.688 (51.183)\n",
      "Epoch-19  48.8s\tTrain: loss 0.6950\taccu 50.9916\tValid: loss 0.6940\taccu 49.8297\n",
      "Epoch 19: val_acc did not improve\n",
      "19 0.001\n",
      "Epoch-20   20 batches\tloss 0.6998 (0.6975)\taccu 46.875 (49.297)\n",
      "Epoch-20   40 batches\tloss 0.6870 (0.6956)\taccu 54.688 (49.805)\n",
      "Epoch-20   60 batches\tloss 0.7067 (0.6957)\taccu 53.125 (50.365)\n",
      "Epoch-20   80 batches\tloss 0.6861 (0.6957)\taccu 59.375 (50.469)\n",
      "Epoch-20  100 batches\tloss 0.6953 (0.6959)\taccu 48.438 (50.562)\n",
      "Epoch-20  120 batches\tloss 0.6977 (0.6958)\taccu 48.438 (50.247)\n",
      "Epoch-20  140 batches\tloss 0.7009 (0.6960)\taccu 46.875 (50.324)\n",
      "Epoch-20  47.9s\tTrain: loss 0.6958\taccu 50.3806\tValid: loss 0.6940\taccu 50.5108\n",
      "Epoch 20: val_acc did not improve\n",
      "20 0.001\n",
      "Epoch-21   20 batches\tloss 0.6935 (0.6922)\taccu 53.125 (52.656)\n",
      "Epoch-21   40 batches\tloss 0.6839 (0.6940)\taccu 59.375 (51.836)\n",
      "Epoch-21   60 batches\tloss 0.7038 (0.6931)\taccu 45.312 (52.188)\n",
      "Epoch-21   80 batches\tloss 0.6970 (0.6933)\taccu 48.438 (51.914)\n",
      "Epoch-21  100 batches\tloss 0.7041 (0.6937)\taccu 48.438 (51.500)\n",
      "Epoch-21  120 batches\tloss 0.6998 (0.6945)\taccu 45.312 (51.250)\n",
      "Epoch-21  140 batches\tloss 0.6810 (0.6948)\taccu 64.062 (51.161)\n",
      "Epoch-21  47.0s\tTrain: loss 0.6946\taccu 51.4824\tValid: loss 0.6947\taccu 50.2103\n",
      "Epoch 21: val_acc did not improve\n",
      "21 0.001\n",
      "Epoch-22   20 batches\tloss 0.6862 (0.6929)\taccu 56.250 (52.266)\n",
      "Epoch-22   40 batches\tloss 0.6847 (0.6934)\taccu 54.688 (52.031)\n",
      "Epoch-22   60 batches\tloss 0.6909 (0.6943)\taccu 51.562 (51.120)\n",
      "Epoch-22   80 batches\tloss 0.7044 (0.6942)\taccu 43.750 (51.113)\n",
      "Epoch-22  100 batches\tloss 0.6965 (0.6940)\taccu 50.000 (51.266)\n",
      "Epoch-22  120 batches\tloss 0.6849 (0.6945)\taccu 57.812 (51.107)\n",
      "Epoch-22  140 batches\tloss 0.6867 (0.6945)\taccu 51.562 (51.217)\n",
      "Epoch-22  47.0s\tTrain: loss 0.6945\taccu 51.1719\tValid: loss 0.6947\taccu 50.1102\n",
      "Epoch 22: val_acc did not improve\n",
      "22 0.001\n",
      "Epoch-23   20 batches\tloss 0.6915 (0.6956)\taccu 51.562 (50.312)\n",
      "Epoch-23   40 batches\tloss 0.6898 (0.6949)\taccu 50.000 (50.234)\n",
      "Epoch-23   60 batches\tloss 0.6944 (0.6945)\taccu 46.875 (50.521)\n",
      "Epoch-23   80 batches\tloss 0.6899 (0.6946)\taccu 50.000 (50.840)\n",
      "Epoch-23  100 batches\tloss 0.6789 (0.6948)\taccu 54.688 (50.984)\n",
      "Epoch-23  120 batches\tloss 0.7001 (0.6948)\taccu 35.938 (51.068)\n",
      "Epoch-23  140 batches\tloss 0.6931 (0.6948)\taccu 45.312 (50.837)\n",
      "Epoch-23  46.6s\tTrain: loss 0.6946\taccu 50.9014\tValid: loss 0.6936\taccu 50.1502\n",
      "Epoch 23: val_acc did not improve\n",
      "23 0.001\n",
      "Epoch-24   20 batches\tloss 0.6898 (0.6938)\taccu 51.562 (51.953)\n",
      "Epoch-24   40 batches\tloss 0.6837 (0.6935)\taccu 56.250 (51.836)\n",
      "Epoch-24   60 batches\tloss 0.6906 (0.6946)\taccu 65.625 (51.354)\n",
      "Epoch-24   80 batches\tloss 0.6902 (0.6944)\taccu 51.562 (51.367)\n",
      "Epoch-24  100 batches\tloss 0.6878 (0.6942)\taccu 51.562 (51.219)\n",
      "Epoch-24  120 batches\tloss 0.6923 (0.6942)\taccu 54.688 (51.328)\n",
      "Epoch-24  140 batches\tloss 0.6920 (0.6942)\taccu 53.125 (51.138)\n",
      "Epoch-24  47.0s\tTrain: loss 0.6944\taccu 50.9415\tValid: loss 0.6934\taccu 49.7095\n",
      "Epoch 24: val_acc did not improve\n",
      "24 0.001\n",
      "Epoch-25   20 batches\tloss 0.6909 (0.6951)\taccu 53.125 (49.609)\n",
      "Epoch-25   40 batches\tloss 0.6946 (0.6952)\taccu 48.438 (49.961)\n",
      "Epoch-25   60 batches\tloss 0.6932 (0.6954)\taccu 51.562 (49.245)\n",
      "Epoch-25   80 batches\tloss 0.6947 (0.6950)\taccu 51.562 (49.961)\n",
      "Epoch-25  100 batches\tloss 0.6997 (0.6954)\taccu 46.875 (49.828)\n",
      "Epoch-25  120 batches\tloss 0.6822 (0.6952)\taccu 57.812 (49.753)\n",
      "Epoch-25  140 batches\tloss 0.6923 (0.6952)\taccu 54.688 (49.989)\n",
      "Epoch-25  47.4s\tTrain: loss 0.6949\taccu 50.1402\tValid: loss 0.6973\taccu 50.0501\n",
      "Epoch 25: val_acc did not improve\n",
      "25 0.001\n",
      "Epoch-26   20 batches\tloss 0.6881 (0.6950)\taccu 64.062 (51.094)\n",
      "Epoch-26   40 batches\tloss 0.6961 (0.6941)\taccu 45.312 (50.977)\n",
      "Epoch-26   60 batches\tloss 0.6928 (0.6945)\taccu 56.250 (50.911)\n",
      "Epoch-26   80 batches\tloss 0.6876 (0.6945)\taccu 57.812 (50.586)\n",
      "Epoch-26  100 batches\tloss 0.6909 (0.6952)\taccu 56.250 (50.500)\n",
      "Epoch-26  120 batches\tloss 0.6917 (0.6949)\taccu 46.875 (50.417)\n",
      "Epoch-26  140 batches\tloss 0.7119 (0.6948)\taccu 39.062 (50.558)\n",
      "Epoch-26  44.0s\tTrain: loss 0.6946\taccu 50.8113\tValid: loss 0.6934\taccu 49.2388\n",
      "Epoch 26: val_acc did not improve\n",
      "26 0.001\n",
      "Epoch-27   20 batches\tloss 0.7001 (0.6945)\taccu 51.562 (51.328)\n",
      "Epoch-27   40 batches\tloss 0.6922 (0.6941)\taccu 59.375 (51.211)\n",
      "Epoch-27   60 batches\tloss 0.7012 (0.6939)\taccu 46.875 (51.016)\n",
      "Epoch-27   80 batches\tloss 0.6907 (0.6937)\taccu 56.250 (51.270)\n",
      "Epoch-27  100 batches\tloss 0.6903 (0.6942)\taccu 51.562 (51.203)\n",
      "Epoch-27  120 batches\tloss 0.6911 (0.6944)\taccu 40.625 (50.651)\n",
      "Epoch-27  140 batches\tloss 0.6950 (0.6943)\taccu 48.438 (50.692)\n",
      "Epoch-27  45.1s\tTrain: loss 0.6944\taccu 50.6310\tValid: loss 0.6932\taccu 50.0801\n",
      "Epoch 27: val_acc did not improve\n",
      "27 0.001\n",
      "Epoch-28   20 batches\tloss 0.7017 (0.6949)\taccu 39.062 (49.688)\n",
      "Epoch-28   40 batches\tloss 0.6940 (0.6943)\taccu 45.312 (50.000)\n",
      "Epoch-28   60 batches\tloss 0.6997 (0.6941)\taccu 50.000 (50.469)\n",
      "Epoch-28   80 batches\tloss 0.6919 (0.6940)\taccu 51.562 (51.250)\n",
      "Epoch-28  100 batches\tloss 0.6932 (0.6943)\taccu 59.375 (51.016)\n",
      "Epoch-28  120 batches\tloss 0.6932 (0.6941)\taccu 46.875 (50.846)\n",
      "Epoch-28  140 batches\tloss 0.6883 (0.6939)\taccu 59.375 (51.060)\n",
      "Epoch-28  49.5s\tTrain: loss 0.6939\taccu 51.1318\tValid: loss 0.6936\taccu 49.9900\n",
      "Epoch 28: val_acc did not improve\n",
      "28 0.001\n",
      "Epoch-29   20 batches\tloss 0.6895 (0.6941)\taccu 57.812 (50.625)\n",
      "Epoch-29   40 batches\tloss 0.6981 (0.6937)\taccu 46.875 (51.289)\n",
      "Epoch-29   60 batches\tloss 0.6908 (0.6939)\taccu 59.375 (50.807)\n",
      "Epoch-29   80 batches\tloss 0.6881 (0.6936)\taccu 53.125 (50.547)\n",
      "Epoch-29  100 batches\tloss 0.6927 (0.6939)\taccu 46.875 (50.219)\n",
      "Epoch-29  120 batches\tloss 0.6957 (0.6939)\taccu 46.875 (49.974)\n",
      "Epoch-29  140 batches\tloss 0.6870 (0.6938)\taccu 57.812 (49.978)\n",
      "Epoch-29  47.8s\tTrain: loss 0.6940\taccu 49.9599\tValid: loss 0.6934\taccu 49.1186\n",
      "Epoch 29: val_acc did not improve\n",
      "29 0.001\n",
      "Epoch-30   20 batches\tloss 0.6909 (0.6938)\taccu 53.125 (51.172)\n",
      "Epoch-30   40 batches\tloss 0.6877 (0.6936)\taccu 57.812 (51.562)\n",
      "Epoch-30   60 batches\tloss 0.6849 (0.6936)\taccu 62.500 (51.719)\n",
      "Epoch-30   80 batches\tloss 0.6908 (0.6938)\taccu 57.812 (51.328)\n",
      "Epoch-30  100 batches\tloss 0.6947 (0.6936)\taccu 48.438 (51.328)\n",
      "Epoch-30  120 batches\tloss 0.6950 (0.6937)\taccu 48.438 (51.055)\n",
      "Epoch-30  140 batches\tloss 0.6938 (0.6938)\taccu 45.312 (50.871)\n",
      "Epoch-30  45.4s\tTrain: loss 0.6937\taccu 50.7612\tValid: loss 0.6932\taccu 50.1102\n",
      "Epoch 30: val_acc did not improve\n",
      "30 0.001\n",
      "Epoch-31   20 batches\tloss 0.7030 (0.6944)\taccu 40.625 (48.984)\n",
      "Epoch-31   40 batches\tloss 0.7002 (0.6947)\taccu 37.500 (49.961)\n",
      "Epoch-31   60 batches\tloss 0.6910 (0.6942)\taccu 48.438 (50.443)\n",
      "Epoch-31   80 batches\tloss 0.6883 (0.6938)\taccu 56.250 (50.781)\n",
      "Epoch-31  100 batches\tloss 0.6828 (0.6933)\taccu 64.062 (51.344)\n",
      "Epoch-31  120 batches\tloss 0.6937 (0.6935)\taccu 46.875 (51.172)\n",
      "Epoch-31  140 batches\tloss 0.6923 (0.6935)\taccu 50.000 (51.094)\n",
      "Epoch-31  45.2s\tTrain: loss 0.6935\taccu 51.2019\tValid: loss 0.6932\taccu 50.3706\n",
      "Epoch 31: val_acc did not improve\n",
      "31 0.001\n",
      "Epoch-32   20 batches\tloss 0.7006 (0.6934)\taccu 32.812 (50.312)\n",
      "Epoch-32   40 batches\tloss 0.6906 (0.6936)\taccu 57.812 (50.234)\n",
      "Epoch-32   60 batches\tloss 0.7016 (0.6941)\taccu 48.438 (50.052)\n",
      "Epoch-32   80 batches\tloss 0.6919 (0.6939)\taccu 51.562 (50.293)\n",
      "Epoch-32  100 batches\tloss 0.6956 (0.6940)\taccu 48.438 (50.438)\n",
      "Epoch-32  120 batches\tloss 0.6918 (0.6938)\taccu 57.812 (50.495)\n",
      "Epoch-32  140 batches\tloss 0.6913 (0.6938)\taccu 50.000 (50.413)\n",
      "Epoch-32  48.6s\tTrain: loss 0.6939\taccu 50.1903\tValid: loss 0.6933\taccu 50.5208\n",
      "Epoch 32: val_acc did not improve\n",
      "32 0.001\n",
      "Epoch-33   20 batches\tloss 0.6909 (0.6928)\taccu 56.250 (51.562)\n",
      "Epoch-33   40 batches\tloss 0.6894 (0.6932)\taccu 57.812 (51.719)\n",
      "Epoch-33   60 batches\tloss 0.6929 (0.6933)\taccu 56.250 (51.406)\n",
      "Epoch-33   80 batches\tloss 0.6942 (0.6935)\taccu 51.562 (50.723)\n",
      "Epoch-33  100 batches\tloss 0.6930 (0.6937)\taccu 50.000 (50.406)\n",
      "Epoch-33  120 batches\tloss 0.6978 (0.6936)\taccu 40.625 (50.469)\n",
      "Epoch-33  140 batches\tloss 0.6876 (0.6936)\taccu 59.375 (50.391)\n",
      "Epoch-33  55.5s\tTrain: loss 0.6935\taccu 50.5609\tValid: loss 0.6939\taccu 50.0401\n",
      "Epoch 33: val_acc did not improve\n",
      "33 0.001\n",
      "Epoch-34   20 batches\tloss 0.6988 (0.6934)\taccu 43.750 (50.078)\n",
      "Epoch-34   40 batches\tloss 0.6952 (0.6940)\taccu 53.125 (50.547)\n",
      "Epoch-34   60 batches\tloss 0.6934 (0.6940)\taccu 50.000 (50.755)\n",
      "Epoch-34   80 batches\tloss 0.6925 (0.6939)\taccu 50.000 (50.781)\n",
      "Epoch-34  100 batches\tloss 0.6997 (0.6938)\taccu 45.312 (50.781)\n",
      "Epoch-34  120 batches\tloss 0.7059 (0.6938)\taccu 42.188 (50.794)\n",
      "Epoch-34  140 batches\tloss 0.6942 (0.6940)\taccu 50.000 (50.402)\n",
      "Epoch-34  51.8s\tTrain: loss 0.6940\taccu 50.3606\tValid: loss 0.6934\taccu 50.0501\n",
      "Epoch 34: val_acc did not improve\n",
      "34 0.001\n",
      "Epoch-35   20 batches\tloss 0.6948 (0.6936)\taccu 45.312 (48.984)\n",
      "Epoch-35   40 batches\tloss 0.6924 (0.6936)\taccu 53.125 (49.648)\n",
      "Epoch-35   60 batches\tloss 0.6768 (0.6933)\taccu 62.500 (50.234)\n",
      "Epoch-35   80 batches\tloss 0.6967 (0.6941)\taccu 48.438 (49.844)\n",
      "Epoch-35  100 batches\tloss 0.7067 (0.6940)\taccu 39.062 (50.125)\n",
      "Epoch-35  120 batches\tloss 0.6916 (0.6940)\taccu 54.688 (49.870)\n",
      "Epoch-35  140 batches\tloss 0.6948 (0.6939)\taccu 43.750 (49.944)\n",
      "Epoch-35  49.8s\tTrain: loss 0.6939\taccu 49.8898\tValid: loss 0.6931\taccu 50.5509\n",
      "Epoch 35: val_acc did not improve\n",
      "35 0.001\n",
      "Epoch-36   20 batches\tloss 0.7022 (0.6926)\taccu 45.312 (51.953)\n",
      "Epoch-36   40 batches\tloss 0.6945 (0.6929)\taccu 45.312 (51.328)\n",
      "Epoch-36   60 batches\tloss 0.6982 (0.6929)\taccu 48.438 (51.406)\n",
      "Epoch-36   80 batches\tloss 0.6918 (0.6933)\taccu 48.438 (50.840)\n",
      "Epoch-36  100 batches\tloss 0.6949 (0.6935)\taccu 46.875 (51.062)\n",
      "Epoch-36  120 batches\tloss 0.6905 (0.6935)\taccu 57.812 (50.768)\n",
      "Epoch-36  140 batches\tloss 0.6989 (0.6934)\taccu 45.312 (50.871)\n",
      "Epoch-36  49.2s\tTrain: loss 0.6935\taccu 50.8914\tValid: loss 0.6934\taccu 49.9599\n",
      "Epoch 36: val_acc did not improve\n",
      "36 0.001\n",
      "Epoch-37   20 batches\tloss 0.6911 (0.6936)\taccu 59.375 (49.141)\n",
      "Epoch-37   40 batches\tloss 0.6950 (0.6937)\taccu 43.750 (48.672)\n",
      "Epoch-37   60 batches\tloss 0.6939 (0.6938)\taccu 43.750 (48.359)\n",
      "Epoch-37   80 batches\tloss 0.6922 (0.6938)\taccu 53.125 (48.965)\n",
      "Epoch-37  100 batches\tloss 0.6969 (0.6936)\taccu 46.875 (49.469)\n",
      "Epoch-37  120 batches\tloss 0.6917 (0.6936)\taccu 56.250 (49.427)\n",
      "Epoch-37  140 batches\tloss 0.6935 (0.6935)\taccu 51.562 (49.531)\n",
      "Epoch-37  49.8s\tTrain: loss 0.6936\taccu 49.5192\tValid: loss 0.6931\taccu 50.1102\n",
      "Epoch 37: val_acc did not improve\n",
      "37 0.001\n",
      "Epoch-38   20 batches\tloss 0.6933 (0.6931)\taccu 45.312 (51.875)\n",
      "Epoch-38   40 batches\tloss 0.6931 (0.6935)\taccu 45.312 (49.883)\n",
      "Epoch-38   60 batches\tloss 0.6944 (0.6936)\taccu 46.875 (49.974)\n",
      "Epoch-38   80 batches\tloss 0.6905 (0.6933)\taccu 51.562 (50.195)\n",
      "Epoch-38  100 batches\tloss 0.6927 (0.6935)\taccu 48.438 (50.094)\n",
      "Epoch-38  120 batches\tloss 0.6951 (0.6935)\taccu 59.375 (50.143)\n",
      "Epoch-38  140 batches\tloss 0.6861 (0.6933)\taccu 59.375 (50.491)\n",
      "Epoch-38  47.5s\tTrain: loss 0.6934\taccu 50.4808\tValid: loss 0.6934\taccu 50.0801\n",
      "Epoch 38: val_acc did not improve\n",
      "38 0.001\n",
      "Epoch-39   20 batches\tloss 0.6939 (0.6948)\taccu 43.750 (48.906)\n",
      "Epoch-39   40 batches\tloss 0.6918 (0.6941)\taccu 57.812 (49.141)\n",
      "Epoch-39   60 batches\tloss 0.6924 (0.6938)\taccu 53.125 (49.922)\n",
      "Epoch-39   80 batches\tloss 0.7021 (0.6934)\taccu 48.438 (50.234)\n",
      "Epoch-39  100 batches\tloss 0.6944 (0.6936)\taccu 48.438 (50.375)\n",
      "Epoch-39  120 batches\tloss 0.6911 (0.6937)\taccu 54.688 (50.156)\n",
      "Epoch-39  140 batches\tloss 0.6933 (0.6937)\taccu 53.125 (50.279)\n",
      "Epoch-39  46.6s\tTrain: loss 0.6937\taccu 50.2804\tValid: loss 0.6932\taccu 50.0100\n",
      "Epoch 39: val_acc did not improve\n",
      "39 0.001\n",
      "Epoch-40   20 batches\tloss 0.6929 (0.6933)\taccu 50.000 (50.859)\n",
      "Epoch-40   40 batches\tloss 0.6990 (0.6930)\taccu 54.688 (52.148)\n",
      "Epoch-40   60 batches\tloss 0.6914 (0.6931)\taccu 59.375 (51.771)\n",
      "Epoch-40   80 batches\tloss 0.6942 (0.6931)\taccu 45.312 (51.660)\n",
      "Epoch-40  100 batches\tloss 0.6981 (0.6931)\taccu 43.750 (51.219)\n",
      "Epoch-40  120 batches\tloss 0.6886 (0.6931)\taccu 59.375 (51.523)\n",
      "Epoch-40  140 batches\tloss 0.6981 (0.6933)\taccu 45.312 (51.105)\n",
      "Epoch-40  45.5s\tTrain: loss 0.6933\taccu 51.0617\tValid: loss 0.6934\taccu 49.9099\n",
      "Epoch 40: val_acc did not improve\n",
      "40 0.001\n",
      "Epoch-41   20 batches\tloss 0.6945 (0.6927)\taccu 48.438 (53.203)\n",
      "Epoch-41   40 batches\tloss 0.6892 (0.6935)\taccu 48.438 (51.172)\n",
      "Epoch-41   60 batches\tloss 0.6953 (0.6936)\taccu 46.875 (51.094)\n",
      "Epoch-41   80 batches\tloss 0.6906 (0.6932)\taccu 54.688 (51.465)\n",
      "Epoch-41  100 batches\tloss 0.6971 (0.6934)\taccu 37.500 (50.922)\n",
      "Epoch-41  120 batches\tloss 0.6926 (0.6934)\taccu 53.125 (50.781)\n",
      "Epoch-41  140 batches\tloss 0.6926 (0.6934)\taccu 57.812 (50.792)\n",
      "Epoch-41  45.0s\tTrain: loss 0.6935\taccu 50.6010\tValid: loss 0.6932\taccu 49.7095\n",
      "Epoch 41: val_acc did not improve\n",
      "41 0.001\n",
      "Epoch-42   20 batches\tloss 0.6930 (0.6938)\taccu 46.875 (50.156)\n",
      "Epoch-42   40 batches\tloss 0.6956 (0.6938)\taccu 48.438 (50.156)\n",
      "Epoch-42   60 batches\tloss 0.6915 (0.6938)\taccu 54.688 (50.625)\n",
      "Epoch-42   80 batches\tloss 0.6929 (0.6936)\taccu 53.125 (51.152)\n",
      "Epoch-42  100 batches\tloss 0.6923 (0.6936)\taccu 54.688 (51.281)\n",
      "Epoch-42  120 batches\tloss 0.6956 (0.6936)\taccu 45.312 (51.185)\n",
      "Epoch-42  140 batches\tloss 0.6893 (0.6936)\taccu 65.625 (51.071)\n",
      "Epoch-42  45.2s\tTrain: loss 0.6936\taccu 51.0617\tValid: loss 0.6938\taccu 50.0801\n",
      "Epoch 42: val_acc did not improve\n",
      "42 0.001\n",
      "Epoch-43   20 batches\tloss 0.6960 (0.6924)\taccu 42.188 (52.734)\n",
      "Epoch-43   40 batches\tloss 0.6929 (0.6933)\taccu 51.562 (51.250)\n",
      "Epoch-43   60 batches\tloss 0.7001 (0.6932)\taccu 43.750 (51.198)\n",
      "Epoch-43   80 batches\tloss 0.6910 (0.6935)\taccu 60.938 (50.586)\n",
      "Epoch-43  100 batches\tloss 0.6950 (0.6934)\taccu 51.562 (51.031)\n",
      "Epoch-43  120 batches\tloss 0.6939 (0.6935)\taccu 46.875 (50.625)\n",
      "Epoch-43  140 batches\tloss 0.6944 (0.6935)\taccu 45.312 (50.614)\n",
      "Epoch-43  44.9s\tTrain: loss 0.6933\taccu 50.5409\tValid: loss 0.6933\taccu 50.0601\n",
      "Epoch 43: val_acc did not improve\n",
      "43 0.001\n",
      "Epoch-44   20 batches\tloss 0.6968 (0.6922)\taccu 48.438 (51.797)\n",
      "Epoch-44   40 batches\tloss 0.6988 (0.6935)\taccu 42.188 (50.000)\n",
      "Epoch-44   60 batches\tloss 0.6914 (0.6934)\taccu 57.812 (50.078)\n",
      "Epoch-44   80 batches\tloss 0.6921 (0.6934)\taccu 57.812 (49.746)\n",
      "Epoch-44  100 batches\tloss 0.6917 (0.6934)\taccu 54.688 (49.969)\n",
      "Epoch-44  120 batches\tloss 0.6945 (0.6933)\taccu 50.000 (50.313)\n",
      "Epoch-44  140 batches\tloss 0.6940 (0.6934)\taccu 45.312 (50.279)\n",
      "Epoch-44  44.7s\tTrain: loss 0.6934\taccu 50.2504\tValid: loss 0.6931\taccu 50.0801\n",
      "Epoch 44: val_acc did not improve\n",
      "44 0.001\n",
      "Epoch-45   20 batches\tloss 0.6922 (0.6929)\taccu 54.688 (51.953)\n",
      "Epoch-45   40 batches\tloss 0.6928 (0.6918)\taccu 53.125 (53.359)\n",
      "Epoch-45   60 batches\tloss 0.6928 (0.6934)\taccu 46.875 (51.068)\n",
      "Epoch-45   80 batches\tloss 0.6921 (0.6935)\taccu 50.000 (50.391)\n",
      "Epoch-45  100 batches\tloss 0.6933 (0.6935)\taccu 51.562 (50.219)\n",
      "Epoch-45  120 batches\tloss 0.6919 (0.6935)\taccu 48.438 (50.195)\n",
      "Epoch-45  140 batches\tloss 0.6940 (0.6935)\taccu 50.000 (50.201)\n",
      "Epoch-45  43.9s\tTrain: loss 0.6934\taccu 50.4107\tValid: loss 0.6932\taccu 50.0801\n",
      "Epoch 45: val_acc did not improve\n",
      "45 0.001\n",
      "Epoch-46   20 batches\tloss 0.6971 (0.6932)\taccu 54.688 (51.406)\n",
      "Epoch-46   40 batches\tloss 0.6918 (0.6924)\taccu 56.250 (51.680)\n",
      "Epoch-46   60 batches\tloss 0.6899 (0.6932)\taccu 53.125 (50.703)\n",
      "Epoch-46   80 batches\tloss 0.6921 (0.6931)\taccu 54.688 (50.723)\n",
      "Epoch-46  100 batches\tloss 0.6941 (0.6931)\taccu 50.000 (50.719)\n",
      "Epoch-46  120 batches\tloss 0.6907 (0.6930)\taccu 53.125 (51.055)\n",
      "Epoch-46  140 batches\tloss 0.6922 (0.6932)\taccu 54.688 (50.770)\n",
      "Epoch-46  45.4s\tTrain: loss 0.6932\taccu 50.6210\tValid: loss 0.6932\taccu 49.8397\n",
      "Epoch 46: val_acc did not improve\n",
      "46 0.001\n",
      "Epoch-47   20 batches\tloss 0.6876 (0.6926)\taccu 59.375 (52.578)\n",
      "Epoch-47   40 batches\tloss 0.6887 (0.6927)\taccu 57.812 (52.461)\n",
      "Epoch-47   60 batches\tloss 0.6914 (0.6927)\taccu 46.875 (51.641)\n",
      "Epoch-47   80 batches\tloss 0.6928 (0.6930)\taccu 51.562 (51.133)\n",
      "Epoch-47  100 batches\tloss 0.6931 (0.6931)\taccu 56.250 (51.094)\n",
      "Epoch-47  120 batches\tloss 0.6930 (0.6930)\taccu 50.000 (51.133)\n",
      "Epoch-47  140 batches\tloss 0.6908 (0.6931)\taccu 60.938 (51.138)\n",
      "Epoch-47  42.6s\tTrain: loss 0.6931\taccu 51.0917\tValid: loss 0.6935\taccu 50.0901\n",
      "Epoch 47: val_acc did not improve\n",
      "47 0.001\n",
      "Epoch-48   20 batches\tloss 0.6892 (0.6931)\taccu 59.375 (51.328)\n",
      "Epoch-48   40 batches\tloss 0.6935 (0.6934)\taccu 46.875 (50.938)\n",
      "Epoch-48   60 batches\tloss 0.6940 (0.6934)\taccu 50.000 (50.260)\n",
      "Epoch-48   80 batches\tloss 0.6987 (0.6934)\taccu 39.062 (50.371)\n",
      "Epoch-48  100 batches\tloss 0.6926 (0.6934)\taccu 56.250 (50.141)\n",
      "Epoch-48  120 batches\tloss 0.6939 (0.6933)\taccu 53.125 (50.378)\n",
      "Epoch-48  140 batches\tloss 0.6937 (0.6932)\taccu 51.562 (50.547)\n",
      "Epoch-48  45.6s\tTrain: loss 0.6931\taccu 50.5409\tValid: loss 0.6934\taccu 49.8598\n",
      "Epoch 48: val_acc did not improve\n",
      "48 0.001\n",
      "Epoch-49   20 batches\tloss 0.6928 (0.6919)\taccu 48.438 (52.266)\n",
      "Epoch-49   40 batches\tloss 0.6906 (0.6929)\taccu 53.125 (50.430)\n",
      "Epoch-49   60 batches\tloss 0.6913 (0.6928)\taccu 54.688 (51.016)\n",
      "Epoch-49   80 batches\tloss 0.6903 (0.6929)\taccu 56.250 (51.074)\n",
      "Epoch-49  100 batches\tloss 0.6942 (0.6931)\taccu 45.312 (50.781)\n",
      "Epoch-49  120 batches\tloss 0.6942 (0.6931)\taccu 43.750 (50.898)\n",
      "Epoch-49  140 batches\tloss 0.6951 (0.6931)\taccu 42.188 (50.848)\n",
      "Epoch-49  46.1s\tTrain: loss 0.6932\taccu 50.6410\tValid: loss 0.6932\taccu 50.0000\n",
      "Epoch 49: val_acc did not improve\n",
      "49 0.001\n",
      "Epoch-50   20 batches\tloss 0.6936 (0.6933)\taccu 56.250 (48.438)\n",
      "Epoch-50   40 batches\tloss 0.6940 (0.6934)\taccu 43.750 (49.688)\n",
      "Epoch-50   60 batches\tloss 0.6921 (0.6933)\taccu 54.688 (50.208)\n",
      "Epoch-50   80 batches\tloss 0.6927 (0.6932)\taccu 51.562 (50.195)\n",
      "Epoch-50  100 batches\tloss 0.6943 (0.6932)\taccu 67.188 (50.469)\n",
      "Epoch-50  120 batches\tloss 0.6968 (0.6932)\taccu 51.562 (50.365)\n",
      "Epoch-50  140 batches\tloss 0.6939 (0.6933)\taccu 45.312 (49.978)\n",
      "Epoch-50  46.6s\tTrain: loss 0.6932\taccu 50.1703\tValid: loss 0.6932\taccu 50.0501\n",
      "Epoch 50: val_acc did not improve\n",
      "50 0.001\n",
      "Epoch-51   20 batches\tloss 0.6919 (0.6927)\taccu 54.688 (50.312)\n",
      "Epoch-51   40 batches\tloss 0.6946 (0.6929)\taccu 40.625 (50.195)\n",
      "Epoch-51   60 batches\tloss 0.6936 (0.6931)\taccu 54.688 (49.740)\n",
      "Epoch-51   80 batches\tloss 0.6915 (0.6932)\taccu 59.375 (49.824)\n",
      "Epoch-51  100 batches\tloss 0.6945 (0.6932)\taccu 46.875 (49.891)\n",
      "Epoch-51  120 batches\tloss 0.6948 (0.6934)\taccu 50.000 (49.688)\n",
      "Epoch-51  140 batches\tloss 0.6923 (0.6936)\taccu 50.000 (49.632)\n",
      "Epoch-51  43.6s\tTrain: loss 0.6936\taccu 49.6595\tValid: loss 0.6931\taccu 49.8998\n",
      "Epoch 51: val_acc did not improve\n",
      "51 0.001\n",
      "Epoch-52   20 batches\tloss 0.6946 (0.6928)\taccu 54.688 (51.172)\n",
      "Epoch-52   40 batches\tloss 0.6921 (0.6937)\taccu 53.125 (49.805)\n",
      "Epoch-52   60 batches\tloss 0.6905 (0.6935)\taccu 48.438 (50.104)\n",
      "Epoch-52   80 batches\tloss 0.6901 (0.6935)\taccu 59.375 (50.957)\n",
      "Epoch-52  100 batches\tloss 0.6945 (0.6936)\taccu 50.000 (50.734)\n",
      "Epoch-52  120 batches\tloss 0.6938 (0.6937)\taccu 50.000 (50.339)\n",
      "Epoch-52  140 batches\tloss 0.6913 (0.6936)\taccu 50.000 (50.379)\n",
      "Epoch-52  45.4s\tTrain: loss 0.6936\taccu 50.1803\tValid: loss 0.6932\taccu 50.1502\n",
      "Epoch 52: val_acc did not improve\n",
      "52 0.001\n",
      "Epoch-53   20 batches\tloss 0.6924 (0.6929)\taccu 56.250 (52.266)\n",
      "Epoch-53   40 batches\tloss 0.6931 (0.6934)\taccu 46.875 (51.328)\n",
      "Epoch-53   60 batches\tloss 0.6937 (0.6933)\taccu 43.750 (50.365)\n",
      "Epoch-53   80 batches\tloss 0.6922 (0.6933)\taccu 50.000 (49.980)\n",
      "Epoch-53  100 batches\tloss 0.6938 (0.6933)\taccu 48.438 (49.703)\n",
      "Epoch-53  120 batches\tloss 0.6923 (0.6933)\taccu 57.812 (49.922)\n",
      "Epoch-53  140 batches\tloss 0.6932 (0.6934)\taccu 54.688 (49.688)\n",
      "Epoch-53  43.1s\tTrain: loss 0.6933\taccu 49.8898\tValid: loss 0.6934\taccu 50.3706\n",
      "Epoch 53: val_acc did not improve\n",
      "53 0.001\n",
      "Epoch-54   20 batches\tloss 0.7013 (0.6932)\taccu 43.750 (50.938)\n",
      "Epoch-54   40 batches\tloss 0.6954 (0.6937)\taccu 37.500 (49.023)\n",
      "Epoch-54   60 batches\tloss 0.6934 (0.6935)\taccu 48.438 (49.583)\n",
      "Epoch-54   80 batches\tloss 0.6935 (0.6934)\taccu 53.125 (50.078)\n",
      "Epoch-54  100 batches\tloss 0.6934 (0.6932)\taccu 53.125 (50.938)\n",
      "Epoch-54  120 batches\tloss 0.6959 (0.6932)\taccu 39.062 (50.781)\n",
      "Epoch-54  140 batches\tloss 0.6938 (0.6933)\taccu 46.875 (50.513)\n",
      "Epoch-54  44.1s\tTrain: loss 0.6933\taccu 50.2404\tValid: loss 0.6933\taccu 50.4407\n",
      "Epoch 54: val_acc did not improve\n",
      "54 0.001\n",
      "Epoch-55   20 batches\tloss 0.6931 (0.6929)\taccu 51.562 (52.344)\n",
      "Epoch-55   40 batches\tloss 0.6917 (0.6931)\taccu 60.938 (51.133)\n",
      "Epoch-55   60 batches\tloss 0.6961 (0.6928)\taccu 48.438 (51.875)\n",
      "Epoch-55   80 batches\tloss 0.6945 (0.6929)\taccu 48.438 (51.523)\n",
      "Epoch-55  100 batches\tloss 0.6891 (0.6930)\taccu 62.500 (51.375)\n",
      "Epoch-55  120 batches\tloss 0.6985 (0.6929)\taccu 48.438 (51.237)\n",
      "Epoch-55  140 batches\tloss 0.6962 (0.6930)\taccu 40.625 (50.982)\n",
      "Epoch-55  43.0s\tTrain: loss 0.6930\taccu 50.9816\tValid: loss 0.6932\taccu 50.2204\n",
      "Epoch 55: val_acc did not improve\n",
      "55 0.001\n",
      "Epoch-56   20 batches\tloss 0.6918 (0.6935)\taccu 56.250 (48.828)\n",
      "Epoch-56   40 batches\tloss 0.6952 (0.6934)\taccu 40.625 (49.766)\n",
      "Epoch-56   60 batches\tloss 0.6936 (0.6934)\taccu 51.562 (49.479)\n",
      "Epoch-56   80 batches\tloss 0.6928 (0.6935)\taccu 51.562 (49.512)\n",
      "Epoch-56  100 batches\tloss 0.6930 (0.6934)\taccu 42.188 (49.531)\n",
      "Epoch-56  120 batches\tloss 0.6907 (0.6934)\taccu 53.125 (49.766)\n",
      "Epoch-56  140 batches\tloss 0.6880 (0.6933)\taccu 67.188 (50.123)\n",
      "Epoch-56  42.3s\tTrain: loss 0.6934\taccu 49.9900\tValid: loss 0.6933\taccu 50.0801\n",
      "Epoch 56: val_acc did not improve\n",
      "56 0.001\n",
      "Epoch-57   20 batches\tloss 0.6945 (0.6935)\taccu 50.000 (48.906)\n",
      "Epoch-57   40 batches\tloss 0.6909 (0.6934)\taccu 54.688 (49.492)\n",
      "Epoch-57   60 batches\tloss 0.6950 (0.6933)\taccu 56.250 (50.104)\n",
      "Epoch-57   80 batches\tloss 0.6954 (0.6934)\taccu 40.625 (49.688)\n",
      "Epoch-57  100 batches\tloss 0.6911 (0.6933)\taccu 45.312 (49.891)\n",
      "Epoch-57  120 batches\tloss 0.6945 (0.6933)\taccu 48.438 (50.130)\n",
      "Epoch-57  140 batches\tloss 0.6922 (0.6933)\taccu 56.250 (50.324)\n",
      "Epoch-57  42.6s\tTrain: loss 0.6933\taccu 50.3005\tValid: loss 0.6934\taccu 50.0801\n",
      "Epoch 57: val_acc did not improve\n",
      "57 0.001\n",
      "Epoch-58   20 batches\tloss 0.6944 (0.6931)\taccu 42.188 (50.938)\n",
      "Epoch-58   40 batches\tloss 0.6922 (0.6931)\taccu 56.250 (50.625)\n",
      "Epoch-58   60 batches\tloss 0.6911 (0.6928)\taccu 56.250 (51.458)\n",
      "Epoch-58   80 batches\tloss 0.6936 (0.6931)\taccu 51.562 (51.426)\n",
      "Epoch-58  100 batches\tloss 0.6962 (0.6931)\taccu 48.438 (51.547)\n",
      "Epoch-58  120 batches\tloss 0.6937 (0.6932)\taccu 53.125 (51.133)\n",
      "Epoch-58  140 batches\tloss 0.6919 (0.6931)\taccu 53.125 (51.228)\n",
      "Epoch-58  45.2s\tTrain: loss 0.6931\taccu 51.0617\tValid: loss 0.6932\taccu 50.3606\n",
      "Epoch 58: val_acc did not improve\n",
      "58 0.001\n",
      "Epoch-59   20 batches\tloss 0.6898 (0.6930)\taccu 56.250 (49.609)\n",
      "Epoch-59   40 batches\tloss 0.6928 (0.6932)\taccu 46.875 (49.531)\n",
      "Epoch-59   60 batches\tloss 0.6928 (0.6933)\taccu 51.562 (49.297)\n",
      "Epoch-59   80 batches\tloss 0.6925 (0.6932)\taccu 53.125 (49.824)\n",
      "Epoch-59  100 batches\tloss 0.6936 (0.6931)\taccu 48.438 (50.188)\n",
      "Epoch-59  120 batches\tloss 0.6876 (0.6929)\taccu 60.938 (50.755)\n",
      "Epoch-59  140 batches\tloss 0.6917 (0.6928)\taccu 46.875 (50.848)\n",
      "Epoch-59  44.1s\tTrain: loss 0.6930\taccu 50.6110\tValid: loss 0.6932\taccu 50.0300\n",
      "Epoch 59: val_acc did not improve\n",
      "59 0.001\n",
      "Epoch-60   20 batches\tloss 0.6926 (0.6933)\taccu 51.562 (51.094)\n",
      "Epoch-60   40 batches\tloss 0.6986 (0.6929)\taccu 51.562 (51.211)\n",
      "Epoch-60   60 batches\tloss 0.6956 (0.6931)\taccu 43.750 (51.406)\n",
      "Epoch-60   80 batches\tloss 0.6930 (0.6930)\taccu 53.125 (51.699)\n",
      "Epoch-60  100 batches\tloss 0.6940 (0.6931)\taccu 56.250 (51.531)\n",
      "Epoch-60  120 batches\tloss 0.6933 (0.6932)\taccu 50.000 (51.276)\n",
      "Epoch-60  140 batches\tloss 0.6937 (0.6932)\taccu 48.438 (50.960)\n",
      "Epoch-60  45.5s\tTrain: loss 0.6932\taccu 50.8313\tValid: loss 0.6933\taccu 50.0200\n",
      "Epoch 60: val_acc did not improve\n",
      "60 0.0001\n",
      "Epoch-61   20 batches\tloss 0.6925 (0.6931)\taccu 56.250 (50.234)\n",
      "Epoch-61   40 batches\tloss 0.6920 (0.6930)\taccu 53.125 (51.016)\n",
      "Epoch-61   60 batches\tloss 0.6935 (0.6930)\taccu 53.125 (50.964)\n",
      "Epoch-61   80 batches\tloss 0.6928 (0.6930)\taccu 54.688 (50.996)\n",
      "Epoch-61  100 batches\tloss 0.6939 (0.6930)\taccu 51.562 (51.062)\n",
      "Epoch-61  120 batches\tloss 0.6923 (0.6931)\taccu 51.562 (50.599)\n",
      "Epoch-61  140 batches\tloss 0.6939 (0.6931)\taccu 48.438 (50.525)\n",
      "Epoch-61  45.0s\tTrain: loss 0.6931\taccu 50.6210\tValid: loss 0.6932\taccu 49.5292\n",
      "Epoch 61: val_acc did not improve\n",
      "61 0.0001\n",
      "Epoch-62   20 batches\tloss 0.6931 (0.6930)\taccu 54.688 (51.328)\n",
      "Epoch-62   40 batches\tloss 0.6934 (0.6932)\taccu 45.312 (50.312)\n",
      "Epoch-62   60 batches\tloss 0.6933 (0.6930)\taccu 45.312 (51.693)\n",
      "Epoch-62   80 batches\tloss 0.6941 (0.6929)\taccu 46.875 (51.953)\n",
      "Epoch-62  100 batches\tloss 0.6925 (0.6929)\taccu 53.125 (51.828)\n",
      "Epoch-62  120 batches\tloss 0.6939 (0.6930)\taccu 54.688 (51.667)\n",
      "Epoch-62  140 batches\tloss 0.6925 (0.6930)\taccu 54.688 (51.283)\n",
      "Epoch-62  205.4s\tTrain: loss 0.6930\taccu 51.2420\tValid: loss 0.6932\taccu 49.3790\n",
      "Epoch 62: val_acc did not improve\n",
      "62 0.0001\n",
      "Epoch-63   20 batches\tloss 0.6931 (0.6929)\taccu 53.125 (51.250)\n",
      "Epoch-63   40 batches\tloss 0.6934 (0.6929)\taccu 51.562 (51.953)\n",
      "Epoch-63   60 batches\tloss 0.6932 (0.6929)\taccu 53.125 (51.927)\n",
      "Epoch-63   80 batches\tloss 0.6941 (0.6929)\taccu 39.062 (51.875)\n",
      "Epoch-63  100 batches\tloss 0.6929 (0.6928)\taccu 48.438 (51.828)\n",
      "Epoch-63  120 batches\tloss 0.6918 (0.6928)\taccu 56.250 (52.161)\n",
      "Epoch-63  140 batches\tloss 0.6936 (0.6929)\taccu 45.312 (51.708)\n",
      "Epoch-63  116.6s\tTrain: loss 0.6929\taccu 51.8129\tValid: loss 0.6932\taccu 49.9900\n",
      "Epoch 63: val_acc did not improve\n",
      "63 0.0001\n",
      "Epoch-64   20 batches\tloss 0.6909 (0.6924)\taccu 62.500 (54.141)\n",
      "Epoch-64   40 batches\tloss 0.6932 (0.6924)\taccu 59.375 (52.891)\n",
      "Epoch-64   60 batches\tloss 0.6944 (0.6924)\taccu 40.625 (52.786)\n",
      "Epoch-64   80 batches\tloss 0.6941 (0.6928)\taccu 46.875 (51.602)\n",
      "Epoch-64  100 batches\tloss 0.6915 (0.6929)\taccu 50.000 (51.250)\n",
      "Epoch-64  120 batches\tloss 0.6907 (0.6928)\taccu 57.812 (51.445)\n",
      "Epoch-64  140 batches\tloss 0.6954 (0.6928)\taccu 46.875 (51.540)\n",
      "Epoch-64  130.8s\tTrain: loss 0.6928\taccu 51.3221\tValid: loss 0.6933\taccu 49.6595\n",
      "Epoch 64: val_acc did not improve\n",
      "64 0.0001\n",
      "Epoch-65   20 batches\tloss 0.6910 (0.6928)\taccu 53.125 (50.391)\n",
      "Epoch-65   40 batches\tloss 0.6942 (0.6927)\taccu 50.000 (50.781)\n",
      "Epoch-65   60 batches\tloss 0.6952 (0.6928)\taccu 60.938 (51.198)\n",
      "Epoch-65   80 batches\tloss 0.6944 (0.6927)\taccu 51.562 (51.504)\n",
      "Epoch-65  100 batches\tloss 0.6958 (0.6928)\taccu 39.062 (51.500)\n",
      "Epoch-65  120 batches\tloss 0.6901 (0.6928)\taccu 60.938 (51.484)\n",
      "Epoch-65  140 batches\tloss 0.6912 (0.6927)\taccu 54.688 (51.417)\n",
      "Epoch-65  109.1s\tTrain: loss 0.6927\taccu 51.4123\tValid: loss 0.6933\taccu 49.8998\n",
      "Epoch 65: val_acc did not improve\n",
      "65 0.0001\n",
      "Epoch-66   20 batches\tloss 0.6941 (0.6933)\taccu 48.438 (50.547)\n",
      "Epoch-66   40 batches\tloss 0.6916 (0.6934)\taccu 51.562 (50.430)\n",
      "Epoch-66   60 batches\tloss 0.6924 (0.6929)\taccu 50.000 (51.276)\n",
      "Epoch-66   80 batches\tloss 0.6945 (0.6928)\taccu 46.875 (51.738)\n",
      "Epoch-66  100 batches\tloss 0.6923 (0.6927)\taccu 42.188 (51.734)\n",
      "Epoch-66  120 batches\tloss 0.6934 (0.6927)\taccu 53.125 (51.927)\n",
      "Epoch-66  140 batches\tloss 0.6944 (0.6926)\taccu 46.875 (52.109)\n",
      "Epoch-66  121.7s\tTrain: loss 0.6926\taccu 51.9431\tValid: loss 0.6934\taccu 49.9800\n",
      "Epoch 66: val_acc did not improve\n",
      "66 0.0001\n",
      "Epoch-67   20 batches\tloss 0.6897 (0.6918)\taccu 57.812 (54.688)\n",
      "Epoch-67   40 batches\tloss 0.6890 (0.6924)\taccu 59.375 (53.203)\n",
      "Epoch-67   60 batches\tloss 0.6899 (0.6920)\taccu 50.000 (53.724)\n",
      "Epoch-67   80 batches\tloss 0.6972 (0.6923)\taccu 53.125 (53.125)\n",
      "Epoch-67  100 batches\tloss 0.6899 (0.6924)\taccu 59.375 (52.891)\n",
      "Epoch-67  120 batches\tloss 0.6924 (0.6926)\taccu 50.000 (52.370)\n",
      "Epoch-67  140 batches\tloss 0.6899 (0.6926)\taccu 57.812 (52.288)\n",
      "Epoch-67  141.2s\tTrain: loss 0.6926\taccu 52.1534\tValid: loss 0.6935\taccu 50.0100\n",
      "Epoch 67: val_acc did not improve\n",
      "67 0.0001\n",
      "Epoch-68   20 batches\tloss 0.6937 (0.6925)\taccu 50.000 (51.250)\n",
      "Epoch-68   40 batches\tloss 0.6960 (0.6924)\taccu 50.000 (52.305)\n",
      "Epoch-68   60 batches\tloss 0.6912 (0.6925)\taccu 53.125 (51.667)\n",
      "Epoch-68   80 batches\tloss 0.6899 (0.6926)\taccu 56.250 (51.484)\n",
      "Epoch-68  100 batches\tloss 0.6946 (0.6924)\taccu 50.000 (51.891)\n",
      "Epoch-68  120 batches\tloss 0.6921 (0.6925)\taccu 54.688 (51.992)\n",
      "Epoch-68  140 batches\tloss 0.6871 (0.6924)\taccu 56.250 (51.964)\n",
      "Epoch-68  127.3s\tTrain: loss 0.6926\taccu 51.7929\tValid: loss 0.6935\taccu 50.0501\n",
      "Epoch 68: val_acc did not improve\n",
      "68 0.0001\n",
      "Epoch-69   20 batches\tloss 0.6911 (0.6916)\taccu 50.000 (53.281)\n",
      "Epoch-69   40 batches\tloss 0.6937 (0.6922)\taccu 53.125 (53.086)\n",
      "Epoch-69   60 batches\tloss 0.6914 (0.6927)\taccu 57.812 (52.422)\n",
      "Epoch-69   80 batches\tloss 0.6931 (0.6925)\taccu 50.000 (52.676)\n",
      "Epoch-69  100 batches\tloss 0.6942 (0.6924)\taccu 56.250 (52.734)\n",
      "Epoch-69  120 batches\tloss 0.6933 (0.6924)\taccu 59.375 (52.747)\n",
      "Epoch-69  140 batches\tloss 0.6937 (0.6926)\taccu 45.312 (52.188)\n",
      "Epoch-69  103.1s\tTrain: loss 0.6926\taccu 52.1334\tValid: loss 0.6935\taccu 50.3906\n",
      "Epoch 69: val_acc did not improve\n",
      "69 0.0001\n",
      "Epoch-70   20 batches\tloss 0.6918 (0.6926)\taccu 51.562 (51.562)\n",
      "Epoch-70   40 batches\tloss 0.6961 (0.6927)\taccu 48.438 (51.953)\n",
      "Epoch-70   60 batches\tloss 0.6976 (0.6927)\taccu 45.312 (51.615)\n",
      "Epoch-70   80 batches\tloss 0.6901 (0.6925)\taccu 50.000 (52.188)\n",
      "Epoch-70  100 batches\tloss 0.6918 (0.6925)\taccu 48.438 (52.422)\n",
      "Epoch-70  120 batches\tloss 0.6935 (0.6924)\taccu 43.750 (52.578)\n",
      "Epoch-70  140 batches\tloss 0.6913 (0.6925)\taccu 54.688 (52.109)\n",
      "Epoch-70  87.5s\tTrain: loss 0.6925\taccu 52.1534\tValid: loss 0.6935\taccu 50.1302\n",
      "Epoch 70: val_acc did not improve\n",
      "70 0.0001\n",
      "Epoch-71   20 batches\tloss 0.6874 (0.6920)\taccu 57.812 (52.188)\n",
      "Epoch-71   40 batches\tloss 0.6923 (0.6922)\taccu 51.562 (52.188)\n",
      "Epoch-71   60 batches\tloss 0.6893 (0.6924)\taccu 64.062 (51.771)\n",
      "Epoch-71   80 batches\tloss 0.6856 (0.6926)\taccu 60.938 (51.348)\n",
      "Epoch-71  100 batches\tloss 0.6942 (0.6924)\taccu 43.750 (51.844)\n",
      "Epoch-71  120 batches\tloss 0.6907 (0.6923)\taccu 62.500 (52.031)\n",
      "Epoch-71  140 batches\tloss 0.6934 (0.6924)\taccu 51.562 (51.652)\n",
      "Epoch-71  46.0s\tTrain: loss 0.6925\taccu 51.7528\tValid: loss 0.6935\taccu 50.5008\n",
      "Epoch 71: val_acc did not improve\n",
      "71 0.0001\n",
      "Epoch-72   20 batches\tloss 0.6903 (0.6924)\taccu 50.000 (51.953)\n",
      "Epoch-72   40 batches\tloss 0.6937 (0.6922)\taccu 56.250 (52.539)\n",
      "Epoch-72   60 batches\tloss 0.6953 (0.6919)\taccu 46.875 (53.542)\n",
      "Epoch-72   80 batches\tloss 0.6883 (0.6920)\taccu 56.250 (53.203)\n",
      "Epoch-72  100 batches\tloss 0.6917 (0.6920)\taccu 48.438 (52.812)\n",
      "Epoch-72  120 batches\tloss 0.6962 (0.6923)\taccu 48.438 (52.240)\n",
      "Epoch-72  140 batches\tloss 0.6918 (0.6925)\taccu 51.562 (51.953)\n",
      "Epoch-72  49.3s\tTrain: loss 0.6925\taccu 51.9832\tValid: loss 0.6935\taccu 50.1302\n",
      "Epoch 72: val_acc did not improve\n",
      "72 0.0001\n",
      "Epoch-73   20 batches\tloss 0.6951 (0.6925)\taccu 46.875 (51.484)\n",
      "Epoch-73   40 batches\tloss 0.6896 (0.6921)\taccu 51.562 (51.992)\n",
      "Epoch-73   60 batches\tloss 0.6897 (0.6923)\taccu 60.938 (51.875)\n",
      "Epoch-73   80 batches\tloss 0.6864 (0.6922)\taccu 60.938 (51.953)\n",
      "Epoch-73  100 batches\tloss 0.6890 (0.6924)\taccu 59.375 (51.750)\n",
      "Epoch-73  120 batches\tloss 0.6902 (0.6923)\taccu 60.938 (52.096)\n",
      "Epoch-73  140 batches\tloss 0.6959 (0.6924)\taccu 42.188 (51.987)\n",
      "Epoch-73  149.7s\tTrain: loss 0.6925\taccu 51.7728\tValid: loss 0.6935\taccu 50.0401\n",
      "Epoch 73: val_acc did not improve\n",
      "73 0.0001\n",
      "Epoch-74   20 batches\tloss 0.6938 (0.6922)\taccu 48.438 (52.422)\n",
      "Epoch-74   40 batches\tloss 0.6899 (0.6920)\taccu 64.062 (52.695)\n",
      "Epoch-74   60 batches\tloss 0.6897 (0.6923)\taccu 56.250 (52.552)\n",
      "Epoch-74   80 batches\tloss 0.6895 (0.6922)\taccu 51.562 (52.637)\n",
      "Epoch-74  100 batches\tloss 0.6906 (0.6923)\taccu 56.250 (52.547)\n",
      "Epoch-74  120 batches\tloss 0.6921 (0.6924)\taccu 45.312 (52.161)\n",
      "Epoch-74  140 batches\tloss 0.6942 (0.6925)\taccu 48.438 (52.154)\n",
      "Epoch-74  94.1s\tTrain: loss 0.6924\taccu 52.1735\tValid: loss 0.6935\taccu 49.9800\n",
      "Epoch 74: val_acc did not improve\n",
      "74 0.0001\n",
      "Epoch-75   20 batches\tloss 0.6913 (0.6924)\taccu 54.688 (51.406)\n",
      "Epoch-75   40 batches\tloss 0.6919 (0.6919)\taccu 51.562 (52.344)\n",
      "Epoch-75   60 batches\tloss 0.6898 (0.6921)\taccu 59.375 (52.422)\n",
      "Epoch-75   80 batches\tloss 0.6924 (0.6921)\taccu 45.312 (52.168)\n",
      "Epoch-75  100 batches\tloss 0.6880 (0.6920)\taccu 59.375 (52.375)\n",
      "Epoch-75  120 batches\tloss 0.6927 (0.6922)\taccu 45.312 (52.383)\n",
      "Epoch-75  140 batches\tloss 0.6902 (0.6922)\taccu 53.125 (52.433)\n",
      "Epoch-75  102.7s\tTrain: loss 0.6923\taccu 52.3938\tValid: loss 0.6935\taccu 50.4307\n",
      "Epoch 75: val_acc did not improve\n",
      "75 0.0001\n",
      "Epoch-76   20 batches\tloss 0.6939 (0.6930)\taccu 54.688 (53.047)\n",
      "Epoch-76   40 batches\tloss 0.6925 (0.6929)\taccu 54.688 (52.539)\n",
      "Epoch-76   60 batches\tloss 0.6900 (0.6928)\taccu 59.375 (52.891)\n",
      "Epoch-76   80 batches\tloss 0.6911 (0.6925)\taccu 53.125 (53.105)\n",
      "Epoch-76  100 batches\tloss 0.6932 (0.6924)\taccu 50.000 (52.812)\n",
      "Epoch-76  120 batches\tloss 0.6937 (0.6925)\taccu 48.438 (52.357)\n",
      "Epoch-76  140 batches\tloss 0.6910 (0.6926)\taccu 57.812 (52.243)\n",
      "Epoch-76  97.3s\tTrain: loss 0.6925\taccu 52.2937\tValid: loss 0.6934\taccu 50.5108\n",
      "Epoch 76: val_acc did not improve\n",
      "76 0.0001\n",
      "Epoch-77   20 batches\tloss 0.6952 (0.6922)\taccu 50.000 (53.281)\n",
      "Epoch-77   40 batches\tloss 0.6997 (0.6925)\taccu 48.438 (52.617)\n",
      "Epoch-77   60 batches\tloss 0.6872 (0.6921)\taccu 67.188 (53.047)\n",
      "Epoch-77   80 batches\tloss 0.6909 (0.6919)\taccu 57.812 (53.027)\n",
      "Epoch-77  100 batches\tloss 0.6904 (0.6921)\taccu 51.562 (52.812)\n",
      "Epoch-77  120 batches\tloss 0.6881 (0.6922)\taccu 59.375 (52.695)\n",
      "Epoch-77  140 batches\tloss 0.7011 (0.6923)\taccu 40.625 (52.455)\n",
      "Epoch-77  117.2s\tTrain: loss 0.6923\taccu 52.4439\tValid: loss 0.6936\taccu 50.0200\n",
      "Epoch 77: val_acc did not improve\n",
      "77 0.0001\n",
      "Epoch-78   20 batches\tloss 0.6904 (0.6915)\taccu 54.688 (53.516)\n",
      "Epoch-78   40 batches\tloss 0.6908 (0.6919)\taccu 56.250 (52.812)\n",
      "Epoch-78   60 batches\tloss 0.6928 (0.6923)\taccu 56.250 (52.500)\n",
      "Epoch-78   80 batches\tloss 0.6896 (0.6922)\taccu 48.438 (52.422)\n",
      "Epoch-78  100 batches\tloss 0.6949 (0.6921)\taccu 56.250 (52.812)\n",
      "Epoch-78  120 batches\tloss 0.6915 (0.6922)\taccu 50.000 (52.513)\n",
      "Epoch-78  140 batches\tloss 0.6903 (0.6922)\taccu 51.562 (52.667)\n",
      "Epoch-78  104.5s\tTrain: loss 0.6923\taccu 52.4740\tValid: loss 0.6935\taccu 50.6010\n",
      "Epoch 78: val_acc did not improve\n",
      "78 0.0001\n",
      "Epoch-79   20 batches\tloss 0.6901 (0.6921)\taccu 53.125 (51.641)\n",
      "Epoch-79   40 batches\tloss 0.6946 (0.6920)\taccu 43.750 (52.266)\n",
      "Epoch-79   60 batches\tloss 0.6950 (0.6924)\taccu 45.312 (50.781)\n",
      "Epoch-79   80 batches\tloss 0.6916 (0.6922)\taccu 50.000 (51.367)\n",
      "Epoch-79  100 batches\tloss 0.6920 (0.6920)\taccu 57.812 (51.734)\n",
      "Epoch-79  120 batches\tloss 0.6927 (0.6921)\taccu 50.000 (51.836)\n",
      "Epoch-79  140 batches\tloss 0.6954 (0.6922)\taccu 43.750 (52.020)\n",
      "Epoch-79  116.7s\tTrain: loss 0.6921\taccu 52.3237\tValid: loss 0.6935\taccu 50.5609\n",
      "Epoch 79: val_acc did not improve\n",
      "79 0.0001\n",
      "Epoch-80   20 batches\tloss 0.6899 (0.6921)\taccu 54.688 (53.281)\n",
      "Epoch-80   40 batches\tloss 0.6949 (0.6920)\taccu 48.438 (53.750)\n",
      "Epoch-80   60 batches\tloss 0.6971 (0.6921)\taccu 45.312 (53.464)\n",
      "Epoch-80   80 batches\tloss 0.6935 (0.6920)\taccu 50.000 (53.203)\n",
      "Epoch-80  100 batches\tloss 0.6995 (0.6919)\taccu 39.062 (53.219)\n",
      "Epoch-80  120 batches\tloss 0.6964 (0.6919)\taccu 51.562 (53.034)\n",
      "Epoch-80  140 batches\tloss 0.6931 (0.6921)\taccu 48.438 (52.545)\n",
      "Epoch-80  113.6s\tTrain: loss 0.6921\taccu 52.4639\tValid: loss 0.6936\taccu 50.5108\n",
      "Epoch 80: val_acc did not improve\n",
      "80 0.0001\n",
      "Epoch-81   20 batches\tloss 0.6910 (0.6932)\taccu 53.125 (49.844)\n",
      "Epoch-81   40 batches\tloss 0.6923 (0.6923)\taccu 48.438 (51.758)\n",
      "Epoch-81   60 batches\tloss 0.6945 (0.6917)\taccu 50.000 (53.021)\n",
      "Epoch-81   80 batches\tloss 0.6930 (0.6917)\taccu 46.875 (53.301)\n",
      "Epoch-81  100 batches\tloss 0.6884 (0.6917)\taccu 56.250 (53.016)\n",
      "Epoch-81  120 batches\tloss 0.6971 (0.6918)\taccu 42.188 (52.643)\n",
      "Epoch-81  140 batches\tloss 0.6877 (0.6922)\taccu 57.812 (52.600)\n",
      "Epoch-81  123.8s\tTrain: loss 0.6920\taccu 52.8045\tValid: loss 0.6936\taccu 50.4407\n",
      "Epoch 81: val_acc did not improve\n",
      "81 0.0001\n",
      "Epoch-82   20 batches\tloss 0.6929 (0.6935)\taccu 51.562 (50.469)\n",
      "Epoch-82   40 batches\tloss 0.6902 (0.6931)\taccu 50.000 (50.703)\n",
      "Epoch-82   60 batches\tloss 0.6911 (0.6929)\taccu 50.000 (51.068)\n",
      "Epoch-82   80 batches\tloss 0.6999 (0.6928)\taccu 42.188 (51.484)\n",
      "Epoch-82  100 batches\tloss 0.6941 (0.6927)\taccu 46.875 (51.406)\n",
      "Epoch-82  120 batches\tloss 0.6935 (0.6925)\taccu 50.000 (51.953)\n",
      "Epoch-82  140 batches\tloss 0.6964 (0.6923)\taccu 45.312 (52.087)\n",
      "Epoch-82  126.1s\tTrain: loss 0.6923\taccu 52.0032\tValid: loss 0.6935\taccu 50.4107\n",
      "Epoch 82: val_acc did not improve\n",
      "82 0.0001\n",
      "Epoch-83   20 batches\tloss 0.6905 (0.6913)\taccu 56.250 (53.828)\n",
      "Epoch-83   40 batches\tloss 0.6864 (0.6923)\taccu 59.375 (53.164)\n",
      "Epoch-83   60 batches\tloss 0.6916 (0.6924)\taccu 53.125 (52.734)\n",
      "Epoch-83   80 batches\tloss 0.6934 (0.6924)\taccu 56.250 (52.539)\n",
      "Epoch-83  100 batches\tloss 0.6969 (0.6924)\taccu 45.312 (52.219)\n",
      "Epoch-83  120 batches\tloss 0.6901 (0.6923)\taccu 57.812 (52.513)\n",
      "Epoch-83  140 batches\tloss 0.6878 (0.6920)\taccu 62.500 (52.679)\n",
      "Epoch-83  51.1s\tTrain: loss 0.6920\taccu 52.6943\tValid: loss 0.6938\taccu 50.3806\n",
      "Epoch 83: val_acc did not improve\n",
      "83 0.0001\n",
      "Epoch-84   20 batches\tloss 0.6897 (0.6925)\taccu 57.812 (52.031)\n",
      "Epoch-84   40 batches\tloss 0.6908 (0.6925)\taccu 56.250 (51.641)\n",
      "Epoch-84   60 batches\tloss 0.6939 (0.6921)\taccu 46.875 (52.109)\n",
      "Epoch-84   80 batches\tloss 0.6928 (0.6920)\taccu 53.125 (52.637)\n",
      "Epoch-84  100 batches\tloss 0.6922 (0.6923)\taccu 51.562 (52.016)\n",
      "Epoch-84  120 batches\tloss 0.6953 (0.6923)\taccu 46.875 (52.083)\n",
      "Epoch-84  140 batches\tloss 0.6888 (0.6921)\taccu 54.688 (52.545)\n",
      "Epoch-84  45.4s\tTrain: loss 0.6920\taccu 52.4239\tValid: loss 0.6938\taccu 50.0000\n",
      "Epoch 84: val_acc did not improve\n",
      "84 0.0001\n",
      "Epoch-85   20 batches\tloss 0.7036 (0.6935)\taccu 40.625 (52.031)\n",
      "Epoch-85   40 batches\tloss 0.6904 (0.6926)\taccu 45.312 (52.070)\n",
      "Epoch-85   60 batches\tloss 0.6878 (0.6922)\taccu 57.812 (52.656)\n",
      "Epoch-85   80 batches\tloss 0.6983 (0.6919)\taccu 48.438 (52.695)\n",
      "Epoch-85  100 batches\tloss 0.6844 (0.6918)\taccu 60.938 (52.797)\n",
      "Epoch-85  120 batches\tloss 0.6895 (0.6918)\taccu 54.688 (52.865)\n",
      "Epoch-85  140 batches\tloss 0.6943 (0.6921)\taccu 54.688 (52.545)\n",
      "Epoch-85  43.5s\tTrain: loss 0.6922\taccu 52.4840\tValid: loss 0.6937\taccu 50.2905\n",
      "Epoch 85: val_acc did not improve\n",
      "85 0.0001\n",
      "Epoch-86   20 batches\tloss 0.6873 (0.6909)\taccu 53.125 (53.828)\n",
      "Epoch-86   40 batches\tloss 0.6908 (0.6914)\taccu 54.688 (53.516)\n",
      "Epoch-86   60 batches\tloss 0.6908 (0.6916)\taccu 53.125 (53.411)\n",
      "Epoch-86   80 batches\tloss 0.6980 (0.6918)\taccu 42.188 (53.223)\n",
      "Epoch-86  100 batches\tloss 0.6920 (0.6918)\taccu 50.000 (52.766)\n",
      "Epoch-86  120 batches\tloss 0.6906 (0.6918)\taccu 50.000 (52.708)\n",
      "Epoch-86  140 batches\tloss 0.6907 (0.6919)\taccu 54.688 (52.656)\n",
      "Epoch-86  42.0s\tTrain: loss 0.6920\taccu 52.5140\tValid: loss 0.6937\taccu 50.5809\n",
      "Epoch 86: val_acc did not improve\n",
      "86 0.0001\n",
      "Epoch-87   20 batches\tloss 0.6964 (0.6916)\taccu 42.188 (51.094)\n",
      "Epoch-87   40 batches\tloss 0.6925 (0.6922)\taccu 51.562 (51.523)\n",
      "Epoch-87   60 batches\tloss 0.6898 (0.6921)\taccu 53.125 (52.109)\n",
      "Epoch-87   80 batches\tloss 0.6947 (0.6926)\taccu 46.875 (51.445)\n",
      "Epoch-87  100 batches\tloss 0.6884 (0.6926)\taccu 57.812 (51.453)\n",
      "Epoch-87  120 batches\tloss 0.6973 (0.6925)\taccu 45.312 (51.784)\n",
      "Epoch-87  140 batches\tloss 0.6875 (0.6922)\taccu 57.812 (52.121)\n",
      "Epoch-87  41.7s\tTrain: loss 0.6921\taccu 52.2336\tValid: loss 0.6937\taccu 49.9099\n",
      "Epoch 87: val_acc did not improve\n",
      "87 0.0001\n",
      "Epoch-88   20 batches\tloss 0.7004 (0.6919)\taccu 43.750 (53.125)\n",
      "Epoch-88   40 batches\tloss 0.6923 (0.6915)\taccu 46.875 (53.164)\n",
      "Epoch-88   60 batches\tloss 0.6895 (0.6919)\taccu 57.812 (53.229)\n",
      "Epoch-88   80 batches\tloss 0.6980 (0.6919)\taccu 56.250 (53.203)\n",
      "Epoch-88  100 batches\tloss 0.6956 (0.6919)\taccu 54.688 (53.188)\n",
      "Epoch-88  120 batches\tloss 0.6923 (0.6921)\taccu 46.875 (53.151)\n",
      "Epoch-88  140 batches\tloss 0.6859 (0.6920)\taccu 57.812 (53.237)\n",
      "Epoch-88  42.5s\tTrain: loss 0.6921\taccu 52.9848\tValid: loss 0.6939\taccu 50.2003\n",
      "Epoch 88: val_acc did not improve\n",
      "88 0.0001\n",
      "Epoch-89   20 batches\tloss 0.6907 (0.6915)\taccu 53.125 (53.672)\n",
      "Epoch-89   40 batches\tloss 0.6862 (0.6915)\taccu 57.812 (52.500)\n",
      "Epoch-89   60 batches\tloss 0.6861 (0.6918)\taccu 48.438 (52.135)\n",
      "Epoch-89   80 batches\tloss 0.7011 (0.6922)\taccu 45.312 (51.816)\n",
      "Epoch-89  100 batches\tloss 0.6897 (0.6923)\taccu 54.688 (51.891)\n",
      "Epoch-89  120 batches\tloss 0.6915 (0.6922)\taccu 60.938 (52.253)\n",
      "Epoch-89  140 batches\tloss 0.6871 (0.6921)\taccu 62.500 (52.578)\n",
      "Epoch-89  41.6s\tTrain: loss 0.6921\taccu 52.4539\tValid: loss 0.6936\taccu 49.8498\n",
      "Epoch 89: val_acc did not improve\n",
      "89 0.0001\n",
      "Epoch-90   20 batches\tloss 0.6952 (0.6919)\taccu 48.438 (51.797)\n",
      "Epoch-90   40 batches\tloss 0.6951 (0.6922)\taccu 42.188 (51.719)\n",
      "Epoch-90   60 batches\tloss 0.6870 (0.6920)\taccu 59.375 (51.927)\n",
      "Epoch-90   80 batches\tloss 0.6862 (0.6917)\taccu 57.812 (52.598)\n",
      "Epoch-90  100 batches\tloss 0.6926 (0.6919)\taccu 43.750 (52.266)\n",
      "Epoch-90  120 batches\tloss 0.6886 (0.6920)\taccu 64.062 (52.227)\n",
      "Epoch-90  140 batches\tloss 0.6846 (0.6919)\taccu 60.938 (52.411)\n",
      "Epoch-90  40.9s\tTrain: loss 0.6919\taccu 52.4339\tValid: loss 0.6935\taccu 50.2604\n",
      "Epoch 90: val_acc did not improve\n",
      "90 1e-05\n",
      "Epoch-91   20 batches\tloss 0.6899 (0.6929)\taccu 53.125 (51.172)\n",
      "Epoch-91   40 batches\tloss 0.6948 (0.6916)\taccu 46.875 (52.773)\n",
      "Epoch-91   60 batches\tloss 0.6900 (0.6916)\taccu 56.250 (52.917)\n",
      "Epoch-91   80 batches\tloss 0.6893 (0.6914)\taccu 54.688 (53.281)\n",
      "Epoch-91  100 batches\tloss 0.6947 (0.6915)\taccu 50.000 (53.266)\n",
      "Epoch-91  120 batches\tloss 0.6896 (0.6919)\taccu 57.812 (52.656)\n",
      "Epoch-91  140 batches\tloss 0.6874 (0.6920)\taccu 59.375 (52.612)\n",
      "Epoch-91  41.2s\tTrain: loss 0.6920\taccu 52.5942\tValid: loss 0.6936\taccu 50.4607\n",
      "Epoch 91: val_acc did not improve\n",
      "91 1e-05\n",
      "Epoch-92   20 batches\tloss 0.6930 (0.6932)\taccu 48.438 (51.094)\n",
      "Epoch-92   40 batches\tloss 0.6906 (0.6916)\taccu 60.938 (53.164)\n",
      "Epoch-92   60 batches\tloss 0.6936 (0.6917)\taccu 48.438 (53.125)\n",
      "Epoch-92   80 batches\tloss 0.6965 (0.6919)\taccu 53.125 (52.598)\n",
      "Epoch-92  100 batches\tloss 0.6954 (0.6921)\taccu 51.562 (52.438)\n",
      "Epoch-92  120 batches\tloss 0.6955 (0.6922)\taccu 48.438 (52.539)\n",
      "Epoch-92  140 batches\tloss 0.6920 (0.6920)\taccu 56.250 (52.656)\n",
      "Epoch-92  43.3s\tTrain: loss 0.6922\taccu 52.4539\tValid: loss 0.6937\taccu 50.1502\n",
      "Epoch 92: val_acc did not improve\n",
      "92 1e-05\n",
      "Epoch-93   20 batches\tloss 0.6938 (0.6943)\taccu 50.000 (50.547)\n",
      "Epoch-93   40 batches\tloss 0.6915 (0.6932)\taccu 45.312 (50.547)\n",
      "Epoch-93   60 batches\tloss 0.6947 (0.6926)\taccu 45.312 (51.198)\n",
      "Epoch-93   80 batches\tloss 0.6837 (0.6922)\taccu 59.375 (51.777)\n",
      "Epoch-93  100 batches\tloss 0.6857 (0.6922)\taccu 59.375 (51.844)\n",
      "Epoch-93  120 batches\tloss 0.6909 (0.6921)\taccu 56.250 (51.875)\n",
      "Epoch-93  140 batches\tloss 0.7010 (0.6920)\taccu 37.500 (52.232)\n",
      "Epoch-93  44.5s\tTrain: loss 0.6919\taccu 52.4239\tValid: loss 0.6937\taccu 50.2604\n",
      "Epoch 93: val_acc did not improve\n",
      "93 1e-05\n",
      "Epoch-94   20 batches\tloss 0.6940 (0.6927)\taccu 48.438 (52.500)\n",
      "Epoch-94   40 batches\tloss 0.6948 (0.6925)\taccu 43.750 (52.539)\n",
      "Epoch-94   60 batches\tloss 0.6953 (0.6923)\taccu 40.625 (52.865)\n",
      "Epoch-94   80 batches\tloss 0.6999 (0.6923)\taccu 43.750 (52.871)\n",
      "Epoch-94  100 batches\tloss 0.6933 (0.6922)\taccu 51.562 (52.688)\n",
      "Epoch-94  120 batches\tloss 0.6922 (0.6922)\taccu 51.562 (52.956)\n",
      "Epoch-94  140 batches\tloss 0.6891 (0.6924)\taccu 53.125 (52.400)\n",
      "Epoch-94  44.8s\tTrain: loss 0.6922\taccu 52.5240\tValid: loss 0.6937\taccu 50.1803\n",
      "Epoch 94: val_acc did not improve\n",
      "94 1e-05\n",
      "Epoch-95   20 batches\tloss 0.6870 (0.6914)\taccu 56.250 (53.281)\n",
      "Epoch-95   40 batches\tloss 0.7036 (0.6911)\taccu 42.188 (53.789)\n",
      "Epoch-95   60 batches\tloss 0.6982 (0.6913)\taccu 48.438 (53.411)\n",
      "Epoch-95   80 batches\tloss 0.6968 (0.6919)\taccu 43.750 (52.832)\n",
      "Epoch-95  100 batches\tloss 0.6876 (0.6918)\taccu 56.250 (52.875)\n",
      "Epoch-95  120 batches\tloss 0.6890 (0.6917)\taccu 53.125 (52.904)\n",
      "Epoch-95  140 batches\tloss 0.6974 (0.6919)\taccu 45.312 (52.623)\n",
      "Epoch-95  42.2s\tTrain: loss 0.6920\taccu 52.5040\tValid: loss 0.6936\taccu 50.2003\n",
      "Epoch 95: val_acc did not improve\n",
      "95 1e-05\n",
      "Epoch-96   20 batches\tloss 0.6894 (0.6926)\taccu 51.562 (52.969)\n",
      "Epoch-96   40 batches\tloss 0.6914 (0.6924)\taccu 57.812 (52.969)\n",
      "Epoch-96   60 batches\tloss 0.6885 (0.6922)\taccu 53.125 (53.255)\n",
      "Epoch-96   80 batches\tloss 0.6950 (0.6920)\taccu 46.875 (53.184)\n",
      "Epoch-96  100 batches\tloss 0.6935 (0.6919)\taccu 48.438 (53.188)\n",
      "Epoch-96  120 batches\tloss 0.6927 (0.6918)\taccu 51.562 (53.112)\n",
      "Epoch-96  140 batches\tloss 0.6911 (0.6920)\taccu 56.250 (52.679)\n",
      "Epoch-96  40.5s\tTrain: loss 0.6920\taccu 52.6242\tValid: loss 0.6937\taccu 50.3205\n",
      "Epoch 96: val_acc did not improve\n",
      "96 1e-05\n",
      "Epoch-97   20 batches\tloss 0.6990 (0.6920)\taccu 40.625 (53.281)\n",
      "Epoch-97   40 batches\tloss 0.6890 (0.6913)\taccu 56.250 (54.492)\n",
      "Epoch-97   60 batches\tloss 0.6927 (0.6916)\taccu 45.312 (53.568)\n",
      "Epoch-97   80 batches\tloss 0.6968 (0.6923)\taccu 53.125 (52.578)\n",
      "Epoch-97  100 batches\tloss 0.6917 (0.6920)\taccu 54.688 (52.531)\n",
      "Epoch-97  120 batches\tloss 0.6947 (0.6920)\taccu 51.562 (52.292)\n",
      "Epoch-97  140 batches\tloss 0.6951 (0.6918)\taccu 48.438 (52.623)\n",
      "Epoch-97  40.0s\tTrain: loss 0.6918\taccu 52.6142\tValid: loss 0.6936\taccu 50.6010\n",
      "Epoch 97: val_acc did not improve\n",
      "97 1e-05\n",
      "Epoch-98   20 batches\tloss 0.6917 (0.6918)\taccu 50.000 (51.250)\n",
      "Epoch-98   40 batches\tloss 0.6876 (0.6919)\taccu 54.688 (52.070)\n",
      "Epoch-98   60 batches\tloss 0.6875 (0.6919)\taccu 54.688 (51.953)\n",
      "Epoch-98   80 batches\tloss 0.6967 (0.6918)\taccu 45.312 (52.363)\n",
      "Epoch-98  100 batches\tloss 0.6903 (0.6918)\taccu 51.562 (52.797)\n",
      "Epoch-98  120 batches\tloss 0.6905 (0.6918)\taccu 54.688 (52.591)\n",
      "Epoch-98  140 batches\tloss 0.6902 (0.6917)\taccu 59.375 (52.734)\n",
      "Epoch-98  39.9s\tTrain: loss 0.6918\taccu 52.6342\tValid: loss 0.6937\taccu 50.2604\n",
      "Epoch 98: val_acc did not improve\n",
      "98 1e-05\n",
      "Epoch-99   20 batches\tloss 0.7013 (0.6918)\taccu 46.875 (52.812)\n",
      "Epoch-99   40 batches\tloss 0.6878 (0.6912)\taccu 59.375 (54.062)\n",
      "Epoch-99   60 batches\tloss 0.6964 (0.6916)\taccu 43.750 (53.359)\n",
      "Epoch-99   80 batches\tloss 0.6958 (0.6917)\taccu 48.438 (52.754)\n",
      "Epoch-99  100 batches\tloss 0.6981 (0.6919)\taccu 40.625 (52.656)\n",
      "Epoch-99  120 batches\tloss 0.6908 (0.6919)\taccu 54.688 (52.435)\n",
      "Epoch-99  140 batches\tloss 0.6902 (0.6920)\taccu 59.375 (52.366)\n",
      "Epoch-99  39.8s\tTrain: loss 0.6920\taccu 52.3638\tValid: loss 0.6938\taccu 50.3005\n",
      "Epoch 99: val_acc did not improve\n",
      "99 1e-05\n",
      "Epoch-100  20 batches\tloss 0.6853 (0.6929)\taccu 70.312 (53.281)\n",
      "Epoch-100  40 batches\tloss 0.6942 (0.6919)\taccu 53.125 (54.336)\n",
      "Epoch-100  60 batches\tloss 0.6928 (0.6917)\taccu 50.000 (53.620)\n",
      "Epoch-100  80 batches\tloss 0.6896 (0.6917)\taccu 62.500 (53.223)\n",
      "Epoch-100 100 batches\tloss 0.6975 (0.6918)\taccu 45.312 (53.188)\n",
      "Epoch-100 120 batches\tloss 0.6961 (0.6917)\taccu 51.562 (53.372)\n",
      "Epoch-100 140 batches\tloss 0.6919 (0.6918)\taccu 53.125 (53.337)\n",
      "Epoch-100 40.2s\tTrain: loss 0.6917\taccu 53.3454\tValid: loss 0.6936\taccu 50.1703\n",
      "Epoch 100: val_acc did not improve\n",
      "100 1e-05\n",
      "Epoch-101  20 batches\tloss 0.6914 (0.6908)\taccu 48.438 (52.500)\n",
      "Epoch-101  40 batches\tloss 0.6878 (0.6914)\taccu 57.812 (52.891)\n",
      "Epoch-101  60 batches\tloss 0.6945 (0.6911)\taccu 56.250 (53.151)\n",
      "Epoch-101  80 batches\tloss 0.6903 (0.6914)\taccu 51.562 (53.008)\n",
      "Epoch-101 100 batches\tloss 0.6937 (0.6918)\taccu 45.312 (52.438)\n",
      "Epoch-101 120 batches\tloss 0.7011 (0.6918)\taccu 42.188 (52.656)\n",
      "Epoch-101 140 batches\tloss 0.6926 (0.6918)\taccu 45.312 (52.667)\n",
      "Epoch-101 39.8s\tTrain: loss 0.6920\taccu 52.4740\tValid: loss 0.6937\taccu 50.2905\n",
      "Epoch 101: val_acc did not improve\n",
      "101 1e-05\n",
      "Epoch-102  20 batches\tloss 0.6977 (0.6924)\taccu 42.188 (52.344)\n",
      "Epoch-102  40 batches\tloss 0.6948 (0.6927)\taccu 56.250 (51.953)\n",
      "Epoch-102  60 batches\tloss 0.6884 (0.6928)\taccu 53.125 (51.823)\n",
      "Epoch-102  80 batches\tloss 0.6907 (0.6923)\taccu 48.438 (52.480)\n",
      "Epoch-102 100 batches\tloss 0.6919 (0.6924)\taccu 54.688 (52.469)\n",
      "Epoch-102 120 batches\tloss 0.6884 (0.6919)\taccu 50.000 (52.930)\n",
      "Epoch-102 140 batches\tloss 0.6956 (0.6919)\taccu 40.625 (52.857)\n",
      "Epoch-102 39.9s\tTrain: loss 0.6920\taccu 52.6542\tValid: loss 0.6936\taccu 50.8013\n",
      "Epoch 102: val_acc improved from 50.7212 to 50.8013, saving model to ./results/NTU/SGN\\0_best.pth\n",
      "102 1e-05\n",
      "Epoch-103  20 batches\tloss 0.6915 (0.6928)\taccu 51.562 (52.734)\n",
      "Epoch-103  40 batches\tloss 0.6884 (0.6917)\taccu 57.812 (53.203)\n",
      "Epoch-103  60 batches\tloss 0.6887 (0.6917)\taccu 64.062 (53.021)\n",
      "Epoch-103  80 batches\tloss 0.7010 (0.6917)\taccu 40.625 (53.008)\n",
      "Epoch-103 100 batches\tloss 0.6856 (0.6917)\taccu 60.938 (53.125)\n",
      "Epoch-103 120 batches\tloss 0.6836 (0.6921)\taccu 70.312 (52.760)\n",
      "Epoch-103 140 batches\tloss 0.6893 (0.6920)\taccu 60.938 (53.025)\n",
      "Epoch-103 39.8s\tTrain: loss 0.6921\taccu 52.9147\tValid: loss 0.6937\taccu 50.2304\n",
      "Epoch 103: val_acc did not improve\n",
      "103 1e-05\n",
      "Epoch-104  20 batches\tloss 0.7021 (0.6915)\taccu 43.750 (51.562)\n",
      "Epoch-104  40 batches\tloss 0.6891 (0.6913)\taccu 59.375 (52.695)\n",
      "Epoch-104  60 batches\tloss 0.6845 (0.6913)\taccu 60.938 (52.656)\n",
      "Epoch-104  80 batches\tloss 0.6898 (0.6914)\taccu 56.250 (52.891)\n",
      "Epoch-104 100 batches\tloss 0.6888 (0.6916)\taccu 59.375 (52.906)\n",
      "Epoch-104 120 batches\tloss 0.6916 (0.6916)\taccu 53.125 (53.164)\n",
      "Epoch-104 140 batches\tloss 0.6917 (0.6919)\taccu 54.688 (52.935)\n",
      "Epoch-104 39.8s\tTrain: loss 0.6919\taccu 52.8045\tValid: loss 0.6938\taccu 49.9499\n",
      "Epoch 104: val_acc did not improve\n",
      "104 1e-05\n",
      "Epoch-105  20 batches\tloss 0.6908 (0.6922)\taccu 54.688 (52.812)\n",
      "Epoch-105  40 batches\tloss 0.6910 (0.6925)\taccu 53.125 (52.500)\n",
      "Epoch-105  60 batches\tloss 0.6934 (0.6923)\taccu 46.875 (52.370)\n",
      "Epoch-105  80 batches\tloss 0.6871 (0.6921)\taccu 59.375 (52.441)\n",
      "Epoch-105 100 batches\tloss 0.6961 (0.6917)\taccu 43.750 (52.750)\n",
      "Epoch-105 120 batches\tloss 0.6898 (0.6919)\taccu 53.125 (52.643)\n",
      "Epoch-105 140 batches\tloss 0.6862 (0.6918)\taccu 62.500 (52.667)\n",
      "Epoch-105 39.7s\tTrain: loss 0.6920\taccu 52.4539\tValid: loss 0.6937\taccu 50.4307\n",
      "Epoch 105: val_acc did not improve\n",
      "105 1e-05\n",
      "Epoch-106  20 batches\tloss 0.6853 (0.6911)\taccu 59.375 (54.141)\n",
      "Epoch-106  40 batches\tloss 0.6896 (0.6911)\taccu 57.812 (53.750)\n",
      "Epoch-106  60 batches\tloss 0.6892 (0.6917)\taccu 57.812 (52.813)\n",
      "Epoch-106  80 batches\tloss 0.6907 (0.6918)\taccu 51.562 (52.910)\n",
      "Epoch-106 100 batches\tloss 0.6923 (0.6922)\taccu 48.438 (52.500)\n",
      "Epoch-106 120 batches\tloss 0.6835 (0.6921)\taccu 65.625 (52.656)\n",
      "Epoch-106 140 batches\tloss 0.6938 (0.6921)\taccu 53.125 (52.712)\n",
      "Epoch-106 39.6s\tTrain: loss 0.6920\taccu 52.9748\tValid: loss 0.6936\taccu 50.3005\n",
      "Epoch 106: val_acc did not improve\n",
      "106 1e-05\n",
      "Epoch-107  20 batches\tloss 0.6954 (0.6915)\taccu 51.562 (53.438)\n",
      "Epoch-107  40 batches\tloss 0.6957 (0.6914)\taccu 54.688 (53.438)\n",
      "Epoch-107  60 batches\tloss 0.6874 (0.6920)\taccu 65.625 (52.839)\n",
      "Epoch-107  80 batches\tloss 0.6925 (0.6921)\taccu 56.250 (52.754)\n",
      "Epoch-107 100 batches\tloss 0.6915 (0.6918)\taccu 51.562 (52.875)\n",
      "Epoch-107 120 batches\tloss 0.6928 (0.6917)\taccu 53.125 (53.138)\n",
      "Epoch-107 140 batches\tloss 0.6961 (0.6919)\taccu 45.312 (52.902)\n",
      "Epoch-107 39.7s\tTrain: loss 0.6920\taccu 52.9547\tValid: loss 0.6936\taccu 50.5609\n",
      "Epoch 107: val_acc did not improve\n",
      "107 1e-05\n",
      "Epoch-108  20 batches\tloss 0.6975 (0.6910)\taccu 45.312 (52.656)\n",
      "Epoch-108  40 batches\tloss 0.6941 (0.6916)\taccu 53.125 (52.852)\n",
      "Epoch-108  60 batches\tloss 0.6911 (0.6924)\taccu 54.688 (52.109)\n",
      "Epoch-108  80 batches\tloss 0.6971 (0.6921)\taccu 43.750 (52.598)\n",
      "Epoch-108 100 batches\tloss 0.6941 (0.6921)\taccu 51.562 (52.422)\n",
      "Epoch-108 120 batches\tloss 0.6873 (0.6920)\taccu 54.688 (52.760)\n",
      "Epoch-108 140 batches\tloss 0.6928 (0.6920)\taccu 50.000 (52.746)\n",
      "Epoch-108 39.7s\tTrain: loss 0.6919\taccu 52.8345\tValid: loss 0.6937\taccu 50.1102\n",
      "Epoch 108: val_acc did not improve\n",
      "108 1e-05\n",
      "Epoch-109  20 batches\tloss 0.6969 (0.6909)\taccu 46.875 (54.219)\n",
      "Epoch-109  40 batches\tloss 0.6846 (0.6919)\taccu 57.812 (53.516)\n",
      "Epoch-109  60 batches\tloss 0.6974 (0.6918)\taccu 45.312 (52.995)\n",
      "Epoch-109  80 batches\tloss 0.6911 (0.6916)\taccu 53.125 (53.203)\n",
      "Epoch-109 100 batches\tloss 0.6950 (0.6917)\taccu 45.312 (53.172)\n",
      "Epoch-109 120 batches\tloss 0.6915 (0.6918)\taccu 56.250 (52.969)\n",
      "Epoch-109 140 batches\tloss 0.6847 (0.6919)\taccu 56.250 (52.679)\n",
      "Epoch-109 39.6s\tTrain: loss 0.6921\taccu 52.4339\tValid: loss 0.6937\taccu 50.1903\n",
      "Epoch 109: val_acc did not improve\n",
      "109 1e-05\n",
      "Epoch-110  20 batches\tloss 0.6994 (0.6940)\taccu 42.188 (49.766)\n",
      "Epoch-110  40 batches\tloss 0.6917 (0.6927)\taccu 46.875 (51.289)\n",
      "Epoch-110  60 batches\tloss 0.6963 (0.6925)\taccu 45.312 (51.354)\n",
      "Epoch-110  80 batches\tloss 0.6935 (0.6924)\taccu 51.562 (51.836)\n",
      "Epoch-110 100 batches\tloss 0.7020 (0.6924)\taccu 40.625 (51.875)\n",
      "Epoch-110 120 batches\tloss 0.6876 (0.6922)\taccu 54.688 (52.148)\n",
      "Epoch-110 140 batches\tloss 0.6891 (0.6921)\taccu 54.688 (52.377)\n",
      "Epoch-110 42.5s\tTrain: loss 0.6921\taccu 52.2937\tValid: loss 0.6936\taccu 50.0701\n",
      "Epoch 110: val_acc did not improve\n",
      "110 1.0000000000000002e-06\n",
      "Epoch-111  20 batches\tloss 0.6930 (0.6928)\taccu 56.250 (51.641)\n",
      "Epoch-111  40 batches\tloss 0.6870 (0.6918)\taccu 59.375 (52.773)\n",
      "Epoch-111  60 batches\tloss 0.6890 (0.6920)\taccu 56.250 (52.396)\n",
      "Epoch-111  80 batches\tloss 0.6907 (0.6919)\taccu 50.000 (52.402)\n",
      "Epoch-111 100 batches\tloss 0.6923 (0.6919)\taccu 54.688 (52.531)\n",
      "Epoch-111 120 batches\tloss 0.6879 (0.6918)\taccu 62.500 (52.747)\n",
      "Epoch-111 140 batches\tloss 0.6990 (0.6918)\taccu 40.625 (52.578)\n",
      "Epoch-111 42.3s\tTrain: loss 0.6919\taccu 52.7845\tValid: loss 0.6936\taccu 50.1302\n",
      "Epoch 111: val_acc did not improve\n",
      "111 1.0000000000000002e-06\n",
      "Epoch-112  20 batches\tloss 0.6953 (0.6927)\taccu 48.438 (50.703)\n",
      "Epoch-112  40 batches\tloss 0.6878 (0.6918)\taccu 53.125 (51.836)\n",
      "Epoch-112  60 batches\tloss 0.6835 (0.6918)\taccu 57.812 (52.396)\n",
      "Epoch-112  80 batches\tloss 0.6874 (0.6919)\taccu 62.500 (52.480)\n",
      "Epoch-112 100 batches\tloss 0.6887 (0.6916)\taccu 56.250 (52.766)\n",
      "Epoch-112 120 batches\tloss 0.6900 (0.6917)\taccu 54.688 (52.487)\n",
      "Epoch-112 140 batches\tloss 0.6943 (0.6918)\taccu 50.000 (52.679)\n",
      "Epoch-112 41.5s\tTrain: loss 0.6918\taccu 52.6542\tValid: loss 0.6938\taccu 49.7997\n",
      "Epoch 112: val_acc did not improve\n",
      "112 1.0000000000000002e-06\n",
      "Epoch-113  20 batches\tloss 0.6990 (0.6925)\taccu 48.438 (53.047)\n",
      "Epoch-113  40 batches\tloss 0.6899 (0.6915)\taccu 54.688 (53.477)\n",
      "Epoch-113  60 batches\tloss 0.6946 (0.6918)\taccu 46.875 (52.760)\n",
      "Epoch-113  80 batches\tloss 0.6870 (0.6921)\taccu 62.500 (52.754)\n",
      "Epoch-113 100 batches\tloss 0.6944 (0.6923)\taccu 50.000 (52.500)\n",
      "Epoch-113 120 batches\tloss 0.6895 (0.6920)\taccu 54.688 (52.865)\n",
      "Epoch-113 140 batches\tloss 0.6910 (0.6918)\taccu 60.938 (53.136)\n",
      "Epoch-113 42.3s\tTrain: loss 0.6918\taccu 52.8946\tValid: loss 0.6937\taccu 50.4307\n",
      "Epoch 113: val_acc did not improve\n",
      "113 1.0000000000000002e-06\n",
      "Epoch-114  20 batches\tloss 0.6945 (0.6927)\taccu 60.938 (53.047)\n",
      "Epoch-114  40 batches\tloss 0.6905 (0.6920)\taccu 57.812 (52.891)\n",
      "Epoch-114  60 batches\tloss 0.6904 (0.6917)\taccu 54.688 (53.542)\n",
      "Epoch-114  80 batches\tloss 0.6913 (0.6916)\taccu 59.375 (53.457)\n",
      "Epoch-114 100 batches\tloss 0.6835 (0.6918)\taccu 60.938 (52.891)\n",
      "Epoch-114 120 batches\tloss 0.6938 (0.6919)\taccu 51.562 (52.852)\n",
      "Epoch-114 140 batches\tloss 0.7015 (0.6922)\taccu 45.312 (52.522)\n",
      "Epoch-114 40.2s\tTrain: loss 0.6920\taccu 52.5341\tValid: loss 0.6938\taccu 50.2905\n",
      "Epoch 114: val_acc did not improve\n",
      "114 1.0000000000000002e-06\n",
      "Epoch-115  20 batches\tloss 0.6960 (0.6924)\taccu 40.625 (52.422)\n",
      "Epoch-115  40 batches\tloss 0.6868 (0.6917)\taccu 60.938 (53.438)\n",
      "Epoch-115  60 batches\tloss 0.6885 (0.6912)\taccu 53.125 (53.411)\n",
      "Epoch-115  80 batches\tloss 0.6971 (0.6916)\taccu 46.875 (52.871)\n",
      "Epoch-115 100 batches\tloss 0.6902 (0.6915)\taccu 59.375 (53.094)\n",
      "Epoch-115 120 batches\tloss 0.6901 (0.6914)\taccu 46.875 (53.177)\n",
      "Epoch-115 140 batches\tloss 0.6921 (0.6916)\taccu 51.562 (53.237)\n",
      "Epoch-115 40.2s\tTrain: loss 0.6918\taccu 52.9447\tValid: loss 0.6936\taccu 50.5409\n",
      "Epoch 115: val_acc did not improve\n",
      "115 1.0000000000000002e-06\n",
      "Epoch-116  20 batches\tloss 0.6908 (0.6912)\taccu 54.688 (54.297)\n",
      "Epoch-116  40 batches\tloss 0.6907 (0.6918)\taccu 57.812 (53.203)\n",
      "Epoch-116  60 batches\tloss 0.6930 (0.6919)\taccu 46.875 (53.359)\n",
      "Epoch-116  80 batches\tloss 0.6922 (0.6923)\taccu 53.125 (52.461)\n",
      "Epoch-116 100 batches\tloss 0.6840 (0.6921)\taccu 64.062 (52.672)\n",
      "Epoch-116 120 batches\tloss 0.6981 (0.6920)\taccu 48.438 (52.852)\n",
      "Epoch-116 140 batches\tloss 0.6932 (0.6919)\taccu 50.000 (52.857)\n",
      "Epoch-116 39.9s\tTrain: loss 0.6919\taccu 52.6643\tValid: loss 0.6937\taccu 49.9099\n",
      "Epoch 116: val_acc did not improve\n",
      "116 1.0000000000000002e-06\n",
      "Epoch-117  20 batches\tloss 0.6941 (0.6932)\taccu 48.438 (50.703)\n",
      "Epoch-117  40 batches\tloss 0.6898 (0.6922)\taccu 59.375 (51.992)\n",
      "Epoch-117  60 batches\tloss 0.6871 (0.6929)\taccu 53.125 (50.260)\n",
      "Epoch-117  80 batches\tloss 0.6897 (0.6921)\taccu 50.000 (51.074)\n",
      "Epoch-117 100 batches\tloss 0.6922 (0.6920)\taccu 62.500 (51.422)\n",
      "Epoch-117 120 batches\tloss 0.6981 (0.6919)\taccu 50.000 (52.227)\n",
      "Epoch-117 140 batches\tloss 0.6914 (0.6920)\taccu 53.125 (52.232)\n",
      "Epoch-117 39.6s\tTrain: loss 0.6921\taccu 52.2536\tValid: loss 0.6937\taccu 50.2204\n",
      "Epoch 117: val_acc did not improve\n",
      "117 1.0000000000000002e-06\n",
      "Epoch-118  20 batches\tloss 0.6903 (0.6928)\taccu 51.562 (52.344)\n",
      "Epoch-118  40 batches\tloss 0.6921 (0.6913)\taccu 48.438 (53.438)\n",
      "Epoch-118  60 batches\tloss 0.6882 (0.6908)\taccu 59.375 (53.932)\n",
      "Epoch-118  80 batches\tloss 0.6914 (0.6916)\taccu 56.250 (53.320)\n",
      "Epoch-118 100 batches\tloss 0.6922 (0.6917)\taccu 57.812 (53.234)\n",
      "Epoch-118 120 batches\tloss 0.6914 (0.6920)\taccu 53.125 (52.891)\n",
      "Epoch-118 140 batches\tloss 0.6900 (0.6920)\taccu 56.250 (52.857)\n",
      "Epoch-118 39.8s\tTrain: loss 0.6919\taccu 52.9147\tValid: loss 0.6936\taccu 50.4307\n",
      "Epoch 118: val_acc did not improve\n",
      "118 1.0000000000000002e-06\n",
      "Epoch-119  20 batches\tloss 0.6925 (0.6906)\taccu 53.125 (52.109)\n",
      "Epoch-119  40 batches\tloss 0.6923 (0.6913)\taccu 56.250 (52.852)\n",
      "Epoch-119  60 batches\tloss 0.6962 (0.6914)\taccu 48.438 (52.708)\n",
      "Epoch-119  80 batches\tloss 0.6961 (0.6917)\taccu 46.875 (52.539)\n",
      "Epoch-119 100 batches\tloss 0.6955 (0.6920)\taccu 50.000 (52.438)\n",
      "Epoch-119 120 batches\tloss 0.6920 (0.6918)\taccu 53.125 (52.513)\n",
      "Epoch-119 140 batches\tloss 0.6937 (0.6918)\taccu 48.438 (52.634)\n",
      "Epoch-119 39.7s\tTrain: loss 0.6919\taccu 52.6042\tValid: loss 0.6937\taccu 50.3205\n",
      "Epoch 119: val_acc did not improve\n",
      "119 1.0000000000000002e-06\n",
      "Epoch-120  20 batches\tloss 0.6922 (0.6906)\taccu 46.875 (54.688)\n",
      "Epoch-120  40 batches\tloss 0.6937 (0.6908)\taccu 59.375 (54.258)\n",
      "Epoch-120  60 batches\tloss 0.6891 (0.6914)\taccu 60.938 (53.516)\n",
      "Epoch-120  80 batches\tloss 0.6843 (0.6913)\taccu 59.375 (53.633)\n",
      "Epoch-120 100 batches\tloss 0.6974 (0.6917)\taccu 46.875 (53.031)\n",
      "Epoch-120 120 batches\tloss 0.6828 (0.6915)\taccu 56.250 (53.216)\n",
      "Epoch-120 140 batches\tloss 0.6859 (0.6916)\taccu 57.812 (53.214)\n",
      "Epoch-120 40.0s\tTrain: loss 0.6918\taccu 52.9347\tValid: loss 0.6936\taccu 50.3005\n",
      "Epoch 120: val_acc did not improve\n",
      "120 1.0000000000000002e-06\n",
      "Epoch-121  20 batches\tloss 0.6903 (0.6938)\taccu 56.250 (49.922)\n",
      "Epoch-121  40 batches\tloss 0.6884 (0.6930)\taccu 54.688 (51.172)\n",
      "Epoch-121  60 batches\tloss 0.6861 (0.6930)\taccu 59.375 (51.198)\n",
      "Epoch-121  80 batches\tloss 0.6928 (0.6926)\taccu 50.000 (51.777)\n",
      "Epoch-121 100 batches\tloss 0.6863 (0.6924)\taccu 62.500 (52.219)\n",
      "Epoch-121 120 batches\tloss 0.6923 (0.6921)\taccu 53.125 (52.253)\n",
      "Epoch-121 140 batches\tloss 0.6927 (0.6919)\taccu 51.562 (52.467)\n",
      "Epoch-121 39.8s\tTrain: loss 0.6918\taccu 52.5841\tValid: loss 0.6938\taccu 50.0801\n",
      "Epoch 121: val_acc did not improve\n",
      "121 1.0000000000000002e-06\n",
      "Epoch-122  20 batches\tloss 0.6953 (0.6929)\taccu 50.000 (52.656)\n",
      "Epoch-122  40 batches\tloss 0.6791 (0.6928)\taccu 64.062 (52.461)\n",
      "Epoch-122  60 batches\tloss 0.6909 (0.6919)\taccu 54.688 (53.307)\n",
      "Epoch-122  80 batches\tloss 0.6902 (0.6919)\taccu 54.688 (52.715)\n",
      "Epoch-122 100 batches\tloss 0.6960 (0.6921)\taccu 43.750 (52.469)\n",
      "Epoch-122 120 batches\tloss 0.6990 (0.6923)\taccu 45.312 (52.227)\n",
      "Epoch-122 140 batches\tloss 0.6880 (0.6920)\taccu 53.125 (52.522)\n",
      "Epoch-122 39.9s\tTrain: loss 0.6919\taccu 52.4139\tValid: loss 0.6936\taccu 50.4808\n",
      "Epoch 122: val_acc did not improve\n",
      "122 1.0000000000000002e-06\n",
      "Epoch-123  20 batches\tloss 0.6995 (0.6930)\taccu 46.875 (50.156)\n",
      "Epoch-123  40 batches\tloss 0.6971 (0.6921)\taccu 54.688 (52.578)\n",
      "Epoch-123  60 batches\tloss 0.6934 (0.6920)\taccu 43.750 (52.578)\n",
      "Epoch-123  80 batches\tloss 0.6992 (0.6923)\taccu 42.188 (52.207)\n",
      "Epoch-123 100 batches\tloss 0.6973 (0.6922)\taccu 51.562 (52.391)\n",
      "Epoch-123 120 batches\tloss 0.6858 (0.6921)\taccu 59.375 (52.422)\n",
      "Epoch-123 140 batches\tloss 0.6945 (0.6921)\taccu 53.125 (52.612)\n",
      "Epoch-123 39.7s\tTrain: loss 0.6920\taccu 52.8145\tValid: loss 0.6936\taccu 50.2504\n",
      "Epoch 123: val_acc did not improve\n",
      "123 1.0000000000000002e-06\n",
      "Epoch-124  20 batches\tloss 0.6889 (0.6922)\taccu 56.250 (53.047)\n",
      "Epoch-124  40 batches\tloss 0.6881 (0.6911)\taccu 51.562 (53.828)\n",
      "Epoch-124  60 batches\tloss 0.6860 (0.6908)\taccu 59.375 (53.958)\n",
      "Epoch-124  80 batches\tloss 0.6927 (0.6915)\taccu 48.438 (53.203)\n",
      "Epoch-124 100 batches\tloss 0.6975 (0.6918)\taccu 48.438 (53.000)\n",
      "Epoch-124 120 batches\tloss 0.6915 (0.6919)\taccu 48.438 (52.982)\n",
      "Epoch-124 140 batches\tloss 0.6879 (0.6919)\taccu 57.812 (52.768)\n",
      "Epoch-124 40.0s\tTrain: loss 0.6920\taccu 52.5040\tValid: loss 0.6937\taccu 50.3005\n",
      "Epoch 124: val_acc did not improve\n",
      "124 1.0000000000000002e-06\n",
      "Epoch-125  20 batches\tloss 0.6832 (0.6915)\taccu 67.188 (52.969)\n",
      "Epoch-125  40 batches\tloss 0.6865 (0.6920)\taccu 51.562 (52.305)\n",
      "Epoch-125  60 batches\tloss 0.6891 (0.6921)\taccu 59.375 (52.708)\n",
      "Epoch-125  80 batches\tloss 0.6924 (0.6923)\taccu 50.000 (52.676)\n",
      "Epoch-125 100 batches\tloss 0.6961 (0.6923)\taccu 48.438 (52.484)\n",
      "Epoch-125 120 batches\tloss 0.6949 (0.6921)\taccu 46.875 (52.461)\n",
      "Epoch-125 140 batches\tloss 0.6902 (0.6919)\taccu 48.438 (52.612)\n",
      "Epoch-125 41.5s\tTrain: loss 0.6918\taccu 52.6242\tValid: loss 0.6937\taccu 50.7512\n",
      "Epoch 125: val_acc did not improve\n",
      "125 1.0000000000000002e-06\n",
      "Epoch-126  20 batches\tloss 0.6957 (0.6937)\taccu 46.875 (50.938)\n",
      "Epoch-126  40 batches\tloss 0.6866 (0.6930)\taccu 60.938 (52.266)\n",
      "Epoch-126  60 batches\tloss 0.6946 (0.6925)\taccu 43.750 (52.708)\n",
      "Epoch-126  80 batches\tloss 0.6888 (0.6921)\taccu 53.125 (52.949)\n",
      "Epoch-126 100 batches\tloss 0.6923 (0.6918)\taccu 48.438 (53.281)\n",
      "Epoch-126 120 batches\tloss 0.6939 (0.6920)\taccu 53.125 (52.721)\n",
      "Epoch-126 140 batches\tloss 0.6957 (0.6920)\taccu 54.688 (52.578)\n",
      "Epoch-126 41.7s\tTrain: loss 0.6921\taccu 52.3438\tValid: loss 0.6938\taccu 50.2304\n",
      "Epoch 126: val_acc did not improve\n",
      "126 1.0000000000000002e-06\n",
      "Epoch-127  20 batches\tloss 0.6940 (0.6919)\taccu 43.750 (52.109)\n",
      "Epoch-127  40 batches\tloss 0.6893 (0.6918)\taccu 50.000 (51.875)\n",
      "Epoch-127  60 batches\tloss 0.6849 (0.6917)\taccu 60.938 (51.953)\n",
      "Epoch-127  80 batches\tloss 0.6918 (0.6917)\taccu 46.875 (51.836)\n",
      "Epoch-127 100 batches\tloss 0.7025 (0.6920)\taccu 39.062 (51.906)\n",
      "Epoch-127 120 batches\tloss 0.6933 (0.6920)\taccu 48.438 (51.979)\n",
      "Epoch-127 140 batches\tloss 0.6880 (0.6918)\taccu 57.812 (52.321)\n",
      "Epoch-127 40.1s\tTrain: loss 0.6918\taccu 52.4439\tValid: loss 0.6937\taccu 50.4507\n",
      "Epoch 127: val_acc did not improve\n",
      "127 1.0000000000000002e-06\n",
      "Epoch-128  20 batches\tloss 0.6908 (0.6921)\taccu 57.812 (53.438)\n",
      "Epoch-128  40 batches\tloss 0.6936 (0.6918)\taccu 57.812 (52.734)\n",
      "Epoch-128  60 batches\tloss 0.6962 (0.6917)\taccu 42.188 (52.630)\n",
      "Epoch-128  80 batches\tloss 0.6916 (0.6920)\taccu 51.562 (52.520)\n",
      "Epoch-128 100 batches\tloss 0.6907 (0.6921)\taccu 48.438 (52.141)\n",
      "Epoch-128 120 batches\tloss 0.6902 (0.6921)\taccu 48.438 (52.266)\n",
      "Epoch-128 140 batches\tloss 0.6911 (0.6922)\taccu 54.688 (52.277)\n",
      "Epoch-128 39.6s\tTrain: loss 0.6920\taccu 52.6042\tValid: loss 0.6938\taccu 50.4708\n",
      "Epoch 128: val_acc did not improve\n",
      "128 1.0000000000000002e-06\n",
      "Epoch-129  20 batches\tloss 0.6926 (0.6930)\taccu 54.688 (51.641)\n",
      "Epoch-129  40 batches\tloss 0.6915 (0.6931)\taccu 56.250 (51.836)\n",
      "Epoch-129  60 batches\tloss 0.6917 (0.6929)\taccu 54.688 (51.797)\n",
      "Epoch-129  80 batches\tloss 0.6901 (0.6924)\taccu 54.688 (52.305)\n",
      "Epoch-129 100 batches\tloss 0.6936 (0.6924)\taccu 50.000 (52.375)\n",
      "Epoch-129 120 batches\tloss 0.6910 (0.6920)\taccu 53.125 (52.982)\n",
      "Epoch-129 140 batches\tloss 0.6844 (0.6920)\taccu 59.375 (52.779)\n",
      "Epoch-129 39.6s\tTrain: loss 0.6918\taccu 52.8446\tValid: loss 0.6937\taccu 50.3105\n",
      "Epoch 129: val_acc did not improve\n",
      "129 1.0000000000000002e-06\n",
      "Epoch-130  20 batches\tloss 0.6898 (0.6906)\taccu 54.688 (54.609)\n",
      "Epoch-130  40 batches\tloss 0.6906 (0.6921)\taccu 57.812 (52.812)\n",
      "Epoch-130  60 batches\tloss 0.6926 (0.6919)\taccu 51.562 (53.255)\n",
      "Epoch-130  80 batches\tloss 0.6923 (0.6924)\taccu 56.250 (52.676)\n",
      "Epoch-130 100 batches\tloss 0.6983 (0.6924)\taccu 53.125 (53.047)\n",
      "Epoch-130 120 batches\tloss 0.6878 (0.6924)\taccu 60.938 (52.891)\n",
      "Epoch-130 140 batches\tloss 0.6901 (0.6923)\taccu 59.375 (52.824)\n",
      "Epoch-130 39.6s\tTrain: loss 0.6922\taccu 52.6943\tValid: loss 0.6937\taccu 50.2804\n",
      "Epoch 130: val_acc did not improve\n",
      "130 1.0000000000000002e-06\n",
      "Epoch-131  20 batches\tloss 0.6887 (0.6914)\taccu 51.562 (53.594)\n",
      "Epoch-131  40 batches\tloss 0.6863 (0.6912)\taccu 57.812 (53.828)\n",
      "Epoch-131  60 batches\tloss 0.6952 (0.6917)\taccu 53.125 (52.786)\n",
      "Epoch-131  80 batches\tloss 0.6922 (0.6924)\taccu 56.250 (51.953)\n",
      "Epoch-131 100 batches\tloss 0.6973 (0.6922)\taccu 48.438 (52.047)\n",
      "Epoch-131 120 batches\tloss 0.6964 (0.6922)\taccu 54.688 (52.253)\n",
      "Epoch-131 140 batches\tloss 0.6900 (0.6921)\taccu 54.688 (52.232)\n",
      "Epoch-131 39.5s\tTrain: loss 0.6921\taccu 52.5240\tValid: loss 0.6938\taccu 50.1603\n",
      "Epoch 131: val_acc did not improve\n",
      "131 1.0000000000000002e-06\n",
      "Epoch-132  20 batches\tloss 0.6936 (0.6903)\taccu 43.750 (53.516)\n",
      "Epoch-132  40 batches\tloss 0.7000 (0.6914)\taccu 46.875 (52.500)\n",
      "Epoch-132  60 batches\tloss 0.6982 (0.6917)\taccu 48.438 (52.578)\n",
      "Epoch-132  80 batches\tloss 0.6844 (0.6916)\taccu 62.500 (52.695)\n",
      "Epoch-132 100 batches\tloss 0.6926 (0.6918)\taccu 51.562 (52.672)\n",
      "Epoch-132 120 batches\tloss 0.6907 (0.6918)\taccu 53.125 (52.500)\n",
      "Epoch-132 140 batches\tloss 0.6937 (0.6920)\taccu 45.312 (52.199)\n",
      "Epoch-132 39.5s\tTrain: loss 0.6920\taccu 52.1935\tValid: loss 0.6939\taccu 49.9499\n",
      "Epoch 132: val_acc did not improve\n",
      "132 1.0000000000000002e-06\n",
      "Epoch-133  20 batches\tloss 0.6892 (0.6925)\taccu 59.375 (51.484)\n",
      "Epoch-133  40 batches\tloss 0.6965 (0.6930)\taccu 46.875 (51.211)\n",
      "Epoch-133  60 batches\tloss 0.6995 (0.6925)\taccu 40.625 (51.563)\n",
      "Epoch-133  80 batches\tloss 0.7023 (0.6921)\taccu 50.000 (52.168)\n",
      "Epoch-133 100 batches\tloss 0.6923 (0.6921)\taccu 57.812 (52.375)\n",
      "Epoch-133 120 batches\tloss 0.6946 (0.6920)\taccu 53.125 (52.669)\n",
      "Epoch-133 140 batches\tloss 0.6926 (0.6920)\taccu 48.438 (52.768)\n",
      "Epoch-133 39.9s\tTrain: loss 0.6920\taccu 52.7043\tValid: loss 0.6937\taccu 50.3806\n",
      "Epoch 133: val_acc did not improve\n",
      "133 1.0000000000000002e-06\n",
      "Epoch-134  20 batches\tloss 0.6926 (0.6925)\taccu 53.125 (52.656)\n",
      "Epoch-134  40 batches\tloss 0.6825 (0.6926)\taccu 62.500 (51.445)\n",
      "Epoch-134  60 batches\tloss 0.6904 (0.6922)\taccu 51.562 (51.849)\n",
      "Epoch-134  80 batches\tloss 0.6871 (0.6920)\taccu 59.375 (52.617)\n",
      "Epoch-134 100 batches\tloss 0.6987 (0.6921)\taccu 43.750 (52.500)\n",
      "Epoch-134 120 batches\tloss 0.6967 (0.6919)\taccu 48.438 (52.617)\n",
      "Epoch-134 140 batches\tloss 0.6936 (0.6919)\taccu 50.000 (52.589)\n",
      "Epoch-134 44.3s\tTrain: loss 0.6919\taccu 52.5641\tValid: loss 0.6937\taccu 50.1903\n",
      "Epoch 134: val_acc did not improve\n",
      "134 1.0000000000000002e-06\n",
      "Epoch-135  20 batches\tloss 0.6799 (0.6923)\taccu 60.938 (51.328)\n",
      "Epoch-135  40 batches\tloss 0.6921 (0.6928)\taccu 54.688 (51.641)\n",
      "Epoch-135  60 batches\tloss 0.6910 (0.6923)\taccu 60.938 (52.682)\n",
      "Epoch-135  80 batches\tloss 0.6894 (0.6921)\taccu 51.562 (52.988)\n",
      "Epoch-135 100 batches\tloss 0.6878 (0.6920)\taccu 60.938 (52.641)\n",
      "Epoch-135 120 batches\tloss 0.6936 (0.6921)\taccu 46.875 (52.448)\n",
      "Epoch-135 140 batches\tloss 0.6929 (0.6922)\taccu 48.438 (52.444)\n",
      "Epoch-135 41.8s\tTrain: loss 0.6921\taccu 52.5541\tValid: loss 0.6937\taccu 50.1603\n",
      "Epoch 135: val_acc did not improve\n",
      "135 1.0000000000000002e-06\n",
      "Epoch-136  20 batches\tloss 0.6960 (0.6911)\taccu 48.438 (52.891)\n",
      "Epoch-136  40 batches\tloss 0.6941 (0.6920)\taccu 43.750 (52.539)\n",
      "Epoch-136  60 batches\tloss 0.6931 (0.6921)\taccu 48.438 (52.448)\n",
      "Epoch-136  80 batches\tloss 0.6878 (0.6921)\taccu 57.812 (52.695)\n",
      "Epoch-136 100 batches\tloss 0.6895 (0.6922)\taccu 59.375 (52.531)\n",
      "Epoch-136 120 batches\tloss 0.6989 (0.6920)\taccu 46.875 (52.747)\n",
      "Epoch-136 140 batches\tloss 0.6863 (0.6921)\taccu 57.812 (52.801)\n",
      "Epoch-136 42.5s\tTrain: loss 0.6920\taccu 53.0349\tValid: loss 0.6937\taccu 50.2504\n",
      "Epoch 136: val_acc did not improve\n",
      "136 1.0000000000000002e-06\n",
      "Epoch-137  20 batches\tloss 0.6942 (0.6901)\taccu 53.125 (54.219)\n",
      "Epoch-137  40 batches\tloss 0.6821 (0.6909)\taccu 64.062 (54.023)\n",
      "Epoch-137  60 batches\tloss 0.6930 (0.6917)\taccu 46.875 (52.891)\n",
      "Epoch-137  80 batches\tloss 0.6852 (0.6921)\taccu 67.188 (52.520)\n",
      "Epoch-137 100 batches\tloss 0.6916 (0.6921)\taccu 50.000 (52.516)\n",
      "Epoch-137 120 batches\tloss 0.6888 (0.6921)\taccu 59.375 (52.526)\n",
      "Epoch-137 140 batches\tloss 0.6935 (0.6920)\taccu 46.875 (52.645)\n",
      "Epoch-137 42.5s\tTrain: loss 0.6920\taccu 52.6943\tValid: loss 0.6936\taccu 50.3806\n",
      "Epoch 137: val_acc did not improve\n",
      "137 1.0000000000000002e-06\n",
      "Epoch-138  20 batches\tloss 0.6912 (0.6914)\taccu 54.688 (53.672)\n",
      "Epoch-138  40 batches\tloss 0.6888 (0.6917)\taccu 65.625 (53.242)\n",
      "Epoch-138  60 batches\tloss 0.6865 (0.6917)\taccu 62.500 (53.021)\n",
      "Epoch-138  80 batches\tloss 0.6862 (0.6914)\taccu 62.500 (53.105)\n",
      "Epoch-138 100 batches\tloss 0.6895 (0.6915)\taccu 54.688 (52.969)\n",
      "Epoch-138 120 batches\tloss 0.6885 (0.6917)\taccu 56.250 (53.008)\n",
      "Epoch-138 140 batches\tloss 0.6908 (0.6917)\taccu 46.875 (52.969)\n",
      "Epoch-138 40.9s\tTrain: loss 0.6920\taccu 52.7444\tValid: loss 0.6937\taccu 50.4307\n",
      "Epoch 138: val_acc did not improve\n",
      "138 1.0000000000000002e-06\n",
      "Epoch-139  20 batches\tloss 0.6862 (0.6922)\taccu 62.500 (52.266)\n",
      "Epoch-139  40 batches\tloss 0.6917 (0.6925)\taccu 51.562 (52.227)\n",
      "Epoch-139  60 batches\tloss 0.6848 (0.6918)\taccu 59.375 (52.786)\n",
      "Epoch-139  80 batches\tloss 0.6914 (0.6922)\taccu 51.562 (52.168)\n",
      "Epoch-139 100 batches\tloss 0.6913 (0.6921)\taccu 54.688 (52.469)\n",
      "Epoch-139 120 batches\tloss 0.6860 (0.6918)\taccu 65.625 (52.878)\n",
      "Epoch-139 140 batches\tloss 0.6891 (0.6919)\taccu 54.688 (52.857)\n",
      "Epoch-139 42.5s\tTrain: loss 0.6918\taccu 52.8846\tValid: loss 0.6936\taccu 50.4507\n",
      "Epoch 139: val_acc did not improve\n",
      "139 1.0000000000000002e-06\n",
      "Epoch-140  20 batches\tloss 0.6956 (0.6925)\taccu 46.875 (53.750)\n",
      "Epoch-140  40 batches\tloss 0.6849 (0.6921)\taccu 60.938 (53.047)\n",
      "Epoch-140  60 batches\tloss 0.6874 (0.6924)\taccu 59.375 (52.500)\n",
      "Epoch-140  80 batches\tloss 0.6899 (0.6926)\taccu 53.125 (51.973)\n",
      "Epoch-140 100 batches\tloss 0.6920 (0.6923)\taccu 53.125 (52.594)\n",
      "Epoch-140 120 batches\tloss 0.6938 (0.6921)\taccu 53.125 (52.865)\n",
      "Epoch-140 140 batches\tloss 0.6932 (0.6921)\taccu 51.562 (52.868)\n",
      "Epoch-140 39.7s\tTrain: loss 0.6921\taccu 52.8446\tValid: loss 0.6937\taccu 50.3305\n",
      "Epoch 140: val_acc did not improve\n",
      "140 1.0000000000000002e-06\n",
      "Epoch-141  20 batches\tloss 0.6960 (0.6910)\taccu 51.562 (53.906)\n",
      "Epoch-141  40 batches\tloss 0.6954 (0.6915)\taccu 45.312 (53.086)\n",
      "Epoch-141  60 batches\tloss 0.6867 (0.6915)\taccu 64.062 (53.333)\n",
      "Epoch-141  80 batches\tloss 0.6920 (0.6916)\taccu 48.438 (52.832)\n",
      "Epoch-141 100 batches\tloss 0.6945 (0.6916)\taccu 48.438 (52.844)\n",
      "Epoch-141 120 batches\tloss 0.6919 (0.6917)\taccu 54.688 (52.813)\n",
      "Epoch-141 140 batches\tloss 0.6903 (0.6917)\taccu 50.000 (52.757)\n",
      "Epoch-141 39.5s\tTrain: loss 0.6919\taccu 52.5341\tValid: loss 0.6937\taccu 50.3806\n",
      "Epoch 141: val_acc did not improve\n",
      "141 1.0000000000000002e-06\n",
      "Epoch-142  20 batches\tloss 0.7017 (0.6915)\taccu 32.812 (51.484)\n",
      "Epoch-142  40 batches\tloss 0.6963 (0.6917)\taccu 53.125 (52.344)\n",
      "Epoch-142  60 batches\tloss 0.6958 (0.6912)\taccu 50.000 (53.229)\n",
      "Epoch-142  80 batches\tloss 0.6913 (0.6915)\taccu 50.000 (52.949)\n",
      "Epoch-142 100 batches\tloss 0.6906 (0.6917)\taccu 56.250 (52.844)\n",
      "Epoch-142 120 batches\tloss 0.6924 (0.6916)\taccu 51.562 (52.917)\n",
      "Epoch-142 140 batches\tloss 0.6901 (0.6917)\taccu 57.812 (52.969)\n",
      "Epoch-142 39.6s\tTrain: loss 0.6917\taccu 52.9748\tValid: loss 0.6937\taccu 49.9299\n",
      "Epoch 142: val_acc did not improve\n",
      "142 1.0000000000000002e-06\n",
      "Epoch-143  20 batches\tloss 0.6919 (0.6917)\taccu 46.875 (52.656)\n",
      "Epoch-143  40 batches\tloss 0.6949 (0.6923)\taccu 40.625 (51.211)\n",
      "Epoch-143  60 batches\tloss 0.6928 (0.6924)\taccu 54.688 (51.380)\n",
      "Epoch-143  80 batches\tloss 0.6935 (0.6923)\taccu 50.000 (51.914)\n",
      "Epoch-143 100 batches\tloss 0.6891 (0.6922)\taccu 57.812 (52.188)\n",
      "Epoch-143 120 batches\tloss 0.6940 (0.6921)\taccu 46.875 (52.344)\n",
      "Epoch-143 140 batches\tloss 0.6954 (0.6923)\taccu 48.438 (52.188)\n",
      "Epoch-143 39.6s\tTrain: loss 0.6920\taccu 52.6142\tValid: loss 0.6937\taccu 50.2003\n",
      "Epoch 143: val_acc did not improve\n",
      "143 1.0000000000000002e-06\n",
      "Epoch-144  20 batches\tloss 0.6925 (0.6911)\taccu 46.875 (55.156)\n",
      "Epoch-144  40 batches\tloss 0.6942 (0.6916)\taccu 48.438 (53.281)\n",
      "Epoch-144  60 batches\tloss 0.6847 (0.6915)\taccu 62.500 (53.672)\n",
      "Epoch-144  80 batches\tloss 0.6858 (0.6913)\taccu 60.938 (53.691)\n",
      "Epoch-144 100 batches\tloss 0.6871 (0.6918)\taccu 54.688 (52.891)\n",
      "Epoch-144 120 batches\tloss 0.6927 (0.6920)\taccu 51.562 (52.956)\n",
      "Epoch-144 140 batches\tloss 0.6922 (0.6920)\taccu 50.000 (52.679)\n",
      "Epoch-144 39.7s\tTrain: loss 0.6922\taccu 52.2436\tValid: loss 0.6936\taccu 50.3706\n",
      "Epoch 144: val_acc did not improve\n",
      "144 1.0000000000000002e-06\n",
      "Epoch-145  20 batches\tloss 0.6968 (0.6922)\taccu 51.562 (53.359)\n",
      "Epoch-145  40 batches\tloss 0.6913 (0.6921)\taccu 59.375 (53.086)\n",
      "Epoch-145  60 batches\tloss 0.6930 (0.6923)\taccu 51.562 (52.786)\n",
      "Epoch-145  80 batches\tloss 0.6917 (0.6924)\taccu 54.688 (52.383)\n",
      "Epoch-145 100 batches\tloss 0.6936 (0.6922)\taccu 48.438 (52.828)\n",
      "Epoch-145 120 batches\tloss 0.6900 (0.6922)\taccu 59.375 (52.786)\n",
      "Epoch-145 140 batches\tloss 0.6939 (0.6922)\taccu 46.875 (52.645)\n",
      "Epoch-145 41.8s\tTrain: loss 0.6921\taccu 52.7444\tValid: loss 0.6938\taccu 50.3506\n",
      "Epoch 145: val_acc did not improve\n",
      "145 1.0000000000000002e-06\n",
      "Epoch-146  20 batches\tloss 0.6907 (0.6918)\taccu 46.875 (51.953)\n",
      "Epoch-146  40 batches\tloss 0.6941 (0.6919)\taccu 48.438 (52.266)\n",
      "Epoch-146  60 batches\tloss 0.6924 (0.6921)\taccu 51.562 (52.240)\n",
      "Epoch-146  80 batches\tloss 0.6978 (0.6920)\taccu 46.875 (52.461)\n",
      "Epoch-146 100 batches\tloss 0.6858 (0.6921)\taccu 50.000 (52.422)\n",
      "Epoch-146 120 batches\tloss 0.6915 (0.6920)\taccu 53.125 (52.565)\n",
      "Epoch-146 140 batches\tloss 0.6922 (0.6920)\taccu 59.375 (52.600)\n",
      "Epoch-146 42.2s\tTrain: loss 0.6919\taccu 52.7544\tValid: loss 0.6936\taccu 50.3305\n",
      "Epoch 146: val_acc did not improve\n",
      "146 1.0000000000000002e-06\n",
      "Epoch-147  20 batches\tloss 0.6884 (0.6893)\taccu 62.500 (56.562)\n",
      "Epoch-147  40 batches\tloss 0.6911 (0.6908)\taccu 56.250 (54.180)\n",
      "Epoch-147  60 batches\tloss 0.6866 (0.6914)\taccu 53.125 (53.281)\n",
      "Epoch-147  80 batches\tloss 0.6972 (0.6917)\taccu 53.125 (53.359)\n",
      "Epoch-147 100 batches\tloss 0.6991 (0.6916)\taccu 46.875 (53.625)\n",
      "Epoch-147 120 batches\tloss 0.6966 (0.6920)\taccu 50.000 (53.255)\n",
      "Epoch-147 140 batches\tloss 0.6894 (0.6919)\taccu 50.000 (53.025)\n",
      "Epoch-147 42.5s\tTrain: loss 0.6920\taccu 52.7444\tValid: loss 0.6937\taccu 50.2704\n",
      "Epoch 147: val_acc did not improve\n",
      "147 1.0000000000000002e-06\n",
      "Epoch-148  20 batches\tloss 0.6857 (0.6922)\taccu 60.938 (52.422)\n",
      "Epoch-148  40 batches\tloss 0.6918 (0.6922)\taccu 54.688 (52.461)\n",
      "Epoch-148  60 batches\tloss 0.6902 (0.6923)\taccu 48.438 (52.240)\n",
      "Epoch-148  80 batches\tloss 0.6956 (0.6926)\taccu 45.312 (52.090)\n",
      "Epoch-148 100 batches\tloss 0.6912 (0.6924)\taccu 51.562 (52.219)\n",
      "Epoch-148 120 batches\tloss 0.6969 (0.6922)\taccu 40.625 (52.057)\n",
      "Epoch-148 140 batches\tloss 0.6948 (0.6922)\taccu 53.125 (52.388)\n",
      "Epoch-148 46.6s\tTrain: loss 0.6921\taccu 52.4439\tValid: loss 0.6937\taccu 50.4808\n",
      "Epoch 148: val_acc did not improve\n",
      "148 1.0000000000000002e-06\n",
      "Epoch-149  20 batches\tloss 0.6996 (0.6933)\taccu 42.188 (52.500)\n",
      "Epoch-149  40 batches\tloss 0.6892 (0.6923)\taccu 54.688 (53.711)\n",
      "Epoch-149  60 batches\tloss 0.6957 (0.6918)\taccu 51.562 (53.880)\n",
      "Epoch-149  80 batches\tloss 0.6935 (0.6921)\taccu 54.688 (53.184)\n",
      "Epoch-149 100 batches\tloss 0.6891 (0.6922)\taccu 54.688 (52.953)\n",
      "Epoch-149 120 batches\tloss 0.6881 (0.6918)\taccu 54.688 (52.956)\n",
      "Epoch-149 140 batches\tloss 0.6944 (0.6920)\taccu 53.125 (52.377)\n",
      "Epoch-149 47.0s\tTrain: loss 0.6922\taccu 52.1034\tValid: loss 0.6936\taccu 50.1803\n",
      "Epoch 149: val_acc did not improve\n",
      "149 1.0000000000000002e-06\n",
      "Epoch-150  20 batches\tloss 0.6931 (0.6921)\taccu 54.688 (51.562)\n",
      "Epoch-150  40 batches\tloss 0.6892 (0.6919)\taccu 53.125 (52.695)\n",
      "Epoch-150  60 batches\tloss 0.6937 (0.6918)\taccu 48.438 (52.630)\n",
      "Epoch-150  80 batches\tloss 0.6963 (0.6918)\taccu 51.562 (53.125)\n",
      "Epoch-150 100 batches\tloss 0.6950 (0.6917)\taccu 43.750 (53.375)\n",
      "Epoch-150 120 batches\tloss 0.6927 (0.6918)\taccu 46.875 (53.372)\n",
      "Epoch-150 140 batches\tloss 0.6958 (0.6918)\taccu 51.562 (53.270)\n",
      "Epoch-150 46.1s\tTrain: loss 0.6918\taccu 53.1851\tValid: loss 0.6937\taccu 50.4708\n",
      "Epoch 150: val_acc did not improve\n",
      "150 1.0000000000000002e-06\n",
      "Epoch-151  20 batches\tloss 0.6926 (0.6937)\taccu 54.688 (51.250)\n",
      "Epoch-151  40 batches\tloss 0.6959 (0.6929)\taccu 51.562 (52.148)\n",
      "Epoch-151  60 batches\tloss 0.6944 (0.6924)\taccu 53.125 (52.500)\n",
      "Epoch-151  80 batches\tloss 0.6922 (0.6923)\taccu 54.688 (52.324)\n",
      "Epoch-151 100 batches\tloss 0.6886 (0.6922)\taccu 60.938 (52.438)\n",
      "Epoch-151 120 batches\tloss 0.6970 (0.6921)\taccu 48.438 (52.266)\n",
      "Epoch-151 140 batches\tloss 0.6946 (0.6919)\taccu 46.875 (52.455)\n",
      "Epoch-151 45.6s\tTrain: loss 0.6920\taccu 52.4840\tValid: loss 0.6937\taccu 50.3606\n",
      "Epoch 151: val_acc did not improve\n",
      "151 1.0000000000000002e-06\n",
      "Epoch-152  20 batches\tloss 0.6978 (0.6913)\taccu 48.438 (54.766)\n",
      "Epoch-152  40 batches\tloss 0.7002 (0.6917)\taccu 48.438 (53.398)\n",
      "Epoch-152  60 batches\tloss 0.6936 (0.6921)\taccu 53.125 (52.760)\n",
      "Epoch-152  80 batches\tloss 0.6885 (0.6918)\taccu 51.562 (53.027)\n",
      "Epoch-152 100 batches\tloss 0.6978 (0.6920)\taccu 45.312 (52.578)\n",
      "Epoch-152 120 batches\tloss 0.6934 (0.6922)\taccu 45.312 (52.357)\n",
      "Epoch-152 140 batches\tloss 0.6889 (0.6919)\taccu 56.250 (52.746)\n",
      "Epoch-152 46.6s\tTrain: loss 0.6919\taccu 52.8646\tValid: loss 0.6937\taccu 50.3105\n",
      "Epoch 152: val_acc did not improve\n",
      "152 1.0000000000000002e-06\n",
      "Epoch-153  20 batches\tloss 0.6883 (0.6924)\taccu 56.250 (52.656)\n",
      "Epoch-153  40 batches\tloss 0.6989 (0.6917)\taccu 43.750 (53.477)\n",
      "Epoch-153  60 batches\tloss 0.6954 (0.6915)\taccu 50.000 (53.255)\n",
      "Epoch-153  80 batches\tloss 0.6886 (0.6913)\taccu 57.812 (53.594)\n",
      "Epoch-153 100 batches\tloss 0.6931 (0.6915)\taccu 48.438 (53.406)\n",
      "Epoch-153 120 batches\tloss 0.6941 (0.6916)\taccu 57.812 (53.398)\n",
      "Epoch-153 140 batches\tloss 0.6895 (0.6916)\taccu 60.938 (53.359)\n",
      "Epoch-153 47.4s\tTrain: loss 0.6919\taccu 53.1651\tValid: loss 0.6936\taccu 50.4808\n",
      "Epoch 153: val_acc did not improve\n",
      "153 1.0000000000000002e-06\n",
      "Epoch-154  20 batches\tloss 0.6943 (0.6900)\taccu 54.688 (55.391)\n",
      "Epoch-154  40 batches\tloss 0.7011 (0.6911)\taccu 46.875 (54.648)\n",
      "Epoch-154  60 batches\tloss 0.6917 (0.6913)\taccu 45.312 (53.516)\n",
      "Epoch-154  80 batches\tloss 0.6927 (0.6913)\taccu 54.688 (53.574)\n",
      "Epoch-154 100 batches\tloss 0.6948 (0.6915)\taccu 46.875 (53.188)\n",
      "Epoch-154 120 batches\tloss 0.6856 (0.6916)\taccu 59.375 (53.151)\n",
      "Epoch-154 140 batches\tloss 0.6945 (0.6917)\taccu 50.000 (53.058)\n",
      "Epoch-154 46.1s\tTrain: loss 0.6918\taccu 52.8446\tValid: loss 0.6937\taccu 50.6310\n",
      "Epoch 154: val_acc did not improve\n",
      "154 1.0000000000000002e-06\n",
      "Epoch-155  20 batches\tloss 0.6957 (0.6921)\taccu 45.312 (51.641)\n",
      "Epoch-155  40 batches\tloss 0.6930 (0.6925)\taccu 57.812 (51.875)\n",
      "Epoch-155  60 batches\tloss 0.6931 (0.6921)\taccu 48.438 (52.604)\n",
      "Epoch-155  80 batches\tloss 0.6931 (0.6920)\taccu 48.438 (52.520)\n",
      "Epoch-155 100 batches\tloss 0.6925 (0.6917)\taccu 45.312 (52.906)\n",
      "Epoch-155 120 batches\tloss 0.6928 (0.6918)\taccu 53.125 (53.060)\n",
      "Epoch-155 140 batches\tloss 0.6922 (0.6918)\taccu 51.562 (52.924)\n",
      "Epoch-155 45.9s\tTrain: loss 0.6919\taccu 52.9848\tValid: loss 0.6937\taccu 50.4307\n",
      "Epoch 155: val_acc did not improve\n",
      "155 1.0000000000000002e-06\n",
      "Epoch-156  20 batches\tloss 0.6923 (0.6917)\taccu 46.875 (52.422)\n",
      "Epoch-156  40 batches\tloss 0.6953 (0.6916)\taccu 54.688 (52.578)\n",
      "Epoch-156  60 batches\tloss 0.6925 (0.6916)\taccu 46.875 (52.760)\n",
      "Epoch-156  80 batches\tloss 0.6927 (0.6920)\taccu 51.562 (52.754)\n",
      "Epoch-156 100 batches\tloss 0.6940 (0.6917)\taccu 48.438 (53.422)\n",
      "Epoch-156 120 batches\tloss 0.6938 (0.6916)\taccu 46.875 (53.398)\n",
      "Epoch-156 140 batches\tloss 0.6949 (0.6918)\taccu 45.312 (53.214)\n",
      "Epoch-156 46.7s\tTrain: loss 0.6917\taccu 53.1651\tValid: loss 0.6937\taccu 49.9299\n",
      "Epoch 156: val_acc did not improve\n",
      "156 1.0000000000000002e-06\n",
      "Epoch-157  20 batches\tloss 0.6860 (0.6914)\taccu 57.812 (52.422)\n",
      "Epoch-157  40 batches\tloss 0.6881 (0.6910)\taccu 48.438 (53.750)\n",
      "Epoch-157  60 batches\tloss 0.6930 (0.6910)\taccu 46.875 (53.490)\n",
      "Epoch-157  80 batches\tloss 0.6948 (0.6913)\taccu 53.125 (53.359)\n",
      "Epoch-157 100 batches\tloss 0.6879 (0.6916)\taccu 60.938 (52.922)\n",
      "Epoch-157 120 batches\tloss 0.6976 (0.6920)\taccu 43.750 (52.513)\n",
      "Epoch-157 140 batches\tloss 0.6906 (0.6920)\taccu 51.562 (52.321)\n",
      "Epoch-157 44.6s\tTrain: loss 0.6921\taccu 52.3237\tValid: loss 0.6937\taccu 50.2905\n",
      "Epoch 157: val_acc did not improve\n",
      "157 1.0000000000000002e-06\n",
      "Epoch-158  20 batches\tloss 0.6892 (0.6900)\taccu 56.250 (55.391)\n",
      "Epoch-158  40 batches\tloss 0.6999 (0.6904)\taccu 51.562 (54.219)\n",
      "Epoch-158  60 batches\tloss 0.6864 (0.6908)\taccu 68.750 (53.516)\n",
      "Epoch-158  80 batches\tloss 0.7038 (0.6917)\taccu 35.938 (52.441)\n",
      "Epoch-158 100 batches\tloss 0.6882 (0.6919)\taccu 62.500 (52.578)\n",
      "Epoch-158 120 batches\tloss 0.6885 (0.6921)\taccu 54.688 (52.344)\n",
      "Epoch-158 140 batches\tloss 0.6969 (0.6921)\taccu 54.688 (52.321)\n",
      "Epoch-158 42.0s\tTrain: loss 0.6921\taccu 52.1935\tValid: loss 0.6937\taccu 50.2003\n",
      "Epoch 158: val_acc did not improve\n",
      "158 1.0000000000000002e-06\n",
      "Epoch-159  20 batches\tloss 0.6953 (0.6922)\taccu 40.625 (52.188)\n",
      "Epoch-159  40 batches\tloss 0.6967 (0.6928)\taccu 43.750 (51.758)\n",
      "Epoch-159  60 batches\tloss 0.6977 (0.6922)\taccu 48.438 (52.630)\n",
      "Epoch-159  80 batches\tloss 0.6899 (0.6919)\taccu 53.125 (52.695)\n",
      "Epoch-159 100 batches\tloss 0.6932 (0.6918)\taccu 48.438 (52.734)\n",
      "Epoch-159 120 batches\tloss 0.6907 (0.6916)\taccu 51.562 (52.917)\n",
      "Epoch-159 140 batches\tloss 0.6952 (0.6918)\taccu 46.875 (52.913)\n",
      "Epoch-159 40.7s\tTrain: loss 0.6918\taccu 52.9647\tValid: loss 0.6938\taccu 50.4507\n",
      "Epoch 159: val_acc did not improve\n",
      "159 1.0000000000000002e-06\n",
      "Epoch-160  20 batches\tloss 0.6896 (0.6926)\taccu 53.125 (52.344)\n",
      "Epoch-160  40 batches\tloss 0.6867 (0.6920)\taccu 59.375 (52.305)\n",
      "Epoch-160  60 batches\tloss 0.6932 (0.6923)\taccu 54.688 (51.771)\n",
      "Epoch-160  80 batches\tloss 0.6902 (0.6920)\taccu 53.125 (52.402)\n",
      "Epoch-160 100 batches\tloss 0.6925 (0.6924)\taccu 50.000 (51.953)\n",
      "Epoch-160 120 batches\tloss 0.6938 (0.6924)\taccu 50.000 (52.240)\n",
      "Epoch-160 140 batches\tloss 0.6937 (0.6922)\taccu 53.125 (52.411)\n",
      "Epoch-160 40.5s\tTrain: loss 0.6921\taccu 52.5441\tValid: loss 0.6938\taccu 50.4107\n",
      "Epoch 160: val_acc did not improve\n",
      "160 1.0000000000000002e-06\n",
      "Epoch-161  20 batches\tloss 0.6936 (0.6942)\taccu 51.562 (49.062)\n",
      "Epoch-161  40 batches\tloss 0.6970 (0.6934)\taccu 48.438 (50.078)\n",
      "Epoch-161  60 batches\tloss 0.6857 (0.6927)\taccu 57.812 (51.224)\n",
      "Epoch-161  80 batches\tloss 0.6927 (0.6920)\taccu 54.688 (52.227)\n",
      "Epoch-161 100 batches\tloss 0.6989 (0.6918)\taccu 43.750 (52.672)\n",
      "Epoch-161 120 batches\tloss 0.6950 (0.6918)\taccu 45.312 (52.682)\n",
      "Epoch-161 140 batches\tloss 0.6956 (0.6917)\taccu 46.875 (52.556)\n",
      "Epoch-161 40.3s\tTrain: loss 0.6919\taccu 52.5341\tValid: loss 0.6937\taccu 49.9800\n",
      "Epoch 161: val_acc did not improve\n",
      "161 1.0000000000000002e-06\n",
      "Epoch-162  20 batches\tloss 0.6885 (0.6917)\taccu 54.688 (53.281)\n",
      "Epoch-162  40 batches\tloss 0.6860 (0.6910)\taccu 64.062 (53.984)\n",
      "Epoch-162  60 batches\tloss 0.6956 (0.6914)\taccu 50.000 (53.438)\n",
      "Epoch-162  80 batches\tloss 0.6927 (0.6913)\taccu 50.000 (53.555)\n",
      "Epoch-162 100 batches\tloss 0.6895 (0.6919)\taccu 50.000 (52.859)\n",
      "Epoch-162 120 batches\tloss 0.6919 (0.6919)\taccu 60.938 (52.891)\n",
      "Epoch-162 140 batches\tloss 0.6915 (0.6919)\taccu 51.562 (52.723)\n",
      "Epoch-162 43.0s\tTrain: loss 0.6920\taccu 52.6442\tValid: loss 0.6937\taccu 50.3305\n",
      "Epoch 162: val_acc did not improve\n",
      "162 1.0000000000000002e-06\n",
      "Epoch-163  20 batches\tloss 0.6914 (0.6929)\taccu 48.438 (51.875)\n",
      "Epoch-163  40 batches\tloss 0.6837 (0.6924)\taccu 64.062 (51.914)\n",
      "Epoch-163  60 batches\tloss 0.6877 (0.6921)\taccu 54.688 (52.448)\n",
      "Epoch-163  80 batches\tloss 0.6954 (0.6921)\taccu 45.312 (52.676)\n",
      "Epoch-163 100 batches\tloss 0.6873 (0.6923)\taccu 59.375 (52.312)\n",
      "Epoch-163 120 batches\tloss 0.6949 (0.6921)\taccu 45.312 (52.331)\n",
      "Epoch-163 140 batches\tloss 0.7010 (0.6920)\taccu 39.062 (52.422)\n",
      "Epoch-163 46.3s\tTrain: loss 0.6919\taccu 52.7344\tValid: loss 0.6937\taccu 50.4307\n",
      "Epoch 163: val_acc did not improve\n",
      "163 1.0000000000000002e-06\n",
      "Epoch-164  20 batches\tloss 0.6903 (0.6909)\taccu 51.562 (53.125)\n",
      "Epoch-164  40 batches\tloss 0.6891 (0.6914)\taccu 54.688 (52.266)\n",
      "Epoch-164  60 batches\tloss 0.6897 (0.6916)\taccu 53.125 (52.708)\n",
      "Epoch-164  80 batches\tloss 0.6918 (0.6922)\taccu 56.250 (52.324)\n",
      "Epoch-164 100 batches\tloss 0.6896 (0.6920)\taccu 53.125 (52.391)\n",
      "Epoch-164 120 batches\tloss 0.6895 (0.6920)\taccu 50.000 (52.435)\n",
      "Epoch-164 140 batches\tloss 0.6945 (0.6920)\taccu 54.688 (52.522)\n",
      "Epoch-164 43.0s\tTrain: loss 0.6922\taccu 52.1935\tValid: loss 0.6936\taccu 50.2804\n",
      "Epoch 164: val_acc did not improve\n",
      "164 1.0000000000000002e-06\n",
      "Epoch-165  20 batches\tloss 0.6959 (0.6918)\taccu 46.875 (51.562)\n",
      "Epoch-165  40 batches\tloss 0.6966 (0.6927)\taccu 43.750 (50.547)\n",
      "Epoch-165  60 batches\tloss 0.6905 (0.6922)\taccu 60.938 (52.057)\n",
      "Epoch-165  80 batches\tloss 0.6945 (0.6927)\taccu 42.188 (51.523)\n",
      "Epoch-165 100 batches\tloss 0.6942 (0.6924)\taccu 51.562 (51.906)\n",
      "Epoch-165 120 batches\tloss 0.6880 (0.6924)\taccu 62.500 (51.823)\n",
      "Epoch-165 140 batches\tloss 0.6912 (0.6924)\taccu 56.250 (51.942)\n",
      "Epoch-165 41.8s\tTrain: loss 0.6922\taccu 52.1735\tValid: loss 0.6937\taccu 50.6611\n",
      "Epoch 165: val_acc did not improve\n",
      "165 1.0000000000000002e-06\n",
      "Epoch-166  20 batches\tloss 0.6931 (0.6902)\taccu 54.688 (53.828)\n",
      "Epoch-166  40 batches\tloss 0.6899 (0.6910)\taccu 54.688 (53.594)\n",
      "Epoch-166  60 batches\tloss 0.6931 (0.6917)\taccu 50.000 (52.552)\n",
      "Epoch-166  80 batches\tloss 0.6898 (0.6917)\taccu 57.812 (52.637)\n",
      "Epoch-166 100 batches\tloss 0.6899 (0.6917)\taccu 50.000 (52.859)\n",
      "Epoch-166 120 batches\tloss 0.6939 (0.6916)\taccu 57.812 (52.956)\n",
      "Epoch-166 140 batches\tloss 0.6967 (0.6918)\taccu 50.000 (52.667)\n",
      "Epoch-166 42.1s\tTrain: loss 0.6918\taccu 52.6943\tValid: loss 0.6937\taccu 50.2204\n",
      "Epoch 166: val_acc did not improve\n",
      "166 1.0000000000000002e-06\n",
      "Epoch-167  20 batches\tloss 0.6899 (0.6918)\taccu 60.938 (53.281)\n",
      "Epoch-167  40 batches\tloss 0.6921 (0.6910)\taccu 54.688 (54.062)\n",
      "Epoch-167  60 batches\tloss 0.6871 (0.6919)\taccu 57.812 (53.333)\n",
      "Epoch-167  80 batches\tloss 0.6948 (0.6918)\taccu 50.000 (52.949)\n",
      "Epoch-167 100 batches\tloss 0.6956 (0.6918)\taccu 43.750 (53.016)\n",
      "Epoch-167 120 batches\tloss 0.6923 (0.6918)\taccu 50.000 (52.839)\n",
      "Epoch-167 140 batches\tloss 0.6865 (0.6918)\taccu 54.688 (52.935)\n",
      "Epoch-167 42.6s\tTrain: loss 0.6918\taccu 53.0349\tValid: loss 0.6938\taccu 50.4006\n",
      "Epoch 167: val_acc did not improve\n",
      "167 1.0000000000000002e-06\n",
      "Epoch-168  20 batches\tloss 0.6874 (0.6914)\taccu 56.250 (53.984)\n",
      "Epoch-168  40 batches\tloss 0.6835 (0.6920)\taccu 64.062 (53.633)\n",
      "Epoch-168  60 batches\tloss 0.7000 (0.6918)\taccu 43.750 (53.385)\n",
      "Epoch-168  80 batches\tloss 0.6956 (0.6918)\taccu 48.438 (53.145)\n",
      "Epoch-168 100 batches\tloss 0.6984 (0.6919)\taccu 42.188 (52.938)\n",
      "Epoch-168 120 batches\tloss 0.6957 (0.6919)\taccu 43.750 (52.956)\n",
      "Epoch-168 140 batches\tloss 0.6995 (0.6918)\taccu 48.438 (52.891)\n",
      "Epoch-168 47.3s\tTrain: loss 0.6918\taccu 52.8546\tValid: loss 0.6938\taccu 50.2604\n",
      "Epoch 168: val_acc did not improve\n",
      "168 1.0000000000000002e-06\n",
      "Epoch-169  20 batches\tloss 0.6814 (0.6909)\taccu 64.062 (54.844)\n",
      "Epoch-169  40 batches\tloss 0.6930 (0.6921)\taccu 48.438 (52.773)\n",
      "Epoch-169  60 batches\tloss 0.6982 (0.6917)\taccu 45.312 (53.307)\n",
      "Epoch-169  80 batches\tloss 0.6917 (0.6917)\taccu 54.688 (53.379)\n",
      "Epoch-169 100 batches\tloss 0.6895 (0.6919)\taccu 57.812 (53.234)\n",
      "Epoch-169 120 batches\tloss 0.6925 (0.6917)\taccu 48.438 (53.359)\n",
      "Epoch-169 140 batches\tloss 0.6924 (0.6918)\taccu 53.125 (53.482)\n",
      "Epoch-169 43.6s\tTrain: loss 0.6917\taccu 53.4355\tValid: loss 0.6937\taccu 50.5308\n",
      "Epoch 169: val_acc did not improve\n",
      "169 1.0000000000000002e-06\n",
      "Epoch-170  20 batches\tloss 0.6922 (0.6916)\taccu 51.562 (52.891)\n",
      "Epoch-170  40 batches\tloss 0.6852 (0.6911)\taccu 62.500 (53.867)\n",
      "Epoch-170  60 batches\tloss 0.6902 (0.6913)\taccu 51.562 (53.906)\n",
      "Epoch-170  80 batches\tloss 0.6899 (0.6914)\taccu 48.438 (53.672)\n",
      "Epoch-170 100 batches\tloss 0.6955 (0.6917)\taccu 48.438 (53.453)\n",
      "Epoch-170 120 batches\tloss 0.6910 (0.6917)\taccu 57.812 (53.099)\n",
      "Epoch-170 140 batches\tloss 0.6952 (0.6919)\taccu 48.438 (52.946)\n",
      "Epoch-170 43.1s\tTrain: loss 0.6919\taccu 52.8846\tValid: loss 0.6936\taccu 50.7111\n",
      "Epoch 170: val_acc did not improve\n",
      "170 1.0000000000000002e-06\n",
      "Epoch-171  20 batches\tloss 0.6830 (0.6919)\taccu 57.812 (52.422)\n",
      "Epoch-171  40 batches\tloss 0.6873 (0.6916)\taccu 56.250 (52.695)\n",
      "Epoch-171  60 batches\tloss 0.6857 (0.6923)\taccu 62.500 (52.266)\n",
      "Epoch-171  80 batches\tloss 0.6961 (0.6924)\taccu 46.875 (51.816)\n",
      "Epoch-171 100 batches\tloss 0.6893 (0.6923)\taccu 51.562 (52.203)\n",
      "Epoch-171 120 batches\tloss 0.6947 (0.6921)\taccu 50.000 (52.422)\n",
      "Epoch-171 140 batches\tloss 0.6961 (0.6921)\taccu 53.125 (52.444)\n",
      "Epoch-171 41.1s\tTrain: loss 0.6920\taccu 52.6843\tValid: loss 0.6936\taccu 50.4607\n",
      "Epoch 171: val_acc did not improve\n",
      "171 1.0000000000000002e-06\n",
      "Epoch-172  20 batches\tloss 0.6927 (0.6913)\taccu 46.875 (51.484)\n",
      "Epoch-172  40 batches\tloss 0.7010 (0.6919)\taccu 46.875 (52.188)\n",
      "Epoch-172  60 batches\tloss 0.6918 (0.6916)\taccu 51.562 (52.760)\n",
      "Epoch-172  80 batches\tloss 0.6958 (0.6915)\taccu 50.000 (52.773)\n",
      "Epoch-172 100 batches\tloss 0.6951 (0.6915)\taccu 53.125 (52.906)\n",
      "Epoch-172 120 batches\tloss 0.6906 (0.6916)\taccu 53.125 (53.047)\n",
      "Epoch-172 140 batches\tloss 0.6898 (0.6916)\taccu 59.375 (52.924)\n",
      "Epoch-172 41.2s\tTrain: loss 0.6917\taccu 52.7845\tValid: loss 0.6938\taccu 50.0100\n",
      "Epoch 172: val_acc did not improve\n",
      "172 1.0000000000000002e-06\n",
      "Epoch-173  20 batches\tloss 0.6904 (0.6913)\taccu 50.000 (52.812)\n",
      "Epoch-173  40 batches\tloss 0.6871 (0.6920)\taccu 51.562 (52.031)\n",
      "Epoch-173  60 batches\tloss 0.6853 (0.6923)\taccu 59.375 (51.875)\n",
      "Epoch-173  80 batches\tloss 0.7028 (0.6920)\taccu 42.188 (52.305)\n",
      "Epoch-173 100 batches\tloss 0.6790 (0.6917)\taccu 68.750 (52.797)\n",
      "Epoch-173 120 batches\tloss 0.6912 (0.6915)\taccu 57.812 (53.047)\n",
      "Epoch-173 140 batches\tloss 0.6848 (0.6919)\taccu 59.375 (52.556)\n",
      "Epoch-173 40.9s\tTrain: loss 0.6920\taccu 52.5441\tValid: loss 0.6937\taccu 50.2905\n",
      "Epoch 173: val_acc did not improve\n",
      "173 1.0000000000000002e-06\n",
      "Epoch-174  20 batches\tloss 0.6923 (0.6934)\taccu 51.562 (52.344)\n",
      "Epoch-174  40 batches\tloss 0.6945 (0.6934)\taccu 50.000 (51.328)\n",
      "Epoch-174  60 batches\tloss 0.6960 (0.6925)\taccu 48.438 (52.109)\n",
      "Epoch-174  80 batches\tloss 0.6910 (0.6922)\taccu 53.125 (52.617)\n",
      "Epoch-174 100 batches\tloss 0.6938 (0.6920)\taccu 54.688 (52.812)\n",
      "Epoch-174 120 batches\tloss 0.6967 (0.6917)\taccu 40.625 (53.242)\n",
      "Epoch-174 140 batches\tloss 0.6930 (0.6917)\taccu 50.000 (53.136)\n",
      "Epoch-174 41.5s\tTrain: loss 0.6918\taccu 53.0248\tValid: loss 0.6937\taccu 50.5909\n",
      "Epoch 174: val_acc did not improve\n",
      "174 1.0000000000000002e-06\n",
      "Epoch-175  20 batches\tloss 0.6891 (0.6917)\taccu 53.125 (53.672)\n",
      "Epoch-175  40 batches\tloss 0.6988 (0.6921)\taccu 48.438 (53.477)\n",
      "Epoch-175  60 batches\tloss 0.6886 (0.6920)\taccu 56.250 (53.464)\n",
      "Epoch-175  80 batches\tloss 0.6870 (0.6917)\taccu 56.250 (53.711)\n",
      "Epoch-175 100 batches\tloss 0.6989 (0.6916)\taccu 45.312 (53.250)\n",
      "Epoch-175 120 batches\tloss 0.6923 (0.6917)\taccu 53.125 (53.203)\n",
      "Epoch-175 140 batches\tloss 0.6916 (0.6920)\taccu 50.000 (52.958)\n",
      "Epoch-175 41.6s\tTrain: loss 0.6920\taccu 53.0148\tValid: loss 0.6937\taccu 50.4207\n",
      "Epoch 175: val_acc did not improve\n",
      "175 1.0000000000000002e-06\n",
      "Epoch-176  20 batches\tloss 0.6921 (0.6934)\taccu 54.688 (51.875)\n",
      "Epoch-176  40 batches\tloss 0.6983 (0.6925)\taccu 42.188 (52.734)\n",
      "Epoch-176  60 batches\tloss 0.6939 (0.6920)\taccu 50.000 (52.708)\n",
      "Epoch-176  80 batches\tloss 0.6875 (0.6917)\taccu 53.125 (53.086)\n",
      "Epoch-176 100 batches\tloss 0.6884 (0.6918)\taccu 57.812 (53.031)\n",
      "Epoch-176 120 batches\tloss 0.6934 (0.6918)\taccu 54.688 (53.086)\n",
      "Epoch-176 140 batches\tloss 0.6885 (0.6919)\taccu 56.250 (53.058)\n",
      "Epoch-176 41.4s\tTrain: loss 0.6919\taccu 53.0248\tValid: loss 0.6938\taccu 50.1302\n",
      "Epoch 176: val_acc did not improve\n",
      "176 1.0000000000000002e-06\n",
      "Epoch-177  20 batches\tloss 0.6959 (0.6913)\taccu 56.250 (52.422)\n",
      "Epoch-177  40 batches\tloss 0.6940 (0.6930)\taccu 51.562 (50.352)\n",
      "Epoch-177  60 batches\tloss 0.6898 (0.6926)\taccu 59.375 (51.484)\n",
      "Epoch-177  80 batches\tloss 0.6995 (0.6929)\taccu 50.000 (51.523)\n",
      "Epoch-177 100 batches\tloss 0.6867 (0.6924)\taccu 62.500 (51.906)\n",
      "Epoch-177 120 batches\tloss 0.6956 (0.6923)\taccu 51.562 (51.888)\n",
      "Epoch-177 140 batches\tloss 0.6906 (0.6923)\taccu 53.125 (52.054)\n",
      "Epoch-177 40.9s\tTrain: loss 0.6921\taccu 52.2937\tValid: loss 0.6937\taccu 50.2404\n",
      "Epoch 177: val_acc did not improve\n",
      "177 1.0000000000000002e-06\n",
      "Epoch-178  20 batches\tloss 0.6879 (0.6937)\taccu 48.438 (50.625)\n",
      "Epoch-178  40 batches\tloss 0.6923 (0.6928)\taccu 45.312 (51.523)\n",
      "Epoch-178  60 batches\tloss 0.6993 (0.6925)\taccu 42.188 (51.536)\n",
      "Epoch-178  80 batches\tloss 0.6920 (0.6926)\taccu 59.375 (51.484)\n",
      "Epoch-178 100 batches\tloss 0.6929 (0.6922)\taccu 42.188 (52.000)\n",
      "Epoch-178 120 batches\tloss 0.6911 (0.6919)\taccu 51.562 (52.396)\n",
      "Epoch-178 140 batches\tloss 0.6842 (0.6920)\taccu 65.625 (52.333)\n",
      "Epoch-178 41.2s\tTrain: loss 0.6919\taccu 52.3237\tValid: loss 0.6937\taccu 50.1903\n",
      "Epoch 178: val_acc did not improve\n",
      "178 1.0000000000000002e-06\n",
      "Epoch-179  20 batches\tloss 0.6903 (0.6905)\taccu 59.375 (54.531)\n",
      "Epoch-179  40 batches\tloss 0.6849 (0.6905)\taccu 57.812 (54.648)\n",
      "Epoch-179  60 batches\tloss 0.6923 (0.6909)\taccu 56.250 (54.036)\n",
      "Epoch-179  80 batches\tloss 0.6857 (0.6913)\taccu 56.250 (53.594)\n",
      "Epoch-179 100 batches\tloss 0.6897 (0.6917)\taccu 60.938 (53.031)\n",
      "Epoch-179 120 batches\tloss 0.6907 (0.6917)\taccu 51.562 (52.799)\n",
      "Epoch-179 140 batches\tloss 0.6899 (0.6918)\taccu 51.562 (52.679)\n",
      "Epoch-179 41.7s\tTrain: loss 0.6916\taccu 53.1651\tValid: loss 0.6937\taccu 50.1603\n",
      "Epoch 179: val_acc did not improve\n",
      "179 1.0000000000000002e-06\n",
      "Epoch-180  20 batches\tloss 0.6929 (0.6915)\taccu 48.438 (53.047)\n",
      "Epoch-180  40 batches\tloss 0.6896 (0.6912)\taccu 57.812 (53.516)\n",
      "Epoch-180  60 batches\tloss 0.6935 (0.6916)\taccu 50.000 (53.073)\n",
      "Epoch-180  80 batches\tloss 0.6925 (0.6913)\taccu 48.438 (53.457)\n",
      "Epoch-180 100 batches\tloss 0.6853 (0.6916)\taccu 64.062 (53.078)\n",
      "Epoch-180 120 batches\tloss 0.6914 (0.6916)\taccu 53.125 (53.216)\n",
      "Epoch-180 140 batches\tloss 0.6936 (0.6918)\taccu 46.875 (52.779)\n",
      "Epoch-180 41.2s\tTrain: loss 0.6917\taccu 52.7544\tValid: loss 0.6937\taccu 50.3806\n",
      "Epoch 180: val_acc did not improve\n",
      "180 1.0000000000000002e-06\n",
      "Epoch-181  20 batches\tloss 0.6883 (0.6913)\taccu 59.375 (53.828)\n",
      "Epoch-181  40 batches\tloss 0.6967 (0.6920)\taccu 53.125 (52.578)\n",
      "Epoch-181  60 batches\tloss 0.6896 (0.6920)\taccu 57.812 (52.422)\n",
      "Epoch-181  80 batches\tloss 0.6908 (0.6919)\taccu 62.500 (52.715)\n",
      "Epoch-181 100 batches\tloss 0.6940 (0.6917)\taccu 53.125 (52.766)\n",
      "Epoch-181 120 batches\tloss 0.6961 (0.6919)\taccu 50.000 (52.747)\n",
      "Epoch-181 140 batches\tloss 0.6879 (0.6919)\taccu 51.562 (52.734)\n",
      "Epoch-181 42.0s\tTrain: loss 0.6920\taccu 52.8145\tValid: loss 0.6938\taccu 50.0100\n",
      "Epoch 181: val_acc did not improve\n",
      "181 1.0000000000000002e-06\n",
      "Epoch-182  20 batches\tloss 0.6899 (0.6914)\taccu 57.812 (53.203)\n",
      "Epoch-182  40 batches\tloss 0.6915 (0.6916)\taccu 48.438 (52.500)\n",
      "Epoch-182  60 batches\tloss 0.6847 (0.6916)\taccu 53.125 (52.552)\n",
      "Epoch-182  80 batches\tloss 0.6929 (0.6920)\taccu 54.688 (52.285)\n",
      "Epoch-182 100 batches\tloss 0.6949 (0.6918)\taccu 51.562 (52.625)\n",
      "Epoch-182 120 batches\tloss 0.6958 (0.6918)\taccu 45.312 (52.826)\n",
      "Epoch-182 140 batches\tloss 0.6985 (0.6918)\taccu 50.000 (52.645)\n",
      "Epoch-182 41.6s\tTrain: loss 0.6918\taccu 52.7143\tValid: loss 0.6937\taccu 50.1903\n",
      "Epoch 182: val_acc did not improve\n",
      "182 1.0000000000000002e-06\n",
      "Epoch-183  20 batches\tloss 0.6901 (0.6919)\taccu 54.688 (51.719)\n",
      "Epoch-183  40 batches\tloss 0.6898 (0.6912)\taccu 57.812 (53.320)\n",
      "Epoch-183  60 batches\tloss 0.6968 (0.6920)\taccu 42.188 (52.135)\n",
      "Epoch-183  80 batches\tloss 0.6877 (0.6918)\taccu 56.250 (52.461)\n",
      "Epoch-183 100 batches\tloss 0.6944 (0.6918)\taccu 51.562 (52.531)\n",
      "Epoch-183 120 batches\tloss 0.6930 (0.6918)\taccu 45.312 (52.617)\n",
      "Epoch-183 140 batches\tloss 0.6929 (0.6918)\taccu 48.438 (52.679)\n",
      "Epoch-183 41.0s\tTrain: loss 0.6918\taccu 52.5741\tValid: loss 0.6937\taccu 50.4207\n",
      "Epoch 183: val_acc did not improve\n",
      "183 1.0000000000000002e-06\n",
      "Epoch-184  20 batches\tloss 0.6895 (0.6911)\taccu 56.250 (52.891)\n",
      "Epoch-184  40 batches\tloss 0.6973 (0.6911)\taccu 48.438 (52.891)\n",
      "Epoch-184  60 batches\tloss 0.6937 (0.6925)\taccu 46.875 (51.615)\n",
      "Epoch-184  80 batches\tloss 0.6959 (0.6921)\taccu 51.562 (52.266)\n",
      "Epoch-184 100 batches\tloss 0.6958 (0.6922)\taccu 50.000 (52.062)\n",
      "Epoch-184 120 batches\tloss 0.6951 (0.6923)\taccu 45.312 (51.953)\n",
      "Epoch-184 140 batches\tloss 0.6904 (0.6923)\taccu 50.000 (52.176)\n",
      "Epoch-184 42.3s\tTrain: loss 0.6920\taccu 52.3838\tValid: loss 0.6937\taccu 50.1402\n",
      "Epoch 184: val_acc did not improve\n",
      "184 1.0000000000000002e-06\n",
      "Epoch-185  20 batches\tloss 0.7001 (0.6903)\taccu 42.188 (54.531)\n",
      "Epoch-185  40 batches\tloss 0.6909 (0.6904)\taccu 45.312 (54.258)\n",
      "Epoch-185  60 batches\tloss 0.6926 (0.6910)\taccu 59.375 (53.724)\n",
      "Epoch-185  80 batches\tloss 0.6895 (0.6910)\taccu 54.688 (53.457)\n",
      "Epoch-185 100 batches\tloss 0.6900 (0.6914)\taccu 50.000 (52.828)\n",
      "Epoch-185 120 batches\tloss 0.6971 (0.6917)\taccu 46.875 (52.734)\n",
      "Epoch-185 140 batches\tloss 0.6927 (0.6917)\taccu 56.250 (52.690)\n",
      "Epoch-185 41.7s\tTrain: loss 0.6918\taccu 52.7945\tValid: loss 0.6936\taccu 50.6510\n",
      "Epoch 185: val_acc did not improve\n",
      "185 1.0000000000000002e-06\n",
      "Epoch-186  20 batches\tloss 0.6956 (0.6916)\taccu 51.562 (52.891)\n",
      "Epoch-186  40 batches\tloss 0.6988 (0.6921)\taccu 40.625 (51.875)\n",
      "Epoch-186  60 batches\tloss 0.6934 (0.6921)\taccu 51.562 (52.474)\n",
      "Epoch-186  80 batches\tloss 0.6948 (0.6918)\taccu 48.438 (52.754)\n",
      "Epoch-186 100 batches\tloss 0.6862 (0.6919)\taccu 54.688 (52.797)\n",
      "Epoch-186 120 batches\tloss 0.6945 (0.6917)\taccu 54.688 (52.969)\n",
      "Epoch-186 140 batches\tloss 0.6911 (0.6918)\taccu 53.125 (53.058)\n",
      "Epoch-186 41.2s\tTrain: loss 0.6918\taccu 53.0349\tValid: loss 0.6938\taccu 50.4307\n",
      "Epoch 186: val_acc did not improve\n",
      "186 1.0000000000000002e-06\n",
      "Epoch-187  20 batches\tloss 0.6857 (0.6932)\taccu 59.375 (51.797)\n",
      "Epoch-187  40 batches\tloss 0.7040 (0.6929)\taccu 37.500 (52.461)\n",
      "Epoch-187  60 batches\tloss 0.6957 (0.6924)\taccu 53.125 (52.865)\n",
      "Epoch-187  80 batches\tloss 0.6891 (0.6923)\taccu 53.125 (53.086)\n",
      "Epoch-187 100 batches\tloss 0.6931 (0.6924)\taccu 48.438 (53.062)\n",
      "Epoch-187 120 batches\tloss 0.6987 (0.6923)\taccu 50.000 (53.281)\n",
      "Epoch-187 140 batches\tloss 0.6921 (0.6919)\taccu 51.562 (53.560)\n",
      "Epoch-187 41.3s\tTrain: loss 0.6919\taccu 53.3854\tValid: loss 0.6937\taccu 50.4908\n",
      "Epoch 187: val_acc did not improve\n",
      "187 1.0000000000000002e-06\n",
      "Epoch-188  20 batches\tloss 0.6879 (0.6927)\taccu 56.250 (52.578)\n",
      "Epoch-188  40 batches\tloss 0.6941 (0.6922)\taccu 50.000 (52.852)\n",
      "Epoch-188  60 batches\tloss 0.6900 (0.6922)\taccu 51.562 (52.396)\n",
      "Epoch-188  80 batches\tloss 0.6864 (0.6923)\taccu 53.125 (52.246)\n",
      "Epoch-188 100 batches\tloss 0.6912 (0.6921)\taccu 50.000 (52.562)\n",
      "Epoch-188 120 batches\tloss 0.6904 (0.6918)\taccu 56.250 (52.904)\n",
      "Epoch-188 140 batches\tloss 0.6920 (0.6919)\taccu 50.000 (52.846)\n",
      "Epoch-188 42.5s\tTrain: loss 0.6920\taccu 52.6743\tValid: loss 0.6937\taccu 50.2103\n",
      "Epoch 188: val_acc did not improve\n",
      "188 1.0000000000000002e-06\n",
      "Epoch-189  20 batches\tloss 0.6914 (0.6913)\taccu 53.125 (53.672)\n",
      "Epoch-189  40 batches\tloss 0.6876 (0.6920)\taccu 62.500 (52.852)\n",
      "Epoch-189  60 batches\tloss 0.6967 (0.6924)\taccu 40.625 (52.656)\n",
      "Epoch-189  80 batches\tloss 0.6850 (0.6921)\taccu 64.062 (53.125)\n",
      "Epoch-189 100 batches\tloss 0.6964 (0.6920)\taccu 51.562 (53.234)\n",
      "Epoch-189 120 batches\tloss 0.6893 (0.6917)\taccu 51.562 (53.372)\n",
      "Epoch-189 140 batches\tloss 0.6865 (0.6918)\taccu 57.812 (53.225)\n",
      "Epoch-189 43.0s\tTrain: loss 0.6918\taccu 53.2652\tValid: loss 0.6938\taccu 49.9900\n",
      "Epoch 189: val_acc did not improve\n",
      "189 1.0000000000000002e-06\n",
      "Epoch-190  20 batches\tloss 0.6858 (0.6918)\taccu 59.375 (53.125)\n",
      "Epoch-190  40 batches\tloss 0.6887 (0.6921)\taccu 54.688 (52.539)\n",
      "Epoch-190  60 batches\tloss 0.6914 (0.6921)\taccu 51.562 (52.604)\n",
      "Epoch-190  80 batches\tloss 0.6927 (0.6918)\taccu 53.125 (53.066)\n",
      "Epoch-190 100 batches\tloss 0.6921 (0.6917)\taccu 51.562 (53.109)\n",
      "Epoch-190 120 batches\tloss 0.6922 (0.6920)\taccu 56.250 (52.682)\n",
      "Epoch-190 140 batches\tloss 0.6850 (0.6918)\taccu 56.250 (53.013)\n",
      "Epoch-190 43.1s\tTrain: loss 0.6919\taccu 52.8846\tValid: loss 0.6938\taccu 50.2704\n",
      "Epoch 190: val_acc did not improve\n",
      "190 1.0000000000000002e-06\n",
      "Epoch-191  20 batches\tloss 0.6925 (0.6917)\taccu 59.375 (53.750)\n",
      "Epoch-191  40 batches\tloss 0.6979 (0.6923)\taccu 46.875 (52.695)\n",
      "Epoch-191  60 batches\tloss 0.6969 (0.6926)\taccu 43.750 (52.526)\n",
      "Epoch-191  80 batches\tloss 0.6973 (0.6925)\taccu 42.188 (52.676)\n",
      "Epoch-191 100 batches\tloss 0.6832 (0.6923)\taccu 59.375 (52.812)\n",
      "Epoch-191 120 batches\tloss 0.6900 (0.6919)\taccu 53.125 (53.021)\n",
      "Epoch-191 140 batches\tloss 0.6940 (0.6918)\taccu 48.438 (52.935)\n",
      "Epoch-191 41.1s\tTrain: loss 0.6918\taccu 52.9547\tValid: loss 0.6938\taccu 50.4107\n",
      "Epoch 191: val_acc did not improve\n",
      "191 1.0000000000000002e-06\n",
      "Epoch-192  20 batches\tloss 0.6931 (0.6930)\taccu 53.125 (51.250)\n",
      "Epoch-192  40 batches\tloss 0.6905 (0.6922)\taccu 56.250 (52.148)\n",
      "Epoch-192  60 batches\tloss 0.6970 (0.6923)\taccu 50.000 (52.344)\n",
      "Epoch-192  80 batches\tloss 0.6948 (0.6923)\taccu 50.000 (52.090)\n",
      "Epoch-192 100 batches\tloss 0.6890 (0.6920)\taccu 57.812 (52.500)\n",
      "Epoch-192 120 batches\tloss 0.6936 (0.6921)\taccu 46.875 (52.383)\n",
      "Epoch-192 140 batches\tloss 0.6917 (0.6920)\taccu 54.688 (52.444)\n",
      "Epoch-192 41.1s\tTrain: loss 0.6918\taccu 52.7344\tValid: loss 0.6938\taccu 50.1603\n",
      "Epoch 192: val_acc did not improve\n",
      "192 1.0000000000000002e-06\n",
      "Epoch-193  20 batches\tloss 0.6920 (0.6906)\taccu 50.000 (53.672)\n",
      "Epoch-193  40 batches\tloss 0.6857 (0.6914)\taccu 57.812 (52.852)\n",
      "Epoch-193  60 batches\tloss 0.6998 (0.6918)\taccu 48.438 (52.656)\n",
      "Epoch-193  80 batches\tloss 0.6946 (0.6922)\taccu 50.000 (52.285)\n",
      "Epoch-193 100 batches\tloss 0.6977 (0.6923)\taccu 48.438 (52.234)\n",
      "Epoch-193 120 batches\tloss 0.6851 (0.6922)\taccu 62.500 (52.318)\n",
      "Epoch-193 140 batches\tloss 0.6833 (0.6921)\taccu 65.625 (52.467)\n",
      "Epoch-193 40.9s\tTrain: loss 0.6920\taccu 52.5040\tValid: loss 0.6938\taccu 50.0701\n",
      "Epoch 193: val_acc did not improve\n",
      "193 1.0000000000000002e-06\n",
      "Epoch-194  20 batches\tloss 0.6979 (0.6914)\taccu 48.438 (52.656)\n",
      "Epoch-194  40 batches\tloss 0.6935 (0.6913)\taccu 54.688 (53.555)\n",
      "Epoch-194  60 batches\tloss 0.6904 (0.6914)\taccu 56.250 (53.646)\n",
      "Epoch-194  80 batches\tloss 0.6839 (0.6916)\taccu 65.625 (53.379)\n",
      "Epoch-194 100 batches\tloss 0.6942 (0.6917)\taccu 45.312 (53.141)\n",
      "Epoch-194 120 batches\tloss 0.6970 (0.6918)\taccu 50.000 (52.865)\n",
      "Epoch-194 140 batches\tloss 0.6955 (0.6917)\taccu 48.438 (53.047)\n",
      "Epoch-194 41.0s\tTrain: loss 0.6918\taccu 52.9147\tValid: loss 0.6938\taccu 50.0200\n",
      "Epoch 194: val_acc did not improve\n",
      "194 1.0000000000000002e-06\n",
      "Epoch-195  20 batches\tloss 0.6909 (0.6918)\taccu 48.438 (53.672)\n",
      "Epoch-195  40 batches\tloss 0.6901 (0.6922)\taccu 48.438 (52.500)\n",
      "Epoch-195  60 batches\tloss 0.6878 (0.6918)\taccu 59.375 (52.995)\n",
      "Epoch-195  80 batches\tloss 0.6877 (0.6921)\taccu 54.688 (52.324)\n",
      "Epoch-195 100 batches\tloss 0.6952 (0.6920)\taccu 50.000 (52.234)\n",
      "Epoch-195 120 batches\tloss 0.6969 (0.6921)\taccu 51.562 (52.122)\n",
      "Epoch-195 140 batches\tloss 0.6972 (0.6919)\taccu 46.875 (52.243)\n",
      "Epoch-195 41.1s\tTrain: loss 0.6918\taccu 52.5741\tValid: loss 0.6937\taccu 50.3005\n",
      "Epoch 195: val_acc did not improve\n",
      "195 1.0000000000000002e-06\n",
      "Epoch-196  20 batches\tloss 0.6899 (0.6911)\taccu 50.000 (54.297)\n",
      "Epoch-196  40 batches\tloss 0.6878 (0.6916)\taccu 54.688 (53.164)\n",
      "Epoch-196  60 batches\tloss 0.6947 (0.6917)\taccu 53.125 (52.969)\n",
      "Epoch-196  80 batches\tloss 0.6890 (0.6923)\taccu 56.250 (51.895)\n",
      "Epoch-196 100 batches\tloss 0.6976 (0.6923)\taccu 46.875 (52.078)\n",
      "Epoch-196 120 batches\tloss 0.6876 (0.6922)\taccu 64.062 (52.370)\n",
      "Epoch-196 140 batches\tloss 0.6909 (0.6922)\taccu 50.000 (52.288)\n",
      "Epoch-196 43.1s\tTrain: loss 0.6921\taccu 52.2636\tValid: loss 0.6937\taccu 50.3806\n",
      "Epoch 196: val_acc did not improve\n",
      "196 1.0000000000000002e-06\n",
      "Epoch-197  20 batches\tloss 0.6865 (0.6906)\taccu 62.500 (55.078)\n",
      "Epoch-197  40 batches\tloss 0.6975 (0.6913)\taccu 48.438 (54.531)\n",
      "Epoch-197  60 batches\tloss 0.6894 (0.6917)\taccu 59.375 (53.177)\n",
      "Epoch-197  80 batches\tloss 0.6991 (0.6922)\taccu 45.312 (52.617)\n",
      "Epoch-197 100 batches\tloss 0.6980 (0.6920)\taccu 40.625 (52.875)\n",
      "Epoch-197 120 batches\tloss 0.6924 (0.6918)\taccu 54.688 (53.086)\n",
      "Epoch-197 140 batches\tloss 0.6891 (0.6918)\taccu 56.250 (53.103)\n",
      "Epoch-197 42.7s\tTrain: loss 0.6918\taccu 53.1350\tValid: loss 0.6937\taccu 50.1903\n",
      "Epoch 197: val_acc did not improve\n",
      "197 1.0000000000000002e-06\n",
      "Epoch-198  20 batches\tloss 0.6849 (0.6898)\taccu 62.500 (55.391)\n",
      "Epoch-198  40 batches\tloss 0.6944 (0.6912)\taccu 50.000 (53.633)\n",
      "Epoch-198  60 batches\tloss 0.6927 (0.6918)\taccu 56.250 (52.917)\n",
      "Epoch-198  80 batches\tloss 0.6931 (0.6923)\taccu 46.875 (52.324)\n",
      "Epoch-198 100 batches\tloss 0.6898 (0.6923)\taccu 50.000 (52.312)\n",
      "Epoch-198 120 batches\tloss 0.6877 (0.6920)\taccu 53.125 (52.513)\n",
      "Epoch-198 140 batches\tloss 0.6948 (0.6919)\taccu 56.250 (52.656)\n",
      "Epoch-198 43.5s\tTrain: loss 0.6919\taccu 52.4840\tValid: loss 0.6937\taccu 50.2304\n",
      "Epoch 198: val_acc did not improve\n",
      "198 1.0000000000000002e-06\n",
      "Epoch-199  20 batches\tloss 0.6943 (0.6912)\taccu 51.562 (52.500)\n",
      "Epoch-199  40 batches\tloss 0.6895 (0.6915)\taccu 57.812 (53.320)\n",
      "Epoch-199  60 batches\tloss 0.6923 (0.6918)\taccu 57.812 (52.760)\n",
      "Epoch-199  80 batches\tloss 0.6914 (0.6921)\taccu 56.250 (52.383)\n",
      "Epoch-199 100 batches\tloss 0.6853 (0.6917)\taccu 64.062 (52.828)\n",
      "Epoch-199 120 batches\tloss 0.6851 (0.6920)\taccu 56.250 (52.656)\n",
      "Epoch-199 140 batches\tloss 0.7012 (0.6920)\taccu 42.188 (52.679)\n",
      "Epoch-199 43.7s\tTrain: loss 0.6921\taccu 52.5240\tValid: loss 0.6937\taccu 50.2905\n",
      "Epoch 199: val_acc did not improve\n",
      "199 1.0000000000000002e-06\n",
      "Epoch-200  20 batches\tloss 0.6957 (0.6939)\taccu 45.312 (50.859)\n",
      "Epoch-200  40 batches\tloss 0.6867 (0.6929)\taccu 57.812 (51.914)\n",
      "Epoch-200  60 batches\tloss 0.6963 (0.6923)\taccu 53.125 (53.151)\n",
      "Epoch-200  80 batches\tloss 0.6923 (0.6918)\taccu 54.688 (53.281)\n",
      "Epoch-200 100 batches\tloss 0.6930 (0.6920)\taccu 60.938 (53.156)\n",
      "Epoch-200 120 batches\tloss 0.6909 (0.6919)\taccu 50.000 (53.021)\n",
      "Epoch-200 140 batches\tloss 0.6873 (0.6919)\taccu 59.375 (52.958)\n",
      "Epoch-200 43.6s\tTrain: loss 0.6919\taccu 52.7043\tValid: loss 0.6937\taccu 50.5008\n",
      "Epoch 200: val_acc did not improve\n",
      "200 1.0000000000000002e-06\n",
      "Epoch-201  20 batches\tloss 0.6855 (0.6901)\taccu 59.375 (55.234)\n",
      "Epoch-201  40 batches\tloss 0.6876 (0.6911)\taccu 59.375 (54.141)\n",
      "Epoch-201  60 batches\tloss 0.6971 (0.6915)\taccu 43.750 (53.958)\n",
      "Epoch-201  80 batches\tloss 0.6950 (0.6917)\taccu 43.750 (53.672)\n",
      "Epoch-201 100 batches\tloss 0.6882 (0.6918)\taccu 54.688 (53.109)\n",
      "Epoch-201 120 batches\tloss 0.7001 (0.6918)\taccu 45.312 (53.125)\n",
      "Epoch-201 140 batches\tloss 0.6984 (0.6919)\taccu 50.000 (53.058)\n",
      "Epoch-201 43.8s\tTrain: loss 0.6919\taccu 53.0549\tValid: loss 0.6937\taccu 50.3305\n",
      "Epoch 201: val_acc did not improve\n",
      "201 1.0000000000000002e-06\n",
      "Epoch-202  20 batches\tloss 0.6801 (0.6904)\taccu 64.062 (53.828)\n",
      "Epoch-202  40 batches\tloss 0.6985 (0.6924)\taccu 46.875 (51.602)\n",
      "Epoch-202  60 batches\tloss 0.6884 (0.6920)\taccu 56.250 (52.083)\n",
      "Epoch-202  80 batches\tloss 0.6907 (0.6922)\taccu 46.875 (51.875)\n",
      "Epoch-202 100 batches\tloss 0.6956 (0.6924)\taccu 50.000 (51.734)\n",
      "Epoch-202 120 batches\tloss 0.6954 (0.6920)\taccu 46.875 (52.044)\n",
      "Epoch-202 140 batches\tloss 0.7015 (0.6918)\taccu 37.500 (52.388)\n",
      "Epoch-202 43.7s\tTrain: loss 0.6918\taccu 52.4840\tValid: loss 0.6937\taccu 50.3706\n",
      "Epoch 202: val_acc did not improve\n",
      "202 1.0000000000000002e-06\n",
      "Epoch-203  20 batches\tloss 0.6966 (0.6930)\taccu 43.750 (51.016)\n",
      "Epoch-203  40 batches\tloss 0.6923 (0.6924)\taccu 51.562 (52.031)\n",
      "Epoch-203  60 batches\tloss 0.6789 (0.6915)\taccu 65.625 (52.865)\n",
      "Epoch-203  80 batches\tloss 0.6836 (0.6913)\taccu 65.625 (53.477)\n",
      "Epoch-203 100 batches\tloss 0.7014 (0.6916)\taccu 45.312 (53.234)\n",
      "Epoch-203 120 batches\tloss 0.7009 (0.6917)\taccu 42.188 (52.995)\n",
      "Epoch-203 140 batches\tloss 0.6932 (0.6920)\taccu 51.562 (52.522)\n",
      "Epoch-203 44.0s\tTrain: loss 0.6919\taccu 52.7344\tValid: loss 0.6938\taccu 50.2404\n",
      "Epoch 203: val_acc did not improve\n",
      "203 1.0000000000000002e-06\n",
      "Epoch-204  20 batches\tloss 0.6854 (0.6915)\taccu 56.250 (53.672)\n",
      "Epoch-204  40 batches\tloss 0.6920 (0.6917)\taccu 57.812 (53.555)\n",
      "Epoch-204  60 batches\tloss 0.6891 (0.6918)\taccu 53.125 (53.099)\n",
      "Epoch-204  80 batches\tloss 0.6988 (0.6915)\taccu 43.750 (53.711)\n",
      "Epoch-204 100 batches\tloss 0.6969 (0.6915)\taccu 50.000 (53.641)\n",
      "Epoch-204 120 batches\tloss 0.6904 (0.6917)\taccu 51.562 (53.359)\n",
      "Epoch-204 140 batches\tloss 0.6896 (0.6918)\taccu 56.250 (53.348)\n",
      "Epoch-204 43.5s\tTrain: loss 0.6919\taccu 53.0950\tValid: loss 0.6938\taccu 50.2804\n",
      "Epoch 204: val_acc did not improve\n",
      "204 1.0000000000000002e-06\n",
      "Epoch-205  20 batches\tloss 0.6992 (0.6910)\taccu 46.875 (52.656)\n",
      "Epoch-205  40 batches\tloss 0.6883 (0.6912)\taccu 57.812 (53.203)\n",
      "Epoch-205  60 batches\tloss 0.6969 (0.6915)\taccu 48.438 (53.333)\n",
      "Epoch-205  80 batches\tloss 0.6840 (0.6918)\taccu 65.625 (53.066)\n",
      "Epoch-205 100 batches\tloss 0.6960 (0.6916)\taccu 50.000 (53.281)\n",
      "Epoch-205 120 batches\tloss 0.6949 (0.6920)\taccu 50.000 (52.760)\n",
      "Epoch-205 140 batches\tloss 0.6911 (0.6922)\taccu 53.125 (52.533)\n",
      "Epoch-205 42.8s\tTrain: loss 0.6921\taccu 52.6943\tValid: loss 0.6937\taccu 50.3606\n",
      "Epoch 205: val_acc did not improve\n",
      "205 1.0000000000000002e-06\n",
      "Epoch-206  20 batches\tloss 0.6934 (0.6920)\taccu 46.875 (52.109)\n",
      "Epoch-206  40 batches\tloss 0.6895 (0.6924)\taccu 56.250 (51.445)\n",
      "Epoch-206  60 batches\tloss 0.6897 (0.6922)\taccu 48.438 (52.057)\n",
      "Epoch-206  80 batches\tloss 0.6882 (0.6921)\taccu 57.812 (52.148)\n",
      "Epoch-206 100 batches\tloss 0.6875 (0.6919)\taccu 62.500 (52.516)\n",
      "Epoch-206 120 batches\tloss 0.6954 (0.6919)\taccu 50.000 (52.604)\n",
      "Epoch-206 140 batches\tloss 0.6883 (0.6919)\taccu 54.688 (52.556)\n",
      "Epoch-206 42.8s\tTrain: loss 0.6919\taccu 52.6843\tValid: loss 0.6938\taccu 50.1803\n",
      "Epoch 206: val_acc did not improve\n",
      "206 1.0000000000000002e-06\n",
      "Epoch-207  20 batches\tloss 0.6946 (0.6915)\taccu 54.688 (54.922)\n",
      "Epoch-207  40 batches\tloss 0.6981 (0.6914)\taccu 45.312 (54.180)\n",
      "Epoch-207  60 batches\tloss 0.6911 (0.6914)\taccu 46.875 (53.620)\n",
      "Epoch-207  80 batches\tloss 0.6923 (0.6915)\taccu 51.562 (53.730)\n",
      "Epoch-207 100 batches\tloss 0.6932 (0.6916)\taccu 46.875 (53.391)\n",
      "Epoch-207 120 batches\tloss 0.6866 (0.6917)\taccu 54.688 (53.021)\n",
      "Epoch-207 140 batches\tloss 0.6957 (0.6918)\taccu 53.125 (52.991)\n",
      "Epoch-207 42.7s\tTrain: loss 0.6920\taccu 52.6743\tValid: loss 0.6937\taccu 50.1402\n",
      "Epoch 207: val_acc did not improve\n",
      "207 1.0000000000000002e-06\n",
      "Epoch-208  20 batches\tloss 0.6937 (0.6909)\taccu 50.000 (53.672)\n",
      "Epoch-208  40 batches\tloss 0.6898 (0.6915)\taccu 64.062 (53.438)\n",
      "Epoch-208  60 batches\tloss 0.6892 (0.6917)\taccu 54.688 (52.813)\n",
      "Epoch-208  80 batches\tloss 0.6900 (0.6917)\taccu 50.000 (52.773)\n",
      "Epoch-208 100 batches\tloss 0.6963 (0.6916)\taccu 46.875 (53.000)\n",
      "Epoch-208 120 batches\tloss 0.6980 (0.6918)\taccu 42.188 (52.643)\n",
      "Epoch-208 140 batches\tloss 0.7003 (0.6917)\taccu 46.875 (52.757)\n",
      "Epoch-208 42.7s\tTrain: loss 0.6917\taccu 52.9046\tValid: loss 0.6938\taccu 50.2103\n",
      "Epoch 208: val_acc did not improve\n",
      "208 1.0000000000000002e-06\n",
      "Epoch-209  20 batches\tloss 0.6948 (0.6935)\taccu 48.438 (50.625)\n",
      "Epoch-209  40 batches\tloss 0.6887 (0.6927)\taccu 53.125 (51.094)\n",
      "Epoch-209  60 batches\tloss 0.6985 (0.6923)\taccu 42.188 (51.901)\n",
      "Epoch-209  80 batches\tloss 0.6911 (0.6922)\taccu 57.812 (51.875)\n",
      "Epoch-209 100 batches\tloss 0.6886 (0.6922)\taccu 60.938 (52.078)\n",
      "Epoch-209 120 batches\tloss 0.6915 (0.6920)\taccu 57.812 (52.435)\n",
      "Epoch-209 140 batches\tloss 0.6919 (0.6920)\taccu 51.562 (52.422)\n",
      "Epoch-209 42.7s\tTrain: loss 0.6919\taccu 52.6142\tValid: loss 0.6937\taccu 50.1603\n",
      "Epoch 209: val_acc did not improve\n",
      "209 1.0000000000000002e-06\n",
      "Epoch-210  20 batches\tloss 0.6927 (0.6908)\taccu 53.125 (53.359)\n",
      "Epoch-210  40 batches\tloss 0.6908 (0.6906)\taccu 54.688 (53.203)\n",
      "Epoch-210  60 batches\tloss 0.6962 (0.6912)\taccu 48.438 (53.151)\n",
      "Epoch-210  80 batches\tloss 0.6862 (0.6917)\taccu 54.688 (52.832)\n",
      "Epoch-210 100 batches\tloss 0.6891 (0.6918)\taccu 56.250 (52.766)\n",
      "Epoch-210 120 batches\tloss 0.6901 (0.6917)\taccu 56.250 (53.073)\n",
      "Epoch-210 140 batches\tloss 0.7018 (0.6918)\taccu 46.875 (52.902)\n",
      "Epoch-210 43.1s\tTrain: loss 0.6919\taccu 52.8846\tValid: loss 0.6937\taccu 50.3405\n",
      "Epoch 210: val_acc did not improve\n",
      "210 1.0000000000000002e-06\n",
      "Epoch-211  20 batches\tloss 0.6956 (0.6898)\taccu 51.562 (56.953)\n",
      "Epoch-211  40 batches\tloss 0.6860 (0.6912)\taccu 54.688 (54.492)\n",
      "Epoch-211  60 batches\tloss 0.6957 (0.6923)\taccu 48.438 (52.682)\n",
      "Epoch-211  80 batches\tloss 0.6927 (0.6922)\taccu 50.000 (52.695)\n",
      "Epoch-211 100 batches\tloss 0.6960 (0.6921)\taccu 53.125 (52.719)\n",
      "Epoch-211 120 batches\tloss 0.6959 (0.6921)\taccu 45.312 (52.578)\n",
      "Epoch-211 140 batches\tloss 0.6876 (0.6920)\taccu 62.500 (52.656)\n",
      "Epoch-211 42.2s\tTrain: loss 0.6920\taccu 52.6442\tValid: loss 0.6938\taccu 50.2003\n",
      "Epoch 211: val_acc did not improve\n",
      "211 1.0000000000000002e-06\n",
      "Epoch-212  20 batches\tloss 0.6981 (0.6919)\taccu 48.438 (53.203)\n",
      "Epoch-212  40 batches\tloss 0.6971 (0.6921)\taccu 43.750 (52.148)\n",
      "Epoch-212  60 batches\tloss 0.7010 (0.6920)\taccu 43.750 (52.344)\n",
      "Epoch-212  80 batches\tloss 0.6878 (0.6920)\taccu 56.250 (52.969)\n",
      "Epoch-212 100 batches\tloss 0.6912 (0.6919)\taccu 54.688 (52.984)\n",
      "Epoch-212 120 batches\tloss 0.7014 (0.6919)\taccu 48.438 (53.151)\n",
      "Epoch-212 140 batches\tloss 0.6921 (0.6919)\taccu 60.938 (52.924)\n",
      "Epoch-212 42.0s\tTrain: loss 0.6919\taccu 53.1150\tValid: loss 0.6937\taccu 50.4107\n",
      "Epoch 212: val_acc did not improve\n",
      "212 1.0000000000000002e-06\n",
      "Epoch-213  20 batches\tloss 0.6919 (0.6925)\taccu 48.438 (52.031)\n",
      "Epoch-213  40 batches\tloss 0.6963 (0.6920)\taccu 56.250 (53.047)\n",
      "Epoch-213  60 batches\tloss 0.6977 (0.6914)\taccu 45.312 (53.333)\n",
      "Epoch-213  80 batches\tloss 0.6918 (0.6916)\taccu 51.562 (53.008)\n",
      "Epoch-213 100 batches\tloss 0.6936 (0.6921)\taccu 56.250 (52.625)\n",
      "Epoch-213 120 batches\tloss 0.6903 (0.6920)\taccu 53.125 (52.891)\n",
      "Epoch-213 140 batches\tloss 0.6849 (0.6921)\taccu 57.812 (52.690)\n",
      "Epoch-213 39.4s\tTrain: loss 0.6920\taccu 52.8345\tValid: loss 0.6938\taccu 50.1102\n",
      "Epoch 213: val_acc did not improve\n",
      "213 1.0000000000000002e-06\n",
      "Epoch-214  20 batches\tloss 0.6863 (0.6933)\taccu 56.250 (50.234)\n",
      "Epoch-214  40 batches\tloss 0.6841 (0.6926)\taccu 65.625 (51.094)\n",
      "Epoch-214  60 batches\tloss 0.6962 (0.6921)\taccu 45.312 (51.771)\n",
      "Epoch-214  80 batches\tloss 0.6909 (0.6926)\taccu 51.562 (51.465)\n",
      "Epoch-214 100 batches\tloss 0.6798 (0.6919)\taccu 62.500 (52.359)\n",
      "Epoch-214 120 batches\tloss 0.6933 (0.6919)\taccu 59.375 (52.669)\n",
      "Epoch-214 140 batches\tloss 0.6921 (0.6921)\taccu 53.125 (52.623)\n",
      "Epoch-214 38.7s\tTrain: loss 0.6919\taccu 52.6542\tValid: loss 0.6937\taccu 50.3205\n",
      "Epoch 214: val_acc did not improve\n",
      "214 1.0000000000000002e-06\n",
      "Epoch-215  20 batches\tloss 0.6864 (0.6925)\taccu 59.375 (53.047)\n",
      "Epoch-215  40 batches\tloss 0.6905 (0.6924)\taccu 50.000 (52.500)\n",
      "Epoch-215  60 batches\tloss 0.6867 (0.6921)\taccu 60.938 (52.813)\n",
      "Epoch-215  80 batches\tloss 0.6836 (0.6920)\taccu 64.062 (52.969)\n",
      "Epoch-215 100 batches\tloss 0.6911 (0.6919)\taccu 48.438 (52.891)\n",
      "Epoch-215 120 batches\tloss 0.6919 (0.6917)\taccu 50.000 (53.125)\n",
      "Epoch-215 140 batches\tloss 0.6942 (0.6918)\taccu 48.438 (52.835)\n",
      "Epoch-215 38.8s\tTrain: loss 0.6918\taccu 52.7544\tValid: loss 0.6937\taccu 50.4006\n",
      "Epoch 215: val_acc did not improve\n",
      "215 1.0000000000000002e-06\n",
      "Epoch-216  20 batches\tloss 0.6983 (0.6916)\taccu 46.875 (52.734)\n",
      "Epoch-216  40 batches\tloss 0.6940 (0.6920)\taccu 51.562 (52.383)\n",
      "Epoch-216  60 batches\tloss 0.6987 (0.6920)\taccu 45.312 (52.500)\n",
      "Epoch-216  80 batches\tloss 0.6869 (0.6921)\taccu 56.250 (52.500)\n",
      "Epoch-216 100 batches\tloss 0.6933 (0.6921)\taccu 54.688 (52.266)\n",
      "Epoch-216 120 batches\tloss 0.6870 (0.6919)\taccu 60.938 (52.865)\n",
      "Epoch-216 140 batches\tloss 0.6914 (0.6920)\taccu 53.125 (52.589)\n",
      "Epoch-216 38.4s\tTrain: loss 0.6920\taccu 52.5441\tValid: loss 0.6938\taccu 50.1202\n",
      "Epoch 216: val_acc did not improve\n",
      "216 1.0000000000000002e-06\n",
      "Epoch-217  20 batches\tloss 0.6895 (0.6917)\taccu 57.812 (53.438)\n",
      "Epoch-217  40 batches\tloss 0.6898 (0.6910)\taccu 60.938 (53.672)\n",
      "Epoch-217  60 batches\tloss 0.6964 (0.6906)\taccu 50.000 (54.583)\n",
      "Epoch-217  80 batches\tloss 0.6877 (0.6910)\taccu 57.812 (53.945)\n",
      "Epoch-217 100 batches\tloss 0.6908 (0.6917)\taccu 50.000 (52.875)\n",
      "Epoch-217 120 batches\tloss 0.6943 (0.6918)\taccu 54.688 (52.982)\n",
      "Epoch-217 140 batches\tloss 0.6878 (0.6919)\taccu 50.000 (52.902)\n",
      "Epoch-217 38.2s\tTrain: loss 0.6921\taccu 52.5741\tValid: loss 0.6936\taccu 50.2905\n",
      "Epoch 217: val_acc did not improve\n",
      "217 1.0000000000000002e-06\n",
      "Epoch-218  20 batches\tloss 0.6941 (0.6914)\taccu 54.688 (53.203)\n",
      "Epoch-218  40 batches\tloss 0.6933 (0.6909)\taccu 51.562 (54.062)\n",
      "Epoch-218  60 batches\tloss 0.6928 (0.6912)\taccu 50.000 (54.089)\n",
      "Epoch-218  80 batches\tloss 0.6936 (0.6912)\taccu 51.562 (53.652)\n",
      "Epoch-218 100 batches\tloss 0.6898 (0.6915)\taccu 59.375 (53.266)\n",
      "Epoch-218 120 batches\tloss 0.6928 (0.6918)\taccu 59.375 (53.060)\n",
      "Epoch-218 140 batches\tloss 0.6957 (0.6918)\taccu 50.000 (53.036)\n",
      "Epoch-218 38.4s\tTrain: loss 0.6921\taccu 52.5441\tValid: loss 0.6937\taccu 50.2304\n",
      "Epoch 218: val_acc did not improve\n",
      "218 1.0000000000000002e-06\n",
      "Epoch-219  20 batches\tloss 0.6938 (0.6929)\taccu 54.688 (51.484)\n",
      "Epoch-219  40 batches\tloss 0.6894 (0.6922)\taccu 54.688 (52.344)\n",
      "Epoch-219  60 batches\tloss 0.6881 (0.6921)\taccu 50.000 (52.266)\n",
      "Epoch-219  80 batches\tloss 0.6965 (0.6924)\taccu 43.750 (52.012)\n",
      "Epoch-219 100 batches\tloss 0.6901 (0.6925)\taccu 50.000 (51.703)\n",
      "Epoch-219 120 batches\tloss 0.6937 (0.6925)\taccu 50.000 (51.888)\n",
      "Epoch-219 140 batches\tloss 0.6891 (0.6923)\taccu 56.250 (52.165)\n",
      "Epoch-219 38.3s\tTrain: loss 0.6922\taccu 52.2837\tValid: loss 0.6938\taccu 50.2103\n",
      "Epoch 219: val_acc did not improve\n",
      "219 1.0000000000000002e-06\n",
      "Epoch-220  20 batches\tloss 0.6900 (0.6899)\taccu 56.250 (56.797)\n",
      "Epoch-220  40 batches\tloss 0.6928 (0.6915)\taccu 48.438 (53.711)\n",
      "Epoch-220  60 batches\tloss 0.6967 (0.6921)\taccu 51.562 (52.865)\n",
      "Epoch-220  80 batches\tloss 0.6956 (0.6921)\taccu 50.000 (52.461)\n",
      "Epoch-220 100 batches\tloss 0.6872 (0.6921)\taccu 54.688 (52.203)\n",
      "Epoch-220 120 batches\tloss 0.6962 (0.6921)\taccu 42.188 (52.344)\n",
      "Epoch-220 140 batches\tloss 0.6914 (0.6920)\taccu 53.125 (52.455)\n",
      "Epoch-220 38.7s\tTrain: loss 0.6920\taccu 52.3538\tValid: loss 0.6937\taccu 50.4507\n",
      "Epoch 220: val_acc did not improve\n",
      "220 1.0000000000000002e-06\n",
      "Epoch-221  20 batches\tloss 0.6953 (0.6928)\taccu 50.000 (51.953)\n",
      "Epoch-221  40 batches\tloss 0.6931 (0.6931)\taccu 46.875 (51.289)\n",
      "Epoch-221  60 batches\tloss 0.6973 (0.6922)\taccu 43.750 (52.578)\n",
      "Epoch-221  80 batches\tloss 0.6978 (0.6923)\taccu 48.438 (52.480)\n",
      "Epoch-221 100 batches\tloss 0.6931 (0.6922)\taccu 51.562 (52.500)\n",
      "Epoch-221 120 batches\tloss 0.6856 (0.6920)\taccu 60.938 (52.786)\n",
      "Epoch-221 140 batches\tloss 0.6916 (0.6921)\taccu 46.875 (52.567)\n",
      "Epoch-221 38.2s\tTrain: loss 0.6920\taccu 52.4940\tValid: loss 0.6938\taccu 49.9700\n",
      "Epoch 221: val_acc did not improve\n",
      "221 1.0000000000000002e-06\n",
      "Epoch-222  20 batches\tloss 0.6930 (0.6904)\taccu 59.375 (55.078)\n",
      "Epoch-222  40 batches\tloss 0.6908 (0.6912)\taccu 54.688 (54.023)\n",
      "Epoch-222  60 batches\tloss 0.6867 (0.6918)\taccu 51.562 (52.891)\n",
      "Epoch-222  80 batches\tloss 0.7013 (0.6919)\taccu 42.188 (53.086)\n",
      "Epoch-222 100 batches\tloss 0.6921 (0.6917)\taccu 46.875 (53.188)\n",
      "Epoch-222 120 batches\tloss 0.6873 (0.6918)\taccu 56.250 (53.073)\n",
      "Epoch-222 140 batches\tloss 0.6947 (0.6919)\taccu 50.000 (52.958)\n",
      "Epoch-222 38.1s\tTrain: loss 0.6918\taccu 53.0950\tValid: loss 0.6937\taccu 50.3906\n",
      "Epoch 222: val_acc did not improve\n",
      "222 1.0000000000000002e-06\n",
      "Epoch-223  20 batches\tloss 0.6941 (0.6921)\taccu 53.125 (53.281)\n",
      "Epoch-223  40 batches\tloss 0.6859 (0.6930)\taccu 64.062 (51.719)\n",
      "Epoch-223  60 batches\tloss 0.6883 (0.6926)\taccu 54.688 (51.823)\n",
      "Epoch-223  80 batches\tloss 0.6940 (0.6922)\taccu 50.000 (52.324)\n",
      "Epoch-223 100 batches\tloss 0.6801 (0.6918)\taccu 62.500 (52.703)\n",
      "Epoch-223 120 batches\tloss 0.6886 (0.6917)\taccu 53.125 (52.682)\n",
      "Epoch-223 140 batches\tloss 0.6930 (0.6917)\taccu 53.125 (52.679)\n",
      "Epoch-223 39.2s\tTrain: loss 0.6918\taccu 52.5240\tValid: loss 0.6938\taccu 49.9800\n",
      "Epoch 223: val_acc did not improve\n",
      "223 1.0000000000000002e-06\n",
      "Epoch-224  20 batches\tloss 0.6954 (0.6915)\taccu 45.312 (53.828)\n",
      "Epoch-224  40 batches\tloss 0.6863 (0.6916)\taccu 60.938 (52.734)\n",
      "Epoch-224  60 batches\tloss 0.6931 (0.6915)\taccu 53.125 (52.813)\n",
      "Epoch-224  80 batches\tloss 0.6856 (0.6916)\taccu 56.250 (52.402)\n",
      "Epoch-224 100 batches\tloss 0.6917 (0.6917)\taccu 48.438 (52.391)\n",
      "Epoch-224 120 batches\tloss 0.6835 (0.6917)\taccu 62.500 (52.487)\n",
      "Epoch-224 140 batches\tloss 0.6883 (0.6918)\taccu 50.000 (52.154)\n",
      "Epoch-224 38.9s\tTrain: loss 0.6919\taccu 52.1534\tValid: loss 0.6938\taccu 50.4207\n",
      "Epoch 224: val_acc did not improve\n",
      "224 1.0000000000000002e-06\n",
      "Epoch-225  20 batches\tloss 0.6902 (0.6925)\taccu 59.375 (52.266)\n",
      "Epoch-225  40 batches\tloss 0.6939 (0.6922)\taccu 53.125 (52.188)\n",
      "Epoch-225  60 batches\tloss 0.6923 (0.6919)\taccu 51.562 (52.839)\n",
      "Epoch-225  80 batches\tloss 0.6873 (0.6921)\taccu 56.250 (52.402)\n",
      "Epoch-225 100 batches\tloss 0.6947 (0.6921)\taccu 45.312 (52.500)\n",
      "Epoch-225 120 batches\tloss 0.6903 (0.6922)\taccu 54.688 (52.630)\n",
      "Epoch-225 140 batches\tloss 0.6924 (0.6920)\taccu 54.688 (52.868)\n",
      "Epoch-225 38.6s\tTrain: loss 0.6921\taccu 52.9247\tValid: loss 0.6938\taccu 50.4407\n",
      "Epoch 225: val_acc did not improve\n",
      "225 1.0000000000000002e-06\n",
      "Epoch-226  20 batches\tloss 0.6875 (0.6910)\taccu 57.812 (53.359)\n",
      "Epoch-226  40 batches\tloss 0.6962 (0.6915)\taccu 46.875 (52.812)\n",
      "Epoch-226  60 batches\tloss 0.6902 (0.6915)\taccu 53.125 (52.917)\n",
      "Epoch-226  80 batches\tloss 0.6856 (0.6916)\taccu 56.250 (52.891)\n",
      "Epoch-226 100 batches\tloss 0.6975 (0.6917)\taccu 45.312 (52.953)\n",
      "Epoch-226 120 batches\tloss 0.6917 (0.6918)\taccu 57.812 (52.734)\n",
      "Epoch-226 140 batches\tloss 0.7007 (0.6919)\taccu 40.625 (52.634)\n",
      "Epoch-226 39.0s\tTrain: loss 0.6917\taccu 52.9347\tValid: loss 0.6937\taccu 50.6711\n",
      "Epoch 226: val_acc did not improve\n",
      "226 1.0000000000000002e-06\n",
      "Epoch-227  20 batches\tloss 0.6863 (0.6905)\taccu 57.812 (53.828)\n",
      "Epoch-227  40 batches\tloss 0.6825 (0.6921)\taccu 68.750 (52.188)\n",
      "Epoch-227  60 batches\tloss 0.6918 (0.6925)\taccu 48.438 (51.432)\n",
      "Epoch-227  80 batches\tloss 0.6908 (0.6924)\taccu 48.438 (52.148)\n",
      "Epoch-227 100 batches\tloss 0.6911 (0.6923)\taccu 50.000 (52.156)\n",
      "Epoch-227 120 batches\tloss 0.6866 (0.6923)\taccu 54.688 (52.279)\n",
      "Epoch-227 140 batches\tloss 0.6896 (0.6921)\taccu 60.938 (52.533)\n",
      "Epoch-227 39.1s\tTrain: loss 0.6920\taccu 52.6743\tValid: loss 0.6936\taccu 50.6711\n",
      "Epoch 227: val_acc did not improve\n",
      "227 1.0000000000000002e-06\n",
      "Epoch-228  20 batches\tloss 0.6964 (0.6922)\taccu 53.125 (53.203)\n",
      "Epoch-228  40 batches\tloss 0.6894 (0.6919)\taccu 60.938 (53.516)\n",
      "Epoch-228  60 batches\tloss 0.6892 (0.6917)\taccu 51.562 (53.411)\n",
      "Epoch-228  80 batches\tloss 0.6929 (0.6920)\taccu 45.312 (52.695)\n",
      "Epoch-228 100 batches\tloss 0.6998 (0.6917)\taccu 46.875 (52.953)\n",
      "Epoch-228 120 batches\tloss 0.6881 (0.6917)\taccu 48.438 (53.008)\n",
      "Epoch-228 140 batches\tloss 0.6922 (0.6917)\taccu 60.938 (53.080)\n",
      "Epoch-228 39.6s\tTrain: loss 0.6919\taccu 52.7845\tValid: loss 0.6937\taccu 50.1703\n",
      "Epoch 228: val_acc did not improve\n",
      "228 1.0000000000000002e-06\n",
      "Epoch-229  20 batches\tloss 0.6857 (0.6920)\taccu 57.812 (52.500)\n",
      "Epoch-229  40 batches\tloss 0.6817 (0.6914)\taccu 59.375 (53.164)\n",
      "Epoch-229  60 batches\tloss 0.6973 (0.6917)\taccu 45.312 (52.604)\n",
      "Epoch-229  80 batches\tloss 0.6909 (0.6915)\taccu 51.562 (52.910)\n",
      "Epoch-229 100 batches\tloss 0.6945 (0.6914)\taccu 50.000 (53.312)\n",
      "Epoch-229 120 batches\tloss 0.6881 (0.6915)\taccu 57.812 (53.086)\n",
      "Epoch-229 140 batches\tloss 0.6877 (0.6916)\taccu 60.938 (52.790)\n",
      "Epoch-229 41.5s\tTrain: loss 0.6917\taccu 52.8946\tValid: loss 0.6938\taccu 50.1903\n",
      "Epoch 229: val_acc did not improve\n",
      "229 1.0000000000000002e-06\n",
      "Epoch-230  20 batches\tloss 0.6892 (0.6900)\taccu 46.875 (54.609)\n",
      "Epoch-230  40 batches\tloss 0.6900 (0.6907)\taccu 50.000 (53.125)\n",
      "Epoch-230  60 batches\tloss 0.6971 (0.6913)\taccu 50.000 (52.604)\n",
      "Epoch-230  80 batches\tloss 0.6985 (0.6917)\taccu 39.062 (52.383)\n",
      "Epoch-230 100 batches\tloss 0.6852 (0.6919)\taccu 60.938 (52.312)\n",
      "Epoch-230 120 batches\tloss 0.6952 (0.6920)\taccu 45.312 (52.188)\n",
      "Epoch-230 140 batches\tloss 0.6922 (0.6919)\taccu 56.250 (52.254)\n",
      "Epoch-230 41.7s\tTrain: loss 0.6919\taccu 52.3438\tValid: loss 0.6938\taccu 50.2304\n",
      "Epoch 230: val_acc did not improve\n",
      "230 1.0000000000000002e-06\n",
      "Epoch-231  20 batches\tloss 0.6960 (0.6924)\taccu 42.188 (52.109)\n",
      "Epoch-231  40 batches\tloss 0.6897 (0.6921)\taccu 53.125 (53.320)\n",
      "Epoch-231  60 batches\tloss 0.6958 (0.6923)\taccu 48.438 (52.734)\n",
      "Epoch-231  80 batches\tloss 0.6849 (0.6923)\taccu 56.250 (52.227)\n",
      "Epoch-231 100 batches\tloss 0.6969 (0.6924)\taccu 42.188 (52.234)\n",
      "Epoch-231 120 batches\tloss 0.6877 (0.6920)\taccu 59.375 (52.721)\n",
      "Epoch-231 140 batches\tloss 0.6936 (0.6921)\taccu 53.125 (52.846)\n",
      "Epoch-231 41.9s\tTrain: loss 0.6920\taccu 52.9147\tValid: loss 0.6937\taccu 50.3205\n",
      "Epoch 231: val_acc did not improve\n",
      "231 1.0000000000000002e-06\n",
      "Epoch-232  20 batches\tloss 0.6903 (0.6917)\taccu 59.375 (53.203)\n",
      "Epoch-232  40 batches\tloss 0.6899 (0.6922)\taccu 53.125 (52.656)\n",
      "Epoch-232  60 batches\tloss 0.6939 (0.6923)\taccu 40.625 (52.161)\n",
      "Epoch-232  80 batches\tloss 0.6883 (0.6919)\taccu 56.250 (52.930)\n",
      "Epoch-232 100 batches\tloss 0.6965 (0.6921)\taccu 51.562 (52.688)\n",
      "Epoch-232 120 batches\tloss 0.6852 (0.6922)\taccu 60.938 (52.526)\n",
      "Epoch-232 140 batches\tloss 0.6971 (0.6921)\taccu 45.312 (52.444)\n",
      "Epoch-232 41.8s\tTrain: loss 0.6919\taccu 52.5140\tValid: loss 0.6938\taccu 50.2304\n",
      "Epoch 232: val_acc did not improve\n",
      "232 1.0000000000000002e-06\n",
      "Epoch-233  20 batches\tloss 0.6930 (0.6918)\taccu 48.438 (52.500)\n",
      "Epoch-233  40 batches\tloss 0.7000 (0.6916)\taccu 46.875 (52.422)\n",
      "Epoch-233  60 batches\tloss 0.6907 (0.6921)\taccu 56.250 (52.396)\n",
      "Epoch-233  80 batches\tloss 0.6885 (0.6921)\taccu 53.125 (52.188)\n",
      "Epoch-233 100 batches\tloss 0.6867 (0.6920)\taccu 59.375 (52.531)\n",
      "Epoch-233 120 batches\tloss 0.6868 (0.6918)\taccu 60.938 (52.917)\n",
      "Epoch-233 140 batches\tloss 0.6970 (0.6920)\taccu 48.438 (52.734)\n",
      "Epoch-233 39.3s\tTrain: loss 0.6919\taccu 52.7644\tValid: loss 0.6938\taccu 50.2905\n",
      "Epoch 233: val_acc did not improve\n",
      "233 1.0000000000000002e-06\n",
      "Epoch-234  20 batches\tloss 0.6921 (0.6923)\taccu 54.688 (53.125)\n",
      "Epoch-234  40 batches\tloss 0.6877 (0.6913)\taccu 54.688 (53.594)\n",
      "Epoch-234  60 batches\tloss 0.6895 (0.6915)\taccu 48.438 (53.203)\n",
      "Epoch-234  80 batches\tloss 0.6907 (0.6918)\taccu 59.375 (52.852)\n",
      "Epoch-234 100 batches\tloss 0.6880 (0.6921)\taccu 54.688 (52.547)\n",
      "Epoch-234 120 batches\tloss 0.6905 (0.6922)\taccu 50.000 (52.422)\n",
      "Epoch-234 140 batches\tloss 0.6873 (0.6920)\taccu 57.812 (52.679)\n",
      "Epoch-234 37.8s\tTrain: loss 0.6919\taccu 52.8446\tValid: loss 0.6937\taccu 50.1903\n",
      "Epoch 234: val_acc did not improve\n",
      "234 1.0000000000000002e-06\n",
      "Epoch-235  20 batches\tloss 0.6887 (0.6922)\taccu 48.438 (51.250)\n",
      "Epoch-235  40 batches\tloss 0.6876 (0.6926)\taccu 60.938 (52.383)\n",
      "Epoch-235  60 batches\tloss 0.6915 (0.6925)\taccu 50.000 (52.448)\n",
      "Epoch-235  80 batches\tloss 0.6944 (0.6924)\taccu 42.188 (52.559)\n",
      "Epoch-235 100 batches\tloss 0.6943 (0.6924)\taccu 43.750 (52.594)\n",
      "Epoch-235 120 batches\tloss 0.6942 (0.6923)\taccu 51.562 (52.461)\n",
      "Epoch-235 140 batches\tloss 0.6814 (0.6921)\taccu 60.938 (52.489)\n",
      "Epoch-235 37.9s\tTrain: loss 0.6920\taccu 52.6943\tValid: loss 0.6937\taccu 50.2304\n",
      "Epoch 235: val_acc did not improve\n",
      "235 1.0000000000000002e-06\n",
      "Epoch-236  20 batches\tloss 0.6923 (0.6920)\taccu 46.875 (52.344)\n",
      "Epoch-236  40 batches\tloss 0.6933 (0.6925)\taccu 56.250 (51.953)\n",
      "Epoch-236  60 batches\tloss 0.6913 (0.6925)\taccu 59.375 (51.771)\n",
      "Epoch-236  80 batches\tloss 0.6867 (0.6924)\taccu 57.812 (51.992)\n",
      "Epoch-236 100 batches\tloss 0.6899 (0.6923)\taccu 57.812 (52.203)\n",
      "Epoch-236 120 batches\tloss 0.6950 (0.6920)\taccu 43.750 (52.474)\n",
      "Epoch-236 140 batches\tloss 0.6957 (0.6918)\taccu 45.312 (52.656)\n",
      "Epoch-236 39.8s\tTrain: loss 0.6919\taccu 52.5841\tValid: loss 0.6938\taccu 50.3105\n",
      "Epoch 236: val_acc did not improve\n",
      "236 1.0000000000000002e-06\n",
      "Epoch-237  20 batches\tloss 0.6926 (0.6900)\taccu 53.125 (53.125)\n",
      "Epoch-237  40 batches\tloss 0.6947 (0.6916)\taccu 51.562 (51.680)\n",
      "Epoch-237  60 batches\tloss 0.6892 (0.6916)\taccu 54.688 (51.979)\n",
      "Epoch-237  80 batches\tloss 0.6960 (0.6917)\taccu 46.875 (52.070)\n",
      "Epoch-237 100 batches\tloss 0.6878 (0.6918)\taccu 60.938 (52.531)\n",
      "Epoch-237 120 batches\tloss 0.6900 (0.6918)\taccu 50.000 (52.604)\n",
      "Epoch-237 140 batches\tloss 0.6960 (0.6918)\taccu 46.875 (52.545)\n",
      "Epoch-237 41.1s\tTrain: loss 0.6918\taccu 52.5942\tValid: loss 0.6938\taccu 50.2604\n",
      "Epoch 237: val_acc did not improve\n",
      "237 1.0000000000000002e-06\n",
      "Epoch-238  20 batches\tloss 0.6904 (0.6905)\taccu 54.688 (54.531)\n",
      "Epoch-238  40 batches\tloss 0.6908 (0.6919)\taccu 60.938 (52.617)\n",
      "Epoch-238  60 batches\tloss 0.6898 (0.6924)\taccu 53.125 (52.057)\n",
      "Epoch-238  80 batches\tloss 0.6823 (0.6919)\taccu 64.062 (52.578)\n",
      "Epoch-238 100 batches\tloss 0.7008 (0.6919)\taccu 40.625 (52.469)\n",
      "Epoch-238 120 batches\tloss 0.6952 (0.6918)\taccu 46.875 (52.617)\n",
      "Epoch-238 140 batches\tloss 0.6930 (0.6917)\taccu 50.000 (52.578)\n",
      "Epoch-238 39.4s\tTrain: loss 0.6917\taccu 52.6743\tValid: loss 0.6937\taccu 50.5108\n",
      "Epoch 238: val_acc did not improve\n",
      "238 1.0000000000000002e-06\n",
      "Epoch-239  20 batches\tloss 0.6924 (0.6929)\taccu 54.688 (50.938)\n",
      "Epoch-239  40 batches\tloss 0.6922 (0.6930)\taccu 53.125 (50.977)\n",
      "Epoch-239  60 batches\tloss 0.6956 (0.6924)\taccu 46.875 (51.510)\n",
      "Epoch-239  80 batches\tloss 0.6922 (0.6921)\taccu 53.125 (52.461)\n",
      "Epoch-239 100 batches\tloss 0.6941 (0.6922)\taccu 53.125 (52.203)\n",
      "Epoch-239 120 batches\tloss 0.6962 (0.6920)\taccu 46.875 (52.552)\n",
      "Epoch-239 140 batches\tloss 0.6886 (0.6920)\taccu 46.875 (52.556)\n",
      "Epoch-239 39.2s\tTrain: loss 0.6920\taccu 52.4740\tValid: loss 0.6937\taccu 50.3806\n",
      "Epoch 239: val_acc did not improve\n",
      "239 1.0000000000000002e-06\n",
      "Epoch-240  20 batches\tloss 0.6947 (0.6915)\taccu 50.000 (52.188)\n",
      "Epoch-240  40 batches\tloss 0.6888 (0.6922)\taccu 59.375 (51.602)\n",
      "Epoch-240  60 batches\tloss 0.6860 (0.6921)\taccu 59.375 (52.083)\n",
      "Epoch-240  80 batches\tloss 0.6949 (0.6922)\taccu 54.688 (52.246)\n",
      "Epoch-240 100 batches\tloss 0.6886 (0.6921)\taccu 59.375 (52.766)\n",
      "Epoch-240 120 batches\tloss 0.6853 (0.6921)\taccu 54.688 (52.552)\n",
      "Epoch-240 140 batches\tloss 0.6829 (0.6920)\taccu 57.812 (52.533)\n",
      "Epoch-240 39.0s\tTrain: loss 0.6921\taccu 52.4840\tValid: loss 0.6937\taccu 49.9599\n",
      "Epoch 240: val_acc did not improve\n",
      "240 1.0000000000000002e-06\n",
      "Epoch-241  20 batches\tloss 0.6948 (0.6928)\taccu 50.000 (51.797)\n",
      "Epoch-241  40 batches\tloss 0.6879 (0.6918)\taccu 51.562 (52.578)\n",
      "Epoch-241  60 batches\tloss 0.6908 (0.6921)\taccu 56.250 (52.604)\n",
      "Epoch-241  80 batches\tloss 0.6934 (0.6920)\taccu 50.000 (53.164)\n",
      "Epoch-241 100 batches\tloss 0.6894 (0.6920)\taccu 59.375 (52.969)\n",
      "Epoch-241 120 batches\tloss 0.6858 (0.6921)\taccu 60.938 (52.656)\n",
      "Epoch-241 140 batches\tloss 0.6892 (0.6919)\taccu 53.125 (52.980)\n",
      "Epoch-241 39.1s\tTrain: loss 0.6919\taccu 52.9447\tValid: loss 0.6938\taccu 50.2504\n",
      "Epoch 241: val_acc did not improve\n",
      "241 1.0000000000000002e-06\n",
      "Epoch-242  20 batches\tloss 0.6921 (0.6945)\taccu 54.688 (50.703)\n",
      "Epoch-242  40 batches\tloss 0.6994 (0.6935)\taccu 46.875 (51.133)\n",
      "Epoch-242  60 batches\tloss 0.6979 (0.6927)\taccu 42.188 (51.198)\n",
      "Epoch-242  80 batches\tloss 0.6927 (0.6926)\taccu 53.125 (51.621)\n",
      "Epoch-242 100 batches\tloss 0.7000 (0.6924)\taccu 46.875 (52.109)\n",
      "Epoch-242 120 batches\tloss 0.6963 (0.6923)\taccu 51.562 (52.201)\n",
      "Epoch-242 140 batches\tloss 0.6906 (0.6921)\taccu 56.250 (52.623)\n",
      "Epoch-242 38.7s\tTrain: loss 0.6920\taccu 52.7744\tValid: loss 0.6938\taccu 50.2204\n",
      "Epoch 242: val_acc did not improve\n",
      "242 1.0000000000000002e-06\n",
      "Epoch-243  20 batches\tloss 0.6841 (0.6913)\taccu 59.375 (52.891)\n",
      "Epoch-243  40 batches\tloss 0.6981 (0.6921)\taccu 50.000 (52.656)\n",
      "Epoch-243  60 batches\tloss 0.6925 (0.6917)\taccu 56.250 (52.891)\n",
      "Epoch-243  80 batches\tloss 0.6964 (0.6921)\taccu 50.000 (52.617)\n",
      "Epoch-243 100 batches\tloss 0.6902 (0.6921)\taccu 51.562 (52.531)\n",
      "Epoch-243 120 batches\tloss 0.6911 (0.6920)\taccu 57.812 (52.539)\n",
      "Epoch-243 140 batches\tloss 0.6890 (0.6921)\taccu 59.375 (52.701)\n",
      "Epoch-243 38.6s\tTrain: loss 0.6919\taccu 52.8245\tValid: loss 0.6936\taccu 50.4607\n",
      "Epoch 243: val_acc did not improve\n",
      "243 1.0000000000000002e-06\n",
      "Epoch-244  20 batches\tloss 0.6979 (0.6912)\taccu 46.875 (52.266)\n",
      "Epoch-244  40 batches\tloss 0.7003 (0.6911)\taccu 46.875 (53.164)\n",
      "Epoch-244  60 batches\tloss 0.6908 (0.6913)\taccu 57.812 (53.568)\n",
      "Epoch-244  80 batches\tloss 0.6892 (0.6917)\taccu 57.812 (52.871)\n",
      "Epoch-244 100 batches\tloss 0.6873 (0.6915)\taccu 57.812 (52.953)\n",
      "Epoch-244 120 batches\tloss 0.6950 (0.6917)\taccu 50.000 (52.865)\n",
      "Epoch-244 140 batches\tloss 0.6897 (0.6919)\taccu 51.562 (52.712)\n",
      "Epoch-244 38.9s\tTrain: loss 0.6919\taccu 52.8045\tValid: loss 0.6938\taccu 50.3205\n",
      "Epoch 244: val_acc did not improve\n",
      "244 1.0000000000000002e-06\n",
      "Epoch-245  20 batches\tloss 0.6883 (0.6916)\taccu 54.688 (52.500)\n",
      "Epoch-245  40 batches\tloss 0.6896 (0.6926)\taccu 56.250 (51.680)\n",
      "Epoch-245  60 batches\tloss 0.6932 (0.6919)\taccu 46.875 (52.057)\n",
      "Epoch-245  80 batches\tloss 0.6942 (0.6917)\taccu 56.250 (52.617)\n",
      "Epoch-245 100 batches\tloss 0.6853 (0.6919)\taccu 56.250 (52.391)\n",
      "Epoch-245 120 batches\tloss 0.6920 (0.6919)\taccu 56.250 (52.396)\n",
      "Epoch-245 140 batches\tloss 0.6889 (0.6919)\taccu 53.125 (52.455)\n",
      "Epoch-245 38.9s\tTrain: loss 0.6920\taccu 52.4539\tValid: loss 0.6936\taccu 50.2604\n",
      "Epoch 245: val_acc did not improve\n",
      "245 1.0000000000000002e-06\n",
      "Epoch-246  20 batches\tloss 0.6892 (0.6919)\taccu 54.688 (53.516)\n",
      "Epoch-246  40 batches\tloss 0.6878 (0.6923)\taccu 57.812 (52.812)\n",
      "Epoch-246  60 batches\tloss 0.6952 (0.6924)\taccu 50.000 (52.526)\n",
      "Epoch-246  80 batches\tloss 0.6921 (0.6921)\taccu 53.125 (52.422)\n",
      "Epoch-246 100 batches\tloss 0.6817 (0.6915)\taccu 64.062 (52.984)\n",
      "Epoch-246 120 batches\tloss 0.6930 (0.6917)\taccu 53.125 (52.891)\n",
      "Epoch-246 140 batches\tloss 0.6926 (0.6920)\taccu 50.000 (52.467)\n",
      "Epoch-246 38.7s\tTrain: loss 0.6919\taccu 52.5942\tValid: loss 0.6937\taccu 50.3405\n",
      "Epoch 246: val_acc did not improve\n",
      "246 1.0000000000000002e-06\n",
      "Epoch-247  20 batches\tloss 0.6921 (0.6911)\taccu 46.875 (52.656)\n",
      "Epoch-247  40 batches\tloss 0.6925 (0.6913)\taccu 48.438 (53.164)\n",
      "Epoch-247  60 batches\tloss 0.6856 (0.6915)\taccu 62.500 (53.177)\n",
      "Epoch-247  80 batches\tloss 0.6851 (0.6912)\taccu 60.938 (53.457)\n",
      "Epoch-247 100 batches\tloss 0.6900 (0.6913)\taccu 57.812 (53.375)\n",
      "Epoch-247 120 batches\tloss 0.6910 (0.6916)\taccu 50.000 (52.747)\n",
      "Epoch-247 140 batches\tloss 0.6930 (0.6917)\taccu 56.250 (52.879)\n",
      "Epoch-247 38.8s\tTrain: loss 0.6917\taccu 52.8846\tValid: loss 0.6937\taccu 50.3806\n",
      "Epoch 247: val_acc did not improve\n",
      "247 1.0000000000000002e-06\n",
      "Epoch-248  20 batches\tloss 0.6927 (0.6930)\taccu 51.562 (51.016)\n",
      "Epoch-248  40 batches\tloss 0.6932 (0.6929)\taccu 46.875 (51.953)\n",
      "Epoch-248  60 batches\tloss 0.6882 (0.6922)\taccu 53.125 (52.422)\n",
      "Epoch-248  80 batches\tloss 0.6912 (0.6918)\taccu 46.875 (52.969)\n",
      "Epoch-248 100 batches\tloss 0.6934 (0.6919)\taccu 56.250 (52.906)\n",
      "Epoch-248 120 batches\tloss 0.6900 (0.6919)\taccu 56.250 (52.760)\n",
      "Epoch-248 140 batches\tloss 0.6904 (0.6919)\taccu 48.438 (52.623)\n",
      "Epoch-248 38.5s\tTrain: loss 0.6920\taccu 52.4840\tValid: loss 0.6937\taccu 49.9900\n",
      "Epoch 248: val_acc did not improve\n",
      "248 1.0000000000000002e-06\n",
      "Epoch-249  20 batches\tloss 0.6867 (0.6907)\taccu 60.938 (52.891)\n",
      "Epoch-249  40 batches\tloss 0.6955 (0.6921)\taccu 53.125 (51.797)\n",
      "Epoch-249  60 batches\tloss 0.6909 (0.6921)\taccu 54.688 (52.083)\n",
      "Epoch-249  80 batches\tloss 0.6918 (0.6921)\taccu 59.375 (52.363)\n",
      "Epoch-249 100 batches\tloss 0.6936 (0.6922)\taccu 53.125 (52.359)\n",
      "Epoch-249 120 batches\tloss 0.6842 (0.6920)\taccu 56.250 (52.669)\n",
      "Epoch-249 140 batches\tloss 0.6899 (0.6919)\taccu 51.562 (52.980)\n",
      "Epoch-249 38.7s\tTrain: loss 0.6920\taccu 52.8546\tValid: loss 0.6937\taccu 50.4407\n",
      "Epoch 249: val_acc did not improve\n",
      "249 1.0000000000000002e-06\n",
      "Epoch-250  20 batches\tloss 0.6938 (0.6915)\taccu 48.438 (54.453)\n",
      "Epoch-250  40 batches\tloss 0.7000 (0.6915)\taccu 43.750 (53.828)\n",
      "Epoch-250  60 batches\tloss 0.6831 (0.6913)\taccu 60.938 (53.854)\n",
      "Epoch-250  80 batches\tloss 0.6924 (0.6915)\taccu 50.000 (53.496)\n",
      "Epoch-250 100 batches\tloss 0.6970 (0.6914)\taccu 48.438 (53.438)\n",
      "Epoch-250 120 batches\tloss 0.6882 (0.6916)\taccu 56.250 (53.268)\n",
      "Epoch-250 140 batches\tloss 0.6941 (0.6918)\taccu 54.688 (53.092)\n",
      "Epoch-250 38.8s\tTrain: loss 0.6919\taccu 53.0349\tValid: loss 0.6937\taccu 50.4607\n",
      "Epoch 250: val_acc did not improve\n",
      "250 1.0000000000000002e-06\n",
      "Epoch-251  20 batches\tloss 0.6947 (0.6916)\taccu 48.438 (53.906)\n",
      "Epoch-251  40 batches\tloss 0.6836 (0.6910)\taccu 65.625 (53.906)\n",
      "Epoch-251  60 batches\tloss 0.6905 (0.6915)\taccu 54.688 (53.203)\n",
      "Epoch-251  80 batches\tloss 0.6922 (0.6914)\taccu 46.875 (53.125)\n",
      "Epoch-251 100 batches\tloss 0.6856 (0.6915)\taccu 64.062 (53.172)\n",
      "Epoch-251 120 batches\tloss 0.6906 (0.6915)\taccu 50.000 (53.112)\n",
      "Epoch-251 140 batches\tloss 0.6896 (0.6916)\taccu 60.938 (53.158)\n",
      "Epoch-251 38.4s\tTrain: loss 0.6917\taccu 52.7744\tValid: loss 0.6936\taccu 50.4307\n",
      "Epoch 251: val_acc did not improve\n",
      "251 1.0000000000000002e-06\n",
      "Epoch-252  20 batches\tloss 0.6988 (0.6913)\taccu 46.875 (51.875)\n",
      "Epoch-252  40 batches\tloss 0.6931 (0.6917)\taccu 46.875 (51.992)\n",
      "Epoch-252  60 batches\tloss 0.6933 (0.6921)\taccu 50.000 (52.188)\n",
      "Epoch-252  80 batches\tloss 0.6976 (0.6921)\taccu 46.875 (52.637)\n",
      "Epoch-252 100 batches\tloss 0.6974 (0.6922)\taccu 48.438 (52.344)\n",
      "Epoch-252 120 batches\tloss 0.6951 (0.6923)\taccu 50.000 (52.109)\n",
      "Epoch-252 140 batches\tloss 0.6883 (0.6921)\taccu 50.000 (52.366)\n",
      "Epoch-252 38.5s\tTrain: loss 0.6919\taccu 52.7444\tValid: loss 0.6938\taccu 50.1603\n",
      "Epoch 252: val_acc did not improve\n",
      "252 1.0000000000000002e-06\n",
      "Epoch-253  20 batches\tloss 0.6917 (0.6906)\taccu 60.938 (55.469)\n",
      "Epoch-253  40 batches\tloss 0.6879 (0.6917)\taccu 54.688 (53.555)\n",
      "Epoch-253  60 batches\tloss 0.6893 (0.6918)\taccu 54.688 (53.281)\n",
      "Epoch-253  80 batches\tloss 0.6879 (0.6918)\taccu 57.812 (52.949)\n",
      "Epoch-253 100 batches\tloss 0.6910 (0.6917)\taccu 51.562 (53.219)\n",
      "Epoch-253 120 batches\tloss 0.6860 (0.6919)\taccu 64.062 (52.891)\n",
      "Epoch-253 140 batches\tloss 0.6934 (0.6918)\taccu 42.188 (52.924)\n",
      "Epoch-253 38.7s\tTrain: loss 0.6919\taccu 52.5240\tValid: loss 0.6938\taccu 50.0401\n",
      "Epoch 253: val_acc did not improve\n",
      "253 1.0000000000000002e-06\n",
      "Epoch-254  20 batches\tloss 0.6888 (0.6922)\taccu 53.125 (52.188)\n",
      "Epoch-254  40 batches\tloss 0.6885 (0.6912)\taccu 56.250 (54.023)\n",
      "Epoch-254  60 batches\tloss 0.6889 (0.6913)\taccu 54.688 (53.802)\n",
      "Epoch-254  80 batches\tloss 0.6964 (0.6918)\taccu 43.750 (53.125)\n",
      "Epoch-254 100 batches\tloss 0.6929 (0.6918)\taccu 53.125 (52.969)\n",
      "Epoch-254 120 batches\tloss 0.6876 (0.6917)\taccu 56.250 (53.203)\n",
      "Epoch-254 140 batches\tloss 0.6938 (0.6918)\taccu 51.562 (53.036)\n",
      "Epoch-254 38.3s\tTrain: loss 0.6918\taccu 53.1951\tValid: loss 0.6937\taccu 50.4407\n",
      "Epoch 254: val_acc did not improve\n",
      "254 1.0000000000000002e-06\n",
      "Epoch-255  20 batches\tloss 0.6841 (0.6920)\taccu 59.375 (52.500)\n",
      "Epoch-255  40 batches\tloss 0.6943 (0.6917)\taccu 51.562 (53.047)\n",
      "Epoch-255  60 batches\tloss 0.6974 (0.6916)\taccu 48.438 (53.307)\n",
      "Epoch-255  80 batches\tloss 0.6936 (0.6913)\taccu 46.875 (53.398)\n",
      "Epoch-255 100 batches\tloss 0.6911 (0.6918)\taccu 57.812 (52.938)\n",
      "Epoch-255 120 batches\tloss 0.6959 (0.6919)\taccu 46.875 (52.813)\n",
      "Epoch-255 140 batches\tloss 0.6959 (0.6918)\taccu 53.125 (52.958)\n",
      "Epoch-255 38.6s\tTrain: loss 0.6919\taccu 52.8145\tValid: loss 0.6937\taccu 50.4708\n",
      "Epoch 255: val_acc did not improve\n",
      "255 1.0000000000000002e-06\n",
      "Epoch-256  20 batches\tloss 0.6940 (0.6917)\taccu 51.562 (51.484)\n",
      "Epoch-256  40 batches\tloss 0.6893 (0.6918)\taccu 56.250 (51.875)\n",
      "Epoch-256  60 batches\tloss 0.6825 (0.6913)\taccu 65.625 (52.708)\n",
      "Epoch-256  80 batches\tloss 0.6937 (0.6912)\taccu 51.562 (53.008)\n",
      "Epoch-256 100 batches\tloss 0.6928 (0.6915)\taccu 51.562 (52.516)\n",
      "Epoch-256 120 batches\tloss 0.6928 (0.6916)\taccu 57.812 (52.565)\n",
      "Epoch-256 140 batches\tloss 0.6871 (0.6916)\taccu 54.688 (52.835)\n",
      "Epoch-256 38.5s\tTrain: loss 0.6917\taccu 52.7143\tValid: loss 0.6937\taccu 50.6911\n",
      "Epoch 256: val_acc did not improve\n",
      "256 1.0000000000000002e-06\n",
      "Epoch-257  20 batches\tloss 0.6907 (0.6928)\taccu 56.250 (51.172)\n",
      "Epoch-257  40 batches\tloss 0.7002 (0.6926)\taccu 45.312 (52.305)\n",
      "Epoch-257  60 batches\tloss 0.6913 (0.6923)\taccu 50.000 (52.188)\n",
      "Epoch-257  80 batches\tloss 0.6888 (0.6921)\taccu 51.562 (52.383)\n",
      "Epoch-257 100 batches\tloss 0.6946 (0.6921)\taccu 46.875 (52.234)\n",
      "Epoch-257 120 batches\tloss 0.6953 (0.6921)\taccu 45.312 (52.135)\n",
      "Epoch-257 140 batches\tloss 0.6887 (0.6922)\taccu 56.250 (52.143)\n",
      "Epoch-257 40.5s\tTrain: loss 0.6921\taccu 52.2436\tValid: loss 0.6936\taccu 50.4407\n",
      "Epoch 257: val_acc did not improve\n",
      "257 1.0000000000000002e-06\n",
      "Epoch-258  20 batches\tloss 0.6983 (0.6910)\taccu 43.750 (53.203)\n",
      "Epoch-258  40 batches\tloss 0.6972 (0.6914)\taccu 51.562 (53.281)\n",
      "Epoch-258  60 batches\tloss 0.6944 (0.6919)\taccu 50.000 (52.786)\n",
      "Epoch-258  80 batches\tloss 0.6997 (0.6916)\taccu 39.062 (52.891)\n",
      "Epoch-258 100 batches\tloss 0.6889 (0.6915)\taccu 50.000 (53.109)\n",
      "Epoch-258 120 batches\tloss 0.6935 (0.6918)\taccu 45.312 (52.747)\n",
      "Epoch-258 140 batches\tloss 0.6927 (0.6919)\taccu 56.250 (52.656)\n",
      "Epoch-258 40.3s\tTrain: loss 0.6918\taccu 52.8345\tValid: loss 0.6937\taccu 50.2003\n",
      "Epoch 258: val_acc did not improve\n",
      "258 1.0000000000000002e-06\n",
      "Epoch-259  20 batches\tloss 0.6911 (0.6922)\taccu 53.125 (52.734)\n",
      "Epoch-259  40 batches\tloss 0.6869 (0.6923)\taccu 60.938 (52.695)\n",
      "Epoch-259  60 batches\tloss 0.6965 (0.6919)\taccu 43.750 (52.891)\n",
      "Epoch-259  80 batches\tloss 0.6947 (0.6918)\taccu 51.562 (52.812)\n",
      "Epoch-259 100 batches\tloss 0.7027 (0.6922)\taccu 37.500 (52.547)\n",
      "Epoch-259 120 batches\tloss 0.6921 (0.6922)\taccu 54.688 (52.526)\n",
      "Epoch-259 140 batches\tloss 0.6895 (0.6921)\taccu 59.375 (52.656)\n",
      "Epoch-259 38.7s\tTrain: loss 0.6918\taccu 52.9647\tValid: loss 0.6938\taccu 50.3906\n",
      "Epoch 259: val_acc did not improve\n",
      "259 1.0000000000000002e-06\n",
      "Epoch-260  20 batches\tloss 0.6943 (0.6930)\taccu 51.562 (52.188)\n",
      "Epoch-260  40 batches\tloss 0.6997 (0.6936)\taccu 45.312 (51.211)\n",
      "Epoch-260  60 batches\tloss 0.6924 (0.6927)\taccu 54.688 (51.797)\n",
      "Epoch-260  80 batches\tloss 0.6895 (0.6926)\taccu 57.812 (52.246)\n",
      "Epoch-260 100 batches\tloss 0.6927 (0.6924)\taccu 54.688 (52.391)\n",
      "Epoch-260 120 batches\tloss 0.6867 (0.6922)\taccu 53.125 (52.500)\n",
      "Epoch-260 140 batches\tloss 0.6915 (0.6921)\taccu 54.688 (52.467)\n",
      "Epoch-260 38.7s\tTrain: loss 0.6920\taccu 52.4038\tValid: loss 0.6937\taccu 50.2404\n",
      "Epoch 260: val_acc did not improve\n",
      "260 1.0000000000000002e-06\n",
      "Epoch-261  20 batches\tloss 0.6901 (0.6907)\taccu 56.250 (55.156)\n",
      "Epoch-261  40 batches\tloss 0.6897 (0.6914)\taccu 53.125 (53.789)\n",
      "Epoch-261  60 batches\tloss 0.6996 (0.6915)\taccu 42.188 (54.219)\n",
      "Epoch-261  80 batches\tloss 0.6933 (0.6917)\taccu 48.438 (53.613)\n",
      "Epoch-261 100 batches\tloss 0.6930 (0.6918)\taccu 53.125 (53.453)\n",
      "Epoch-261 120 batches\tloss 0.6864 (0.6920)\taccu 57.812 (53.073)\n",
      "Epoch-261 140 batches\tloss 0.6908 (0.6918)\taccu 51.562 (53.069)\n",
      "Epoch-261 38.5s\tTrain: loss 0.6920\taccu 52.9046\tValid: loss 0.6937\taccu 50.3305\n",
      "Epoch 261: val_acc did not improve\n",
      "261 1.0000000000000002e-06\n",
      "Epoch-262  20 batches\tloss 0.6862 (0.6902)\taccu 60.938 (55.078)\n",
      "Epoch-262  40 batches\tloss 0.6811 (0.6900)\taccu 62.500 (54.805)\n",
      "Epoch-262  60 batches\tloss 0.6893 (0.6908)\taccu 54.688 (53.568)\n",
      "Epoch-262  80 batches\tloss 0.6935 (0.6911)\taccu 50.000 (52.832)\n",
      "Epoch-262 100 batches\tloss 0.6965 (0.6914)\taccu 45.312 (52.641)\n",
      "Epoch-262 120 batches\tloss 0.6895 (0.6916)\taccu 54.688 (52.409)\n",
      "Epoch-262 140 batches\tloss 0.6852 (0.6916)\taccu 57.812 (52.578)\n",
      "Epoch-262 38.7s\tTrain: loss 0.6917\taccu 52.6843\tValid: loss 0.6936\taccu 50.5008\n",
      "Epoch 262: val_acc did not improve\n",
      "262 1.0000000000000002e-06\n",
      "Epoch-263  20 batches\tloss 0.6870 (0.6924)\taccu 60.938 (52.031)\n",
      "Epoch-263  40 batches\tloss 0.6906 (0.6914)\taccu 54.688 (52.695)\n",
      "Epoch-263  60 batches\tloss 0.6925 (0.6910)\taccu 57.812 (53.203)\n",
      "Epoch-263  80 batches\tloss 0.6831 (0.6912)\taccu 68.750 (53.262)\n",
      "Epoch-263 100 batches\tloss 0.6861 (0.6913)\taccu 50.000 (53.125)\n",
      "Epoch-263 120 batches\tloss 0.6970 (0.6916)\taccu 40.625 (52.956)\n",
      "Epoch-263 140 batches\tloss 0.6929 (0.6918)\taccu 46.875 (52.600)\n",
      "Epoch-263 38.8s\tTrain: loss 0.6918\taccu 52.7244\tValid: loss 0.6937\taccu 50.0300\n",
      "Epoch 263: val_acc did not improve\n",
      "263 1.0000000000000002e-06\n",
      "Epoch-264  20 batches\tloss 0.6863 (0.6924)\taccu 60.938 (51.875)\n",
      "Epoch-264  40 batches\tloss 0.6956 (0.6917)\taccu 50.000 (52.305)\n",
      "Epoch-264  60 batches\tloss 0.6935 (0.6922)\taccu 50.000 (51.901)\n",
      "Epoch-264  80 batches\tloss 0.6883 (0.6920)\taccu 54.688 (52.207)\n",
      "Epoch-264 100 batches\tloss 0.6936 (0.6917)\taccu 46.875 (52.625)\n",
      "Epoch-264 120 batches\tloss 0.6847 (0.6919)\taccu 59.375 (52.344)\n",
      "Epoch-264 140 batches\tloss 0.6953 (0.6919)\taccu 51.562 (52.500)\n",
      "Epoch-264 39.0s\tTrain: loss 0.6919\taccu 52.5441\tValid: loss 0.6937\taccu 50.0601\n",
      "Epoch 264: val_acc did not improve\n",
      "264 1.0000000000000002e-06\n",
      "Epoch-265  20 batches\tloss 0.6915 (0.6922)\taccu 57.812 (52.812)\n",
      "Epoch-265  40 batches\tloss 0.6954 (0.6921)\taccu 46.875 (52.422)\n",
      "Epoch-265  60 batches\tloss 0.6899 (0.6922)\taccu 50.000 (52.500)\n",
      "Epoch-265  80 batches\tloss 0.6943 (0.6921)\taccu 48.438 (52.324)\n",
      "Epoch-265 100 batches\tloss 0.6897 (0.6922)\taccu 51.562 (52.328)\n",
      "Epoch-265 120 batches\tloss 0.6889 (0.6924)\taccu 54.688 (52.370)\n",
      "Epoch-265 140 batches\tloss 0.6878 (0.6922)\taccu 54.688 (52.600)\n",
      "Epoch-265 38.6s\tTrain: loss 0.6921\taccu 52.7344\tValid: loss 0.6938\taccu 49.9700\n",
      "Epoch 265: val_acc did not improve\n",
      "265 1.0000000000000002e-06\n",
      "Epoch-266  20 batches\tloss 0.6924 (0.6910)\taccu 51.562 (54.453)\n",
      "Epoch-266  40 batches\tloss 0.6895 (0.6911)\taccu 54.688 (54.375)\n",
      "Epoch-266  60 batches\tloss 0.6961 (0.6917)\taccu 46.875 (53.255)\n",
      "Epoch-266  80 batches\tloss 0.6872 (0.6914)\taccu 57.812 (53.477)\n",
      "Epoch-266 100 batches\tloss 0.6931 (0.6916)\taccu 51.562 (53.031)\n",
      "Epoch-266 120 batches\tloss 0.6926 (0.6920)\taccu 51.562 (52.643)\n",
      "Epoch-266 140 batches\tloss 0.6968 (0.6921)\taccu 40.625 (52.377)\n",
      "Epoch-266 38.5s\tTrain: loss 0.6921\taccu 52.4239\tValid: loss 0.6938\taccu 50.1703\n",
      "Epoch 266: val_acc did not improve\n",
      "266 1.0000000000000002e-06\n",
      "Epoch-267  20 batches\tloss 0.6911 (0.6918)\taccu 57.812 (52.578)\n",
      "Epoch-267  40 batches\tloss 0.6942 (0.6916)\taccu 51.562 (53.555)\n",
      "Epoch-267  60 batches\tloss 0.6886 (0.6914)\taccu 54.688 (53.750)\n",
      "Epoch-267  80 batches\tloss 0.6912 (0.6915)\taccu 51.562 (53.750)\n",
      "Epoch-267 100 batches\tloss 0.6941 (0.6916)\taccu 46.875 (53.234)\n",
      "Epoch-267 120 batches\tloss 0.6875 (0.6916)\taccu 67.188 (53.255)\n",
      "Epoch-267 140 batches\tloss 0.6904 (0.6918)\taccu 45.312 (52.935)\n",
      "Epoch-267 38.6s\tTrain: loss 0.6918\taccu 53.0950\tValid: loss 0.6937\taccu 50.3405\n",
      "Epoch 267: val_acc did not improve\n",
      "267 1.0000000000000002e-06\n",
      "Epoch-268  20 batches\tloss 0.6908 (0.6921)\taccu 46.875 (53.438)\n",
      "Epoch-268  40 batches\tloss 0.6932 (0.6921)\taccu 46.875 (52.617)\n",
      "Epoch-268  60 batches\tloss 0.6949 (0.6920)\taccu 53.125 (53.021)\n",
      "Epoch-268  80 batches\tloss 0.6940 (0.6917)\taccu 50.000 (53.262)\n",
      "Epoch-268 100 batches\tloss 0.6970 (0.6920)\taccu 46.875 (52.734)\n",
      "Epoch-268 120 batches\tloss 0.6892 (0.6921)\taccu 51.562 (52.604)\n",
      "Epoch-268 140 batches\tloss 0.6919 (0.6920)\taccu 57.812 (52.757)\n",
      "Epoch-268 38.6s\tTrain: loss 0.6919\taccu 52.8746\tValid: loss 0.6937\taccu 50.2003\n",
      "Epoch 268: val_acc did not improve\n",
      "268 1.0000000000000002e-06\n",
      "Epoch-269  20 batches\tloss 0.6910 (0.6927)\taccu 46.875 (50.859)\n",
      "Epoch-269  40 batches\tloss 0.6933 (0.6926)\taccu 51.562 (52.070)\n",
      "Epoch-269  60 batches\tloss 0.6847 (0.6925)\taccu 60.938 (52.240)\n",
      "Epoch-269  80 batches\tloss 0.6907 (0.6922)\taccu 57.812 (52.480)\n",
      "Epoch-269 100 batches\tloss 0.6855 (0.6920)\taccu 62.500 (52.859)\n",
      "Epoch-269 120 batches\tloss 0.6898 (0.6920)\taccu 53.125 (52.891)\n",
      "Epoch-269 140 batches\tloss 0.6898 (0.6919)\taccu 59.375 (53.025)\n",
      "Epoch-269 38.7s\tTrain: loss 0.6920\taccu 52.7544\tValid: loss 0.6939\taccu 50.0100\n",
      "Epoch 269: val_acc did not improve\n",
      "269 1.0000000000000002e-06\n",
      "Epoch-270  20 batches\tloss 0.6883 (0.6908)\taccu 53.125 (53.516)\n",
      "Epoch-270  40 batches\tloss 0.6983 (0.6918)\taccu 45.312 (53.438)\n",
      "Epoch-270  60 batches\tloss 0.6960 (0.6911)\taccu 48.438 (53.776)\n",
      "Epoch-270  80 batches\tloss 0.6896 (0.6911)\taccu 56.250 (53.848)\n",
      "Epoch-270 100 batches\tloss 0.6863 (0.6915)\taccu 59.375 (53.344)\n",
      "Epoch-270 120 batches\tloss 0.7021 (0.6918)\taccu 39.062 (52.852)\n",
      "Epoch-270 140 batches\tloss 0.6809 (0.6919)\taccu 67.188 (52.690)\n",
      "Epoch-270 38.8s\tTrain: loss 0.6918\taccu 52.8646\tValid: loss 0.6937\taccu 50.4607\n",
      "Epoch 270: val_acc did not improve\n",
      "270 1.0000000000000002e-06\n",
      "Epoch-271  20 batches\tloss 0.6948 (0.6915)\taccu 53.125 (53.828)\n",
      "Epoch-271  40 batches\tloss 0.6915 (0.6921)\taccu 56.250 (53.320)\n",
      "Epoch-271  60 batches\tloss 0.6989 (0.6924)\taccu 46.875 (52.786)\n",
      "Epoch-271  80 batches\tloss 0.6995 (0.6922)\taccu 42.188 (52.578)\n",
      "Epoch-271 100 batches\tloss 0.6908 (0.6921)\taccu 56.250 (52.625)\n",
      "Epoch-271 120 batches\tloss 0.7037 (0.6919)\taccu 32.812 (52.826)\n",
      "Epoch-271 140 batches\tloss 0.6909 (0.6919)\taccu 50.000 (52.879)\n",
      "Epoch-271 38.7s\tTrain: loss 0.6918\taccu 52.9647\tValid: loss 0.6938\taccu 50.3606\n",
      "Epoch 271: val_acc did not improve\n",
      "271 1.0000000000000002e-06\n",
      "Epoch-272  20 batches\tloss 0.6862 (0.6917)\taccu 59.375 (53.047)\n",
      "Epoch-272  40 batches\tloss 0.6885 (0.6920)\taccu 56.250 (52.148)\n",
      "Epoch-272  60 batches\tloss 0.6926 (0.6925)\taccu 48.438 (52.344)\n",
      "Epoch-272  80 batches\tloss 0.6901 (0.6919)\taccu 56.250 (52.930)\n",
      "Epoch-272 100 batches\tloss 0.6970 (0.6921)\taccu 50.000 (52.766)\n",
      "Epoch-272 120 batches\tloss 0.6937 (0.6919)\taccu 46.875 (52.760)\n",
      "Epoch-272 140 batches\tloss 0.6916 (0.6921)\taccu 53.125 (52.757)\n",
      "Epoch-272 38.9s\tTrain: loss 0.6920\taccu 52.9347\tValid: loss 0.6937\taccu 50.8814\n",
      "Epoch 272: val_acc improved from 50.8013 to 50.8814, saving model to ./results/NTU/SGN\\0_best.pth\n",
      "272 1.0000000000000002e-06\n",
      "Epoch-273  20 batches\tloss 0.6950 (0.6930)\taccu 46.875 (52.266)\n",
      "Epoch-273  40 batches\tloss 0.6919 (0.6922)\taccu 53.125 (52.305)\n",
      "Epoch-273  60 batches\tloss 0.6991 (0.6926)\taccu 46.875 (52.135)\n",
      "Epoch-273  80 batches\tloss 0.6870 (0.6922)\taccu 56.250 (52.656)\n",
      "Epoch-273 100 batches\tloss 0.6860 (0.6921)\taccu 60.938 (52.906)\n",
      "Epoch-273 120 batches\tloss 0.6895 (0.6921)\taccu 53.125 (52.813)\n",
      "Epoch-273 140 batches\tloss 0.6972 (0.6919)\taccu 45.312 (52.891)\n",
      "Epoch-273 38.8s\tTrain: loss 0.6919\taccu 52.9948\tValid: loss 0.6937\taccu 50.1803\n",
      "Epoch 273: val_acc did not improve\n",
      "273 1.0000000000000002e-06\n",
      "Epoch-274  20 batches\tloss 0.6980 (0.6919)\taccu 45.312 (52.344)\n",
      "Epoch-274  40 batches\tloss 0.6863 (0.6918)\taccu 60.938 (52.305)\n",
      "Epoch-274  60 batches\tloss 0.6952 (0.6920)\taccu 43.750 (51.745)\n",
      "Epoch-274  80 batches\tloss 0.6893 (0.6920)\taccu 59.375 (51.816)\n",
      "Epoch-274 100 batches\tloss 0.6907 (0.6921)\taccu 56.250 (51.766)\n",
      "Epoch-274 120 batches\tloss 0.6972 (0.6919)\taccu 51.562 (51.966)\n",
      "Epoch-274 140 batches\tloss 0.6899 (0.6917)\taccu 57.812 (52.299)\n",
      "Epoch-274 38.7s\tTrain: loss 0.6917\taccu 52.2837\tValid: loss 0.6937\taccu 50.3906\n",
      "Epoch 274: val_acc did not improve\n",
      "274 1.0000000000000002e-06\n",
      "Epoch-275  20 batches\tloss 0.6854 (0.6917)\taccu 56.250 (51.172)\n",
      "Epoch-275  40 batches\tloss 0.6945 (0.6919)\taccu 53.125 (51.055)\n",
      "Epoch-275  60 batches\tloss 0.6934 (0.6920)\taccu 53.125 (52.005)\n",
      "Epoch-275  80 batches\tloss 0.6952 (0.6920)\taccu 53.125 (52.168)\n",
      "Epoch-275 100 batches\tloss 0.6864 (0.6919)\taccu 65.625 (52.391)\n",
      "Epoch-275 120 batches\tloss 0.6896 (0.6918)\taccu 51.562 (52.643)\n",
      "Epoch-275 140 batches\tloss 0.6871 (0.6917)\taccu 56.250 (52.567)\n",
      "Epoch-275 38.7s\tTrain: loss 0.6918\taccu 52.6442\tValid: loss 0.6937\taccu 50.2404\n",
      "Epoch 275: val_acc did not improve\n",
      "275 1.0000000000000002e-06\n",
      "Epoch-276  20 batches\tloss 0.6928 (0.6932)\taccu 56.250 (51.406)\n",
      "Epoch-276  40 batches\tloss 0.6930 (0.6921)\taccu 51.562 (53.203)\n",
      "Epoch-276  60 batches\tloss 0.6898 (0.6918)\taccu 46.875 (53.177)\n",
      "Epoch-276  80 batches\tloss 0.6912 (0.6921)\taccu 54.688 (52.422)\n",
      "Epoch-276 100 batches\tloss 0.6960 (0.6923)\taccu 45.312 (51.906)\n",
      "Epoch-276 120 batches\tloss 0.6868 (0.6921)\taccu 59.375 (52.435)\n",
      "Epoch-276 140 batches\tloss 0.6973 (0.6922)\taccu 43.750 (52.188)\n",
      "Epoch-276 38.5s\tTrain: loss 0.6920\taccu 52.4539\tValid: loss 0.6938\taccu 50.4006\n",
      "Epoch 276: val_acc did not improve\n",
      "276 1.0000000000000002e-06\n",
      "Epoch-277  20 batches\tloss 0.6978 (0.6906)\taccu 51.562 (55.156)\n",
      "Epoch-277  40 batches\tloss 0.6947 (0.6911)\taccu 43.750 (53.750)\n",
      "Epoch-277  60 batches\tloss 0.6928 (0.6912)\taccu 53.125 (53.359)\n",
      "Epoch-277  80 batches\tloss 0.6918 (0.6912)\taccu 46.875 (53.359)\n",
      "Epoch-277 100 batches\tloss 0.6869 (0.6916)\taccu 57.812 (52.844)\n",
      "Epoch-277 120 batches\tloss 0.6879 (0.6916)\taccu 53.125 (53.021)\n",
      "Epoch-277 140 batches\tloss 0.6896 (0.6917)\taccu 53.125 (53.069)\n",
      "Epoch-277 38.6s\tTrain: loss 0.6918\taccu 53.0749\tValid: loss 0.6937\taccu 50.3305\n",
      "Epoch 277: val_acc did not improve\n",
      "277 1.0000000000000002e-06\n",
      "Epoch-278  20 batches\tloss 0.6992 (0.6913)\taccu 46.875 (54.141)\n",
      "Epoch-278  40 batches\tloss 0.6927 (0.6922)\taccu 62.500 (52.773)\n",
      "Epoch-278  60 batches\tloss 0.6993 (0.6921)\taccu 48.438 (52.760)\n",
      "Epoch-278  80 batches\tloss 0.6871 (0.6918)\taccu 57.812 (53.008)\n",
      "Epoch-278 100 batches\tloss 0.6979 (0.6920)\taccu 46.875 (52.891)\n",
      "Epoch-278 120 batches\tloss 0.6953 (0.6920)\taccu 46.875 (52.865)\n",
      "Epoch-278 140 batches\tloss 0.6857 (0.6918)\taccu 62.500 (52.835)\n",
      "Epoch-278 38.5s\tTrain: loss 0.6918\taccu 52.7945\tValid: loss 0.6938\taccu 50.3105\n",
      "Epoch 278: val_acc did not improve\n",
      "278 1.0000000000000002e-06\n",
      "Epoch-279  20 batches\tloss 0.6909 (0.6910)\taccu 56.250 (52.266)\n",
      "Epoch-279  40 batches\tloss 0.6896 (0.6908)\taccu 60.938 (53.906)\n",
      "Epoch-279  60 batches\tloss 0.7017 (0.6913)\taccu 45.312 (53.542)\n",
      "Epoch-279  80 batches\tloss 0.6939 (0.6918)\taccu 51.562 (52.930)\n",
      "Epoch-279 100 batches\tloss 0.6945 (0.6917)\taccu 46.875 (53.094)\n",
      "Epoch-279 120 batches\tloss 0.6890 (0.6917)\taccu 56.250 (53.242)\n",
      "Epoch-279 140 batches\tloss 0.6906 (0.6916)\taccu 56.250 (53.092)\n",
      "Epoch-279 38.5s\tTrain: loss 0.6918\taccu 52.7744\tValid: loss 0.6937\taccu 50.3806\n",
      "Epoch 279: val_acc did not improve\n",
      "279 1.0000000000000002e-06\n",
      "Epoch-280  20 batches\tloss 0.6825 (0.6902)\taccu 62.500 (55.078)\n",
      "Epoch-280  40 batches\tloss 0.6998 (0.6914)\taccu 48.438 (53.359)\n",
      "Epoch-280  60 batches\tloss 0.6931 (0.6914)\taccu 54.688 (53.333)\n",
      "Epoch-280  80 batches\tloss 0.6969 (0.6921)\taccu 50.000 (53.281)\n",
      "Epoch-280 100 batches\tloss 0.6970 (0.6918)\taccu 53.125 (53.734)\n",
      "Epoch-280 120 batches\tloss 0.6949 (0.6920)\taccu 50.000 (53.281)\n",
      "Epoch-280 140 batches\tloss 0.6931 (0.6919)\taccu 51.562 (53.382)\n",
      "Epoch-280 38.7s\tTrain: loss 0.6918\taccu 53.3253\tValid: loss 0.6937\taccu 50.3105\n",
      "Epoch 280: val_acc did not improve\n",
      "280 1.0000000000000002e-06\n",
      "Epoch-281  20 batches\tloss 0.6917 (0.6922)\taccu 53.125 (53.828)\n",
      "Epoch-281  40 batches\tloss 0.6907 (0.6924)\taccu 53.125 (53.398)\n",
      "Epoch-281  60 batches\tloss 0.6987 (0.6917)\taccu 46.875 (53.828)\n",
      "Epoch-281  80 batches\tloss 0.6944 (0.6918)\taccu 48.438 (53.398)\n",
      "Epoch-281 100 batches\tloss 0.6873 (0.6922)\taccu 57.812 (52.750)\n",
      "Epoch-281 120 batches\tloss 0.6914 (0.6922)\taccu 57.812 (52.422)\n",
      "Epoch-281 140 batches\tloss 0.6906 (0.6921)\taccu 59.375 (52.723)\n",
      "Epoch-281 38.4s\tTrain: loss 0.6920\taccu 52.8245\tValid: loss 0.6937\taccu 50.2404\n",
      "Epoch 281: val_acc did not improve\n",
      "281 1.0000000000000002e-06\n",
      "Epoch-282  20 batches\tloss 0.6868 (0.6930)\taccu 62.500 (50.859)\n",
      "Epoch-282  40 batches\tloss 0.6953 (0.6924)\taccu 48.438 (51.641)\n",
      "Epoch-282  60 batches\tloss 0.6914 (0.6918)\taccu 51.562 (52.760)\n",
      "Epoch-282  80 batches\tloss 0.6928 (0.6917)\taccu 46.875 (52.637)\n",
      "Epoch-282 100 batches\tloss 0.6859 (0.6919)\taccu 57.812 (52.500)\n",
      "Epoch-282 120 batches\tloss 0.6859 (0.6920)\taccu 54.688 (52.148)\n",
      "Epoch-282 140 batches\tloss 0.6916 (0.6922)\taccu 54.688 (52.009)\n",
      "Epoch-282 38.5s\tTrain: loss 0.6919\taccu 52.4038\tValid: loss 0.6938\taccu 50.2404\n",
      "Epoch 282: val_acc did not improve\n",
      "282 1.0000000000000002e-06\n",
      "Epoch-283  20 batches\tloss 0.6902 (0.6915)\taccu 62.500 (53.438)\n",
      "Epoch-283  40 batches\tloss 0.6891 (0.6917)\taccu 51.562 (51.836)\n",
      "Epoch-283  60 batches\tloss 0.6900 (0.6917)\taccu 54.688 (52.057)\n",
      "Epoch-283  80 batches\tloss 0.6972 (0.6918)\taccu 46.875 (51.895)\n",
      "Epoch-283 100 batches\tloss 0.6941 (0.6921)\taccu 48.438 (51.969)\n",
      "Epoch-283 120 batches\tloss 0.6851 (0.6922)\taccu 59.375 (52.070)\n",
      "Epoch-283 140 batches\tloss 0.6972 (0.6923)\taccu 46.875 (52.031)\n",
      "Epoch-283 38.4s\tTrain: loss 0.6920\taccu 52.5841\tValid: loss 0.6937\taccu 50.6410\n",
      "Epoch 283: val_acc did not improve\n",
      "283 1.0000000000000002e-06\n",
      "Epoch-284  20 batches\tloss 0.6933 (0.6919)\taccu 50.000 (53.359)\n",
      "Epoch-284  40 batches\tloss 0.6831 (0.6920)\taccu 67.188 (52.422)\n",
      "Epoch-284  60 batches\tloss 0.6908 (0.6919)\taccu 53.125 (52.604)\n",
      "Epoch-284  80 batches\tloss 0.6962 (0.6919)\taccu 56.250 (52.715)\n",
      "Epoch-284 100 batches\tloss 0.6943 (0.6921)\taccu 46.875 (52.625)\n",
      "Epoch-284 120 batches\tloss 0.6899 (0.6922)\taccu 54.688 (52.552)\n",
      "Epoch-284 140 batches\tloss 0.6785 (0.6921)\taccu 67.188 (52.522)\n",
      "Epoch-284 38.8s\tTrain: loss 0.6921\taccu 52.4139\tValid: loss 0.6936\taccu 50.4207\n",
      "Epoch 284: val_acc did not improve\n",
      "284 1.0000000000000002e-06\n",
      "Epoch-285  20 batches\tloss 0.6923 (0.6930)\taccu 56.250 (51.562)\n",
      "Epoch-285  40 batches\tloss 0.7007 (0.6927)\taccu 37.500 (51.406)\n",
      "Epoch-285  60 batches\tloss 0.6928 (0.6919)\taccu 56.250 (52.917)\n",
      "Epoch-285  80 batches\tloss 0.6843 (0.6919)\taccu 60.938 (52.969)\n",
      "Epoch-285 100 batches\tloss 0.6929 (0.6919)\taccu 53.125 (53.031)\n",
      "Epoch-285 120 batches\tloss 0.6946 (0.6919)\taccu 48.438 (53.021)\n",
      "Epoch-285 140 batches\tloss 0.6888 (0.6920)\taccu 57.812 (52.846)\n",
      "Epoch-285 38.4s\tTrain: loss 0.6919\taccu 53.0048\tValid: loss 0.6938\taccu 50.2404\n",
      "Epoch 285: val_acc did not improve\n",
      "285 1.0000000000000002e-06\n",
      "Epoch-286  20 batches\tloss 0.6827 (0.6899)\taccu 67.188 (56.094)\n",
      "Epoch-286  40 batches\tloss 0.6916 (0.6916)\taccu 53.125 (54.023)\n",
      "Epoch-286  60 batches\tloss 0.6963 (0.6920)\taccu 45.312 (52.943)\n",
      "Epoch-286  80 batches\tloss 0.6978 (0.6924)\taccu 43.750 (52.812)\n",
      "Epoch-286 100 batches\tloss 0.6836 (0.6921)\taccu 62.500 (52.719)\n",
      "Epoch-286 120 batches\tloss 0.7008 (0.6922)\taccu 37.500 (52.396)\n",
      "Epoch-286 140 batches\tloss 0.6887 (0.6920)\taccu 56.250 (52.690)\n",
      "Epoch-286 38.6s\tTrain: loss 0.6921\taccu 52.5341\tValid: loss 0.6937\taccu 50.1603\n",
      "Epoch 286: val_acc did not improve\n",
      "286 1.0000000000000002e-06\n",
      "Epoch-287  20 batches\tloss 0.6943 (0.6932)\taccu 42.188 (51.250)\n",
      "Epoch-287  40 batches\tloss 0.6872 (0.6926)\taccu 50.000 (51.914)\n",
      "Epoch-287  60 batches\tloss 0.6894 (0.6925)\taccu 59.375 (51.797)\n",
      "Epoch-287  80 batches\tloss 0.7015 (0.6924)\taccu 34.375 (51.836)\n",
      "Epoch-287 100 batches\tloss 0.6903 (0.6922)\taccu 60.938 (52.281)\n",
      "Epoch-287 120 batches\tloss 0.6865 (0.6921)\taccu 56.250 (52.044)\n",
      "Epoch-287 140 batches\tloss 0.6846 (0.6922)\taccu 60.938 (52.098)\n",
      "Epoch-287 38.4s\tTrain: loss 0.6921\taccu 52.2035\tValid: loss 0.6938\taccu 49.8998\n",
      "Epoch 287: val_acc did not improve\n",
      "287 1.0000000000000002e-06\n",
      "Epoch-288  20 batches\tloss 0.6935 (0.6913)\taccu 50.000 (53.438)\n",
      "Epoch-288  40 batches\tloss 0.6948 (0.6905)\taccu 54.688 (53.594)\n",
      "Epoch-288  60 batches\tloss 0.6924 (0.6909)\taccu 50.000 (53.411)\n",
      "Epoch-288  80 batches\tloss 0.6883 (0.6915)\taccu 54.688 (53.027)\n",
      "Epoch-288 100 batches\tloss 0.6912 (0.6914)\taccu 53.125 (53.062)\n",
      "Epoch-288 120 batches\tloss 0.6947 (0.6916)\taccu 54.688 (53.151)\n",
      "Epoch-288 140 batches\tloss 0.6901 (0.6917)\taccu 48.438 (53.147)\n",
      "Epoch-288 38.5s\tTrain: loss 0.6919\taccu 52.8846\tValid: loss 0.6937\taccu 50.0401\n",
      "Epoch 288: val_acc did not improve\n",
      "288 1.0000000000000002e-06\n",
      "Epoch-289  20 batches\tloss 0.6855 (0.6892)\taccu 57.812 (55.391)\n",
      "Epoch-289  40 batches\tloss 0.6965 (0.6913)\taccu 51.562 (53.398)\n",
      "Epoch-289  60 batches\tloss 0.6915 (0.6911)\taccu 56.250 (53.776)\n",
      "Epoch-289  80 batches\tloss 0.6978 (0.6914)\taccu 43.750 (53.535)\n",
      "Epoch-289 100 batches\tloss 0.6957 (0.6918)\taccu 53.125 (53.172)\n",
      "Epoch-289 120 batches\tloss 0.6929 (0.6918)\taccu 50.000 (52.839)\n",
      "Epoch-289 140 batches\tloss 0.6956 (0.6917)\taccu 56.250 (52.835)\n",
      "Epoch-289 38.5s\tTrain: loss 0.6919\taccu 52.6643\tValid: loss 0.6937\taccu 50.0100\n",
      "Epoch 289: val_acc did not improve\n",
      "289 1.0000000000000002e-06\n",
      "Epoch-290  20 batches\tloss 0.6952 (0.6938)\taccu 53.125 (51.328)\n",
      "Epoch-290  40 batches\tloss 0.6911 (0.6934)\taccu 54.688 (51.445)\n",
      "Epoch-290  60 batches\tloss 0.6918 (0.6927)\taccu 53.125 (51.875)\n",
      "Epoch-290  80 batches\tloss 0.6896 (0.6926)\taccu 53.125 (51.953)\n",
      "Epoch-290 100 batches\tloss 0.6845 (0.6923)\taccu 64.062 (52.328)\n",
      "Epoch-290 120 batches\tloss 0.6843 (0.6920)\taccu 60.938 (52.565)\n",
      "Epoch-290 140 batches\tloss 0.6889 (0.6920)\taccu 54.688 (52.734)\n",
      "Epoch-290 38.8s\tTrain: loss 0.6918\taccu 52.8045\tValid: loss 0.6937\taccu 50.4107\n",
      "Epoch 290: val_acc did not improve\n",
      "290 1.0000000000000002e-06\n",
      "Epoch-291  20 batches\tloss 0.6934 (0.6924)\taccu 50.000 (52.969)\n",
      "Epoch-291  40 batches\tloss 0.6918 (0.6930)\taccu 40.625 (51.641)\n",
      "Epoch-291  60 batches\tloss 0.6921 (0.6928)\taccu 53.125 (51.719)\n",
      "Epoch-291  80 batches\tloss 0.6912 (0.6919)\taccu 53.125 (52.422)\n",
      "Epoch-291 100 batches\tloss 0.6958 (0.6919)\taccu 45.312 (52.500)\n",
      "Epoch-291 120 batches\tloss 0.6943 (0.6915)\taccu 46.875 (53.034)\n",
      "Epoch-291 140 batches\tloss 0.6919 (0.6917)\taccu 43.750 (52.656)\n",
      "Epoch-291 38.4s\tTrain: loss 0.6917\taccu 52.8746\tValid: loss 0.6937\taccu 50.2003\n",
      "Epoch 291: val_acc did not improve\n",
      "291 1.0000000000000002e-06\n",
      "Epoch-292  20 batches\tloss 0.6995 (0.6928)\taccu 48.438 (51.172)\n",
      "Epoch-292  40 batches\tloss 0.6898 (0.6929)\taccu 51.562 (50.781)\n",
      "Epoch-292  60 batches\tloss 0.6854 (0.6924)\taccu 60.938 (51.667)\n",
      "Epoch-292  80 batches\tloss 0.6958 (0.6924)\taccu 45.312 (51.738)\n",
      "Epoch-292 100 batches\tloss 0.6971 (0.6923)\taccu 46.875 (52.125)\n",
      "Epoch-292 120 batches\tloss 0.6892 (0.6922)\taccu 60.938 (52.539)\n",
      "Epoch-292 140 batches\tloss 0.6906 (0.6920)\taccu 53.125 (52.645)\n",
      "Epoch-292 38.4s\tTrain: loss 0.6917\taccu 53.0449\tValid: loss 0.6936\taccu 50.3506\n",
      "Epoch 292: val_acc did not improve\n",
      "292 1.0000000000000002e-06\n",
      "Epoch-293  20 batches\tloss 0.6864 (0.6908)\taccu 56.250 (53.750)\n",
      "Epoch-293  40 batches\tloss 0.6857 (0.6918)\taccu 60.938 (52.695)\n",
      "Epoch-293  60 batches\tloss 0.6886 (0.6917)\taccu 56.250 (52.760)\n",
      "Epoch-293  80 batches\tloss 0.6870 (0.6919)\taccu 56.250 (52.266)\n",
      "Epoch-293 100 batches\tloss 0.6913 (0.6922)\taccu 59.375 (51.906)\n",
      "Epoch-293 120 batches\tloss 0.6934 (0.6923)\taccu 50.000 (51.784)\n",
      "Epoch-293 140 batches\tloss 0.6908 (0.6921)\taccu 59.375 (52.221)\n",
      "Epoch-293 38.5s\tTrain: loss 0.6921\taccu 52.2336\tValid: loss 0.6937\taccu 50.1002\n",
      "Epoch 293: val_acc did not improve\n",
      "293 1.0000000000000002e-06\n",
      "Epoch-294  20 batches\tloss 0.6873 (0.6913)\taccu 57.812 (54.688)\n",
      "Epoch-294  40 batches\tloss 0.6966 (0.6920)\taccu 45.312 (52.539)\n",
      "Epoch-294  60 batches\tloss 0.6921 (0.6916)\taccu 50.000 (53.073)\n",
      "Epoch-294  80 batches\tloss 0.6898 (0.6916)\taccu 54.688 (53.086)\n",
      "Epoch-294 100 batches\tloss 0.6956 (0.6914)\taccu 48.438 (53.219)\n",
      "Epoch-294 120 batches\tloss 0.6877 (0.6918)\taccu 53.125 (52.734)\n",
      "Epoch-294 140 batches\tloss 0.6903 (0.6917)\taccu 57.812 (52.768)\n",
      "Epoch-294 38.5s\tTrain: loss 0.6920\taccu 52.4539\tValid: loss 0.6937\taccu 50.2103\n",
      "Epoch 294: val_acc did not improve\n",
      "294 1.0000000000000002e-06\n",
      "Epoch-295  20 batches\tloss 0.6880 (0.6909)\taccu 57.812 (54.531)\n",
      "Epoch-295  40 batches\tloss 0.6837 (0.6920)\taccu 60.938 (52.344)\n",
      "Epoch-295  60 batches\tloss 0.6860 (0.6921)\taccu 59.375 (52.500)\n",
      "Epoch-295  80 batches\tloss 0.6954 (0.6924)\taccu 43.750 (52.012)\n",
      "Epoch-295 100 batches\tloss 0.6960 (0.6923)\taccu 48.438 (52.125)\n",
      "Epoch-295 120 batches\tloss 0.6967 (0.6920)\taccu 46.875 (52.331)\n",
      "Epoch-295 140 batches\tloss 0.6833 (0.6919)\taccu 60.938 (52.589)\n",
      "Epoch-295 38.7s\tTrain: loss 0.6919\taccu 52.2837\tValid: loss 0.6936\taccu 50.2804\n",
      "Epoch 295: val_acc did not improve\n",
      "295 1.0000000000000002e-06\n",
      "Epoch-296  20 batches\tloss 0.7005 (0.6929)\taccu 46.875 (52.969)\n",
      "Epoch-296  40 batches\tloss 0.6965 (0.6925)\taccu 37.500 (52.969)\n",
      "Epoch-296  60 batches\tloss 0.6962 (0.6923)\taccu 53.125 (53.047)\n",
      "Epoch-296  80 batches\tloss 0.6857 (0.6924)\taccu 59.375 (53.301)\n",
      "Epoch-296 100 batches\tloss 0.6892 (0.6922)\taccu 57.812 (53.141)\n",
      "Epoch-296 120 batches\tloss 0.6877 (0.6919)\taccu 54.688 (53.047)\n",
      "Epoch-296 140 batches\tloss 0.6906 (0.6917)\taccu 51.562 (53.181)\n",
      "Epoch-296 38.7s\tTrain: loss 0.6919\taccu 52.9247\tValid: loss 0.6936\taccu 50.5208\n",
      "Epoch 296: val_acc did not improve\n",
      "296 1.0000000000000002e-06\n",
      "Epoch-297  20 batches\tloss 0.6959 (0.6907)\taccu 46.875 (54.219)\n",
      "Epoch-297  40 batches\tloss 0.6929 (0.6908)\taccu 45.312 (53.906)\n",
      "Epoch-297  60 batches\tloss 0.6932 (0.6915)\taccu 56.250 (52.682)\n",
      "Epoch-297  80 batches\tloss 0.6901 (0.6918)\taccu 53.125 (52.266)\n",
      "Epoch-297 100 batches\tloss 0.6924 (0.6915)\taccu 56.250 (52.469)\n",
      "Epoch-297 120 batches\tloss 0.6965 (0.6917)\taccu 45.312 (52.240)\n",
      "Epoch-297 140 batches\tloss 0.6933 (0.6917)\taccu 57.812 (52.533)\n",
      "Epoch-297 38.8s\tTrain: loss 0.6918\taccu 52.2937\tValid: loss 0.6937\taccu 50.4808\n",
      "Epoch 297: val_acc did not improve\n",
      "297 1.0000000000000002e-06\n",
      "Epoch-298  20 batches\tloss 0.6894 (0.6916)\taccu 51.562 (53.281)\n",
      "Epoch-298  40 batches\tloss 0.6924 (0.6929)\taccu 48.438 (51.367)\n",
      "Epoch-298  60 batches\tloss 0.6931 (0.6925)\taccu 48.438 (51.641)\n",
      "Epoch-298  80 batches\tloss 0.6927 (0.6922)\taccu 53.125 (52.363)\n",
      "Epoch-298 100 batches\tloss 0.6879 (0.6919)\taccu 54.688 (52.375)\n",
      "Epoch-298 120 batches\tloss 0.6862 (0.6918)\taccu 57.812 (52.448)\n",
      "Epoch-298 140 batches\tloss 0.6852 (0.6917)\taccu 56.250 (52.589)\n",
      "Epoch-298 38.4s\tTrain: loss 0.6918\taccu 52.4840\tValid: loss 0.6938\taccu 50.4607\n",
      "Epoch 298: val_acc did not improve\n",
      "298 1.0000000000000002e-06\n",
      "Epoch-299  20 batches\tloss 0.6973 (0.6916)\taccu 45.312 (53.594)\n",
      "Epoch-299  40 batches\tloss 0.6843 (0.6908)\taccu 59.375 (53.555)\n",
      "Epoch-299  60 batches\tloss 0.6916 (0.6916)\taccu 54.688 (52.786)\n",
      "Epoch-299  80 batches\tloss 0.6843 (0.6914)\taccu 65.625 (52.871)\n",
      "Epoch-299 100 batches\tloss 0.6970 (0.6916)\taccu 53.125 (52.766)\n",
      "Epoch-299 120 batches\tloss 0.6965 (0.6919)\taccu 50.000 (52.383)\n",
      "Epoch-299 140 batches\tloss 0.6935 (0.6918)\taccu 50.000 (52.377)\n",
      "Epoch-299 38.7s\tTrain: loss 0.6919\taccu 52.3337\tValid: loss 0.6937\taccu 50.1302\n",
      "Epoch 299: val_acc did not improve\n",
      "299 1.0000000000000002e-06\n",
      "Epoch-300  20 batches\tloss 0.6960 (0.6912)\taccu 50.000 (53.672)\n",
      "Epoch-300  40 batches\tloss 0.6975 (0.6915)\taccu 42.188 (52.734)\n",
      "Epoch-300  60 batches\tloss 0.6898 (0.6913)\taccu 56.250 (52.943)\n",
      "Epoch-300  80 batches\tloss 0.6933 (0.6916)\taccu 51.562 (52.910)\n",
      "Epoch-300 100 batches\tloss 0.6932 (0.6916)\taccu 53.125 (53.156)\n",
      "Epoch-300 120 batches\tloss 0.6847 (0.6917)\taccu 60.938 (52.799)\n",
      "Epoch-300 140 batches\tloss 0.6847 (0.6917)\taccu 59.375 (53.069)\n",
      "Epoch-300 38.5s\tTrain: loss 0.6918\taccu 52.9848\tValid: loss 0.6938\taccu 50.5909\n",
      "Epoch 300: val_acc did not improve\n",
      "300 1.0000000000000002e-06\n",
      "Epoch-301  20 batches\tloss 0.6948 (0.6912)\taccu 53.125 (53.359)\n",
      "Epoch-301  40 batches\tloss 0.6920 (0.6911)\taccu 50.000 (53.633)\n",
      "Epoch-301  60 batches\tloss 0.6907 (0.6913)\taccu 54.688 (53.698)\n",
      "Epoch-301  80 batches\tloss 0.6885 (0.6911)\taccu 62.500 (53.594)\n",
      "Epoch-301 100 batches\tloss 0.7031 (0.6912)\taccu 40.625 (53.141)\n",
      "Epoch-301 120 batches\tloss 0.6960 (0.6914)\taccu 54.688 (53.034)\n",
      "Epoch-301 140 batches\tloss 0.6924 (0.6916)\taccu 48.438 (52.634)\n",
      "Epoch-301 38.5s\tTrain: loss 0.6917\taccu 52.6843\tValid: loss 0.6938\taccu 50.4708\n",
      "Epoch 301: val_acc did not improve\n",
      "301 1.0000000000000002e-06\n",
      "Epoch-302  20 batches\tloss 0.6908 (0.6929)\taccu 57.812 (52.422)\n",
      "Epoch-302  40 batches\tloss 0.6865 (0.6921)\taccu 54.688 (53.203)\n",
      "Epoch-302  60 batches\tloss 0.6908 (0.6920)\taccu 54.688 (53.464)\n",
      "Epoch-302  80 batches\tloss 0.6879 (0.6918)\taccu 56.250 (53.457)\n",
      "Epoch-302 100 batches\tloss 0.6931 (0.6918)\taccu 57.812 (53.094)\n",
      "Epoch-302 120 batches\tloss 0.6850 (0.6918)\taccu 60.938 (52.891)\n",
      "Epoch-302 140 batches\tloss 0.6942 (0.6917)\taccu 51.562 (52.969)\n",
      "Epoch-302 38.8s\tTrain: loss 0.6917\taccu 52.8946\tValid: loss 0.6937\taccu 50.3305\n",
      "Epoch 302: val_acc did not improve\n",
      "302 1.0000000000000002e-06\n",
      "Epoch-303  20 batches\tloss 0.6842 (0.6904)\taccu 56.250 (52.734)\n",
      "Epoch-303  40 batches\tloss 0.7041 (0.6908)\taccu 37.500 (52.891)\n",
      "Epoch-303  60 batches\tloss 0.6893 (0.6908)\taccu 54.688 (53.802)\n",
      "Epoch-303  80 batches\tloss 0.6871 (0.6910)\taccu 65.625 (53.965)\n",
      "Epoch-303 100 batches\tloss 0.6934 (0.6913)\taccu 53.125 (53.844)\n",
      "Epoch-303 120 batches\tloss 0.6972 (0.6915)\taccu 43.750 (53.503)\n",
      "Epoch-303 140 batches\tloss 0.6976 (0.6917)\taccu 46.875 (53.248)\n",
      "Epoch-303 39.0s\tTrain: loss 0.6916\taccu 53.3053\tValid: loss 0.6937\taccu 50.1102\n",
      "Epoch 303: val_acc did not improve\n",
      "303 1.0000000000000002e-06\n",
      "Epoch-304  20 batches\tloss 0.7000 (0.6929)\taccu 51.562 (52.734)\n",
      "Epoch-304  40 batches\tloss 0.6862 (0.6923)\taccu 57.812 (52.773)\n",
      "Epoch-304  60 batches\tloss 0.6970 (0.6924)\taccu 48.438 (52.630)\n",
      "Epoch-304  80 batches\tloss 0.6929 (0.6923)\taccu 50.000 (52.578)\n",
      "Epoch-304 100 batches\tloss 0.6881 (0.6921)\taccu 57.812 (52.922)\n",
      "Epoch-304 120 batches\tloss 0.6905 (0.6921)\taccu 54.688 (53.021)\n",
      "Epoch-304 140 batches\tloss 0.6917 (0.6922)\taccu 57.812 (52.757)\n",
      "Epoch-304 40.0s\tTrain: loss 0.6921\taccu 52.7544\tValid: loss 0.6937\taccu 50.1102\n",
      "Epoch 304: val_acc did not improve\n",
      "304 1.0000000000000002e-06\n",
      "Epoch-305  20 batches\tloss 0.6887 (0.6916)\taccu 56.250 (52.734)\n",
      "Epoch-305  40 batches\tloss 0.6936 (0.6915)\taccu 45.312 (52.344)\n",
      "Epoch-305  60 batches\tloss 0.7045 (0.6915)\taccu 39.062 (52.474)\n",
      "Epoch-305  80 batches\tloss 0.6890 (0.6916)\taccu 57.812 (52.578)\n",
      "Epoch-305 100 batches\tloss 0.6945 (0.6918)\taccu 42.188 (52.719)\n",
      "Epoch-305 120 batches\tloss 0.6910 (0.6918)\taccu 48.438 (52.734)\n",
      "Epoch-305 140 batches\tloss 0.6950 (0.6917)\taccu 48.438 (52.824)\n",
      "Epoch-305 39.9s\tTrain: loss 0.6918\taccu 52.6943\tValid: loss 0.6938\taccu 50.0801\n",
      "Epoch 305: val_acc did not improve\n",
      "305 1.0000000000000002e-06\n",
      "Epoch-306  20 batches\tloss 0.6861 (0.6931)\taccu 60.938 (52.109)\n",
      "Epoch-306  40 batches\tloss 0.6924 (0.6921)\taccu 53.125 (53.008)\n",
      "Epoch-306  60 batches\tloss 0.6907 (0.6926)\taccu 59.375 (52.344)\n",
      "Epoch-306  80 batches\tloss 0.6959 (0.6922)\taccu 51.562 (52.246)\n",
      "Epoch-306 100 batches\tloss 0.6971 (0.6924)\taccu 40.625 (51.734)\n",
      "Epoch-306 120 batches\tloss 0.6860 (0.6919)\taccu 60.938 (52.214)\n",
      "Epoch-306 140 batches\tloss 0.6925 (0.6919)\taccu 54.688 (52.321)\n",
      "Epoch-306 38.8s\tTrain: loss 0.6919\taccu 52.5040\tValid: loss 0.6936\taccu 50.3405\n",
      "Epoch 306: val_acc did not improve\n",
      "306 1.0000000000000002e-06\n",
      "Epoch-307  20 batches\tloss 0.6843 (0.6924)\taccu 70.312 (51.328)\n",
      "Epoch-307  40 batches\tloss 0.6931 (0.6928)\taccu 46.875 (51.641)\n",
      "Epoch-307  60 batches\tloss 0.6835 (0.6924)\taccu 57.812 (52.109)\n",
      "Epoch-307  80 batches\tloss 0.6957 (0.6921)\taccu 51.562 (52.383)\n",
      "Epoch-307 100 batches\tloss 0.6842 (0.6922)\taccu 59.375 (52.125)\n",
      "Epoch-307 120 batches\tloss 0.6888 (0.6916)\taccu 57.812 (52.917)\n",
      "Epoch-307 140 batches\tloss 0.6921 (0.6917)\taccu 48.438 (52.958)\n",
      "Epoch-307 38.5s\tTrain: loss 0.6918\taccu 52.6542\tValid: loss 0.6935\taccu 50.1903\n",
      "Epoch 307: val_acc did not improve\n",
      "307 1.0000000000000002e-06\n",
      "Epoch-308  20 batches\tloss 0.6898 (0.6915)\taccu 53.125 (52.812)\n",
      "Epoch-308  40 batches\tloss 0.6910 (0.6915)\taccu 57.812 (53.008)\n",
      "Epoch-308  60 batches\tloss 0.7020 (0.6915)\taccu 45.312 (53.203)\n",
      "Epoch-308  80 batches\tloss 0.6976 (0.6917)\taccu 53.125 (52.949)\n",
      "Epoch-308 100 batches\tloss 0.6950 (0.6918)\taccu 54.688 (52.688)\n",
      "Epoch-308 120 batches\tloss 0.6849 (0.6918)\taccu 57.812 (52.734)\n",
      "Epoch-308 140 batches\tloss 0.6887 (0.6919)\taccu 51.562 (52.556)\n",
      "Epoch-308 38.4s\tTrain: loss 0.6920\taccu 52.6442\tValid: loss 0.6937\taccu 50.4006\n",
      "Epoch 308: val_acc did not improve\n",
      "308 1.0000000000000002e-06\n",
      "Epoch-309  20 batches\tloss 0.6875 (0.6925)\taccu 62.500 (53.047)\n",
      "Epoch-309  40 batches\tloss 0.6928 (0.6922)\taccu 50.000 (52.500)\n",
      "Epoch-309  60 batches\tloss 0.6920 (0.6917)\taccu 48.438 (52.578)\n",
      "Epoch-309  80 batches\tloss 0.6934 (0.6919)\taccu 51.562 (52.266)\n",
      "Epoch-309 100 batches\tloss 0.6887 (0.6917)\taccu 54.688 (52.641)\n",
      "Epoch-309 120 batches\tloss 0.6886 (0.6920)\taccu 60.938 (52.487)\n",
      "Epoch-309 140 batches\tloss 0.6905 (0.6919)\taccu 50.000 (52.600)\n",
      "Epoch-309 38.4s\tTrain: loss 0.6917\taccu 52.6042\tValid: loss 0.6937\taccu 50.0300\n",
      "Epoch 309: val_acc did not improve\n",
      "309 1.0000000000000002e-06\n",
      "Epoch-310  20 batches\tloss 0.6858 (0.6914)\taccu 59.375 (53.672)\n",
      "Epoch-310  40 batches\tloss 0.6944 (0.6919)\taccu 46.875 (52.461)\n",
      "Epoch-310  60 batches\tloss 0.6903 (0.6922)\taccu 51.562 (52.396)\n",
      "Epoch-310  80 batches\tloss 0.6875 (0.6920)\taccu 53.125 (52.520)\n",
      "Epoch-310 100 batches\tloss 0.6873 (0.6917)\taccu 65.625 (52.703)\n",
      "Epoch-310 120 batches\tloss 0.6931 (0.6917)\taccu 53.125 (52.617)\n",
      "Epoch-310 140 batches\tloss 0.6912 (0.6920)\taccu 57.812 (52.578)\n",
      "Epoch-310 38.3s\tTrain: loss 0.6920\taccu 52.4639\tValid: loss 0.6937\taccu 50.2204\n",
      "Epoch 310: val_acc did not improve\n",
      "310 1.0000000000000002e-06\n",
      "Epoch-311  20 batches\tloss 0.6964 (0.6920)\taccu 43.750 (52.500)\n",
      "Epoch-311  40 batches\tloss 0.6967 (0.6918)\taccu 50.000 (52.617)\n",
      "Epoch-311  60 batches\tloss 0.6941 (0.6915)\taccu 53.125 (53.438)\n",
      "Epoch-311  80 batches\tloss 0.6913 (0.6920)\taccu 54.688 (52.949)\n",
      "Epoch-311 100 batches\tloss 0.6964 (0.6919)\taccu 46.875 (52.922)\n",
      "Epoch-311 120 batches\tloss 0.6890 (0.6920)\taccu 56.250 (53.060)\n",
      "Epoch-311 140 batches\tloss 0.6908 (0.6920)\taccu 51.562 (53.125)\n",
      "Epoch-311 38.5s\tTrain: loss 0.6920\taccu 53.0248\tValid: loss 0.6938\taccu 50.2103\n",
      "Epoch 311: val_acc did not improve\n",
      "311 1.0000000000000002e-06\n",
      "Epoch-312  20 batches\tloss 0.6939 (0.6926)\taccu 51.562 (51.719)\n",
      "Epoch-312  40 batches\tloss 0.6883 (0.6923)\taccu 56.250 (52.891)\n",
      "Epoch-312  60 batches\tloss 0.6927 (0.6921)\taccu 46.875 (52.630)\n",
      "Epoch-312  80 batches\tloss 0.6895 (0.6924)\taccu 64.062 (52.324)\n",
      "Epoch-312 100 batches\tloss 0.6879 (0.6922)\taccu 56.250 (52.484)\n",
      "Epoch-312 120 batches\tloss 0.6841 (0.6920)\taccu 56.250 (52.773)\n",
      "Epoch-312 140 batches\tloss 0.6946 (0.6921)\taccu 53.125 (52.723)\n",
      "Epoch-312 38.6s\tTrain: loss 0.6920\taccu 52.7945\tValid: loss 0.6938\taccu 50.2905\n",
      "Epoch 312: val_acc did not improve\n",
      "312 1.0000000000000002e-06\n",
      "Epoch-313  20 batches\tloss 0.6902 (0.6934)\taccu 53.125 (50.391)\n",
      "Epoch-313  40 batches\tloss 0.6919 (0.6922)\taccu 54.688 (52.812)\n",
      "Epoch-313  60 batches\tloss 0.6882 (0.6920)\taccu 59.375 (52.813)\n",
      "Epoch-313  80 batches\tloss 0.6896 (0.6914)\taccu 51.562 (53.301)\n",
      "Epoch-313 100 batches\tloss 0.6945 (0.6920)\taccu 54.688 (52.422)\n",
      "Epoch-313 120 batches\tloss 0.6846 (0.6918)\taccu 67.188 (52.878)\n",
      "Epoch-313 140 batches\tloss 0.6894 (0.6918)\taccu 57.812 (52.846)\n",
      "Epoch-313 38.5s\tTrain: loss 0.6919\taccu 52.6042\tValid: loss 0.6938\taccu 49.7196\n",
      "Epoch 313: val_acc did not improve\n",
      "313 1.0000000000000002e-06\n",
      "Epoch-314  20 batches\tloss 0.6851 (0.6921)\taccu 64.062 (53.359)\n",
      "Epoch-314  40 batches\tloss 0.6851 (0.6919)\taccu 56.250 (53.477)\n",
      "Epoch-314  60 batches\tloss 0.6937 (0.6917)\taccu 56.250 (53.724)\n",
      "Epoch-314  80 batches\tloss 0.6981 (0.6920)\taccu 48.438 (53.203)\n",
      "Epoch-314 100 batches\tloss 0.6926 (0.6916)\taccu 43.750 (53.250)\n",
      "Epoch-314 120 batches\tloss 0.7018 (0.6919)\taccu 37.500 (53.008)\n",
      "Epoch-314 140 batches\tloss 0.6920 (0.6919)\taccu 48.438 (52.835)\n",
      "Epoch-314 38.4s\tTrain: loss 0.6920\taccu 52.7744\tValid: loss 0.6937\taccu 50.3606\n",
      "Epoch 314: val_acc did not improve\n",
      "314 1.0000000000000002e-06\n",
      "Epoch-315  20 batches\tloss 0.6974 (0.6921)\taccu 39.062 (52.734)\n",
      "Epoch-315  40 batches\tloss 0.6924 (0.6926)\taccu 46.875 (51.016)\n",
      "Epoch-315  60 batches\tloss 0.6925 (0.6919)\taccu 46.875 (51.563)\n",
      "Epoch-315  80 batches\tloss 0.6943 (0.6920)\taccu 50.000 (51.973)\n",
      "Epoch-315 100 batches\tloss 0.6887 (0.6920)\taccu 59.375 (52.422)\n",
      "Epoch-315 120 batches\tloss 0.6924 (0.6918)\taccu 50.000 (52.799)\n",
      "Epoch-315 140 batches\tloss 0.6979 (0.6919)\taccu 42.188 (52.835)\n",
      "Epoch-315 38.4s\tTrain: loss 0.6919\taccu 52.9347\tValid: loss 0.6937\taccu 50.6611\n",
      "Epoch 315: val_acc did not improve\n",
      "315 1.0000000000000002e-06\n",
      "Epoch-316  20 batches\tloss 0.6879 (0.6903)\taccu 59.375 (55.000)\n",
      "Epoch-316  40 batches\tloss 0.6890 (0.6910)\taccu 50.000 (53.984)\n",
      "Epoch-316  60 batches\tloss 0.6933 (0.6917)\taccu 50.000 (53.411)\n",
      "Epoch-316  80 batches\tloss 0.6961 (0.6917)\taccu 42.188 (52.891)\n",
      "Epoch-316 100 batches\tloss 0.6885 (0.6916)\taccu 59.375 (53.188)\n",
      "Epoch-316 120 batches\tloss 0.6870 (0.6917)\taccu 57.812 (53.060)\n",
      "Epoch-316 140 batches\tloss 0.6861 (0.6919)\taccu 59.375 (52.734)\n",
      "Epoch-316 38.5s\tTrain: loss 0.6920\taccu 52.5841\tValid: loss 0.6937\taccu 50.2704\n",
      "Epoch 316: val_acc did not improve\n",
      "316 1.0000000000000002e-06\n",
      "Epoch-317  20 batches\tloss 0.6835 (0.6924)\taccu 59.375 (51.562)\n",
      "Epoch-317  40 batches\tloss 0.6953 (0.6920)\taccu 50.000 (52.148)\n",
      "Epoch-317  60 batches\tloss 0.6856 (0.6916)\taccu 53.125 (52.760)\n",
      "Epoch-317  80 batches\tloss 0.6922 (0.6918)\taccu 45.312 (52.598)\n",
      "Epoch-317 100 batches\tloss 0.6850 (0.6916)\taccu 64.062 (53.141)\n",
      "Epoch-317 120 batches\tloss 0.6924 (0.6919)\taccu 50.000 (52.760)\n",
      "Epoch-317 140 batches\tloss 0.6873 (0.6918)\taccu 56.250 (52.857)\n",
      "Epoch-317 38.6s\tTrain: loss 0.6920\taccu 52.8345\tValid: loss 0.6937\taccu 50.4507\n",
      "Epoch 317: val_acc did not improve\n",
      "317 1.0000000000000002e-06\n",
      "Epoch-318  20 batches\tloss 0.6957 (0.6925)\taccu 53.125 (51.172)\n",
      "Epoch-318  40 batches\tloss 0.6878 (0.6920)\taccu 60.938 (51.758)\n",
      "Epoch-318  60 batches\tloss 0.6880 (0.6919)\taccu 54.688 (51.771)\n",
      "Epoch-318  80 batches\tloss 0.6871 (0.6922)\taccu 56.250 (51.250)\n",
      "Epoch-318 100 batches\tloss 0.6903 (0.6919)\taccu 64.062 (51.938)\n",
      "Epoch-318 120 batches\tloss 0.6911 (0.6921)\taccu 56.250 (51.536)\n",
      "Epoch-318 140 batches\tloss 0.6838 (0.6920)\taccu 67.188 (52.121)\n",
      "Epoch-318 38.6s\tTrain: loss 0.6919\taccu 52.4139\tValid: loss 0.6937\taccu 50.3706\n",
      "Epoch 318: val_acc did not improve\n",
      "318 1.0000000000000002e-06\n",
      "Epoch-319  20 batches\tloss 0.6932 (0.6920)\taccu 53.125 (53.984)\n",
      "Epoch-319  40 batches\tloss 0.6834 (0.6911)\taccu 64.062 (53.984)\n",
      "Epoch-319  60 batches\tloss 0.6803 (0.6914)\taccu 68.750 (53.594)\n",
      "Epoch-319  80 batches\tloss 0.6913 (0.6914)\taccu 54.688 (53.691)\n",
      "Epoch-319 100 batches\tloss 0.6946 (0.6916)\taccu 50.000 (53.266)\n",
      "Epoch-319 120 batches\tloss 0.6900 (0.6917)\taccu 59.375 (53.255)\n",
      "Epoch-319 140 batches\tloss 0.6945 (0.6917)\taccu 46.875 (53.248)\n",
      "Epoch-319 38.4s\tTrain: loss 0.6916\taccu 53.3153\tValid: loss 0.6938\taccu 49.9199\n",
      "Epoch 319: val_acc did not improve\n",
      "319 1.0000000000000002e-06\n",
      "Epoch-320  20 batches\tloss 0.6917 (0.6922)\taccu 62.500 (52.656)\n",
      "Epoch-320  40 batches\tloss 0.6910 (0.6921)\taccu 60.938 (52.500)\n",
      "Epoch-320  60 batches\tloss 0.6935 (0.6919)\taccu 51.562 (52.786)\n",
      "Epoch-320  80 batches\tloss 0.6906 (0.6916)\taccu 54.688 (53.164)\n",
      "Epoch-320 100 batches\tloss 0.6973 (0.6918)\taccu 53.125 (53.172)\n",
      "Epoch-320 120 batches\tloss 0.6821 (0.6918)\taccu 64.062 (53.099)\n",
      "Epoch-320 140 batches\tloss 0.6941 (0.6922)\taccu 48.438 (52.489)\n",
      "Epoch-320 38.5s\tTrain: loss 0.6921\taccu 52.6142\tValid: loss 0.6937\taccu 50.3906\n",
      "Epoch 320: val_acc did not improve\n",
      "320 1.0000000000000002e-06\n",
      "Epoch-321  20 batches\tloss 0.6922 (0.6909)\taccu 51.562 (54.375)\n",
      "Epoch-321  40 batches\tloss 0.6928 (0.6915)\taccu 50.000 (53.516)\n",
      "Epoch-321  60 batches\tloss 0.6892 (0.6915)\taccu 54.688 (52.943)\n",
      "Epoch-321  80 batches\tloss 0.6923 (0.6916)\taccu 56.250 (52.793)\n",
      "Epoch-321 100 batches\tloss 0.7005 (0.6916)\taccu 43.750 (53.047)\n",
      "Epoch-321 120 batches\tloss 0.6993 (0.6916)\taccu 48.438 (53.138)\n",
      "Epoch-321 140 batches\tloss 0.6835 (0.6919)\taccu 64.062 (53.181)\n",
      "Epoch-321 38.5s\tTrain: loss 0.6918\taccu 53.1851\tValid: loss 0.6937\taccu 50.2704\n",
      "Epoch 321: val_acc did not improve\n",
      "321 1.0000000000000002e-06\n",
      "Epoch-322  20 batches\tloss 0.6856 (0.6909)\taccu 59.375 (54.062)\n",
      "Epoch-322  40 batches\tloss 0.6927 (0.6914)\taccu 48.438 (53.086)\n",
      "Epoch-322  60 batches\tloss 0.6896 (0.6911)\taccu 54.688 (53.203)\n",
      "Epoch-322  80 batches\tloss 0.6813 (0.6914)\taccu 68.750 (53.125)\n",
      "Epoch-322 100 batches\tloss 0.6948 (0.6917)\taccu 48.438 (52.656)\n",
      "Epoch-322 120 batches\tloss 0.6894 (0.6917)\taccu 62.500 (53.021)\n",
      "Epoch-322 140 batches\tloss 0.6918 (0.6919)\taccu 46.875 (52.712)\n",
      "Epoch-322 38.4s\tTrain: loss 0.6919\taccu 52.8446\tValid: loss 0.6936\taccu 50.2404\n",
      "Epoch 322: val_acc did not improve\n",
      "322 1.0000000000000002e-06\n",
      "Epoch-323  20 batches\tloss 0.6945 (0.6925)\taccu 46.875 (50.312)\n",
      "Epoch-323  40 batches\tloss 0.6973 (0.6916)\taccu 40.625 (51.719)\n",
      "Epoch-323  60 batches\tloss 0.6938 (0.6916)\taccu 57.812 (52.240)\n",
      "Epoch-323  80 batches\tloss 0.6997 (0.6924)\taccu 43.750 (51.777)\n",
      "Epoch-323 100 batches\tloss 0.6897 (0.6923)\taccu 56.250 (51.969)\n",
      "Epoch-323 120 batches\tloss 0.6920 (0.6920)\taccu 50.000 (52.227)\n",
      "Epoch-323 140 batches\tloss 0.6906 (0.6920)\taccu 60.938 (52.321)\n",
      "Epoch-323 38.4s\tTrain: loss 0.6920\taccu 52.4740\tValid: loss 0.6937\taccu 50.1603\n",
      "Epoch 323: val_acc did not improve\n",
      "323 1.0000000000000002e-06\n",
      "Epoch-324  20 batches\tloss 0.6910 (0.6912)\taccu 54.688 (53.203)\n",
      "Epoch-324  40 batches\tloss 0.7023 (0.6917)\taccu 46.875 (53.750)\n",
      "Epoch-324  60 batches\tloss 0.6912 (0.6920)\taccu 51.562 (53.255)\n",
      "Epoch-324  80 batches\tloss 0.6920 (0.6923)\taccu 45.312 (52.793)\n",
      "Epoch-324 100 batches\tloss 0.6973 (0.6921)\taccu 46.875 (53.031)\n",
      "Epoch-324 120 batches\tloss 0.6903 (0.6920)\taccu 56.250 (53.190)\n",
      "Epoch-324 140 batches\tloss 0.6988 (0.6919)\taccu 43.750 (53.103)\n",
      "Epoch-324 38.5s\tTrain: loss 0.6920\taccu 52.7344\tValid: loss 0.6937\taccu 50.2905\n",
      "Epoch 324: val_acc did not improve\n",
      "324 1.0000000000000002e-06\n",
      "Epoch-325  20 batches\tloss 0.6926 (0.6895)\taccu 50.000 (54.609)\n",
      "Epoch-325  40 batches\tloss 0.6942 (0.6907)\taccu 46.875 (53.984)\n",
      "Epoch-325  60 batches\tloss 0.6920 (0.6910)\taccu 48.438 (54.115)\n",
      "Epoch-325  80 batches\tloss 0.6900 (0.6912)\taccu 57.812 (53.379)\n",
      "Epoch-325 100 batches\tloss 0.6925 (0.6915)\taccu 53.125 (53.156)\n",
      "Epoch-325 120 batches\tloss 0.6944 (0.6915)\taccu 46.875 (53.164)\n",
      "Epoch-325 140 batches\tloss 0.6923 (0.6916)\taccu 48.438 (53.047)\n",
      "Epoch-325 38.6s\tTrain: loss 0.6918\taccu 52.7644\tValid: loss 0.6937\taccu 50.3506\n",
      "Epoch 325: val_acc did not improve\n",
      "325 1.0000000000000002e-06\n",
      "Epoch-326  20 batches\tloss 0.6887 (0.6907)\taccu 53.125 (52.891)\n",
      "Epoch-326  40 batches\tloss 0.6861 (0.6909)\taccu 59.375 (53.867)\n",
      "Epoch-326  60 batches\tloss 0.6914 (0.6911)\taccu 56.250 (53.646)\n",
      "Epoch-326  80 batches\tloss 0.6870 (0.6913)\taccu 57.812 (53.359)\n",
      "Epoch-326 100 batches\tloss 0.7028 (0.6914)\taccu 39.062 (53.016)\n",
      "Epoch-326 120 batches\tloss 0.6957 (0.6915)\taccu 46.875 (53.008)\n",
      "Epoch-326 140 batches\tloss 0.6999 (0.6917)\taccu 46.875 (52.790)\n",
      "Epoch-326 41.6s\tTrain: loss 0.6916\taccu 52.9046\tValid: loss 0.6937\taccu 50.3606\n",
      "Epoch 326: val_acc did not improve\n",
      "326 1.0000000000000002e-06\n",
      "Epoch-327  20 batches\tloss 0.6983 (0.6905)\taccu 50.000 (53.828)\n",
      "Epoch-327  40 batches\tloss 0.6881 (0.6905)\taccu 59.375 (54.727)\n",
      "Epoch-327  60 batches\tloss 0.6885 (0.6905)\taccu 64.062 (54.792)\n",
      "Epoch-327  80 batches\tloss 0.6921 (0.6910)\taccu 54.688 (54.121)\n",
      "Epoch-327 100 batches\tloss 0.7012 (0.6914)\taccu 42.188 (53.594)\n",
      "Epoch-327 120 batches\tloss 0.6903 (0.6917)\taccu 56.250 (53.333)\n",
      "Epoch-327 140 batches\tloss 0.6950 (0.6919)\taccu 51.562 (53.181)\n",
      "Epoch-327 41.3s\tTrain: loss 0.6920\taccu 53.2352\tValid: loss 0.6937\taccu 50.5509\n",
      "Epoch 327: val_acc did not improve\n",
      "327 1.0000000000000002e-06\n",
      "Epoch-328  20 batches\tloss 0.6924 (0.6918)\taccu 46.875 (51.641)\n",
      "Epoch-328  40 batches\tloss 0.6930 (0.6919)\taccu 53.125 (52.695)\n",
      "Epoch-328  60 batches\tloss 0.6883 (0.6920)\taccu 51.562 (52.031)\n",
      "Epoch-328  80 batches\tloss 0.6894 (0.6917)\taccu 62.500 (52.480)\n",
      "Epoch-328 100 batches\tloss 0.6927 (0.6918)\taccu 54.688 (52.500)\n",
      "Epoch-328 120 batches\tloss 0.6880 (0.6918)\taccu 56.250 (52.513)\n",
      "Epoch-328 140 batches\tloss 0.6897 (0.6920)\taccu 56.250 (52.355)\n",
      "Epoch-328 38.6s\tTrain: loss 0.6921\taccu 52.4639\tValid: loss 0.6938\taccu 50.3506\n",
      "Epoch 328: val_acc did not improve\n",
      "328 1.0000000000000002e-06\n",
      "Epoch-329  20 batches\tloss 0.6880 (0.6906)\taccu 57.812 (54.922)\n",
      "Epoch-329  40 batches\tloss 0.6898 (0.6911)\taccu 50.000 (53.594)\n",
      "Epoch-329  60 batches\tloss 0.6948 (0.6909)\taccu 48.438 (53.854)\n",
      "Epoch-329  80 batches\tloss 0.6940 (0.6916)\taccu 48.438 (52.754)\n",
      "Epoch-329 100 batches\tloss 0.6956 (0.6917)\taccu 48.438 (52.625)\n",
      "Epoch-329 120 batches\tloss 0.6953 (0.6917)\taccu 51.562 (52.643)\n",
      "Epoch-329 140 batches\tloss 0.6951 (0.6918)\taccu 53.125 (52.801)\n",
      "Epoch-329 41.6s\tTrain: loss 0.6918\taccu 52.6142\tValid: loss 0.6937\taccu 50.4207\n",
      "Epoch 329: val_acc did not improve\n",
      "329 1.0000000000000002e-06\n",
      "Epoch-330  20 batches\tloss 0.6898 (0.6917)\taccu 56.250 (52.656)\n",
      "Epoch-330  40 batches\tloss 0.6973 (0.6919)\taccu 48.438 (53.008)\n",
      "Epoch-330  60 batches\tloss 0.6913 (0.6915)\taccu 56.250 (53.646)\n",
      "Epoch-330  80 batches\tloss 0.6963 (0.6914)\taccu 45.312 (53.789)\n",
      "Epoch-330 100 batches\tloss 0.6887 (0.6919)\taccu 51.562 (53.188)\n",
      "Epoch-330 120 batches\tloss 0.6934 (0.6922)\taccu 54.688 (52.578)\n",
      "Epoch-330 140 batches\tloss 0.6892 (0.6923)\taccu 59.375 (52.422)\n",
      "Epoch-330 38.8s\tTrain: loss 0.6921\taccu 52.5441\tValid: loss 0.6938\taccu 50.0300\n",
      "Epoch 330: val_acc did not improve\n",
      "330 1.0000000000000002e-06\n",
      "Epoch-331  20 batches\tloss 0.6932 (0.6913)\taccu 46.875 (53.359)\n",
      "Epoch-331  40 batches\tloss 0.6979 (0.6916)\taccu 48.438 (52.344)\n",
      "Epoch-331  60 batches\tloss 0.6882 (0.6914)\taccu 59.375 (52.708)\n",
      "Epoch-331  80 batches\tloss 0.6939 (0.6915)\taccu 48.438 (52.773)\n",
      "Epoch-331 100 batches\tloss 0.6914 (0.6916)\taccu 50.000 (52.469)\n",
      "Epoch-331 120 batches\tloss 0.6889 (0.6918)\taccu 57.812 (52.487)\n",
      "Epoch-331 140 batches\tloss 0.6856 (0.6920)\taccu 59.375 (52.388)\n",
      "Epoch-331 41.3s\tTrain: loss 0.6918\taccu 52.6142\tValid: loss 0.6939\taccu 50.1102\n",
      "Epoch 331: val_acc did not improve\n",
      "331 1.0000000000000002e-06\n",
      "Epoch-332  20 batches\tloss 0.6901 (0.6926)\taccu 56.250 (51.250)\n",
      "Epoch-332  40 batches\tloss 0.6934 (0.6924)\taccu 54.688 (52.461)\n",
      "Epoch-332  60 batches\tloss 0.6866 (0.6922)\taccu 57.812 (52.422)\n",
      "Epoch-332  80 batches\tloss 0.6978 (0.6924)\taccu 48.438 (52.285)\n",
      "Epoch-332 100 batches\tloss 0.6939 (0.6925)\taccu 48.438 (52.062)\n",
      "Epoch-332 120 batches\tloss 0.6939 (0.6922)\taccu 54.688 (52.396)\n",
      "Epoch-332 140 batches\tloss 0.6941 (0.6922)\taccu 46.875 (52.567)\n",
      "Epoch-332 41.3s\tTrain: loss 0.6923\taccu 52.5541\tValid: loss 0.6937\taccu 50.4407\n",
      "Epoch 332: val_acc did not improve\n",
      "332 1.0000000000000002e-06\n",
      "Epoch-333  20 batches\tloss 0.6787 (0.6900)\taccu 65.625 (55.078)\n",
      "Epoch-333  40 batches\tloss 0.6884 (0.6907)\taccu 53.125 (54.688)\n",
      "Epoch-333  60 batches\tloss 0.6907 (0.6908)\taccu 54.688 (54.141)\n",
      "Epoch-333  80 batches\tloss 0.6965 (0.6911)\taccu 53.125 (54.160)\n",
      "Epoch-333 100 batches\tloss 0.7038 (0.6915)\taccu 43.750 (53.766)\n",
      "Epoch-333 120 batches\tloss 0.7002 (0.6918)\taccu 43.750 (53.372)\n",
      "Epoch-333 140 batches\tloss 0.6905 (0.6915)\taccu 51.562 (53.359)\n",
      "Epoch-333 38.8s\tTrain: loss 0.6916\taccu 53.3454\tValid: loss 0.6938\taccu 50.4607\n",
      "Epoch 333: val_acc did not improve\n",
      "333 1.0000000000000002e-06\n",
      "Epoch-334  20 batches\tloss 0.6860 (0.6915)\taccu 60.938 (54.141)\n",
      "Epoch-334  40 batches\tloss 0.6923 (0.6916)\taccu 51.562 (52.930)\n",
      "Epoch-334  60 batches\tloss 0.6874 (0.6918)\taccu 59.375 (52.604)\n",
      "Epoch-334  80 batches\tloss 0.6926 (0.6920)\taccu 48.438 (52.617)\n",
      "Epoch-334 100 batches\tloss 0.6911 (0.6921)\taccu 56.250 (52.781)\n",
      "Epoch-334 120 batches\tloss 0.6988 (0.6919)\taccu 57.812 (52.956)\n",
      "Epoch-334 140 batches\tloss 0.6877 (0.6918)\taccu 56.250 (53.103)\n",
      "Epoch-334 38.6s\tTrain: loss 0.6918\taccu 52.9948\tValid: loss 0.6937\taccu 50.3305\n",
      "Epoch 334: val_acc did not improve\n",
      "334 1.0000000000000002e-06\n",
      "Epoch-335  20 batches\tloss 0.6907 (0.6928)\taccu 56.250 (50.859)\n",
      "Epoch-335  40 batches\tloss 0.6880 (0.6916)\taccu 62.500 (52.031)\n",
      "Epoch-335  60 batches\tloss 0.6920 (0.6917)\taccu 57.812 (52.604)\n",
      "Epoch-335  80 batches\tloss 0.6879 (0.6915)\taccu 54.688 (52.676)\n",
      "Epoch-335 100 batches\tloss 0.6967 (0.6918)\taccu 53.125 (52.578)\n",
      "Epoch-335 120 batches\tloss 0.6996 (0.6919)\taccu 48.438 (52.565)\n",
      "Epoch-335 140 batches\tloss 0.6949 (0.6917)\taccu 51.562 (52.712)\n",
      "Epoch-335 38.5s\tTrain: loss 0.6918\taccu 52.7143\tValid: loss 0.6938\taccu 50.3606\n",
      "Epoch 335: val_acc did not improve\n",
      "335 1.0000000000000002e-06\n",
      "Epoch-336  20 batches\tloss 0.6918 (0.6925)\taccu 57.812 (52.188)\n",
      "Epoch-336  40 batches\tloss 0.6894 (0.6921)\taccu 56.250 (52.344)\n",
      "Epoch-336  60 batches\tloss 0.6966 (0.6921)\taccu 54.688 (52.474)\n",
      "Epoch-336  80 batches\tloss 0.6923 (0.6920)\taccu 50.000 (52.695)\n",
      "Epoch-336 100 batches\tloss 0.6831 (0.6922)\taccu 65.625 (52.453)\n",
      "Epoch-336 120 batches\tloss 0.6877 (0.6917)\taccu 57.812 (53.034)\n",
      "Epoch-336 140 batches\tloss 0.6913 (0.6917)\taccu 59.375 (53.192)\n",
      "Epoch-336 39.1s\tTrain: loss 0.6917\taccu 53.2352\tValid: loss 0.6937\taccu 50.6911\n",
      "Epoch 336: val_acc did not improve\n",
      "336 1.0000000000000002e-06\n",
      "Epoch-337  20 batches\tloss 0.6955 (0.6919)\taccu 53.125 (52.734)\n",
      "Epoch-337  40 batches\tloss 0.6904 (0.6915)\taccu 57.812 (53.594)\n",
      "Epoch-337  60 batches\tloss 0.6934 (0.6925)\taccu 54.688 (52.526)\n",
      "Epoch-337  80 batches\tloss 0.6910 (0.6922)\taccu 51.562 (52.598)\n",
      "Epoch-337 100 batches\tloss 0.6825 (0.6920)\taccu 67.188 (52.391)\n",
      "Epoch-337 120 batches\tloss 0.6965 (0.6920)\taccu 48.438 (52.409)\n",
      "Epoch-337 140 batches\tloss 0.6987 (0.6918)\taccu 42.188 (52.567)\n",
      "Epoch-337 39.1s\tTrain: loss 0.6918\taccu 52.6643\tValid: loss 0.6939\taccu 50.1402\n",
      "Epoch 337: val_acc did not improve\n",
      "337 1.0000000000000002e-06\n",
      "Epoch-338  20 batches\tloss 0.6961 (0.6919)\taccu 45.312 (51.562)\n",
      "Epoch-338  40 batches\tloss 0.6856 (0.6916)\taccu 62.500 (52.344)\n",
      "Epoch-338  60 batches\tloss 0.6934 (0.6921)\taccu 53.125 (52.083)\n",
      "Epoch-338  80 batches\tloss 0.6890 (0.6921)\taccu 53.125 (52.168)\n",
      "Epoch-338 100 batches\tloss 0.6900 (0.6919)\taccu 51.562 (52.344)\n",
      "Epoch-338 120 batches\tloss 0.6865 (0.6917)\taccu 59.375 (52.656)\n",
      "Epoch-338 140 batches\tloss 0.6939 (0.6918)\taccu 43.750 (52.400)\n",
      "Epoch-338 38.5s\tTrain: loss 0.6919\taccu 52.1334\tValid: loss 0.6937\taccu 50.2204\n",
      "Epoch 338: val_acc did not improve\n",
      "338 1.0000000000000002e-06\n",
      "Epoch-339  20 batches\tloss 0.6938 (0.6929)\taccu 48.438 (50.312)\n",
      "Epoch-339  40 batches\tloss 0.6949 (0.6919)\taccu 46.875 (52.734)\n",
      "Epoch-339  60 batches\tloss 0.6914 (0.6919)\taccu 56.250 (53.099)\n",
      "Epoch-339  80 batches\tloss 0.6957 (0.6916)\taccu 48.438 (53.242)\n",
      "Epoch-339 100 batches\tloss 0.6950 (0.6917)\taccu 48.438 (52.812)\n",
      "Epoch-339 120 batches\tloss 0.6934 (0.6916)\taccu 54.688 (53.372)\n",
      "Epoch-339 140 batches\tloss 0.6945 (0.6916)\taccu 43.750 (53.248)\n",
      "Epoch-339 40.3s\tTrain: loss 0.6917\taccu 53.1150\tValid: loss 0.6938\taccu 50.1002\n",
      "Epoch 339: val_acc did not improve\n",
      "339 1.0000000000000002e-06\n",
      "Epoch-340  20 batches\tloss 0.6909 (0.6923)\taccu 53.125 (52.422)\n",
      "Epoch-340  40 batches\tloss 0.6891 (0.6919)\taccu 56.250 (52.227)\n",
      "Epoch-340  60 batches\tloss 0.6870 (0.6918)\taccu 57.812 (52.760)\n",
      "Epoch-340  80 batches\tloss 0.6921 (0.6915)\taccu 53.125 (53.516)\n",
      "Epoch-340 100 batches\tloss 0.6923 (0.6913)\taccu 57.812 (53.719)\n",
      "Epoch-340 120 batches\tloss 0.6833 (0.6915)\taccu 62.500 (53.424)\n",
      "Epoch-340 140 batches\tloss 0.6905 (0.6916)\taccu 56.250 (53.225)\n",
      "Epoch-340 39.9s\tTrain: loss 0.6918\taccu 52.8245\tValid: loss 0.6938\taccu 50.3906\n",
      "Epoch 340: val_acc did not improve\n",
      "340 1.0000000000000002e-06\n",
      "Epoch-341  20 batches\tloss 0.6934 (0.6937)\taccu 50.000 (50.703)\n",
      "Epoch-341  40 batches\tloss 0.6942 (0.6924)\taccu 56.250 (51.914)\n",
      "Epoch-341  60 batches\tloss 0.6969 (0.6921)\taccu 48.438 (52.396)\n",
      "Epoch-341  80 batches\tloss 0.6922 (0.6919)\taccu 50.000 (52.422)\n",
      "Epoch-341 100 batches\tloss 0.6911 (0.6919)\taccu 54.688 (52.594)\n",
      "Epoch-341 120 batches\tloss 0.6937 (0.6919)\taccu 46.875 (52.878)\n",
      "Epoch-341 140 batches\tloss 0.6853 (0.6921)\taccu 59.375 (52.801)\n",
      "Epoch-341 39.3s\tTrain: loss 0.6919\taccu 53.0048\tValid: loss 0.6938\taccu 50.2404\n",
      "Epoch 341: val_acc did not improve\n",
      "341 1.0000000000000002e-06\n",
      "Epoch-342  20 batches\tloss 0.6913 (0.6910)\taccu 45.312 (53.359)\n",
      "Epoch-342  40 batches\tloss 0.6955 (0.6913)\taccu 53.125 (52.969)\n",
      "Epoch-342  60 batches\tloss 0.6870 (0.6911)\taccu 62.500 (53.359)\n",
      "Epoch-342  80 batches\tloss 0.6927 (0.6914)\taccu 50.000 (53.223)\n",
      "Epoch-342 100 batches\tloss 0.6893 (0.6915)\taccu 60.938 (53.062)\n",
      "Epoch-342 120 batches\tloss 0.6824 (0.6915)\taccu 64.062 (53.333)\n",
      "Epoch-342 140 batches\tloss 0.7014 (0.6916)\taccu 45.312 (53.292)\n",
      "Epoch-342 40.1s\tTrain: loss 0.6916\taccu 53.1550\tValid: loss 0.6940\taccu 49.9499\n",
      "Epoch 342: val_acc did not improve\n",
      "342 1.0000000000000002e-06\n",
      "Epoch-343  20 batches\tloss 0.6835 (0.6926)\taccu 64.062 (51.250)\n",
      "Epoch-343  40 batches\tloss 0.6856 (0.6915)\taccu 57.812 (53.047)\n",
      "Epoch-343  60 batches\tloss 0.6973 (0.6921)\taccu 50.000 (52.344)\n",
      "Epoch-343  80 batches\tloss 0.6912 (0.6920)\taccu 62.500 (52.617)\n",
      "Epoch-343 100 batches\tloss 0.6993 (0.6920)\taccu 48.438 (52.922)\n",
      "Epoch-343 120 batches\tloss 0.6829 (0.6918)\taccu 60.938 (52.969)\n",
      "Epoch-343 140 batches\tloss 0.6963 (0.6920)\taccu 50.000 (52.913)\n",
      "Epoch-343 43.8s\tTrain: loss 0.6918\taccu 53.0449\tValid: loss 0.6938\taccu 50.1803\n",
      "Epoch 343: val_acc did not improve\n",
      "343 1.0000000000000002e-06\n",
      "Epoch-344  20 batches\tloss 0.7022 (0.6923)\taccu 43.750 (52.578)\n",
      "Epoch-344  40 batches\tloss 0.6915 (0.6910)\taccu 56.250 (53.477)\n",
      "Epoch-344  60 batches\tloss 0.6914 (0.6914)\taccu 53.125 (53.281)\n",
      "Epoch-344  80 batches\tloss 0.6962 (0.6918)\taccu 43.750 (52.598)\n",
      "Epoch-344 100 batches\tloss 0.6859 (0.6921)\taccu 59.375 (52.406)\n",
      "Epoch-344 120 batches\tloss 0.6897 (0.6920)\taccu 56.250 (52.409)\n",
      "Epoch-344 140 batches\tloss 0.6990 (0.6921)\taccu 40.625 (52.199)\n",
      "Epoch-344 42.0s\tTrain: loss 0.6919\taccu 52.4339\tValid: loss 0.6937\taccu 50.3806\n",
      "Epoch 344: val_acc did not improve\n",
      "344 1.0000000000000002e-06\n",
      "Epoch-345  20 batches\tloss 0.7011 (0.6919)\taccu 45.312 (51.719)\n",
      "Epoch-345  40 batches\tloss 0.6841 (0.6916)\taccu 54.688 (52.227)\n",
      "Epoch-345  60 batches\tloss 0.6876 (0.6914)\taccu 54.688 (52.760)\n",
      "Epoch-345  80 batches\tloss 0.6884 (0.6915)\taccu 56.250 (52.559)\n",
      "Epoch-345 100 batches\tloss 0.6867 (0.6916)\taccu 59.375 (52.562)\n",
      "Epoch-345 120 batches\tloss 0.6992 (0.6918)\taccu 43.750 (52.292)\n",
      "Epoch-345 140 batches\tloss 0.6851 (0.6916)\taccu 59.375 (52.478)\n",
      "Epoch-345 40.4s\tTrain: loss 0.6917\taccu 52.5040\tValid: loss 0.6937\taccu 50.6911\n",
      "Epoch 345: val_acc did not improve\n",
      "345 1.0000000000000002e-06\n",
      "Epoch-346  20 batches\tloss 0.6936 (0.6908)\taccu 48.438 (52.891)\n",
      "Epoch-346  40 batches\tloss 0.6983 (0.6913)\taccu 46.875 (53.906)\n",
      "Epoch-346  60 batches\tloss 0.6879 (0.6911)\taccu 57.812 (54.141)\n",
      "Epoch-346  80 batches\tloss 0.6856 (0.6912)\taccu 60.938 (53.691)\n",
      "Epoch-346 100 batches\tloss 0.6887 (0.6917)\taccu 53.125 (52.953)\n",
      "Epoch-346 120 batches\tloss 0.6924 (0.6919)\taccu 54.688 (52.852)\n",
      "Epoch-346 140 batches\tloss 0.6916 (0.6919)\taccu 57.812 (52.623)\n",
      "Epoch-346 39.1s\tTrain: loss 0.6919\taccu 52.5441\tValid: loss 0.6938\taccu 50.2905\n",
      "Epoch 346: val_acc did not improve\n",
      "346 1.0000000000000002e-06\n",
      "Epoch-347  20 batches\tloss 0.6871 (0.6909)\taccu 60.938 (53.984)\n",
      "Epoch-347  40 batches\tloss 0.6970 (0.6916)\taccu 45.312 (53.125)\n",
      "Epoch-347  60 batches\tloss 0.6956 (0.6915)\taccu 51.562 (53.438)\n",
      "Epoch-347  80 batches\tloss 0.6934 (0.6919)\taccu 50.000 (52.871)\n",
      "Epoch-347 100 batches\tloss 0.6946 (0.6918)\taccu 50.000 (52.797)\n",
      "Epoch-347 120 batches\tloss 0.6924 (0.6919)\taccu 57.812 (52.604)\n",
      "Epoch-347 140 batches\tloss 0.6922 (0.6920)\taccu 53.125 (52.422)\n",
      "Epoch-347 38.6s\tTrain: loss 0.6920\taccu 52.3337\tValid: loss 0.6938\taccu 50.4107\n",
      "Epoch 347: val_acc did not improve\n",
      "347 1.0000000000000002e-06\n",
      "Epoch-348  20 batches\tloss 0.6953 (0.6912)\taccu 48.438 (52.812)\n",
      "Epoch-348  40 batches\tloss 0.7014 (0.6922)\taccu 48.438 (52.148)\n",
      "Epoch-348  60 batches\tloss 0.6876 (0.6920)\taccu 56.250 (52.760)\n",
      "Epoch-348  80 batches\tloss 0.6940 (0.6923)\taccu 54.688 (52.344)\n",
      "Epoch-348 100 batches\tloss 0.7009 (0.6921)\taccu 42.188 (52.469)\n",
      "Epoch-348 120 batches\tloss 0.6947 (0.6919)\taccu 53.125 (52.708)\n",
      "Epoch-348 140 batches\tloss 0.6970 (0.6918)\taccu 46.875 (52.969)\n",
      "Epoch-348 38.5s\tTrain: loss 0.6919\taccu 53.0048\tValid: loss 0.6937\taccu 50.4006\n",
      "Epoch 348: val_acc did not improve\n",
      "348 1.0000000000000002e-06\n",
      "Epoch-349  20 batches\tloss 0.6880 (0.6927)\taccu 54.688 (51.328)\n",
      "Epoch-349  40 batches\tloss 0.6884 (0.6924)\taccu 59.375 (52.344)\n",
      "Epoch-349  60 batches\tloss 0.6932 (0.6923)\taccu 50.000 (52.188)\n",
      "Epoch-349  80 batches\tloss 0.6881 (0.6915)\taccu 59.375 (53.027)\n",
      "Epoch-349 100 batches\tloss 0.6932 (0.6913)\taccu 53.125 (53.328)\n",
      "Epoch-349 120 batches\tloss 0.6996 (0.6915)\taccu 45.312 (53.164)\n",
      "Epoch-349 140 batches\tloss 0.6932 (0.6915)\taccu 45.312 (53.181)\n",
      "Epoch-349 38.9s\tTrain: loss 0.6916\taccu 53.0849\tValid: loss 0.6937\taccu 49.9800\n",
      "Epoch 349: val_acc did not improve\n",
      "349 1.0000000000000002e-06\n",
      "Epoch-350  20 batches\tloss 0.6914 (0.6926)\taccu 51.562 (50.234)\n",
      "Epoch-350  40 batches\tloss 0.6877 (0.6927)\taccu 59.375 (51.055)\n",
      "Epoch-350  60 batches\tloss 0.6858 (0.6922)\taccu 60.938 (51.458)\n",
      "Epoch-350  80 batches\tloss 0.6964 (0.6924)\taccu 45.312 (51.348)\n",
      "Epoch-350 100 batches\tloss 0.6860 (0.6922)\taccu 65.625 (51.781)\n",
      "Epoch-350 120 batches\tloss 0.6912 (0.6920)\taccu 54.688 (51.862)\n",
      "Epoch-350 140 batches\tloss 0.6935 (0.6921)\taccu 57.812 (52.188)\n",
      "Epoch-350 40.9s\tTrain: loss 0.6919\taccu 52.4339\tValid: loss 0.6939\taccu 50.2003\n",
      "Epoch 350: val_acc did not improve\n",
      "350 1.0000000000000002e-06\n",
      "Epoch-351  20 batches\tloss 0.6941 (0.6929)\taccu 50.000 (51.641)\n",
      "Epoch-351  40 batches\tloss 0.6984 (0.6930)\taccu 46.875 (50.469)\n",
      "Epoch-351  60 batches\tloss 0.6910 (0.6925)\taccu 53.125 (51.641)\n",
      "Epoch-351  80 batches\tloss 0.6927 (0.6920)\taccu 46.875 (52.246)\n",
      "Epoch-351 100 batches\tloss 0.6851 (0.6919)\taccu 56.250 (52.422)\n",
      "Epoch-351 120 batches\tloss 0.6880 (0.6919)\taccu 59.375 (52.396)\n",
      "Epoch-351 140 batches\tloss 0.6969 (0.6919)\taccu 46.875 (52.522)\n",
      "Epoch-351 40.1s\tTrain: loss 0.6919\taccu 52.7043\tValid: loss 0.6938\taccu 49.9199\n",
      "Epoch 351: val_acc did not improve\n",
      "351 1.0000000000000002e-06\n",
      "Epoch-352  20 batches\tloss 0.6819 (0.6912)\taccu 64.062 (55.078)\n",
      "Epoch-352  40 batches\tloss 0.6888 (0.6920)\taccu 62.500 (53.516)\n",
      "Epoch-352  60 batches\tloss 0.6876 (0.6921)\taccu 60.938 (53.073)\n",
      "Epoch-352  80 batches\tloss 0.6903 (0.6924)\taccu 50.000 (52.637)\n",
      "Epoch-352 100 batches\tloss 0.6887 (0.6923)\taccu 59.375 (52.734)\n",
      "Epoch-352 120 batches\tloss 0.6891 (0.6923)\taccu 59.375 (52.539)\n",
      "Epoch-352 140 batches\tloss 0.6984 (0.6921)\taccu 43.750 (52.545)\n",
      "Epoch-352 38.5s\tTrain: loss 0.6920\taccu 52.4940\tValid: loss 0.6938\taccu 50.4107\n",
      "Epoch 352: val_acc did not improve\n",
      "352 1.0000000000000002e-06\n",
      "Epoch-353  20 batches\tloss 0.6976 (0.6920)\taccu 43.750 (53.672)\n",
      "Epoch-353  40 batches\tloss 0.6963 (0.6914)\taccu 43.750 (53.672)\n",
      "Epoch-353  60 batches\tloss 0.6875 (0.6913)\taccu 54.688 (53.464)\n",
      "Epoch-353  80 batches\tloss 0.6953 (0.6915)\taccu 46.875 (53.301)\n",
      "Epoch-353 100 batches\tloss 0.6888 (0.6919)\taccu 46.875 (52.891)\n",
      "Epoch-353 120 batches\tloss 0.6934 (0.6922)\taccu 50.000 (52.461)\n",
      "Epoch-353 140 batches\tloss 0.6894 (0.6920)\taccu 56.250 (52.612)\n",
      "Epoch-353 38.7s\tTrain: loss 0.6921\taccu 52.5140\tValid: loss 0.6937\taccu 50.4808\n",
      "Epoch 353: val_acc did not improve\n",
      "353 1.0000000000000002e-06\n",
      "Epoch-354  20 batches\tloss 0.6957 (0.6906)\taccu 56.250 (54.219)\n",
      "Epoch-354  40 batches\tloss 0.6928 (0.6911)\taccu 60.938 (54.492)\n",
      "Epoch-354  60 batches\tloss 0.6962 (0.6916)\taccu 51.562 (53.724)\n",
      "Epoch-354  80 batches\tloss 0.6918 (0.6922)\taccu 51.562 (52.734)\n",
      "Epoch-354 100 batches\tloss 0.6942 (0.6920)\taccu 56.250 (52.906)\n",
      "Epoch-354 120 batches\tloss 0.6955 (0.6923)\taccu 50.000 (52.318)\n",
      "Epoch-354 140 batches\tloss 0.6939 (0.6920)\taccu 46.875 (52.567)\n",
      "Epoch-354 38.7s\tTrain: loss 0.6920\taccu 52.6442\tValid: loss 0.6938\taccu 50.4607\n",
      "Epoch 354: val_acc did not improve\n",
      "354 1.0000000000000002e-06\n",
      "Epoch-355  20 batches\tloss 0.6954 (0.6931)\taccu 46.875 (51.641)\n",
      "Epoch-355  40 batches\tloss 0.6912 (0.6934)\taccu 57.812 (51.523)\n",
      "Epoch-355  60 batches\tloss 0.6971 (0.6922)\taccu 42.188 (52.865)\n",
      "Epoch-355  80 batches\tloss 0.6797 (0.6921)\taccu 65.625 (52.988)\n",
      "Epoch-355 100 batches\tloss 0.6920 (0.6922)\taccu 59.375 (52.734)\n",
      "Epoch-355 120 batches\tloss 0.6932 (0.6924)\taccu 53.125 (52.331)\n",
      "Epoch-355 140 batches\tloss 0.6944 (0.6920)\taccu 56.250 (52.757)\n",
      "Epoch-355 38.6s\tTrain: loss 0.6919\taccu 52.9046\tValid: loss 0.6937\taccu 50.4006\n",
      "Epoch 355: val_acc did not improve\n",
      "355 1.0000000000000002e-06\n",
      "Epoch-356  20 batches\tloss 0.6945 (0.6926)\taccu 45.312 (51.406)\n",
      "Epoch-356  40 batches\tloss 0.6848 (0.6920)\taccu 64.062 (52.188)\n",
      "Epoch-356  60 batches\tloss 0.6899 (0.6917)\taccu 59.375 (52.474)\n",
      "Epoch-356  80 batches\tloss 0.6872 (0.6916)\taccu 59.375 (52.559)\n",
      "Epoch-356 100 batches\tloss 0.6903 (0.6917)\taccu 54.688 (52.656)\n",
      "Epoch-356 120 batches\tloss 0.6880 (0.6917)\taccu 56.250 (52.643)\n",
      "Epoch-356 140 batches\tloss 0.6905 (0.6919)\taccu 56.250 (52.400)\n",
      "Epoch-356 39.0s\tTrain: loss 0.6917\taccu 52.6142\tValid: loss 0.6937\taccu 50.4107\n",
      "Epoch 356: val_acc did not improve\n",
      "356 1.0000000000000002e-06\n",
      "Epoch-357  20 batches\tloss 0.6852 (0.6909)\taccu 62.500 (53.125)\n",
      "Epoch-357  40 batches\tloss 0.6925 (0.6912)\taccu 51.562 (53.008)\n",
      "Epoch-357  60 batches\tloss 0.6979 (0.6917)\taccu 46.875 (52.786)\n",
      "Epoch-357  80 batches\tloss 0.7014 (0.6917)\taccu 39.062 (52.578)\n",
      "Epoch-357 100 batches\tloss 0.6885 (0.6921)\taccu 56.250 (52.344)\n",
      "Epoch-357 120 batches\tloss 0.6989 (0.6919)\taccu 46.875 (52.734)\n",
      "Epoch-357 140 batches\tloss 0.6934 (0.6917)\taccu 43.750 (53.002)\n",
      "Epoch-357 38.5s\tTrain: loss 0.6917\taccu 53.1651\tValid: loss 0.6938\taccu 50.4207\n",
      "Epoch 357: val_acc did not improve\n",
      "357 1.0000000000000002e-06\n",
      "Epoch-358  20 batches\tloss 0.6947 (0.6905)\taccu 54.688 (53.594)\n",
      "Epoch-358  40 batches\tloss 0.6893 (0.6914)\taccu 57.812 (52.695)\n",
      "Epoch-358  60 batches\tloss 0.6942 (0.6915)\taccu 51.562 (52.708)\n",
      "Epoch-358  80 batches\tloss 0.6933 (0.6915)\taccu 56.250 (52.871)\n",
      "Epoch-358 100 batches\tloss 0.6964 (0.6913)\taccu 46.875 (53.125)\n",
      "Epoch-358 120 batches\tloss 0.6850 (0.6914)\taccu 62.500 (53.086)\n",
      "Epoch-358 140 batches\tloss 0.6967 (0.6915)\taccu 53.125 (52.946)\n",
      "Epoch-358 39.0s\tTrain: loss 0.6918\taccu 52.7244\tValid: loss 0.6937\taccu 50.4607\n",
      "Epoch 358: val_acc did not improve\n",
      "358 1.0000000000000002e-06\n",
      "Epoch-359  20 batches\tloss 0.7001 (0.6909)\taccu 46.875 (54.453)\n",
      "Epoch-359  40 batches\tloss 0.6923 (0.6909)\taccu 56.250 (53.984)\n",
      "Epoch-359  60 batches\tloss 0.6906 (0.6915)\taccu 50.000 (53.203)\n",
      "Epoch-359  80 batches\tloss 0.6909 (0.6914)\taccu 54.688 (53.535)\n",
      "Epoch-359 100 batches\tloss 0.6967 (0.6916)\taccu 46.875 (53.344)\n",
      "Epoch-359 120 batches\tloss 0.6924 (0.6915)\taccu 57.812 (53.372)\n",
      "Epoch-359 140 batches\tloss 0.6915 (0.6916)\taccu 43.750 (53.058)\n",
      "Epoch-359 38.5s\tTrain: loss 0.6917\taccu 52.8946\tValid: loss 0.6938\taccu 50.4507\n",
      "Epoch 359: val_acc did not improve\n",
      "359 1.0000000000000002e-06\n",
      "Epoch-360  20 batches\tloss 0.6911 (0.6926)\taccu 50.000 (50.938)\n",
      "Epoch-360  40 batches\tloss 0.6859 (0.6915)\taccu 59.375 (52.891)\n",
      "Epoch-360  60 batches\tloss 0.6963 (0.6912)\taccu 51.562 (53.229)\n",
      "Epoch-360  80 batches\tloss 0.6913 (0.6916)\taccu 54.688 (52.773)\n",
      "Epoch-360 100 batches\tloss 0.6922 (0.6915)\taccu 46.875 (53.062)\n",
      "Epoch-360 120 batches\tloss 0.6933 (0.6917)\taccu 54.688 (53.177)\n",
      "Epoch-360 140 batches\tloss 0.6889 (0.6917)\taccu 56.250 (53.170)\n",
      "Epoch-360 38.4s\tTrain: loss 0.6919\taccu 52.7845\tValid: loss 0.6938\taccu 50.2003\n",
      "Epoch 360: val_acc did not improve\n",
      "360 1.0000000000000002e-06\n",
      "Epoch-361  20 batches\tloss 0.6846 (0.6918)\taccu 57.812 (52.109)\n",
      "Epoch-361  40 batches\tloss 0.6953 (0.6918)\taccu 51.562 (53.164)\n",
      "Epoch-361  60 batches\tloss 0.6864 (0.6915)\taccu 59.375 (53.177)\n",
      "Epoch-361  80 batches\tloss 0.6891 (0.6916)\taccu 59.375 (52.930)\n",
      "Epoch-361 100 batches\tloss 0.6940 (0.6920)\taccu 51.562 (52.453)\n",
      "Epoch-361 120 batches\tloss 0.6867 (0.6921)\taccu 53.125 (51.979)\n",
      "Epoch-361 140 batches\tloss 0.6911 (0.6921)\taccu 59.375 (52.042)\n",
      "Epoch-361 38.6s\tTrain: loss 0.6921\taccu 52.1434\tValid: loss 0.6937\taccu 50.2204\n",
      "Epoch 361: val_acc did not improve\n",
      "361 1.0000000000000002e-06\n",
      "Epoch-362  20 batches\tloss 0.6879 (0.6920)\taccu 59.375 (53.359)\n",
      "Epoch-362  40 batches\tloss 0.6834 (0.6914)\taccu 59.375 (53.398)\n",
      "Epoch-362  60 batches\tloss 0.6965 (0.6914)\taccu 46.875 (53.490)\n",
      "Epoch-362  80 batches\tloss 0.6962 (0.6914)\taccu 45.312 (53.262)\n",
      "Epoch-362 100 batches\tloss 0.6938 (0.6916)\taccu 43.750 (52.750)\n",
      "Epoch-362 120 batches\tloss 0.6883 (0.6916)\taccu 54.688 (52.956)\n",
      "Epoch-362 140 batches\tloss 0.6919 (0.6918)\taccu 53.125 (52.723)\n",
      "Epoch-362 38.5s\tTrain: loss 0.6921\taccu 52.6442\tValid: loss 0.6937\taccu 50.3205\n",
      "Epoch 362: val_acc did not improve\n",
      "362 1.0000000000000002e-06\n",
      "Epoch-363  20 batches\tloss 0.6835 (0.6910)\taccu 60.938 (52.734)\n",
      "Epoch-363  40 batches\tloss 0.6902 (0.6911)\taccu 56.250 (53.398)\n",
      "Epoch-363  60 batches\tloss 0.6878 (0.6909)\taccu 53.125 (53.516)\n",
      "Epoch-363  80 batches\tloss 0.6916 (0.6914)\taccu 53.125 (52.715)\n",
      "Epoch-363 100 batches\tloss 0.6935 (0.6916)\taccu 45.312 (52.891)\n",
      "Epoch-363 120 batches\tloss 0.6865 (0.6918)\taccu 60.938 (52.813)\n",
      "Epoch-363 140 batches\tloss 0.6919 (0.6919)\taccu 51.562 (52.600)\n",
      "Epoch-363 39.1s\tTrain: loss 0.6919\taccu 52.5441\tValid: loss 0.6937\taccu 50.0801\n",
      "Epoch 363: val_acc did not improve\n",
      "363 1.0000000000000002e-06\n",
      "Epoch-364  20 batches\tloss 0.6884 (0.6919)\taccu 59.375 (52.266)\n",
      "Epoch-364  40 batches\tloss 0.6847 (0.6914)\taccu 62.500 (52.930)\n",
      "Epoch-364  60 batches\tloss 0.6894 (0.6914)\taccu 56.250 (53.542)\n",
      "Epoch-364  80 batches\tloss 0.6992 (0.6917)\taccu 45.312 (53.105)\n",
      "Epoch-364 100 batches\tloss 0.6947 (0.6917)\taccu 46.875 (53.047)\n",
      "Epoch-364 120 batches\tloss 0.6906 (0.6919)\taccu 51.562 (52.943)\n",
      "Epoch-364 140 batches\tloss 0.6914 (0.6918)\taccu 50.000 (53.125)\n",
      "Epoch-364 38.6s\tTrain: loss 0.6916\taccu 53.2752\tValid: loss 0.6937\taccu 50.4006\n",
      "Epoch 364: val_acc did not improve\n",
      "364 1.0000000000000002e-06\n",
      "Epoch-365  20 batches\tloss 0.6923 (0.6920)\taccu 50.000 (50.312)\n",
      "Epoch-365  40 batches\tloss 0.6917 (0.6917)\taccu 50.000 (51.133)\n",
      "Epoch-365  60 batches\tloss 0.6886 (0.6915)\taccu 60.938 (51.510)\n",
      "Epoch-365  80 batches\tloss 0.6990 (0.6916)\taccu 40.625 (51.934)\n",
      "Epoch-365 100 batches\tloss 0.6912 (0.6917)\taccu 57.812 (52.000)\n",
      "Epoch-365 120 batches\tloss 0.6974 (0.6920)\taccu 45.312 (51.953)\n",
      "Epoch-365 140 batches\tloss 0.6958 (0.6918)\taccu 48.438 (52.366)\n",
      "Epoch-365 38.7s\tTrain: loss 0.6917\taccu 52.5441\tValid: loss 0.6936\taccu 50.1903\n",
      "Epoch 365: val_acc did not improve\n",
      "365 1.0000000000000002e-06\n",
      "Epoch-366  20 batches\tloss 0.6874 (0.6918)\taccu 57.812 (55.000)\n",
      "Epoch-366  40 batches\tloss 0.6870 (0.6916)\taccu 51.562 (54.336)\n",
      "Epoch-366  60 batches\tloss 0.6867 (0.6916)\taccu 60.938 (53.802)\n",
      "Epoch-366  80 batches\tloss 0.6906 (0.6919)\taccu 48.438 (53.242)\n",
      "Epoch-366 100 batches\tloss 0.6945 (0.6916)\taccu 56.250 (53.562)\n",
      "Epoch-366 120 batches\tloss 0.6856 (0.6916)\taccu 59.375 (53.776)\n",
      "Epoch-366 140 batches\tloss 0.6890 (0.6918)\taccu 54.688 (53.348)\n",
      "Epoch-366 38.3s\tTrain: loss 0.6917\taccu 53.3554\tValid: loss 0.6937\taccu 50.1102\n",
      "Epoch 366: val_acc did not improve\n",
      "366 1.0000000000000002e-06\n",
      "Epoch-367  20 batches\tloss 0.6795 (0.6911)\taccu 59.375 (53.281)\n",
      "Epoch-367  40 batches\tloss 0.6996 (0.6919)\taccu 48.438 (51.602)\n",
      "Epoch-367  60 batches\tloss 0.6987 (0.6921)\taccu 42.188 (51.641)\n",
      "Epoch-367  80 batches\tloss 0.6946 (0.6923)\taccu 51.562 (51.816)\n",
      "Epoch-367 100 batches\tloss 0.6857 (0.6923)\taccu 60.938 (51.656)\n",
      "Epoch-367 120 batches\tloss 0.6907 (0.6924)\taccu 57.812 (51.771)\n",
      "Epoch-367 140 batches\tloss 0.6971 (0.6922)\taccu 43.750 (52.165)\n",
      "Epoch-367 38.3s\tTrain: loss 0.6920\taccu 52.5942\tValid: loss 0.6938\taccu 50.4407\n",
      "Epoch 367: val_acc did not improve\n",
      "367 1.0000000000000002e-06\n",
      "Epoch-368  20 batches\tloss 0.6883 (0.6916)\taccu 57.812 (52.188)\n",
      "Epoch-368  40 batches\tloss 0.6872 (0.6919)\taccu 57.812 (52.031)\n",
      "Epoch-368  60 batches\tloss 0.6914 (0.6922)\taccu 51.562 (52.214)\n",
      "Epoch-368  80 batches\tloss 0.6955 (0.6925)\taccu 50.000 (52.031)\n",
      "Epoch-368 100 batches\tloss 0.6936 (0.6924)\taccu 45.312 (51.906)\n",
      "Epoch-368 120 batches\tloss 0.6885 (0.6922)\taccu 60.938 (52.253)\n",
      "Epoch-368 140 batches\tloss 0.6867 (0.6919)\taccu 57.812 (52.467)\n",
      "Epoch-368 38.3s\tTrain: loss 0.6920\taccu 52.4038\tValid: loss 0.6937\taccu 50.6711\n",
      "Epoch 368: val_acc did not improve\n",
      "368 1.0000000000000002e-06\n",
      "Epoch-369  20 batches\tloss 0.7010 (0.6929)\taccu 42.188 (50.938)\n",
      "Epoch-369  40 batches\tloss 0.6895 (0.6922)\taccu 56.250 (52.070)\n",
      "Epoch-369  60 batches\tloss 0.6983 (0.6919)\taccu 43.750 (52.240)\n",
      "Epoch-369  80 batches\tloss 0.6917 (0.6918)\taccu 54.688 (52.637)\n",
      "Epoch-369 100 batches\tloss 0.6935 (0.6915)\taccu 56.250 (53.094)\n",
      "Epoch-369 120 batches\tloss 0.6949 (0.6914)\taccu 51.562 (53.216)\n",
      "Epoch-369 140 batches\tloss 0.6906 (0.6914)\taccu 57.812 (53.415)\n",
      "Epoch-369 38.5s\tTrain: loss 0.6913\taccu 53.2552\tValid: loss 0.6937\taccu 50.3105\n",
      "Epoch 369: val_acc did not improve\n",
      "369 1.0000000000000002e-06\n",
      "Epoch-370  20 batches\tloss 0.6968 (0.6921)\taccu 51.562 (52.188)\n",
      "Epoch-370  40 batches\tloss 0.6980 (0.6927)\taccu 45.312 (51.836)\n",
      "Epoch-370  60 batches\tloss 0.6885 (0.6920)\taccu 60.938 (52.500)\n",
      "Epoch-370  80 batches\tloss 0.6973 (0.6919)\taccu 42.188 (52.480)\n",
      "Epoch-370 100 batches\tloss 0.6941 (0.6918)\taccu 48.438 (52.766)\n",
      "Epoch-370 120 batches\tloss 0.6907 (0.6916)\taccu 60.938 (53.034)\n",
      "Epoch-370 140 batches\tloss 0.6959 (0.6917)\taccu 45.312 (53.002)\n",
      "Epoch-370 38.4s\tTrain: loss 0.6919\taccu 52.6442\tValid: loss 0.6938\taccu 50.4107\n",
      "Epoch 370: val_acc did not improve\n",
      "370 1.0000000000000002e-06\n",
      "Epoch-371  20 batches\tloss 0.6938 (0.6906)\taccu 57.812 (54.297)\n",
      "Epoch-371  40 batches\tloss 0.6903 (0.6919)\taccu 50.000 (52.812)\n",
      "Epoch-371  60 batches\tloss 0.6883 (0.6922)\taccu 60.938 (52.656)\n",
      "Epoch-371  80 batches\tloss 0.6958 (0.6921)\taccu 37.500 (52.578)\n",
      "Epoch-371 100 batches\tloss 0.6921 (0.6919)\taccu 51.562 (53.062)\n",
      "Epoch-371 120 batches\tloss 0.6847 (0.6919)\taccu 56.250 (52.839)\n",
      "Epoch-371 140 batches\tloss 0.6802 (0.6920)\taccu 67.188 (52.656)\n",
      "Epoch-371 38.5s\tTrain: loss 0.6920\taccu 52.4639\tValid: loss 0.6937\taccu 50.1803\n",
      "Epoch 371: val_acc did not improve\n",
      "371 1.0000000000000002e-06\n",
      "Epoch-372  20 batches\tloss 0.7012 (0.6918)\taccu 39.062 (53.203)\n",
      "Epoch-372  40 batches\tloss 0.6908 (0.6920)\taccu 62.500 (52.773)\n",
      "Epoch-372  60 batches\tloss 0.6906 (0.6921)\taccu 51.562 (52.474)\n",
      "Epoch-372  80 batches\tloss 0.6946 (0.6923)\taccu 53.125 (52.539)\n",
      "Epoch-372 100 batches\tloss 0.6893 (0.6921)\taccu 54.688 (52.891)\n",
      "Epoch-372 120 batches\tloss 0.6951 (0.6920)\taccu 53.125 (53.047)\n",
      "Epoch-372 140 batches\tloss 0.6922 (0.6920)\taccu 46.875 (52.835)\n",
      "Epoch-372 38.6s\tTrain: loss 0.6919\taccu 52.8446\tValid: loss 0.6937\taccu 50.4006\n",
      "Epoch 372: val_acc did not improve\n",
      "372 1.0000000000000002e-06\n",
      "Epoch-373  20 batches\tloss 0.6948 (0.6930)\taccu 42.188 (51.484)\n",
      "Epoch-373  40 batches\tloss 0.6816 (0.6921)\taccu 65.625 (52.461)\n",
      "Epoch-373  60 batches\tloss 0.6866 (0.6916)\taccu 56.250 (53.099)\n",
      "Epoch-373  80 batches\tloss 0.6962 (0.6916)\taccu 51.562 (53.105)\n",
      "Epoch-373 100 batches\tloss 0.6906 (0.6917)\taccu 48.438 (52.688)\n",
      "Epoch-373 120 batches\tloss 0.6914 (0.6920)\taccu 54.688 (52.305)\n",
      "Epoch-373 140 batches\tloss 0.6932 (0.6919)\taccu 46.875 (52.422)\n",
      "Epoch-373 38.7s\tTrain: loss 0.6918\taccu 52.4239\tValid: loss 0.6938\taccu 50.1002\n",
      "Epoch 373: val_acc did not improve\n",
      "373 1.0000000000000002e-06\n",
      "Epoch-374  20 batches\tloss 0.6903 (0.6899)\taccu 54.688 (54.766)\n",
      "Epoch-374  40 batches\tloss 0.6981 (0.6912)\taccu 53.125 (54.375)\n",
      "Epoch-374  60 batches\tloss 0.6926 (0.6915)\taccu 48.438 (53.281)\n",
      "Epoch-374  80 batches\tloss 0.6902 (0.6918)\taccu 53.125 (52.480)\n",
      "Epoch-374 100 batches\tloss 0.6900 (0.6917)\taccu 50.000 (52.578)\n",
      "Epoch-374 120 batches\tloss 0.6935 (0.6919)\taccu 50.000 (52.318)\n",
      "Epoch-374 140 batches\tloss 0.6964 (0.6916)\taccu 54.688 (52.824)\n",
      "Epoch-374 38.8s\tTrain: loss 0.6919\taccu 52.4940\tValid: loss 0.6938\taccu 50.2804\n",
      "Epoch 374: val_acc did not improve\n",
      "374 1.0000000000000002e-06\n",
      "Epoch-375  20 batches\tloss 0.6946 (0.6933)\taccu 51.562 (51.953)\n",
      "Epoch-375  40 batches\tloss 0.6982 (0.6926)\taccu 46.875 (52.383)\n",
      "Epoch-375  60 batches\tloss 0.6931 (0.6924)\taccu 56.250 (52.656)\n",
      "Epoch-375  80 batches\tloss 0.6966 (0.6926)\taccu 43.750 (52.031)\n",
      "Epoch-375 100 batches\tloss 0.6941 (0.6928)\taccu 56.250 (51.734)\n",
      "Epoch-375 120 batches\tloss 0.6871 (0.6924)\taccu 57.812 (52.174)\n",
      "Epoch-375 140 batches\tloss 0.6851 (0.6921)\taccu 59.375 (52.500)\n",
      "Epoch-375 38.7s\tTrain: loss 0.6920\taccu 52.6342\tValid: loss 0.6939\taccu 50.4407\n",
      "Epoch 375: val_acc did not improve\n",
      "375 1.0000000000000002e-06\n",
      "Epoch-376  20 batches\tloss 0.6903 (0.6910)\taccu 56.250 (54.688)\n",
      "Epoch-376  40 batches\tloss 0.6970 (0.6912)\taccu 46.875 (53.555)\n",
      "Epoch-376  60 batches\tloss 0.6929 (0.6916)\taccu 54.688 (53.151)\n",
      "Epoch-376  80 batches\tloss 0.6907 (0.6918)\taccu 51.562 (53.008)\n",
      "Epoch-376 100 batches\tloss 0.6992 (0.6918)\taccu 43.750 (52.938)\n",
      "Epoch-376 120 batches\tloss 0.6913 (0.6922)\taccu 53.125 (52.435)\n",
      "Epoch-376 140 batches\tloss 0.6865 (0.6920)\taccu 60.938 (52.433)\n",
      "Epoch-376 38.6s\tTrain: loss 0.6920\taccu 52.4840\tValid: loss 0.6938\taccu 50.3506\n",
      "Epoch 376: val_acc did not improve\n",
      "376 1.0000000000000002e-06\n",
      "Epoch-377  20 batches\tloss 0.6928 (0.6920)\taccu 50.000 (53.672)\n",
      "Epoch-377  40 batches\tloss 0.6870 (0.6913)\taccu 56.250 (54.180)\n",
      "Epoch-377  60 batches\tloss 0.6868 (0.6919)\taccu 54.688 (53.438)\n",
      "Epoch-377  80 batches\tloss 0.6958 (0.6921)\taccu 45.312 (53.184)\n",
      "Epoch-377 100 batches\tloss 0.6947 (0.6923)\taccu 48.438 (53.016)\n",
      "Epoch-377 120 batches\tloss 0.6893 (0.6921)\taccu 53.125 (52.813)\n",
      "Epoch-377 140 batches\tloss 0.6868 (0.6920)\taccu 56.250 (52.790)\n",
      "Epoch-377 38.5s\tTrain: loss 0.6918\taccu 52.9247\tValid: loss 0.6938\taccu 50.5509\n",
      "Epoch 377: val_acc did not improve\n",
      "377 1.0000000000000002e-06\n",
      "Epoch-378  20 batches\tloss 0.6865 (0.6908)\taccu 57.812 (53.594)\n",
      "Epoch-378  40 batches\tloss 0.6852 (0.6910)\taccu 54.688 (54.258)\n",
      "Epoch-378  60 batches\tloss 0.6981 (0.6912)\taccu 42.188 (54.089)\n",
      "Epoch-378  80 batches\tloss 0.6920 (0.6916)\taccu 48.438 (53.320)\n",
      "Epoch-378 100 batches\tloss 0.6924 (0.6915)\taccu 50.000 (53.328)\n",
      "Epoch-378 120 batches\tloss 0.6851 (0.6916)\taccu 56.250 (53.112)\n",
      "Epoch-378 140 batches\tloss 0.6879 (0.6916)\taccu 57.812 (53.214)\n",
      "Epoch-378 38.7s\tTrain: loss 0.6918\taccu 52.9347\tValid: loss 0.6939\taccu 50.2204\n",
      "Epoch 378: val_acc did not improve\n",
      "378 1.0000000000000002e-06\n",
      "Epoch-379  20 batches\tloss 0.6897 (0.6932)\taccu 54.688 (51.250)\n",
      "Epoch-379  40 batches\tloss 0.6837 (0.6918)\taccu 70.312 (52.969)\n",
      "Epoch-379  60 batches\tloss 0.6907 (0.6914)\taccu 51.562 (53.464)\n",
      "Epoch-379  80 batches\tloss 0.6863 (0.6913)\taccu 60.938 (53.555)\n",
      "Epoch-379 100 batches\tloss 0.6893 (0.6916)\taccu 53.125 (52.891)\n",
      "Epoch-379 120 batches\tloss 0.6950 (0.6918)\taccu 43.750 (52.617)\n",
      "Epoch-379 140 batches\tloss 0.6945 (0.6919)\taccu 53.125 (52.489)\n",
      "Epoch-379 38.5s\tTrain: loss 0.6920\taccu 52.4139\tValid: loss 0.6937\taccu 50.5809\n",
      "Epoch 379: val_acc did not improve\n",
      "379 1.0000000000000002e-06\n",
      "Epoch-380  20 batches\tloss 0.6884 (0.6915)\taccu 54.688 (52.188)\n",
      "Epoch-380  40 batches\tloss 0.6864 (0.6907)\taccu 51.562 (53.672)\n",
      "Epoch-380  60 batches\tloss 0.6940 (0.6915)\taccu 46.875 (52.448)\n",
      "Epoch-380  80 batches\tloss 0.7026 (0.6916)\taccu 37.500 (52.363)\n",
      "Epoch-380 100 batches\tloss 0.6955 (0.6919)\taccu 45.312 (51.938)\n",
      "Epoch-380 120 batches\tloss 0.6869 (0.6919)\taccu 54.688 (51.966)\n",
      "Epoch-380 140 batches\tloss 0.6925 (0.6920)\taccu 46.875 (52.087)\n",
      "Epoch-380 38.5s\tTrain: loss 0.6921\taccu 51.8830\tValid: loss 0.6937\taccu 50.4908\n",
      "Epoch 380: val_acc did not improve\n",
      "380 1.0000000000000002e-06\n",
      "Epoch-381  20 batches\tloss 0.6929 (0.6920)\taccu 54.688 (52.734)\n",
      "Epoch-381  40 batches\tloss 0.6961 (0.6922)\taccu 54.688 (51.953)\n",
      "Epoch-381  60 batches\tloss 0.6914 (0.6915)\taccu 50.000 (52.917)\n",
      "Epoch-381  80 batches\tloss 0.6842 (0.6918)\taccu 64.062 (52.598)\n",
      "Epoch-381 100 batches\tloss 0.6856 (0.6917)\taccu 62.500 (52.750)\n",
      "Epoch-381 120 batches\tloss 0.6922 (0.6917)\taccu 50.000 (52.760)\n",
      "Epoch-381 140 batches\tloss 0.6987 (0.6918)\taccu 42.188 (52.656)\n",
      "Epoch-381 38.5s\tTrain: loss 0.6918\taccu 52.6142\tValid: loss 0.6939\taccu 50.2905\n",
      "Epoch 381: val_acc did not improve\n",
      "381 1.0000000000000002e-06\n",
      "Epoch-382  20 batches\tloss 0.6972 (0.6920)\taccu 50.000 (52.500)\n",
      "Epoch-382  40 batches\tloss 0.6952 (0.6921)\taccu 50.000 (51.641)\n",
      "Epoch-382  60 batches\tloss 0.6943 (0.6922)\taccu 50.000 (51.589)\n",
      "Epoch-382  80 batches\tloss 0.6905 (0.6918)\taccu 54.688 (51.855)\n",
      "Epoch-382 100 batches\tloss 0.6858 (0.6919)\taccu 65.625 (52.047)\n",
      "Epoch-382 120 batches\tloss 0.6997 (0.6920)\taccu 43.750 (52.005)\n",
      "Epoch-382 140 batches\tloss 0.6899 (0.6917)\taccu 57.812 (52.467)\n",
      "Epoch-382 38.9s\tTrain: loss 0.6918\taccu 52.5140\tValid: loss 0.6937\taccu 50.2003\n",
      "Epoch 382: val_acc did not improve\n",
      "382 1.0000000000000002e-06\n",
      "Epoch-383  20 batches\tloss 0.6925 (0.6929)\taccu 57.812 (51.641)\n",
      "Epoch-383  40 batches\tloss 0.6856 (0.6925)\taccu 59.375 (51.875)\n",
      "Epoch-383  60 batches\tloss 0.6956 (0.6920)\taccu 48.438 (52.656)\n",
      "Epoch-383  80 batches\tloss 0.6865 (0.6918)\taccu 65.625 (53.164)\n",
      "Epoch-383 100 batches\tloss 0.6909 (0.6922)\taccu 50.000 (52.734)\n",
      "Epoch-383 120 batches\tloss 0.6913 (0.6921)\taccu 50.000 (52.734)\n",
      "Epoch-383 140 batches\tloss 0.6947 (0.6919)\taccu 51.562 (52.969)\n",
      "Epoch-383 38.6s\tTrain: loss 0.6918\taccu 53.0449\tValid: loss 0.6938\taccu 50.5208\n",
      "Epoch 383: val_acc did not improve\n",
      "383 1.0000000000000002e-06\n",
      "Epoch-384  20 batches\tloss 0.6872 (0.6912)\taccu 59.375 (52.969)\n",
      "Epoch-384  40 batches\tloss 0.6987 (0.6918)\taccu 45.312 (53.125)\n",
      "Epoch-384  60 batches\tloss 0.6947 (0.6919)\taccu 48.438 (53.229)\n",
      "Epoch-384  80 batches\tloss 0.6912 (0.6916)\taccu 54.688 (53.398)\n",
      "Epoch-384 100 batches\tloss 0.6965 (0.6917)\taccu 46.875 (53.484)\n",
      "Epoch-384 120 batches\tloss 0.6926 (0.6919)\taccu 51.562 (53.125)\n",
      "Epoch-384 140 batches\tloss 0.6911 (0.6918)\taccu 54.688 (53.359)\n",
      "Epoch-384 38.5s\tTrain: loss 0.6917\taccu 53.2752\tValid: loss 0.6937\taccu 50.7913\n",
      "Epoch 384: val_acc did not improve\n",
      "384 1.0000000000000002e-06\n",
      "Epoch-385  20 batches\tloss 0.6925 (0.6923)\taccu 50.000 (52.031)\n",
      "Epoch-385  40 batches\tloss 0.6951 (0.6932)\taccu 50.000 (51.133)\n",
      "Epoch-385  60 batches\tloss 0.6906 (0.6930)\taccu 50.000 (51.667)\n",
      "Epoch-385  80 batches\tloss 0.6865 (0.6928)\taccu 62.500 (51.836)\n",
      "Epoch-385 100 batches\tloss 0.6914 (0.6925)\taccu 54.688 (51.984)\n",
      "Epoch-385 120 batches\tloss 0.6900 (0.6924)\taccu 56.250 (52.539)\n",
      "Epoch-385 140 batches\tloss 0.6934 (0.6922)\taccu 56.250 (52.935)\n",
      "Epoch-385 38.4s\tTrain: loss 0.6920\taccu 53.0749\tValid: loss 0.6938\taccu 50.5208\n",
      "Epoch 385: val_acc did not improve\n",
      "385 1.0000000000000002e-06\n",
      "Epoch-386  20 batches\tloss 0.6966 (0.6916)\taccu 46.875 (50.859)\n",
      "Epoch-386  40 batches\tloss 0.6878 (0.6923)\taccu 60.938 (51.562)\n",
      "Epoch-386  60 batches\tloss 0.6885 (0.6921)\taccu 59.375 (52.318)\n",
      "Epoch-386  80 batches\tloss 0.6934 (0.6922)\taccu 51.562 (52.168)\n",
      "Epoch-386 100 batches\tloss 0.6872 (0.6919)\taccu 57.812 (52.625)\n",
      "Epoch-386 120 batches\tloss 0.6950 (0.6922)\taccu 50.000 (52.122)\n",
      "Epoch-386 140 batches\tloss 0.6955 (0.6920)\taccu 48.438 (52.388)\n",
      "Epoch-386 38.7s\tTrain: loss 0.6920\taccu 52.4539\tValid: loss 0.6937\taccu 50.3205\n",
      "Epoch 386: val_acc did not improve\n",
      "386 1.0000000000000002e-06\n",
      "Epoch-387  20 batches\tloss 0.6906 (0.6920)\taccu 53.125 (53.828)\n",
      "Epoch-387  40 batches\tloss 0.6958 (0.6929)\taccu 48.438 (51.953)\n",
      "Epoch-387  60 batches\tloss 0.6851 (0.6925)\taccu 57.812 (52.240)\n",
      "Epoch-387  80 batches\tloss 0.6869 (0.6925)\taccu 54.688 (51.992)\n",
      "Epoch-387 100 batches\tloss 0.6927 (0.6921)\taccu 45.312 (52.406)\n",
      "Epoch-387 120 batches\tloss 0.6921 (0.6920)\taccu 50.000 (52.773)\n",
      "Epoch-387 140 batches\tloss 0.6929 (0.6922)\taccu 54.688 (52.623)\n",
      "Epoch-387 38.2s\tTrain: loss 0.6921\taccu 52.5641\tValid: loss 0.6937\taccu 50.5509\n",
      "Epoch 387: val_acc did not improve\n",
      "387 1.0000000000000002e-06\n",
      "Epoch-388  20 batches\tloss 0.6901 (0.6922)\taccu 57.812 (51.484)\n",
      "Epoch-388  40 batches\tloss 0.6886 (0.6929)\taccu 51.562 (51.484)\n",
      "Epoch-388  60 batches\tloss 0.6953 (0.6923)\taccu 42.188 (51.615)\n",
      "Epoch-388  80 batches\tloss 0.6965 (0.6923)\taccu 48.438 (51.719)\n",
      "Epoch-388 100 batches\tloss 0.6885 (0.6919)\taccu 56.250 (52.312)\n",
      "Epoch-388 120 batches\tloss 0.6968 (0.6920)\taccu 45.312 (52.188)\n",
      "Epoch-388 140 batches\tloss 0.6892 (0.6919)\taccu 56.250 (52.321)\n",
      "Epoch-388 38.3s\tTrain: loss 0.6918\taccu 52.5040\tValid: loss 0.6938\taccu 50.6611\n",
      "Epoch 388: val_acc did not improve\n",
      "388 1.0000000000000002e-06\n",
      "Epoch-389  20 batches\tloss 0.6895 (0.6910)\taccu 53.125 (53.828)\n",
      "Epoch-389  40 batches\tloss 0.6954 (0.6920)\taccu 51.562 (52.891)\n",
      "Epoch-389  60 batches\tloss 0.6845 (0.6913)\taccu 67.188 (53.594)\n",
      "Epoch-389  80 batches\tloss 0.6962 (0.6917)\taccu 46.875 (53.223)\n",
      "Epoch-389 100 batches\tloss 0.6964 (0.6919)\taccu 43.750 (53.047)\n",
      "Epoch-389 120 batches\tloss 0.7010 (0.6918)\taccu 37.500 (53.021)\n",
      "Epoch-389 140 batches\tloss 0.6842 (0.6920)\taccu 64.062 (52.723)\n",
      "Epoch-389 38.3s\tTrain: loss 0.6920\taccu 52.6943\tValid: loss 0.6938\taccu 50.4307\n",
      "Epoch 389: val_acc did not improve\n",
      "389 1.0000000000000002e-06\n",
      "Epoch-390  20 batches\tloss 0.6928 (0.6921)\taccu 54.688 (52.812)\n",
      "Epoch-390  40 batches\tloss 0.6970 (0.6928)\taccu 45.312 (51.836)\n",
      "Epoch-390  60 batches\tloss 0.6874 (0.6924)\taccu 57.812 (52.448)\n",
      "Epoch-390  80 batches\tloss 0.6883 (0.6921)\taccu 53.125 (52.500)\n",
      "Epoch-390 100 batches\tloss 0.6943 (0.6920)\taccu 46.875 (52.484)\n",
      "Epoch-390 120 batches\tloss 0.6911 (0.6922)\taccu 53.125 (52.370)\n",
      "Epoch-390 140 batches\tloss 0.6963 (0.6921)\taccu 46.875 (52.310)\n",
      "Epoch-390 38.5s\tTrain: loss 0.6919\taccu 52.6142\tValid: loss 0.6937\taccu 50.2504\n",
      "Epoch 390: val_acc did not improve\n",
      "390 1.0000000000000002e-06\n",
      "Epoch-391  20 batches\tloss 0.6896 (0.6904)\taccu 56.250 (54.844)\n",
      "Epoch-391  40 batches\tloss 0.6961 (0.6913)\taccu 48.438 (53.633)\n",
      "Epoch-391  60 batches\tloss 0.6887 (0.6914)\taccu 57.812 (53.646)\n",
      "Epoch-391  80 batches\tloss 0.6956 (0.6919)\taccu 50.000 (52.656)\n",
      "Epoch-391 100 batches\tloss 0.6914 (0.6919)\taccu 51.562 (52.578)\n",
      "Epoch-391 120 batches\tloss 0.6894 (0.6918)\taccu 56.250 (52.773)\n",
      "Epoch-391 140 batches\tloss 0.6912 (0.6919)\taccu 50.000 (52.790)\n",
      "Epoch-391 38.3s\tTrain: loss 0.6920\taccu 52.6342\tValid: loss 0.6937\taccu 50.4307\n",
      "Epoch 391: val_acc did not improve\n",
      "391 1.0000000000000002e-06\n",
      "Epoch-392  20 batches\tloss 0.7007 (0.6923)\taccu 39.062 (50.391)\n",
      "Epoch-392  40 batches\tloss 0.6896 (0.6914)\taccu 48.438 (51.797)\n",
      "Epoch-392  60 batches\tloss 0.6994 (0.6914)\taccu 45.312 (52.344)\n",
      "Epoch-392  80 batches\tloss 0.6887 (0.6916)\taccu 54.688 (52.402)\n",
      "Epoch-392 100 batches\tloss 0.6871 (0.6916)\taccu 57.812 (52.781)\n",
      "Epoch-392 120 batches\tloss 0.6955 (0.6918)\taccu 56.250 (52.695)\n",
      "Epoch-392 140 batches\tloss 0.6976 (0.6920)\taccu 53.125 (52.578)\n",
      "Epoch-392 38.3s\tTrain: loss 0.6919\taccu 52.5140\tValid: loss 0.6938\taccu 49.9900\n",
      "Epoch 392: val_acc did not improve\n",
      "392 1.0000000000000002e-06\n",
      "Epoch-393  20 batches\tloss 0.6942 (0.6931)\taccu 51.562 (51.406)\n",
      "Epoch-393  40 batches\tloss 0.6877 (0.6919)\taccu 60.938 (52.891)\n",
      "Epoch-393  60 batches\tloss 0.6882 (0.6915)\taccu 59.375 (53.411)\n",
      "Epoch-393  80 batches\tloss 0.6927 (0.6918)\taccu 53.125 (52.910)\n",
      "Epoch-393 100 batches\tloss 0.6976 (0.6920)\taccu 46.875 (52.562)\n",
      "Epoch-393 120 batches\tloss 0.6857 (0.6921)\taccu 56.250 (52.591)\n",
      "Epoch-393 140 batches\tloss 0.6945 (0.6921)\taccu 48.438 (52.310)\n",
      "Epoch-393 38.4s\tTrain: loss 0.6920\taccu 52.5841\tValid: loss 0.6938\taccu 50.2504\n",
      "Epoch 393: val_acc did not improve\n",
      "393 1.0000000000000002e-06\n",
      "Epoch-394  20 batches\tloss 0.6851 (0.6910)\taccu 57.812 (53.672)\n",
      "Epoch-394  40 batches\tloss 0.6906 (0.6905)\taccu 56.250 (53.672)\n",
      "Epoch-394  60 batches\tloss 0.7026 (0.6911)\taccu 39.062 (53.203)\n",
      "Epoch-394  80 batches\tloss 0.6911 (0.6911)\taccu 53.125 (53.379)\n",
      "Epoch-394 100 batches\tloss 0.6913 (0.6912)\taccu 56.250 (53.453)\n",
      "Epoch-394 120 batches\tloss 0.6877 (0.6915)\taccu 51.562 (52.904)\n",
      "Epoch-394 140 batches\tloss 0.6876 (0.6918)\taccu 56.250 (52.667)\n",
      "Epoch-394 38.5s\tTrain: loss 0.6918\taccu 52.6643\tValid: loss 0.6938\taccu 49.8898\n",
      "Epoch 394: val_acc did not improve\n",
      "394 1.0000000000000002e-06\n",
      "Epoch-395  20 batches\tloss 0.6936 (0.6924)\taccu 53.125 (52.656)\n",
      "Epoch-395  40 batches\tloss 0.6845 (0.6916)\taccu 57.812 (54.023)\n",
      "Epoch-395  60 batches\tloss 0.6914 (0.6915)\taccu 45.312 (53.307)\n",
      "Epoch-395  80 batches\tloss 0.6955 (0.6919)\taccu 45.312 (53.066)\n",
      "Epoch-395 100 batches\tloss 0.6966 (0.6919)\taccu 53.125 (52.984)\n",
      "Epoch-395 120 batches\tloss 0.6900 (0.6920)\taccu 59.375 (52.917)\n",
      "Epoch-395 140 batches\tloss 0.6927 (0.6921)\taccu 53.125 (52.801)\n",
      "Epoch-395 38.4s\tTrain: loss 0.6920\taccu 52.8746\tValid: loss 0.6937\taccu 50.3205\n",
      "Epoch 395: val_acc did not improve\n",
      "395 1.0000000000000002e-06\n",
      "Epoch-396  20 batches\tloss 0.6947 (0.6924)\taccu 53.125 (51.484)\n",
      "Epoch-396  40 batches\tloss 0.6935 (0.6922)\taccu 51.562 (51.719)\n",
      "Epoch-396  60 batches\tloss 0.6960 (0.6919)\taccu 43.750 (51.953)\n",
      "Epoch-396  80 batches\tloss 0.6964 (0.6919)\taccu 50.000 (52.383)\n",
      "Epoch-396 100 batches\tloss 0.6930 (0.6917)\taccu 54.688 (52.922)\n",
      "Epoch-396 120 batches\tloss 0.6814 (0.6915)\taccu 70.312 (53.451)\n",
      "Epoch-396 140 batches\tloss 0.6969 (0.6917)\taccu 46.875 (53.192)\n",
      "Epoch-396 38.7s\tTrain: loss 0.6919\taccu 52.7945\tValid: loss 0.6939\taccu 49.8598\n",
      "Epoch 396: val_acc did not improve\n",
      "396 1.0000000000000002e-06\n",
      "Epoch-397  20 batches\tloss 0.6924 (0.6913)\taccu 53.125 (53.594)\n",
      "Epoch-397  40 batches\tloss 0.6854 (0.6910)\taccu 59.375 (53.867)\n",
      "Epoch-397  60 batches\tloss 0.6914 (0.6912)\taccu 56.250 (53.828)\n",
      "Epoch-397  80 batches\tloss 0.6798 (0.6913)\taccu 71.875 (53.555)\n",
      "Epoch-397 100 batches\tloss 0.6907 (0.6911)\taccu 51.562 (54.062)\n",
      "Epoch-397 120 batches\tloss 0.6901 (0.6915)\taccu 54.688 (53.581)\n",
      "Epoch-397 140 batches\tloss 0.6957 (0.6917)\taccu 48.438 (53.214)\n",
      "Epoch-397 40.1s\tTrain: loss 0.6917\taccu 53.2051\tValid: loss 0.6939\taccu 50.2905\n",
      "Epoch 397: val_acc did not improve\n",
      "397 1.0000000000000002e-06\n",
      "Epoch-398  20 batches\tloss 0.6817 (0.6915)\taccu 62.500 (54.531)\n",
      "Epoch-398  40 batches\tloss 0.7030 (0.6924)\taccu 48.438 (52.891)\n",
      "Epoch-398  60 batches\tloss 0.6860 (0.6921)\taccu 67.188 (52.604)\n",
      "Epoch-398  80 batches\tloss 0.6872 (0.6922)\taccu 60.938 (52.305)\n",
      "Epoch-398 100 batches\tloss 0.6867 (0.6922)\taccu 57.812 (52.312)\n",
      "Epoch-398 120 batches\tloss 0.6842 (0.6922)\taccu 53.125 (52.461)\n",
      "Epoch-398 140 batches\tloss 0.6831 (0.6918)\taccu 64.062 (52.645)\n",
      "Epoch-398 39.9s\tTrain: loss 0.6920\taccu 52.6843\tValid: loss 0.6939\taccu 50.1102\n",
      "Epoch 398: val_acc did not improve\n",
      "398 1.0000000000000002e-06\n",
      "Epoch-399  20 batches\tloss 0.6902 (0.6911)\taccu 64.062 (55.469)\n",
      "Epoch-399  40 batches\tloss 0.6974 (0.6921)\taccu 45.312 (53.359)\n",
      "Epoch-399  60 batches\tloss 0.6883 (0.6917)\taccu 57.812 (53.203)\n",
      "Epoch-399  80 batches\tloss 0.6853 (0.6914)\taccu 59.375 (53.105)\n",
      "Epoch-399 100 batches\tloss 0.6911 (0.6919)\taccu 51.562 (52.422)\n",
      "Epoch-399 120 batches\tloss 0.6874 (0.6918)\taccu 62.500 (52.721)\n",
      "Epoch-399 140 batches\tloss 0.6905 (0.6916)\taccu 51.562 (53.002)\n",
      "Epoch-399 38.4s\tTrain: loss 0.6918\taccu 52.8245\tValid: loss 0.6937\taccu 50.3105\n",
      "Epoch 399: val_acc did not improve\n",
      "399 1.0000000000000002e-06\n",
      "Epoch-400  20 batches\tloss 0.6916 (0.6912)\taccu 48.438 (52.812)\n",
      "Epoch-400  40 batches\tloss 0.6855 (0.6920)\taccu 60.938 (52.461)\n",
      "Epoch-400  60 batches\tloss 0.6938 (0.6923)\taccu 46.875 (51.797)\n",
      "Epoch-400  80 batches\tloss 0.6967 (0.6925)\taccu 50.000 (51.816)\n",
      "Epoch-400 100 batches\tloss 0.6889 (0.6922)\taccu 50.000 (52.297)\n",
      "Epoch-400 120 batches\tloss 0.6957 (0.6919)\taccu 53.125 (52.344)\n",
      "Epoch-400 140 batches\tloss 0.6928 (0.6921)\taccu 56.250 (52.188)\n",
      "Epoch-400 38.5s\tTrain: loss 0.6920\taccu 52.3738\tValid: loss 0.6938\taccu 50.2304\n",
      "Epoch 400: val_acc did not improve\n",
      "400 1.0000000000000002e-06\n",
      "Epoch-401  20 batches\tloss 0.6951 (0.6920)\taccu 40.625 (52.422)\n",
      "Epoch-401  40 batches\tloss 0.6854 (0.6915)\taccu 59.375 (53.125)\n",
      "Epoch-401  60 batches\tloss 0.6906 (0.6915)\taccu 56.250 (53.099)\n",
      "Epoch-401  80 batches\tloss 0.6921 (0.6924)\taccu 57.812 (52.363)\n",
      "Epoch-401 100 batches\tloss 0.6859 (0.6922)\taccu 57.812 (52.562)\n",
      "Epoch-401 120 batches\tloss 0.6961 (0.6920)\taccu 50.000 (52.708)\n",
      "Epoch-401 140 batches\tloss 0.6822 (0.6919)\taccu 64.062 (52.846)\n",
      "Epoch-401 38.6s\tTrain: loss 0.6918\taccu 53.2051\tValid: loss 0.6939\taccu 50.0601\n",
      "Epoch 401: val_acc did not improve\n",
      "401 1.0000000000000002e-06\n",
      "Epoch-402  20 batches\tloss 0.6933 (0.6916)\taccu 50.000 (52.656)\n",
      "Epoch-402  40 batches\tloss 0.6996 (0.6921)\taccu 43.750 (51.484)\n",
      "Epoch-402  60 batches\tloss 0.7038 (0.6920)\taccu 42.188 (51.927)\n",
      "Epoch-402  80 batches\tloss 0.6895 (0.6917)\taccu 56.250 (52.559)\n",
      "Epoch-402 100 batches\tloss 0.6936 (0.6916)\taccu 51.562 (52.594)\n",
      "Epoch-402 120 batches\tloss 0.6898 (0.6919)\taccu 57.812 (52.721)\n",
      "Epoch-402 140 batches\tloss 0.6966 (0.6921)\taccu 46.875 (52.444)\n",
      "Epoch-402 38.9s\tTrain: loss 0.6919\taccu 52.5541\tValid: loss 0.6937\taccu 50.3906\n",
      "Epoch 402: val_acc did not improve\n",
      "402 1.0000000000000002e-06\n",
      "Epoch-403  20 batches\tloss 0.6845 (0.6907)\taccu 57.812 (54.922)\n",
      "Epoch-403  40 batches\tloss 0.6935 (0.6909)\taccu 46.875 (54.609)\n",
      "Epoch-403  60 batches\tloss 0.6925 (0.6911)\taccu 59.375 (54.635)\n",
      "Epoch-403  80 batches\tloss 0.6882 (0.6911)\taccu 57.812 (53.965)\n",
      "Epoch-403 100 batches\tloss 0.6876 (0.6911)\taccu 57.812 (53.953)\n",
      "Epoch-403 120 batches\tloss 0.6867 (0.6914)\taccu 59.375 (53.568)\n",
      "Epoch-403 140 batches\tloss 0.6920 (0.6917)\taccu 51.562 (53.359)\n",
      "Epoch-403 38.8s\tTrain: loss 0.6917\taccu 53.2752\tValid: loss 0.6938\taccu 50.0801\n",
      "Epoch 403: val_acc did not improve\n",
      "403 1.0000000000000002e-06\n",
      "Epoch-404  20 batches\tloss 0.6877 (0.6917)\taccu 56.250 (53.281)\n",
      "Epoch-404  40 batches\tloss 0.6859 (0.6913)\taccu 53.125 (53.555)\n",
      "Epoch-404  60 batches\tloss 0.6908 (0.6912)\taccu 53.125 (53.307)\n",
      "Epoch-404  80 batches\tloss 0.6941 (0.6917)\taccu 50.000 (52.793)\n",
      "Epoch-404 100 batches\tloss 0.6881 (0.6920)\taccu 62.500 (52.828)\n",
      "Epoch-404 120 batches\tloss 0.6899 (0.6920)\taccu 53.125 (52.773)\n",
      "Epoch-404 140 batches\tloss 0.6904 (0.6919)\taccu 54.688 (52.757)\n",
      "Epoch-404 38.4s\tTrain: loss 0.6920\taccu 52.6943\tValid: loss 0.6938\taccu 50.4507\n",
      "Epoch 404: val_acc did not improve\n",
      "404 1.0000000000000002e-06\n",
      "Epoch-405  20 batches\tloss 0.6903 (0.6931)\taccu 51.562 (51.641)\n",
      "Epoch-405  40 batches\tloss 0.6996 (0.6918)\taccu 45.312 (52.344)\n",
      "Epoch-405  60 batches\tloss 0.7032 (0.6921)\taccu 35.938 (51.875)\n",
      "Epoch-405  80 batches\tloss 0.6916 (0.6924)\taccu 53.125 (51.934)\n",
      "Epoch-405 100 batches\tloss 0.6898 (0.6925)\taccu 54.688 (51.953)\n",
      "Epoch-405 120 batches\tloss 0.6908 (0.6920)\taccu 57.812 (52.448)\n",
      "Epoch-405 140 batches\tloss 0.6872 (0.6920)\taccu 62.500 (52.578)\n",
      "Epoch-405 38.7s\tTrain: loss 0.6919\taccu 52.5841\tValid: loss 0.6938\taccu 50.0601\n",
      "Epoch 405: val_acc did not improve\n",
      "405 1.0000000000000002e-06\n",
      "Epoch-406  20 batches\tloss 0.6978 (0.6918)\taccu 48.438 (52.188)\n",
      "Epoch-406  40 batches\tloss 0.6839 (0.6915)\taccu 60.938 (52.773)\n",
      "Epoch-406  60 batches\tloss 0.6887 (0.6917)\taccu 53.125 (52.526)\n",
      "Epoch-406  80 batches\tloss 0.6918 (0.6916)\taccu 56.250 (52.969)\n",
      "Epoch-406 100 batches\tloss 0.6910 (0.6917)\taccu 56.250 (52.984)\n",
      "Epoch-406 120 batches\tloss 0.6922 (0.6917)\taccu 53.125 (52.852)\n",
      "Epoch-406 140 batches\tloss 0.6916 (0.6917)\taccu 53.125 (52.946)\n",
      "Epoch-406 38.5s\tTrain: loss 0.6918\taccu 52.7444\tValid: loss 0.6938\taccu 50.5609\n",
      "Epoch 406: val_acc did not improve\n",
      "406 1.0000000000000002e-06\n",
      "Epoch-407  20 batches\tloss 0.6943 (0.6905)\taccu 39.062 (52.188)\n",
      "Epoch-407  40 batches\tloss 0.6887 (0.6908)\taccu 53.125 (52.773)\n",
      "Epoch-407  60 batches\tloss 0.6908 (0.6910)\taccu 51.562 (52.891)\n",
      "Epoch-407  80 batches\tloss 0.6911 (0.6910)\taccu 60.938 (53.105)\n",
      "Epoch-407 100 batches\tloss 0.6995 (0.6913)\taccu 45.312 (53.016)\n",
      "Epoch-407 120 batches\tloss 0.6895 (0.6914)\taccu 53.125 (52.904)\n",
      "Epoch-407 140 batches\tloss 0.6950 (0.6916)\taccu 46.875 (52.723)\n",
      "Epoch-407 38.6s\tTrain: loss 0.6918\taccu 52.5140\tValid: loss 0.6937\taccu 50.2504\n",
      "Epoch 407: val_acc did not improve\n",
      "407 1.0000000000000002e-06\n",
      "Epoch-408  20 batches\tloss 0.6838 (0.6904)\taccu 54.688 (52.969)\n",
      "Epoch-408  40 batches\tloss 0.6988 (0.6911)\taccu 50.000 (53.359)\n",
      "Epoch-408  60 batches\tloss 0.7012 (0.6915)\taccu 43.750 (53.307)\n",
      "Epoch-408  80 batches\tloss 0.6855 (0.6917)\taccu 62.500 (52.949)\n",
      "Epoch-408 100 batches\tloss 0.6907 (0.6916)\taccu 50.000 (52.875)\n",
      "Epoch-408 120 batches\tloss 0.6918 (0.6919)\taccu 50.000 (52.487)\n",
      "Epoch-408 140 batches\tloss 0.6941 (0.6918)\taccu 50.000 (52.366)\n",
      "Epoch-408 38.4s\tTrain: loss 0.6918\taccu 52.4840\tValid: loss 0.6937\taccu 50.5008\n",
      "Epoch 408: val_acc did not improve\n",
      "408 1.0000000000000002e-06\n",
      "Epoch-409  20 batches\tloss 0.6914 (0.6935)\taccu 53.125 (50.781)\n",
      "Epoch-409  40 batches\tloss 0.6938 (0.6918)\taccu 51.562 (52.578)\n",
      "Epoch-409  60 batches\tloss 0.6874 (0.6919)\taccu 46.875 (52.396)\n",
      "Epoch-409  80 batches\tloss 0.6944 (0.6919)\taccu 51.562 (52.305)\n",
      "Epoch-409 100 batches\tloss 0.6838 (0.6919)\taccu 62.500 (52.344)\n",
      "Epoch-409 120 batches\tloss 0.6964 (0.6920)\taccu 40.625 (52.331)\n",
      "Epoch-409 140 batches\tloss 0.6922 (0.6919)\taccu 62.500 (52.511)\n",
      "Epoch-409 38.6s\tTrain: loss 0.6919\taccu 52.6042\tValid: loss 0.6938\taccu 50.3706\n",
      "Epoch 409: val_acc did not improve\n",
      "409 1.0000000000000002e-06\n",
      "Epoch-410  20 batches\tloss 0.6937 (0.6899)\taccu 53.125 (55.234)\n",
      "Epoch-410  40 batches\tloss 0.6928 (0.6909)\taccu 46.875 (53.477)\n",
      "Epoch-410  60 batches\tloss 0.6870 (0.6916)\taccu 57.812 (52.708)\n",
      "Epoch-410  80 batches\tloss 0.7009 (0.6915)\taccu 42.188 (53.105)\n",
      "Epoch-410 100 batches\tloss 0.6950 (0.6917)\taccu 48.438 (52.953)\n",
      "Epoch-410 120 batches\tloss 0.6856 (0.6917)\taccu 59.375 (53.034)\n",
      "Epoch-410 140 batches\tloss 0.6974 (0.6916)\taccu 51.562 (53.147)\n",
      "Epoch-410 38.6s\tTrain: loss 0.6917\taccu 52.9948\tValid: loss 0.6937\taccu 50.3506\n",
      "Epoch 410: val_acc did not improve\n",
      "410 1.0000000000000002e-06\n",
      "Epoch-411  20 batches\tloss 0.6983 (0.6933)\taccu 46.875 (51.250)\n",
      "Epoch-411  40 batches\tloss 0.6859 (0.6923)\taccu 57.812 (51.836)\n",
      "Epoch-411  60 batches\tloss 0.6924 (0.6920)\taccu 50.000 (52.396)\n",
      "Epoch-411  80 batches\tloss 0.7016 (0.6919)\taccu 42.188 (52.266)\n",
      "Epoch-411 100 batches\tloss 0.6945 (0.6923)\taccu 56.250 (51.969)\n",
      "Epoch-411 120 batches\tloss 0.6964 (0.6921)\taccu 45.312 (51.901)\n",
      "Epoch-411 140 batches\tloss 0.6967 (0.6921)\taccu 54.688 (52.143)\n",
      "Epoch-411 38.4s\tTrain: loss 0.6920\taccu 52.4539\tValid: loss 0.6939\taccu 50.1302\n",
      "Epoch 411: val_acc did not improve\n",
      "411 1.0000000000000002e-06\n",
      "Epoch-412  20 batches\tloss 0.6982 (0.6906)\taccu 45.312 (54.844)\n",
      "Epoch-412  40 batches\tloss 0.6858 (0.6909)\taccu 56.250 (53.633)\n",
      "Epoch-412  60 batches\tloss 0.6836 (0.6911)\taccu 57.812 (53.385)\n",
      "Epoch-412  80 batches\tloss 0.6961 (0.6911)\taccu 46.875 (53.027)\n",
      "Epoch-412 100 batches\tloss 0.6878 (0.6913)\taccu 60.938 (53.031)\n",
      "Epoch-412 120 batches\tloss 0.6871 (0.6914)\taccu 53.125 (52.839)\n",
      "Epoch-412 140 batches\tloss 0.6873 (0.6915)\taccu 57.812 (52.723)\n",
      "Epoch-412 38.4s\tTrain: loss 0.6917\taccu 52.6743\tValid: loss 0.6938\taccu 49.8397\n",
      "Epoch 412: val_acc did not improve\n",
      "412 1.0000000000000002e-06\n",
      "Epoch-413  20 batches\tloss 0.6897 (0.6920)\taccu 62.500 (53.281)\n",
      "Epoch-413  40 batches\tloss 0.6950 (0.6921)\taccu 50.000 (52.969)\n",
      "Epoch-413  60 batches\tloss 0.6868 (0.6923)\taccu 57.812 (52.474)\n",
      "Epoch-413  80 batches\tloss 0.6968 (0.6924)\taccu 43.750 (52.031)\n",
      "Epoch-413 100 batches\tloss 0.6931 (0.6921)\taccu 46.875 (52.203)\n",
      "Epoch-413 120 batches\tloss 0.6825 (0.6919)\taccu 67.188 (52.253)\n",
      "Epoch-413 140 batches\tloss 0.6926 (0.6920)\taccu 54.688 (52.288)\n",
      "Epoch-413 38.2s\tTrain: loss 0.6920\taccu 52.5641\tValid: loss 0.6937\taccu 50.5008\n",
      "Epoch 413: val_acc did not improve\n",
      "413 1.0000000000000002e-06\n",
      "Epoch-414  20 batches\tloss 0.6906 (0.6899)\taccu 54.688 (53.828)\n",
      "Epoch-414  40 batches\tloss 0.6888 (0.6905)\taccu 53.125 (54.297)\n",
      "Epoch-414  60 batches\tloss 0.6872 (0.6908)\taccu 56.250 (53.932)\n",
      "Epoch-414  80 batches\tloss 0.6946 (0.6912)\taccu 48.438 (53.516)\n",
      "Epoch-414 100 batches\tloss 0.6893 (0.6914)\taccu 56.250 (53.031)\n",
      "Epoch-414 120 batches\tloss 0.6974 (0.6916)\taccu 46.875 (52.956)\n",
      "Epoch-414 140 batches\tloss 0.6903 (0.6915)\taccu 57.812 (53.203)\n",
      "Epoch-414 38.5s\tTrain: loss 0.6917\taccu 52.9547\tValid: loss 0.6939\taccu 50.0601\n",
      "Epoch 414: val_acc did not improve\n",
      "414 1.0000000000000002e-06\n",
      "Epoch-415  20 batches\tloss 0.6967 (0.6934)\taccu 48.438 (52.734)\n",
      "Epoch-415  40 batches\tloss 0.6946 (0.6927)\taccu 48.438 (53.398)\n",
      "Epoch-415  60 batches\tloss 0.6905 (0.6925)\taccu 56.250 (53.047)\n",
      "Epoch-415  80 batches\tloss 0.6946 (0.6927)\taccu 48.438 (52.637)\n",
      "Epoch-415 100 batches\tloss 0.6985 (0.6927)\taccu 50.000 (52.578)\n",
      "Epoch-415 120 batches\tloss 0.6892 (0.6922)\taccu 57.812 (52.799)\n",
      "Epoch-415 140 batches\tloss 0.6922 (0.6920)\taccu 48.438 (52.958)\n",
      "Epoch-415 38.5s\tTrain: loss 0.6919\taccu 53.0148\tValid: loss 0.6936\taccu 50.6110\n",
      "Epoch 415: val_acc did not improve\n",
      "415 1.0000000000000002e-06\n",
      "Epoch-416  20 batches\tloss 0.6906 (0.6920)\taccu 46.875 (52.969)\n",
      "Epoch-416  40 batches\tloss 0.6882 (0.6910)\taccu 50.000 (53.438)\n",
      "Epoch-416  60 batches\tloss 0.6965 (0.6912)\taccu 48.438 (53.333)\n",
      "Epoch-416  80 batches\tloss 0.6927 (0.6914)\taccu 50.000 (53.418)\n",
      "Epoch-416 100 batches\tloss 0.6883 (0.6915)\taccu 57.812 (52.984)\n",
      "Epoch-416 120 batches\tloss 0.6920 (0.6919)\taccu 53.125 (52.500)\n",
      "Epoch-416 140 batches\tloss 0.6976 (0.6920)\taccu 37.500 (52.254)\n",
      "Epoch-416 38.3s\tTrain: loss 0.6920\taccu 52.3438\tValid: loss 0.6938\taccu 50.1703\n",
      "Epoch 416: val_acc did not improve\n",
      "416 1.0000000000000002e-06\n",
      "Epoch-417  20 batches\tloss 0.6893 (0.6923)\taccu 51.562 (52.891)\n",
      "Epoch-417  40 batches\tloss 0.7028 (0.6925)\taccu 42.188 (52.617)\n",
      "Epoch-417  60 batches\tloss 0.6916 (0.6923)\taccu 57.812 (52.161)\n",
      "Epoch-417  80 batches\tloss 0.6864 (0.6917)\taccu 51.562 (52.988)\n",
      "Epoch-417 100 batches\tloss 0.6912 (0.6920)\taccu 57.812 (52.641)\n",
      "Epoch-417 120 batches\tloss 0.6902 (0.6920)\taccu 53.125 (52.604)\n",
      "Epoch-417 140 batches\tloss 0.6923 (0.6919)\taccu 50.000 (52.701)\n",
      "Epoch-417 38.7s\tTrain: loss 0.6918\taccu 52.7845\tValid: loss 0.6939\taccu 50.0901\n",
      "Epoch 417: val_acc did not improve\n",
      "417 1.0000000000000002e-06\n",
      "Epoch-418  20 batches\tloss 0.6892 (0.6922)\taccu 51.562 (51.797)\n",
      "Epoch-418  40 batches\tloss 0.6925 (0.6928)\taccu 56.250 (51.719)\n",
      "Epoch-418  60 batches\tloss 0.6911 (0.6926)\taccu 51.562 (51.667)\n",
      "Epoch-418  80 batches\tloss 0.6907 (0.6920)\taccu 59.375 (52.207)\n",
      "Epoch-418 100 batches\tloss 0.6882 (0.6920)\taccu 56.250 (52.406)\n",
      "Epoch-418 120 batches\tloss 0.6942 (0.6921)\taccu 50.000 (52.253)\n",
      "Epoch-418 140 batches\tloss 0.6964 (0.6921)\taccu 48.438 (52.355)\n",
      "Epoch-418 38.4s\tTrain: loss 0.6920\taccu 52.4740\tValid: loss 0.6938\taccu 50.2404\n",
      "Epoch 418: val_acc did not improve\n",
      "418 1.0000000000000002e-06\n",
      "Epoch-419  20 batches\tloss 0.6969 (0.6919)\taccu 43.750 (50.859)\n",
      "Epoch-419  40 batches\tloss 0.6901 (0.6920)\taccu 50.000 (51.836)\n",
      "Epoch-419  60 batches\tloss 0.6949 (0.6921)\taccu 51.562 (52.266)\n",
      "Epoch-419  80 batches\tloss 0.6946 (0.6921)\taccu 46.875 (52.422)\n",
      "Epoch-419 100 batches\tloss 0.6854 (0.6918)\taccu 62.500 (53.125)\n",
      "Epoch-419 120 batches\tloss 0.6892 (0.6917)\taccu 51.562 (53.073)\n",
      "Epoch-419 140 batches\tloss 0.6923 (0.6917)\taccu 46.875 (53.092)\n",
      "Epoch-419 38.5s\tTrain: loss 0.6918\taccu 52.8746\tValid: loss 0.6939\taccu 50.2704\n",
      "Epoch 419: val_acc did not improve\n",
      "419 1.0000000000000002e-06\n",
      "Epoch-420  20 batches\tloss 0.6913 (0.6925)\taccu 50.000 (52.578)\n",
      "Epoch-420  40 batches\tloss 0.6948 (0.6921)\taccu 48.438 (53.242)\n",
      "Epoch-420  60 batches\tloss 0.6949 (0.6923)\taccu 50.000 (52.943)\n",
      "Epoch-420  80 batches\tloss 0.6917 (0.6919)\taccu 51.562 (53.086)\n",
      "Epoch-420 100 batches\tloss 0.6897 (0.6919)\taccu 53.125 (53.062)\n",
      "Epoch-420 120 batches\tloss 0.6893 (0.6919)\taccu 46.875 (52.708)\n",
      "Epoch-420 140 batches\tloss 0.6979 (0.6920)\taccu 40.625 (52.701)\n",
      "Epoch-420 38.4s\tTrain: loss 0.6920\taccu 52.5942\tValid: loss 0.6937\taccu 50.5208\n",
      "Epoch 420: val_acc did not improve\n",
      "420 1.0000000000000002e-06\n",
      "Epoch-421  20 batches\tloss 0.6910 (0.6902)\taccu 51.562 (53.750)\n",
      "Epoch-421  40 batches\tloss 0.6924 (0.6911)\taccu 54.688 (52.734)\n",
      "Epoch-421  60 batches\tloss 0.6832 (0.6919)\taccu 64.062 (52.786)\n",
      "Epoch-421  80 batches\tloss 0.6875 (0.6918)\taccu 53.125 (52.852)\n",
      "Epoch-421 100 batches\tloss 0.6838 (0.6918)\taccu 64.062 (52.938)\n",
      "Epoch-421 120 batches\tloss 0.6920 (0.6917)\taccu 51.562 (52.982)\n",
      "Epoch-421 140 batches\tloss 0.6945 (0.6916)\taccu 50.000 (53.058)\n",
      "Epoch-421 38.3s\tTrain: loss 0.6917\taccu 52.8946\tValid: loss 0.6938\taccu 50.1603\n",
      "Epoch 421: val_acc did not improve\n",
      "421 1.0000000000000002e-06\n",
      "Epoch-422  20 batches\tloss 0.6900 (0.6909)\taccu 53.125 (55.547)\n",
      "Epoch-422  40 batches\tloss 0.6884 (0.6911)\taccu 57.812 (54.883)\n",
      "Epoch-422  60 batches\tloss 0.6878 (0.6917)\taccu 57.812 (53.411)\n",
      "Epoch-422  80 batches\tloss 0.6884 (0.6919)\taccu 54.688 (52.715)\n",
      "Epoch-422 100 batches\tloss 0.6908 (0.6919)\taccu 56.250 (52.719)\n",
      "Epoch-422 120 batches\tloss 0.6904 (0.6916)\taccu 53.125 (52.969)\n",
      "Epoch-422 140 batches\tloss 0.6909 (0.6917)\taccu 56.250 (52.779)\n",
      "Epoch-422 38.2s\tTrain: loss 0.6918\taccu 52.8446\tValid: loss 0.6937\taccu 50.4708\n",
      "Epoch 422: val_acc did not improve\n",
      "422 1.0000000000000002e-06\n",
      "Epoch-423  20 batches\tloss 0.6916 (0.6923)\taccu 57.812 (51.719)\n",
      "Epoch-423  40 batches\tloss 0.7000 (0.6925)\taccu 45.312 (52.422)\n",
      "Epoch-423  60 batches\tloss 0.6896 (0.6919)\taccu 51.562 (52.578)\n",
      "Epoch-423  80 batches\tloss 0.6824 (0.6921)\taccu 65.625 (52.441)\n",
      "Epoch-423 100 batches\tloss 0.6864 (0.6922)\taccu 62.500 (52.484)\n",
      "Epoch-423 120 batches\tloss 0.6891 (0.6920)\taccu 54.688 (52.500)\n",
      "Epoch-423 140 batches\tloss 0.6891 (0.6919)\taccu 56.250 (52.589)\n",
      "Epoch-423 38.5s\tTrain: loss 0.6918\taccu 52.7444\tValid: loss 0.6937\taccu 50.3606\n",
      "Epoch 423: val_acc did not improve\n",
      "423 1.0000000000000002e-06\n",
      "Epoch-424  20 batches\tloss 0.6915 (0.6920)\taccu 54.688 (52.578)\n",
      "Epoch-424  40 batches\tloss 0.6845 (0.6920)\taccu 65.625 (53.086)\n",
      "Epoch-424  60 batches\tloss 0.6949 (0.6916)\taccu 57.812 (53.672)\n",
      "Epoch-424  80 batches\tloss 0.7032 (0.6914)\taccu 45.312 (54.023)\n",
      "Epoch-424 100 batches\tloss 0.6903 (0.6912)\taccu 53.125 (54.062)\n",
      "Epoch-424 120 batches\tloss 0.6852 (0.6912)\taccu 54.688 (53.776)\n",
      "Epoch-424 140 batches\tloss 0.6864 (0.6915)\taccu 54.688 (53.304)\n",
      "Epoch-424 38.3s\tTrain: loss 0.6916\taccu 53.1550\tValid: loss 0.6937\taccu 50.3906\n",
      "Epoch 424: val_acc did not improve\n",
      "424 1.0000000000000002e-06\n",
      "Epoch-425  20 batches\tloss 0.6879 (0.6913)\taccu 56.250 (52.422)\n",
      "Epoch-425  40 batches\tloss 0.6906 (0.6919)\taccu 56.250 (52.422)\n",
      "Epoch-425  60 batches\tloss 0.6899 (0.6915)\taccu 54.688 (53.255)\n",
      "Epoch-425  80 batches\tloss 0.6959 (0.6915)\taccu 51.562 (53.086)\n",
      "Epoch-425 100 batches\tloss 0.6890 (0.6918)\taccu 57.812 (52.906)\n",
      "Epoch-425 120 batches\tloss 0.6892 (0.6919)\taccu 51.562 (52.878)\n",
      "Epoch-425 140 batches\tloss 0.7014 (0.6919)\taccu 46.875 (52.879)\n",
      "Epoch-425 38.2s\tTrain: loss 0.6918\taccu 52.9147\tValid: loss 0.6937\taccu 50.3906\n",
      "Epoch 425: val_acc did not improve\n",
      "425 1.0000000000000002e-06\n",
      "Epoch-426  20 batches\tloss 0.6923 (0.6906)\taccu 54.688 (55.156)\n",
      "Epoch-426  40 batches\tloss 0.6864 (0.6913)\taccu 54.688 (53.945)\n",
      "Epoch-426  60 batches\tloss 0.6817 (0.6911)\taccu 64.062 (53.802)\n",
      "Epoch-426  80 batches\tloss 0.6953 (0.6907)\taccu 48.438 (54.316)\n",
      "Epoch-426 100 batches\tloss 0.6887 (0.6913)\taccu 57.812 (53.719)\n",
      "Epoch-426 120 batches\tloss 0.6933 (0.6918)\taccu 50.000 (53.073)\n",
      "Epoch-426 140 batches\tloss 0.6947 (0.6917)\taccu 46.875 (52.969)\n",
      "Epoch-426 38.4s\tTrain: loss 0.6919\taccu 52.7845\tValid: loss 0.6938\taccu 50.5008\n",
      "Epoch 426: val_acc did not improve\n",
      "426 1.0000000000000002e-06\n",
      "Epoch-427  20 batches\tloss 0.6900 (0.6911)\taccu 53.125 (54.062)\n",
      "Epoch-427  40 batches\tloss 0.6934 (0.6917)\taccu 53.125 (52.539)\n",
      "Epoch-427  60 batches\tloss 0.6993 (0.6918)\taccu 42.188 (52.760)\n",
      "Epoch-427  80 batches\tloss 0.6925 (0.6918)\taccu 50.000 (52.363)\n",
      "Epoch-427 100 batches\tloss 0.6997 (0.6918)\taccu 43.750 (52.250)\n",
      "Epoch-427 120 batches\tloss 0.6922 (0.6920)\taccu 50.000 (52.227)\n",
      "Epoch-427 140 batches\tloss 0.6976 (0.6920)\taccu 45.312 (52.321)\n",
      "Epoch-427 38.3s\tTrain: loss 0.6920\taccu 52.4139\tValid: loss 0.6937\taccu 50.5509\n",
      "Epoch 427: val_acc did not improve\n",
      "427 1.0000000000000002e-06\n",
      "Epoch-428  20 batches\tloss 0.6978 (0.6924)\taccu 45.312 (52.344)\n",
      "Epoch-428  40 batches\tloss 0.6971 (0.6928)\taccu 42.188 (51.914)\n",
      "Epoch-428  60 batches\tloss 0.6937 (0.6922)\taccu 50.000 (52.682)\n",
      "Epoch-428  80 batches\tloss 0.6973 (0.6922)\taccu 46.875 (52.793)\n",
      "Epoch-428 100 batches\tloss 0.6838 (0.6918)\taccu 62.500 (53.125)\n",
      "Epoch-428 120 batches\tloss 0.6927 (0.6919)\taccu 50.000 (53.086)\n",
      "Epoch-428 140 batches\tloss 0.6970 (0.6920)\taccu 50.000 (52.935)\n",
      "Epoch-428 38.4s\tTrain: loss 0.6919\taccu 52.9447\tValid: loss 0.6938\taccu 50.1903\n",
      "Epoch 428: val_acc did not improve\n",
      "428 1.0000000000000002e-06\n",
      "Epoch-429  20 batches\tloss 0.7011 (0.6917)\taccu 42.188 (55.156)\n",
      "Epoch-429  40 batches\tloss 0.6890 (0.6914)\taccu 57.812 (54.531)\n",
      "Epoch-429  60 batches\tloss 0.7003 (0.6917)\taccu 46.875 (53.568)\n",
      "Epoch-429  80 batches\tloss 0.6923 (0.6918)\taccu 48.438 (53.418)\n",
      "Epoch-429 100 batches\tloss 0.6871 (0.6917)\taccu 59.375 (53.375)\n",
      "Epoch-429 120 batches\tloss 0.6952 (0.6919)\taccu 50.000 (52.995)\n",
      "Epoch-429 140 batches\tloss 0.7003 (0.6920)\taccu 43.750 (52.913)\n",
      "Epoch-429 38.5s\tTrain: loss 0.6920\taccu 52.8045\tValid: loss 0.6937\taccu 50.4207\n",
      "Epoch 429: val_acc did not improve\n",
      "429 1.0000000000000002e-06\n",
      "Epoch-430  20 batches\tloss 0.6925 (0.6924)\taccu 54.688 (52.500)\n",
      "Epoch-430  40 batches\tloss 0.6947 (0.6923)\taccu 50.000 (51.797)\n",
      "Epoch-430  60 batches\tloss 0.6907 (0.6916)\taccu 54.688 (52.969)\n",
      "Epoch-430  80 batches\tloss 0.6923 (0.6916)\taccu 50.000 (53.047)\n",
      "Epoch-430 100 batches\tloss 0.6955 (0.6919)\taccu 50.000 (52.859)\n",
      "Epoch-430 120 batches\tloss 0.7016 (0.6917)\taccu 45.312 (53.242)\n",
      "Epoch-430 140 batches\tloss 0.6982 (0.6916)\taccu 45.312 (53.359)\n",
      "Epoch-430 38.2s\tTrain: loss 0.6916\taccu 53.4756\tValid: loss 0.6937\taccu 50.5008\n",
      "Epoch 430: val_acc did not improve\n",
      "430 1.0000000000000002e-06\n",
      "Epoch-431  20 batches\tloss 0.6958 (0.6926)\taccu 43.750 (51.328)\n",
      "Epoch-431  40 batches\tloss 0.6841 (0.6921)\taccu 59.375 (52.383)\n",
      "Epoch-431  60 batches\tloss 0.6962 (0.6915)\taccu 50.000 (53.021)\n",
      "Epoch-431  80 batches\tloss 0.6857 (0.6918)\taccu 54.688 (52.754)\n",
      "Epoch-431 100 batches\tloss 0.6880 (0.6923)\taccu 56.250 (52.438)\n",
      "Epoch-431 120 batches\tloss 0.6914 (0.6922)\taccu 53.125 (52.331)\n",
      "Epoch-431 140 batches\tloss 0.6894 (0.6922)\taccu 56.250 (52.433)\n",
      "Epoch-431 38.5s\tTrain: loss 0.6920\taccu 52.6843\tValid: loss 0.6938\taccu 50.4908\n",
      "Epoch 431: val_acc did not improve\n",
      "431 1.0000000000000002e-06\n",
      "Epoch-432  20 batches\tloss 0.6986 (0.6938)\taccu 42.188 (50.312)\n",
      "Epoch-432  40 batches\tloss 0.6921 (0.6920)\taccu 46.875 (51.562)\n",
      "Epoch-432  60 batches\tloss 0.6909 (0.6918)\taccu 48.438 (51.823)\n",
      "Epoch-432  80 batches\tloss 0.6968 (0.6920)\taccu 42.188 (51.719)\n",
      "Epoch-432 100 batches\tloss 0.6829 (0.6919)\taccu 59.375 (51.953)\n",
      "Epoch-432 120 batches\tloss 0.6885 (0.6919)\taccu 54.688 (52.135)\n",
      "Epoch-432 140 batches\tloss 0.6950 (0.6918)\taccu 48.438 (52.489)\n",
      "Epoch-432 38.1s\tTrain: loss 0.6918\taccu 52.4840\tValid: loss 0.6937\taccu 50.6210\n",
      "Epoch 432: val_acc did not improve\n",
      "432 1.0000000000000002e-06\n",
      "Epoch-433  20 batches\tloss 0.6925 (0.6918)\taccu 46.875 (52.969)\n",
      "Epoch-433  40 batches\tloss 0.6928 (0.6931)\taccu 54.688 (51.211)\n",
      "Epoch-433  60 batches\tloss 0.6870 (0.6930)\taccu 64.062 (51.589)\n",
      "Epoch-433  80 batches\tloss 0.6902 (0.6926)\taccu 46.875 (51.562)\n",
      "Epoch-433 100 batches\tloss 0.6972 (0.6925)\taccu 48.438 (51.781)\n",
      "Epoch-433 120 batches\tloss 0.6924 (0.6923)\taccu 42.188 (51.849)\n",
      "Epoch-433 140 batches\tloss 0.6931 (0.6921)\taccu 54.688 (52.232)\n",
      "Epoch-433 38.7s\tTrain: loss 0.6919\taccu 52.5140\tValid: loss 0.6938\taccu 50.1002\n",
      "Epoch 433: val_acc did not improve\n",
      "433 1.0000000000000002e-06\n",
      "Epoch-434  20 batches\tloss 0.6894 (0.6907)\taccu 53.125 (53.359)\n",
      "Epoch-434  40 batches\tloss 0.6915 (0.6901)\taccu 64.062 (54.688)\n",
      "Epoch-434  60 batches\tloss 0.6881 (0.6904)\taccu 50.000 (54.063)\n",
      "Epoch-434  80 batches\tloss 0.6863 (0.6907)\taccu 60.938 (53.906)\n",
      "Epoch-434 100 batches\tloss 0.6898 (0.6912)\taccu 53.125 (53.516)\n",
      "Epoch-434 120 batches\tloss 0.6837 (0.6915)\taccu 64.062 (53.008)\n",
      "Epoch-434 140 batches\tloss 0.6922 (0.6919)\taccu 53.125 (52.589)\n",
      "Epoch-434 38.3s\tTrain: loss 0.6918\taccu 52.8045\tValid: loss 0.6938\taccu 50.4808\n",
      "Epoch 434: val_acc did not improve\n",
      "434 1.0000000000000002e-06\n",
      "Epoch-435  20 batches\tloss 0.6956 (0.6922)\taccu 51.562 (52.422)\n",
      "Epoch-435  40 batches\tloss 0.6861 (0.6920)\taccu 60.938 (52.422)\n",
      "Epoch-435  60 batches\tloss 0.6922 (0.6917)\taccu 53.125 (52.891)\n",
      "Epoch-435  80 batches\tloss 0.6871 (0.6919)\taccu 57.812 (52.773)\n",
      "Epoch-435 100 batches\tloss 0.6845 (0.6918)\taccu 59.375 (52.922)\n",
      "Epoch-435 120 batches\tloss 0.6949 (0.6918)\taccu 45.312 (52.956)\n",
      "Epoch-435 140 batches\tloss 0.6927 (0.6918)\taccu 51.562 (52.924)\n",
      "Epoch-435 38.3s\tTrain: loss 0.6919\taccu 52.7344\tValid: loss 0.6938\taccu 50.2504\n",
      "Epoch 435: val_acc did not improve\n",
      "435 1.0000000000000002e-06\n",
      "Epoch-436  20 batches\tloss 0.6911 (0.6923)\taccu 50.000 (50.312)\n",
      "Epoch-436  40 batches\tloss 0.6856 (0.6917)\taccu 62.500 (51.992)\n",
      "Epoch-436  60 batches\tloss 0.6923 (0.6922)\taccu 54.688 (52.083)\n",
      "Epoch-436  80 batches\tloss 0.6957 (0.6922)\taccu 43.750 (52.109)\n",
      "Epoch-436 100 batches\tloss 0.6947 (0.6922)\taccu 53.125 (52.547)\n",
      "Epoch-436 120 batches\tloss 0.6935 (0.6923)\taccu 53.125 (52.370)\n",
      "Epoch-436 140 batches\tloss 0.6908 (0.6922)\taccu 53.125 (52.444)\n",
      "Epoch-436 38.4s\tTrain: loss 0.6920\taccu 52.5341\tValid: loss 0.6939\taccu 50.1002\n",
      "Epoch 436: val_acc did not improve\n",
      "436 1.0000000000000002e-06\n",
      "Epoch-437  20 batches\tloss 0.6902 (0.6916)\taccu 48.438 (52.422)\n",
      "Epoch-437  40 batches\tloss 0.7001 (0.6919)\taccu 39.062 (51.328)\n",
      "Epoch-437  60 batches\tloss 0.6968 (0.6920)\taccu 48.438 (52.083)\n",
      "Epoch-437  80 batches\tloss 0.6881 (0.6921)\taccu 57.812 (51.504)\n",
      "Epoch-437 100 batches\tloss 0.6930 (0.6923)\taccu 51.562 (51.672)\n",
      "Epoch-437 120 batches\tloss 0.6891 (0.6921)\taccu 51.562 (51.888)\n",
      "Epoch-437 140 batches\tloss 0.6978 (0.6920)\taccu 50.000 (52.154)\n",
      "Epoch-437 38.4s\tTrain: loss 0.6920\taccu 52.2035\tValid: loss 0.6939\taccu 50.2204\n",
      "Epoch 437: val_acc did not improve\n",
      "437 1.0000000000000002e-06\n",
      "Epoch-438  20 batches\tloss 0.6870 (0.6933)\taccu 54.688 (51.641)\n",
      "Epoch-438  40 batches\tloss 0.6883 (0.6924)\taccu 53.125 (51.523)\n",
      "Epoch-438  60 batches\tloss 0.6870 (0.6923)\taccu 53.125 (51.797)\n",
      "Epoch-438  80 batches\tloss 0.6942 (0.6920)\taccu 45.312 (51.953)\n",
      "Epoch-438 100 batches\tloss 0.6841 (0.6919)\taccu 62.500 (52.656)\n",
      "Epoch-438 120 batches\tloss 0.6912 (0.6917)\taccu 50.000 (52.721)\n",
      "Epoch-438 140 batches\tloss 0.6915 (0.6916)\taccu 50.000 (52.857)\n",
      "Epoch-438 38.2s\tTrain: loss 0.6917\taccu 52.8045\tValid: loss 0.6937\taccu 50.1603\n",
      "Epoch 438: val_acc did not improve\n",
      "438 1.0000000000000002e-06\n",
      "Epoch-439  20 batches\tloss 0.6890 (0.6915)\taccu 54.688 (52.422)\n",
      "Epoch-439  40 batches\tloss 0.6952 (0.6912)\taccu 50.000 (53.047)\n",
      "Epoch-439  60 batches\tloss 0.6890 (0.6913)\taccu 56.250 (53.073)\n",
      "Epoch-439  80 batches\tloss 0.6933 (0.6915)\taccu 54.688 (53.066)\n",
      "Epoch-439 100 batches\tloss 0.6950 (0.6918)\taccu 50.000 (52.641)\n",
      "Epoch-439 120 batches\tloss 0.6914 (0.6919)\taccu 51.562 (52.643)\n",
      "Epoch-439 140 batches\tloss 0.6907 (0.6918)\taccu 53.125 (52.690)\n",
      "Epoch-439 38.5s\tTrain: loss 0.6918\taccu 52.7143\tValid: loss 0.6938\taccu 50.4607\n",
      "Epoch 439: val_acc did not improve\n",
      "439 1.0000000000000002e-06\n",
      "Epoch-440  20 batches\tloss 0.6911 (0.6904)\taccu 57.812 (54.297)\n",
      "Epoch-440  40 batches\tloss 0.6920 (0.6909)\taccu 48.438 (53.828)\n",
      "Epoch-440  60 batches\tloss 0.6889 (0.6913)\taccu 53.125 (53.411)\n",
      "Epoch-440  80 batches\tloss 0.6965 (0.6917)\taccu 53.125 (53.066)\n",
      "Epoch-440 100 batches\tloss 0.6971 (0.6914)\taccu 51.562 (53.406)\n",
      "Epoch-440 120 batches\tloss 0.6917 (0.6912)\taccu 59.375 (53.880)\n",
      "Epoch-440 140 batches\tloss 0.6965 (0.6915)\taccu 46.875 (53.449)\n",
      "Epoch-440 38.6s\tTrain: loss 0.6917\taccu 53.3153\tValid: loss 0.6938\taccu 50.5909\n",
      "Epoch 440: val_acc did not improve\n",
      "440 1.0000000000000002e-06\n",
      "Epoch-441  20 batches\tloss 0.6864 (0.6925)\taccu 64.062 (51.562)\n",
      "Epoch-441  40 batches\tloss 0.6927 (0.6921)\taccu 48.438 (52.031)\n",
      "Epoch-441  60 batches\tloss 0.6920 (0.6921)\taccu 51.562 (51.979)\n",
      "Epoch-441  80 batches\tloss 0.6841 (0.6923)\taccu 65.625 (51.914)\n",
      "Epoch-441 100 batches\tloss 0.6887 (0.6923)\taccu 53.125 (51.922)\n",
      "Epoch-441 120 batches\tloss 0.6945 (0.6921)\taccu 48.438 (52.083)\n",
      "Epoch-441 140 batches\tloss 0.6908 (0.6920)\taccu 51.562 (52.333)\n",
      "Epoch-441 38.8s\tTrain: loss 0.6920\taccu 52.3638\tValid: loss 0.6939\taccu 50.2905\n",
      "Epoch 441: val_acc did not improve\n",
      "441 1.0000000000000002e-06\n",
      "Epoch-442  20 batches\tloss 0.6911 (0.6923)\taccu 53.125 (52.422)\n",
      "Epoch-442  40 batches\tloss 0.6904 (0.6918)\taccu 57.812 (53.125)\n",
      "Epoch-442  60 batches\tloss 0.6944 (0.6912)\taccu 42.188 (53.854)\n",
      "Epoch-442  80 batches\tloss 0.6953 (0.6917)\taccu 48.438 (53.164)\n",
      "Epoch-442 100 batches\tloss 0.6912 (0.6920)\taccu 54.688 (52.734)\n",
      "Epoch-442 120 batches\tloss 0.6960 (0.6920)\taccu 43.750 (52.721)\n",
      "Epoch-442 140 batches\tloss 0.6888 (0.6919)\taccu 51.562 (52.913)\n",
      "Epoch-442 38.6s\tTrain: loss 0.6919\taccu 52.8045\tValid: loss 0.6938\taccu 50.5809\n",
      "Epoch 442: val_acc did not improve\n",
      "442 1.0000000000000002e-06\n",
      "Epoch-443  20 batches\tloss 0.6979 (0.6935)\taccu 42.188 (49.609)\n",
      "Epoch-443  40 batches\tloss 0.6953 (0.6921)\taccu 46.875 (51.680)\n",
      "Epoch-443  60 batches\tloss 0.6924 (0.6919)\taccu 45.312 (52.370)\n",
      "Epoch-443  80 batches\tloss 0.7008 (0.6923)\taccu 39.062 (52.363)\n",
      "Epoch-443 100 batches\tloss 0.6879 (0.6919)\taccu 57.812 (52.797)\n",
      "Epoch-443 120 batches\tloss 0.6931 (0.6917)\taccu 51.562 (52.878)\n",
      "Epoch-443 140 batches\tloss 0.6902 (0.6917)\taccu 53.125 (52.924)\n",
      "Epoch-443 39.2s\tTrain: loss 0.6918\taccu 52.6943\tValid: loss 0.6938\taccu 50.1302\n",
      "Epoch 443: val_acc did not improve\n",
      "443 1.0000000000000002e-06\n",
      "Epoch-444  20 batches\tloss 0.6865 (0.6919)\taccu 57.812 (52.656)\n",
      "Epoch-444  40 batches\tloss 0.6906 (0.6911)\taccu 57.812 (54.297)\n",
      "Epoch-444  60 batches\tloss 0.6923 (0.6919)\taccu 57.812 (52.552)\n",
      "Epoch-444  80 batches\tloss 0.6926 (0.6920)\taccu 53.125 (52.500)\n",
      "Epoch-444 100 batches\tloss 0.6991 (0.6922)\taccu 48.438 (52.281)\n",
      "Epoch-444 120 batches\tloss 0.6913 (0.6921)\taccu 56.250 (52.253)\n",
      "Epoch-444 140 batches\tloss 0.6877 (0.6918)\taccu 64.062 (52.634)\n",
      "Epoch-444 40.3s\tTrain: loss 0.6918\taccu 52.6442\tValid: loss 0.6939\taccu 50.4006\n",
      "Epoch 444: val_acc did not improve\n",
      "444 1.0000000000000002e-06\n",
      "Epoch-445  20 batches\tloss 0.6940 (0.6928)\taccu 50.000 (52.500)\n",
      "Epoch-445  40 batches\tloss 0.6948 (0.6925)\taccu 48.438 (52.383)\n",
      "Epoch-445  60 batches\tloss 0.6869 (0.6921)\taccu 54.688 (52.682)\n",
      "Epoch-445  80 batches\tloss 0.6915 (0.6917)\taccu 51.562 (52.676)\n",
      "Epoch-445 100 batches\tloss 0.6925 (0.6916)\taccu 50.000 (52.938)\n",
      "Epoch-445 120 batches\tloss 0.6991 (0.6917)\taccu 40.625 (52.682)\n",
      "Epoch-445 140 batches\tloss 0.6888 (0.6915)\taccu 53.125 (52.946)\n",
      "Epoch-445 40.0s\tTrain: loss 0.6915\taccu 52.8345\tValid: loss 0.6938\taccu 50.3005\n",
      "Epoch 445: val_acc did not improve\n",
      "445 1.0000000000000002e-06\n",
      "Epoch-446  20 batches\tloss 0.6945 (0.6920)\taccu 50.000 (52.188)\n",
      "Epoch-446  40 batches\tloss 0.6977 (0.6930)\taccu 46.875 (51.484)\n",
      "Epoch-446  60 batches\tloss 0.6907 (0.6927)\taccu 54.688 (52.031)\n",
      "Epoch-446  80 batches\tloss 0.6862 (0.6924)\taccu 56.250 (52.363)\n",
      "Epoch-446 100 batches\tloss 0.6882 (0.6926)\taccu 59.375 (52.250)\n",
      "Epoch-446 120 batches\tloss 0.6978 (0.6922)\taccu 45.312 (52.695)\n",
      "Epoch-446 140 batches\tloss 0.6927 (0.6922)\taccu 53.125 (52.578)\n",
      "Epoch-446 38.4s\tTrain: loss 0.6921\taccu 52.5140\tValid: loss 0.6937\taccu 50.5008\n",
      "Epoch 446: val_acc did not improve\n",
      "446 1.0000000000000002e-06\n",
      "Epoch-447  20 batches\tloss 0.7003 (0.6922)\taccu 48.438 (52.812)\n",
      "Epoch-447  40 batches\tloss 0.6913 (0.6925)\taccu 54.688 (51.953)\n",
      "Epoch-447  60 batches\tloss 0.6990 (0.6926)\taccu 45.312 (51.979)\n",
      "Epoch-447  80 batches\tloss 0.6997 (0.6923)\taccu 48.438 (52.383)\n",
      "Epoch-447 100 batches\tloss 0.6972 (0.6924)\taccu 48.438 (52.062)\n",
      "Epoch-447 120 batches\tloss 0.6960 (0.6922)\taccu 43.750 (52.161)\n",
      "Epoch-447 140 batches\tloss 0.6983 (0.6921)\taccu 48.438 (52.310)\n",
      "Epoch-447 38.4s\tTrain: loss 0.6920\taccu 52.3738\tValid: loss 0.6939\taccu 50.0401\n",
      "Epoch 447: val_acc did not improve\n",
      "447 1.0000000000000002e-06\n",
      "Epoch-448  20 batches\tloss 0.6903 (0.6932)\taccu 57.812 (50.078)\n",
      "Epoch-448  40 batches\tloss 0.6842 (0.6916)\taccu 59.375 (51.992)\n",
      "Epoch-448  60 batches\tloss 0.6857 (0.6918)\taccu 54.688 (51.797)\n",
      "Epoch-448  80 batches\tloss 0.6889 (0.6922)\taccu 46.875 (51.680)\n",
      "Epoch-448 100 batches\tloss 0.6911 (0.6920)\taccu 56.250 (52.234)\n",
      "Epoch-448 120 batches\tloss 0.6830 (0.6920)\taccu 54.688 (52.448)\n",
      "Epoch-448 140 batches\tloss 0.6906 (0.6922)\taccu 59.375 (52.366)\n",
      "Epoch-448 38.3s\tTrain: loss 0.6920\taccu 52.5841\tValid: loss 0.6937\taccu 50.2204\n",
      "Epoch 448: val_acc did not improve\n",
      "448 1.0000000000000002e-06\n",
      "Epoch-449  20 batches\tloss 0.6861 (0.6917)\taccu 62.500 (53.750)\n",
      "Epoch-449  40 batches\tloss 0.6977 (0.6920)\taccu 46.875 (53.047)\n",
      "Epoch-449  60 batches\tloss 0.6881 (0.6917)\taccu 59.375 (53.594)\n",
      "Epoch-449  80 batches\tloss 0.6981 (0.6915)\taccu 50.000 (53.691)\n",
      "Epoch-449 100 batches\tloss 0.6876 (0.6916)\taccu 59.375 (53.359)\n",
      "Epoch-449 120 batches\tloss 0.6862 (0.6916)\taccu 53.125 (53.255)\n",
      "Epoch-449 140 batches\tloss 0.6874 (0.6918)\taccu 60.938 (52.891)\n",
      "Epoch-449 38.1s\tTrain: loss 0.6920\taccu 52.7845\tValid: loss 0.6937\taccu 50.3706\n",
      "Epoch 449: val_acc did not improve\n",
      "449 1.0000000000000002e-06\n",
      "Epoch-450  20 batches\tloss 0.6917 (0.6903)\taccu 50.000 (54.453)\n",
      "Epoch-450  40 batches\tloss 0.6937 (0.6915)\taccu 50.000 (53.320)\n",
      "Epoch-450  60 batches\tloss 0.6990 (0.6918)\taccu 43.750 (53.125)\n",
      "Epoch-450  80 batches\tloss 0.7015 (0.6919)\taccu 45.312 (53.105)\n",
      "Epoch-450 100 batches\tloss 0.6964 (0.6917)\taccu 51.562 (53.375)\n",
      "Epoch-450 120 batches\tloss 0.6966 (0.6918)\taccu 46.875 (53.203)\n",
      "Epoch-450 140 batches\tloss 0.6919 (0.6919)\taccu 53.125 (53.158)\n",
      "Epoch-450 38.5s\tTrain: loss 0.6918\taccu 53.1050\tValid: loss 0.6937\taccu 50.2504\n",
      "Epoch 450: val_acc did not improve\n",
      "450 1.0000000000000002e-06\n",
      "Epoch-451  20 batches\tloss 0.6915 (0.6919)\taccu 51.562 (52.969)\n",
      "Epoch-451  40 batches\tloss 0.6962 (0.6913)\taccu 53.125 (52.891)\n",
      "Epoch-451  60 batches\tloss 0.6889 (0.6910)\taccu 54.688 (53.464)\n",
      "Epoch-451  80 batches\tloss 0.7001 (0.6916)\taccu 50.000 (53.242)\n",
      "Epoch-451 100 batches\tloss 0.6983 (0.6918)\taccu 51.562 (52.938)\n",
      "Epoch-451 120 batches\tloss 0.6892 (0.6918)\taccu 59.375 (52.930)\n",
      "Epoch-451 140 batches\tloss 0.6946 (0.6918)\taccu 48.438 (52.757)\n",
      "Epoch-451 38.5s\tTrain: loss 0.6919\taccu 52.4639\tValid: loss 0.6937\taccu 50.4006\n",
      "Epoch 451: val_acc did not improve\n",
      "451 1.0000000000000002e-06\n",
      "Epoch-452  20 batches\tloss 0.6932 (0.6920)\taccu 53.125 (53.672)\n",
      "Epoch-452  40 batches\tloss 0.6862 (0.6919)\taccu 65.625 (52.852)\n",
      "Epoch-452  60 batches\tloss 0.6989 (0.6926)\taccu 42.188 (52.109)\n",
      "Epoch-452  80 batches\tloss 0.6920 (0.6926)\taccu 51.562 (51.895)\n",
      "Epoch-452 100 batches\tloss 0.6865 (0.6922)\taccu 59.375 (52.109)\n",
      "Epoch-452 120 batches\tloss 0.6906 (0.6921)\taccu 56.250 (52.396)\n",
      "Epoch-452 140 batches\tloss 0.6899 (0.6919)\taccu 53.125 (52.545)\n",
      "Epoch-452 38.3s\tTrain: loss 0.6918\taccu 52.6843\tValid: loss 0.6938\taccu 50.3205\n",
      "Epoch 452: val_acc did not improve\n",
      "452 1.0000000000000002e-06\n",
      "Epoch-453  20 batches\tloss 0.6936 (0.6911)\taccu 48.438 (54.609)\n",
      "Epoch-453  40 batches\tloss 0.6903 (0.6910)\taccu 53.125 (54.492)\n",
      "Epoch-453  60 batches\tloss 0.6958 (0.6911)\taccu 42.188 (53.802)\n",
      "Epoch-453  80 batches\tloss 0.6887 (0.6910)\taccu 53.125 (54.062)\n",
      "Epoch-453 100 batches\tloss 0.6873 (0.6912)\taccu 62.500 (53.750)\n",
      "Epoch-453 120 batches\tloss 0.6938 (0.6914)\taccu 51.562 (53.646)\n",
      "Epoch-453 140 batches\tloss 0.6961 (0.6916)\taccu 39.062 (53.326)\n",
      "Epoch-453 38.4s\tTrain: loss 0.6916\taccu 53.2853\tValid: loss 0.6938\taccu 49.9900\n",
      "Epoch 453: val_acc did not improve\n",
      "453 1.0000000000000002e-06\n",
      "Epoch-454  20 batches\tloss 0.6935 (0.6922)\taccu 51.562 (54.062)\n",
      "Epoch-454  40 batches\tloss 0.6942 (0.6918)\taccu 50.000 (53.398)\n",
      "Epoch-454  60 batches\tloss 0.6905 (0.6924)\taccu 51.562 (52.708)\n",
      "Epoch-454  80 batches\tloss 0.6932 (0.6922)\taccu 51.562 (52.695)\n",
      "Epoch-454 100 batches\tloss 0.6922 (0.6920)\taccu 53.125 (52.812)\n",
      "Epoch-454 120 batches\tloss 0.6969 (0.6918)\taccu 43.750 (53.190)\n",
      "Epoch-454 140 batches\tloss 0.6965 (0.6920)\taccu 43.750 (53.025)\n",
      "Epoch-454 38.7s\tTrain: loss 0.6919\taccu 53.0649\tValid: loss 0.6937\taccu 50.7312\n",
      "Epoch 454: val_acc did not improve\n",
      "454 1.0000000000000002e-06\n",
      "Epoch-455  20 batches\tloss 0.6856 (0.6901)\taccu 64.062 (53.594)\n",
      "Epoch-455  40 batches\tloss 0.7003 (0.6917)\taccu 39.062 (52.109)\n",
      "Epoch-455  60 batches\tloss 0.6996 (0.6922)\taccu 37.500 (51.953)\n",
      "Epoch-455  80 batches\tloss 0.6967 (0.6921)\taccu 48.438 (51.797)\n",
      "Epoch-455 100 batches\tloss 0.6850 (0.6916)\taccu 54.688 (52.359)\n",
      "Epoch-455 120 batches\tloss 0.6908 (0.6919)\taccu 54.688 (52.227)\n",
      "Epoch-455 140 batches\tloss 0.6855 (0.6920)\taccu 64.062 (52.154)\n",
      "Epoch-455 38.5s\tTrain: loss 0.6917\taccu 52.4940\tValid: loss 0.6938\taccu 50.2404\n",
      "Epoch 455: val_acc did not improve\n",
      "455 1.0000000000000002e-06\n",
      "Epoch-456  20 batches\tloss 0.6989 (0.6921)\taccu 37.500 (53.672)\n",
      "Epoch-456  40 batches\tloss 0.7001 (0.6920)\taccu 42.188 (53.125)\n",
      "Epoch-456  60 batches\tloss 0.6953 (0.6918)\taccu 50.000 (53.125)\n",
      "Epoch-456  80 batches\tloss 0.6869 (0.6917)\taccu 62.500 (53.320)\n",
      "Epoch-456 100 batches\tloss 0.6951 (0.6917)\taccu 50.000 (53.094)\n",
      "Epoch-456 120 batches\tloss 0.6902 (0.6916)\taccu 62.500 (53.346)\n",
      "Epoch-456 140 batches\tloss 0.6970 (0.6916)\taccu 48.438 (53.192)\n",
      "Epoch-456 38.3s\tTrain: loss 0.6917\taccu 53.0048\tValid: loss 0.6938\taccu 50.4207\n",
      "Epoch 456: val_acc did not improve\n",
      "456 1.0000000000000002e-06\n",
      "Epoch-457  20 batches\tloss 0.6905 (0.6911)\taccu 50.000 (52.500)\n",
      "Epoch-457  40 batches\tloss 0.6965 (0.6916)\taccu 45.312 (52.422)\n",
      "Epoch-457  60 batches\tloss 0.6918 (0.6920)\taccu 53.125 (52.266)\n",
      "Epoch-457  80 batches\tloss 0.6901 (0.6920)\taccu 56.250 (52.480)\n",
      "Epoch-457 100 batches\tloss 0.6882 (0.6920)\taccu 56.250 (52.578)\n",
      "Epoch-457 120 batches\tloss 0.6884 (0.6919)\taccu 57.812 (52.669)\n",
      "Epoch-457 140 batches\tloss 0.6861 (0.6920)\taccu 64.062 (52.701)\n",
      "Epoch-457 38.4s\tTrain: loss 0.6921\taccu 52.5841\tValid: loss 0.6938\taccu 50.4908\n",
      "Epoch 457: val_acc did not improve\n",
      "457 1.0000000000000002e-06\n",
      "Epoch-458  20 batches\tloss 0.6983 (0.6918)\taccu 42.188 (52.031)\n",
      "Epoch-458  40 batches\tloss 0.6952 (0.6915)\taccu 50.000 (53.047)\n",
      "Epoch-458  60 batches\tloss 0.6931 (0.6912)\taccu 54.688 (53.698)\n",
      "Epoch-458  80 batches\tloss 0.6982 (0.6916)\taccu 45.312 (53.223)\n",
      "Epoch-458 100 batches\tloss 0.6923 (0.6916)\taccu 53.125 (53.078)\n",
      "Epoch-458 120 batches\tloss 0.6910 (0.6914)\taccu 45.312 (53.164)\n",
      "Epoch-458 140 batches\tloss 0.6984 (0.6916)\taccu 45.312 (53.125)\n",
      "Epoch-458 38.4s\tTrain: loss 0.6918\taccu 53.0349\tValid: loss 0.6937\taccu 50.7913\n",
      "Epoch 458: val_acc did not improve\n",
      "458 1.0000000000000002e-06\n",
      "Epoch-459  20 batches\tloss 0.6905 (0.6921)\taccu 59.375 (53.047)\n",
      "Epoch-459  40 batches\tloss 0.6985 (0.6926)\taccu 42.188 (52.070)\n",
      "Epoch-459  60 batches\tloss 0.6959 (0.6923)\taccu 48.438 (52.344)\n",
      "Epoch-459  80 batches\tloss 0.6910 (0.6920)\taccu 54.688 (52.480)\n",
      "Epoch-459 100 batches\tloss 0.6937 (0.6923)\taccu 50.000 (52.016)\n",
      "Epoch-459 120 batches\tloss 0.6899 (0.6921)\taccu 54.688 (52.096)\n",
      "Epoch-459 140 batches\tloss 0.6921 (0.6920)\taccu 51.562 (52.377)\n",
      "Epoch-459 38.6s\tTrain: loss 0.6920\taccu 52.3938\tValid: loss 0.6939\taccu 50.0501\n",
      "Epoch 459: val_acc did not improve\n",
      "459 1.0000000000000002e-06\n",
      "Epoch-460  20 batches\tloss 0.6872 (0.6910)\taccu 57.812 (52.969)\n",
      "Epoch-460  40 batches\tloss 0.6900 (0.6922)\taccu 56.250 (52.070)\n",
      "Epoch-460  60 batches\tloss 0.6895 (0.6923)\taccu 54.688 (52.344)\n",
      "Epoch-460  80 batches\tloss 0.6942 (0.6919)\taccu 45.312 (52.754)\n",
      "Epoch-460 100 batches\tloss 0.6861 (0.6917)\taccu 57.812 (53.062)\n",
      "Epoch-460 120 batches\tloss 0.6960 (0.6916)\taccu 46.875 (53.216)\n",
      "Epoch-460 140 batches\tloss 0.6924 (0.6920)\taccu 51.562 (52.567)\n",
      "Epoch-460 38.2s\tTrain: loss 0.6920\taccu 52.4840\tValid: loss 0.6938\taccu 50.2504\n",
      "Epoch 460: val_acc did not improve\n",
      "460 1.0000000000000002e-06\n",
      "Epoch-461  20 batches\tloss 0.6854 (0.6927)\taccu 60.938 (51.953)\n",
      "Epoch-461  40 batches\tloss 0.6859 (0.6921)\taccu 57.812 (52.891)\n",
      "Epoch-461  60 batches\tloss 0.6918 (0.6923)\taccu 53.125 (52.422)\n",
      "Epoch-461  80 batches\tloss 0.6886 (0.6921)\taccu 56.250 (52.734)\n",
      "Epoch-461 100 batches\tloss 0.6924 (0.6918)\taccu 54.688 (53.234)\n",
      "Epoch-461 120 batches\tloss 0.6856 (0.6920)\taccu 59.375 (52.891)\n",
      "Epoch-461 140 batches\tloss 0.6871 (0.6920)\taccu 59.375 (52.690)\n",
      "Epoch-461 38.7s\tTrain: loss 0.6919\taccu 52.6342\tValid: loss 0.6937\taccu 50.3706\n",
      "Epoch 461: val_acc did not improve\n",
      "461 1.0000000000000002e-06\n",
      "Epoch-462  20 batches\tloss 0.6974 (0.6930)\taccu 45.312 (51.094)\n",
      "Epoch-462  40 batches\tloss 0.6893 (0.6924)\taccu 64.062 (52.070)\n",
      "Epoch-462  60 batches\tloss 0.6889 (0.6922)\taccu 53.125 (52.240)\n",
      "Epoch-462  80 batches\tloss 0.6987 (0.6924)\taccu 43.750 (51.816)\n",
      "Epoch-462 100 batches\tloss 0.6896 (0.6920)\taccu 57.812 (52.281)\n",
      "Epoch-462 120 batches\tloss 0.6952 (0.6918)\taccu 51.562 (52.578)\n",
      "Epoch-462 140 batches\tloss 0.6922 (0.6918)\taccu 50.000 (52.344)\n",
      "Epoch-462 38.5s\tTrain: loss 0.6918\taccu 52.4038\tValid: loss 0.6938\taccu 50.1002\n",
      "Epoch 462: val_acc did not improve\n",
      "462 1.0000000000000002e-06\n",
      "Epoch-463  20 batches\tloss 0.6929 (0.6920)\taccu 50.000 (52.969)\n",
      "Epoch-463  40 batches\tloss 0.6923 (0.6917)\taccu 50.000 (52.852)\n",
      "Epoch-463  60 batches\tloss 0.6886 (0.6922)\taccu 56.250 (52.813)\n",
      "Epoch-463  80 batches\tloss 0.6953 (0.6923)\taccu 45.312 (52.324)\n",
      "Epoch-463 100 batches\tloss 0.6903 (0.6922)\taccu 57.812 (52.406)\n",
      "Epoch-463 120 batches\tloss 0.6935 (0.6918)\taccu 48.438 (52.904)\n",
      "Epoch-463 140 batches\tloss 0.6905 (0.6920)\taccu 53.125 (52.723)\n",
      "Epoch-463 38.4s\tTrain: loss 0.6919\taccu 52.7344\tValid: loss 0.6939\taccu 50.3005\n",
      "Epoch 463: val_acc did not improve\n",
      "463 1.0000000000000002e-06\n",
      "Epoch-464  20 batches\tloss 0.6936 (0.6915)\taccu 48.438 (52.188)\n",
      "Epoch-464  40 batches\tloss 0.6889 (0.6923)\taccu 51.562 (51.719)\n",
      "Epoch-464  60 batches\tloss 0.6902 (0.6921)\taccu 50.000 (52.370)\n",
      "Epoch-464  80 batches\tloss 0.6976 (0.6921)\taccu 48.438 (52.324)\n",
      "Epoch-464 100 batches\tloss 0.6890 (0.6919)\taccu 56.250 (52.688)\n",
      "Epoch-464 120 batches\tloss 0.6914 (0.6920)\taccu 48.438 (52.435)\n",
      "Epoch-464 140 batches\tloss 0.6933 (0.6920)\taccu 53.125 (52.600)\n",
      "Epoch-464 38.4s\tTrain: loss 0.6918\taccu 52.6943\tValid: loss 0.6938\taccu 50.1803\n",
      "Epoch 464: val_acc did not improve\n",
      "464 1.0000000000000002e-06\n",
      "Epoch-465  20 batches\tloss 0.6896 (0.6930)\taccu 51.562 (51.719)\n",
      "Epoch-465  40 batches\tloss 0.6876 (0.6925)\taccu 64.062 (52.461)\n",
      "Epoch-465  60 batches\tloss 0.6924 (0.6924)\taccu 50.000 (52.578)\n",
      "Epoch-465  80 batches\tloss 0.6870 (0.6925)\taccu 64.062 (52.422)\n",
      "Epoch-465 100 batches\tloss 0.6863 (0.6925)\taccu 60.938 (52.422)\n",
      "Epoch-465 120 batches\tloss 0.6949 (0.6922)\taccu 45.312 (52.591)\n",
      "Epoch-465 140 batches\tloss 0.6857 (0.6920)\taccu 54.688 (52.779)\n",
      "Epoch-465 38.5s\tTrain: loss 0.6921\taccu 52.7043\tValid: loss 0.6937\taccu 50.4407\n",
      "Epoch 465: val_acc did not improve\n",
      "465 1.0000000000000002e-06\n",
      "Epoch-466  20 batches\tloss 0.6978 (0.6922)\taccu 48.438 (52.031)\n",
      "Epoch-466  40 batches\tloss 0.6910 (0.6916)\taccu 59.375 (52.695)\n",
      "Epoch-466  60 batches\tloss 0.6850 (0.6919)\taccu 62.500 (52.292)\n",
      "Epoch-466  80 batches\tloss 0.6896 (0.6917)\taccu 57.812 (52.520)\n",
      "Epoch-466 100 batches\tloss 0.6932 (0.6916)\taccu 51.562 (53.000)\n",
      "Epoch-466 120 batches\tloss 0.6872 (0.6916)\taccu 54.688 (52.956)\n",
      "Epoch-466 140 batches\tloss 0.6907 (0.6915)\taccu 48.438 (53.181)\n",
      "Epoch-466 38.5s\tTrain: loss 0.6917\taccu 52.9848\tValid: loss 0.6938\taccu 50.5709\n",
      "Epoch 466: val_acc did not improve\n",
      "466 1.0000000000000002e-06\n",
      "Epoch-467  20 batches\tloss 0.6919 (0.6908)\taccu 53.125 (53.672)\n",
      "Epoch-467  40 batches\tloss 0.6992 (0.6914)\taccu 45.312 (53.164)\n",
      "Epoch-467  60 batches\tloss 0.6963 (0.6907)\taccu 46.875 (53.984)\n",
      "Epoch-467  80 batches\tloss 0.7036 (0.6915)\taccu 37.500 (53.125)\n",
      "Epoch-467 100 batches\tloss 0.6974 (0.6918)\taccu 46.875 (52.688)\n",
      "Epoch-467 120 batches\tloss 0.6927 (0.6921)\taccu 50.000 (52.305)\n",
      "Epoch-467 140 batches\tloss 0.6850 (0.6918)\taccu 57.812 (52.533)\n",
      "Epoch-467 38.8s\tTrain: loss 0.6919\taccu 52.5841\tValid: loss 0.6939\taccu 50.1002\n",
      "Epoch 467: val_acc did not improve\n",
      "467 1.0000000000000002e-06\n",
      "Epoch-468  20 batches\tloss 0.6925 (0.6904)\taccu 48.438 (53.750)\n",
      "Epoch-468  40 batches\tloss 0.7022 (0.6911)\taccu 43.750 (53.555)\n",
      "Epoch-468  60 batches\tloss 0.6875 (0.6919)\taccu 59.375 (52.917)\n",
      "Epoch-468  80 batches\tloss 0.6841 (0.6921)\taccu 57.812 (52.617)\n",
      "Epoch-468 100 batches\tloss 0.6875 (0.6923)\taccu 59.375 (52.328)\n",
      "Epoch-468 120 batches\tloss 0.6943 (0.6922)\taccu 51.562 (52.305)\n",
      "Epoch-468 140 batches\tloss 0.6875 (0.6921)\taccu 59.375 (52.533)\n",
      "Epoch-468 38.7s\tTrain: loss 0.6919\taccu 52.6643\tValid: loss 0.6939\taccu 49.8598\n",
      "Epoch 468: val_acc did not improve\n",
      "468 1.0000000000000002e-06\n",
      "Epoch-469  20 batches\tloss 0.6824 (0.6925)\taccu 60.938 (52.344)\n",
      "Epoch-469  40 batches\tloss 0.6866 (0.6917)\taccu 60.938 (52.773)\n",
      "Epoch-469  60 batches\tloss 0.6958 (0.6917)\taccu 45.312 (52.552)\n",
      "Epoch-469  80 batches\tloss 0.6859 (0.6918)\taccu 57.812 (53.027)\n",
      "Epoch-469 100 batches\tloss 0.6850 (0.6920)\taccu 64.062 (52.422)\n",
      "Epoch-469 120 batches\tloss 0.6977 (0.6919)\taccu 43.750 (52.370)\n",
      "Epoch-469 140 batches\tloss 0.6940 (0.6916)\taccu 53.125 (52.712)\n",
      "Epoch-469 38.5s\tTrain: loss 0.6918\taccu 52.5741\tValid: loss 0.6937\taccu 50.5308\n",
      "Epoch 469: val_acc did not improve\n",
      "469 1.0000000000000002e-06\n",
      "Epoch-470  20 batches\tloss 0.6989 (0.6917)\taccu 43.750 (51.562)\n",
      "Epoch-470  40 batches\tloss 0.6961 (0.6918)\taccu 46.875 (52.109)\n",
      "Epoch-470  60 batches\tloss 0.7029 (0.6920)\taccu 39.062 (52.005)\n",
      "Epoch-470  80 batches\tloss 0.6885 (0.6922)\taccu 57.812 (52.070)\n",
      "Epoch-470 100 batches\tloss 0.6960 (0.6921)\taccu 54.688 (52.344)\n",
      "Epoch-470 120 batches\tloss 0.6922 (0.6919)\taccu 54.688 (52.370)\n",
      "Epoch-470 140 batches\tloss 0.6910 (0.6917)\taccu 54.688 (52.600)\n",
      "Epoch-470 38.6s\tTrain: loss 0.6916\taccu 52.7043\tValid: loss 0.6938\taccu 50.2103\n",
      "Epoch 470: val_acc did not improve\n",
      "470 1.0000000000000002e-06\n",
      "Epoch-471  20 batches\tloss 0.6890 (0.6905)\taccu 54.688 (53.281)\n",
      "Epoch-471  40 batches\tloss 0.6925 (0.6918)\taccu 57.812 (52.852)\n",
      "Epoch-471  60 batches\tloss 0.6979 (0.6918)\taccu 50.000 (52.813)\n",
      "Epoch-471  80 batches\tloss 0.6907 (0.6918)\taccu 54.688 (52.734)\n",
      "Epoch-471 100 batches\tloss 0.6995 (0.6920)\taccu 42.188 (52.516)\n",
      "Epoch-471 120 batches\tloss 0.6904 (0.6921)\taccu 56.250 (52.422)\n",
      "Epoch-471 140 batches\tloss 0.6962 (0.6921)\taccu 43.750 (52.634)\n",
      "Epoch-471 38.5s\tTrain: loss 0.6920\taccu 52.7544\tValid: loss 0.6938\taccu 50.6911\n",
      "Epoch 471: val_acc did not improve\n",
      "471 1.0000000000000002e-06\n",
      "Epoch-472  20 batches\tloss 0.6911 (0.6913)\taccu 56.250 (53.828)\n",
      "Epoch-472  40 batches\tloss 0.6878 (0.6909)\taccu 56.250 (54.883)\n",
      "Epoch-472  60 batches\tloss 0.7007 (0.6913)\taccu 43.750 (54.036)\n",
      "Epoch-472  80 batches\tloss 0.6915 (0.6917)\taccu 57.812 (53.711)\n",
      "Epoch-472 100 batches\tloss 0.6869 (0.6920)\taccu 56.250 (53.109)\n",
      "Epoch-472 120 batches\tloss 0.6975 (0.6918)\taccu 43.750 (53.333)\n",
      "Epoch-472 140 batches\tloss 0.6934 (0.6918)\taccu 54.688 (53.214)\n",
      "Epoch-472 38.4s\tTrain: loss 0.6917\taccu 53.3854\tValid: loss 0.6938\taccu 50.2103\n",
      "Epoch 472: val_acc did not improve\n",
      "472 1.0000000000000002e-06\n",
      "Epoch-473  20 batches\tloss 0.6900 (0.6908)\taccu 51.562 (52.891)\n",
      "Epoch-473  40 batches\tloss 0.6943 (0.6912)\taccu 46.875 (53.281)\n",
      "Epoch-473  60 batches\tloss 0.6903 (0.6912)\taccu 51.562 (53.672)\n",
      "Epoch-473  80 batches\tloss 0.6912 (0.6914)\taccu 53.125 (53.379)\n",
      "Epoch-473 100 batches\tloss 0.6988 (0.6919)\taccu 48.438 (53.109)\n",
      "Epoch-473 120 batches\tloss 0.6847 (0.6917)\taccu 59.375 (53.372)\n",
      "Epoch-473 140 batches\tloss 0.6949 (0.6917)\taccu 50.000 (53.170)\n",
      "Epoch-473 38.6s\tTrain: loss 0.6918\taccu 52.9447\tValid: loss 0.6937\taccu 50.3205\n",
      "Epoch 473: val_acc did not improve\n",
      "473 1.0000000000000002e-06\n",
      "Epoch-474  20 batches\tloss 0.6873 (0.6907)\taccu 62.500 (53.594)\n",
      "Epoch-474  40 batches\tloss 0.6846 (0.6909)\taccu 64.062 (53.477)\n",
      "Epoch-474  60 batches\tloss 0.6957 (0.6917)\taccu 51.562 (52.917)\n",
      "Epoch-474  80 batches\tloss 0.6872 (0.6918)\taccu 65.625 (52.539)\n",
      "Epoch-474 100 batches\tloss 0.6925 (0.6915)\taccu 48.438 (52.859)\n",
      "Epoch-474 120 batches\tloss 0.6822 (0.6916)\taccu 67.188 (52.721)\n",
      "Epoch-474 140 batches\tloss 0.7050 (0.6919)\taccu 34.375 (52.478)\n",
      "Epoch-474 38.5s\tTrain: loss 0.6919\taccu 52.5942\tValid: loss 0.6938\taccu 50.3405\n",
      "Epoch 474: val_acc did not improve\n",
      "474 1.0000000000000002e-06\n",
      "Epoch-475  20 batches\tloss 0.6948 (0.6916)\taccu 50.000 (53.359)\n",
      "Epoch-475  40 batches\tloss 0.6894 (0.6918)\taccu 56.250 (52.852)\n",
      "Epoch-475  60 batches\tloss 0.6897 (0.6924)\taccu 60.938 (52.370)\n",
      "Epoch-475  80 batches\tloss 0.6899 (0.6926)\taccu 57.812 (52.188)\n",
      "Epoch-475 100 batches\tloss 0.6926 (0.6924)\taccu 57.812 (51.953)\n",
      "Epoch-475 120 batches\tloss 0.6936 (0.6923)\taccu 53.125 (51.940)\n",
      "Epoch-475 140 batches\tloss 0.6896 (0.6921)\taccu 56.250 (52.176)\n",
      "Epoch-475 38.3s\tTrain: loss 0.6920\taccu 52.2236\tValid: loss 0.6938\taccu 50.5709\n",
      "Epoch 475: val_acc did not improve\n",
      "475 1.0000000000000002e-06\n",
      "Epoch-476  20 batches\tloss 0.6959 (0.6918)\taccu 51.562 (53.047)\n",
      "Epoch-476  40 batches\tloss 0.6946 (0.6922)\taccu 46.875 (52.109)\n",
      "Epoch-476  60 batches\tloss 0.6855 (0.6921)\taccu 62.500 (52.370)\n",
      "Epoch-476  80 batches\tloss 0.6917 (0.6924)\taccu 50.000 (52.246)\n",
      "Epoch-476 100 batches\tloss 0.6829 (0.6921)\taccu 65.625 (52.438)\n",
      "Epoch-476 120 batches\tloss 0.6917 (0.6920)\taccu 51.562 (52.409)\n",
      "Epoch-476 140 batches\tloss 0.6888 (0.6920)\taccu 59.375 (52.221)\n",
      "Epoch-476 38.4s\tTrain: loss 0.6918\taccu 52.4038\tValid: loss 0.6937\taccu 50.4808\n",
      "Epoch 476: val_acc did not improve\n",
      "476 1.0000000000000002e-06\n",
      "Epoch-477  20 batches\tloss 0.6919 (0.6907)\taccu 53.125 (52.969)\n",
      "Epoch-477  40 batches\tloss 0.6962 (0.6905)\taccu 43.750 (53.477)\n",
      "Epoch-477  60 batches\tloss 0.6934 (0.6911)\taccu 50.000 (53.047)\n",
      "Epoch-477  80 batches\tloss 0.6966 (0.6912)\taccu 51.562 (53.066)\n",
      "Epoch-477 100 batches\tloss 0.6926 (0.6912)\taccu 56.250 (53.031)\n",
      "Epoch-477 120 batches\tloss 0.6794 (0.6914)\taccu 67.188 (53.060)\n",
      "Epoch-477 140 batches\tloss 0.6867 (0.6918)\taccu 56.250 (52.500)\n",
      "Epoch-477 38.6s\tTrain: loss 0.6917\taccu 52.8446\tValid: loss 0.6937\taccu 50.3005\n",
      "Epoch 477: val_acc did not improve\n",
      "477 1.0000000000000002e-06\n",
      "Epoch-478  20 batches\tloss 0.6897 (0.6912)\taccu 57.812 (53.281)\n",
      "Epoch-478  40 batches\tloss 0.6961 (0.6917)\taccu 53.125 (53.047)\n",
      "Epoch-478  60 batches\tloss 0.6947 (0.6914)\taccu 54.688 (53.594)\n",
      "Epoch-478  80 batches\tloss 0.6891 (0.6914)\taccu 59.375 (53.281)\n",
      "Epoch-478 100 batches\tloss 0.7016 (0.6915)\taccu 43.750 (52.984)\n",
      "Epoch-478 120 batches\tloss 0.6888 (0.6916)\taccu 53.125 (53.021)\n",
      "Epoch-478 140 batches\tloss 0.7001 (0.6916)\taccu 45.312 (53.125)\n",
      "Epoch-478 38.3s\tTrain: loss 0.6917\taccu 52.9848\tValid: loss 0.6938\taccu 50.5208\n",
      "Epoch 478: val_acc did not improve\n",
      "478 1.0000000000000002e-06\n",
      "Epoch-479  20 batches\tloss 0.6868 (0.6906)\taccu 50.000 (53.125)\n",
      "Epoch-479  40 batches\tloss 0.6930 (0.6916)\taccu 50.000 (52.266)\n",
      "Epoch-479  60 batches\tloss 0.6950 (0.6916)\taccu 50.000 (52.604)\n",
      "Epoch-479  80 batches\tloss 0.6952 (0.6916)\taccu 53.125 (52.598)\n",
      "Epoch-479 100 batches\tloss 0.6954 (0.6916)\taccu 54.688 (52.906)\n",
      "Epoch-479 120 batches\tloss 0.6912 (0.6916)\taccu 54.688 (53.099)\n",
      "Epoch-479 140 batches\tloss 0.6864 (0.6915)\taccu 57.812 (53.147)\n",
      "Epoch-479 38.4s\tTrain: loss 0.6917\taccu 52.9247\tValid: loss 0.6939\taccu 50.1202\n",
      "Epoch 479: val_acc did not improve\n",
      "479 1.0000000000000002e-06\n",
      "Epoch-480  20 batches\tloss 0.6921 (0.6910)\taccu 51.562 (52.266)\n",
      "Epoch-480  40 batches\tloss 0.6920 (0.6905)\taccu 48.438 (54.102)\n",
      "Epoch-480  60 batches\tloss 0.6946 (0.6910)\taccu 51.562 (53.750)\n",
      "Epoch-480  80 batches\tloss 0.6965 (0.6913)\taccu 51.562 (53.418)\n",
      "Epoch-480 100 batches\tloss 0.7012 (0.6914)\taccu 42.188 (53.297)\n",
      "Epoch-480 120 batches\tloss 0.6916 (0.6914)\taccu 48.438 (53.307)\n",
      "Epoch-480 140 batches\tloss 0.6954 (0.6915)\taccu 46.875 (53.292)\n",
      "Epoch-480 38.4s\tTrain: loss 0.6919\taccu 52.7344\tValid: loss 0.6939\taccu 50.2404\n",
      "Epoch 480: val_acc did not improve\n",
      "480 1.0000000000000002e-06\n",
      "Epoch-481  20 batches\tloss 0.6910 (0.6908)\taccu 51.562 (53.984)\n",
      "Epoch-481  40 batches\tloss 0.6954 (0.6911)\taccu 43.750 (53.516)\n",
      "Epoch-481  60 batches\tloss 0.6913 (0.6914)\taccu 53.125 (53.177)\n",
      "Epoch-481  80 batches\tloss 0.6922 (0.6918)\taccu 60.938 (52.969)\n",
      "Epoch-481 100 batches\tloss 0.6873 (0.6922)\taccu 56.250 (52.594)\n",
      "Epoch-481 120 batches\tloss 0.6929 (0.6921)\taccu 59.375 (52.734)\n",
      "Epoch-481 140 batches\tloss 0.7016 (0.6921)\taccu 37.500 (52.701)\n",
      "Epoch-481 38.3s\tTrain: loss 0.6919\taccu 52.9848\tValid: loss 0.6937\taccu 50.5409\n",
      "Epoch 481: val_acc did not improve\n",
      "481 1.0000000000000002e-06\n",
      "Epoch-482  20 batches\tloss 0.6927 (0.6923)\taccu 50.000 (51.797)\n",
      "Epoch-482  40 batches\tloss 0.6899 (0.6920)\taccu 62.500 (52.539)\n",
      "Epoch-482  60 batches\tloss 0.7006 (0.6920)\taccu 40.625 (53.151)\n",
      "Epoch-482  80 batches\tloss 0.6895 (0.6918)\taccu 54.688 (53.379)\n",
      "Epoch-482 100 batches\tloss 0.6909 (0.6920)\taccu 57.812 (53.016)\n",
      "Epoch-482 120 batches\tloss 0.6932 (0.6917)\taccu 53.125 (53.190)\n",
      "Epoch-482 140 batches\tloss 0.6966 (0.6918)\taccu 46.875 (52.801)\n",
      "Epoch-482 38.3s\tTrain: loss 0.6919\taccu 52.5341\tValid: loss 0.6937\taccu 50.2905\n",
      "Epoch 482: val_acc did not improve\n",
      "482 1.0000000000000002e-06\n",
      "Epoch-483  20 batches\tloss 0.6964 (0.6927)\taccu 46.875 (51.562)\n",
      "Epoch-483  40 batches\tloss 0.6857 (0.6924)\taccu 62.500 (52.617)\n",
      "Epoch-483  60 batches\tloss 0.6946 (0.6926)\taccu 53.125 (52.396)\n",
      "Epoch-483  80 batches\tloss 0.6853 (0.6919)\taccu 59.375 (52.852)\n",
      "Epoch-483 100 batches\tloss 0.6967 (0.6920)\taccu 51.562 (52.750)\n",
      "Epoch-483 120 batches\tloss 0.6903 (0.6919)\taccu 59.375 (53.034)\n",
      "Epoch-483 140 batches\tloss 0.6874 (0.6917)\taccu 60.938 (53.080)\n",
      "Epoch-483 38.5s\tTrain: loss 0.6919\taccu 52.7845\tValid: loss 0.6939\taccu 50.1903\n",
      "Epoch 483: val_acc did not improve\n",
      "483 1.0000000000000002e-06\n",
      "Epoch-484  20 batches\tloss 0.6893 (0.6918)\taccu 54.688 (53.750)\n",
      "Epoch-484  40 batches\tloss 0.6889 (0.6916)\taccu 59.375 (53.516)\n",
      "Epoch-484  60 batches\tloss 0.6897 (0.6920)\taccu 54.688 (53.359)\n",
      "Epoch-484  80 batches\tloss 0.6843 (0.6920)\taccu 64.062 (53.027)\n",
      "Epoch-484 100 batches\tloss 0.6962 (0.6922)\taccu 46.875 (52.688)\n",
      "Epoch-484 120 batches\tloss 0.6890 (0.6921)\taccu 59.375 (52.617)\n",
      "Epoch-484 140 batches\tloss 0.6810 (0.6920)\taccu 67.188 (52.768)\n",
      "Epoch-484 38.4s\tTrain: loss 0.6919\taccu 52.6542\tValid: loss 0.6937\taccu 50.2304\n",
      "Epoch 484: val_acc did not improve\n",
      "484 1.0000000000000002e-06\n",
      "Epoch-485  20 batches\tloss 0.6887 (0.6927)\taccu 56.250 (51.641)\n",
      "Epoch-485  40 batches\tloss 0.6864 (0.6923)\taccu 57.812 (52.656)\n",
      "Epoch-485  60 batches\tloss 0.6948 (0.6926)\taccu 51.562 (52.422)\n",
      "Epoch-485  80 batches\tloss 0.6952 (0.6925)\taccu 53.125 (52.461)\n",
      "Epoch-485 100 batches\tloss 0.6878 (0.6919)\taccu 54.688 (53.141)\n",
      "Epoch-485 120 batches\tloss 0.6866 (0.6918)\taccu 60.938 (53.529)\n",
      "Epoch-485 140 batches\tloss 0.6857 (0.6918)\taccu 57.812 (53.371)\n",
      "Epoch-485 38.5s\tTrain: loss 0.6919\taccu 53.1250\tValid: loss 0.6937\taccu 50.4908\n",
      "Epoch 485: val_acc did not improve\n",
      "485 1.0000000000000002e-06\n",
      "Epoch-486  20 batches\tloss 0.6920 (0.6926)\taccu 54.688 (51.328)\n",
      "Epoch-486  40 batches\tloss 0.6881 (0.6919)\taccu 56.250 (52.031)\n",
      "Epoch-486  60 batches\tloss 0.6914 (0.6917)\taccu 53.125 (52.135)\n",
      "Epoch-486  80 batches\tloss 0.6910 (0.6916)\taccu 51.562 (52.168)\n",
      "Epoch-486 100 batches\tloss 0.6931 (0.6914)\taccu 54.688 (52.703)\n",
      "Epoch-486 120 batches\tloss 0.6878 (0.6913)\taccu 54.688 (53.008)\n",
      "Epoch-486 140 batches\tloss 0.6893 (0.6915)\taccu 57.812 (52.980)\n",
      "Epoch-486 38.6s\tTrain: loss 0.6916\taccu 53.0148\tValid: loss 0.6939\taccu 49.9599\n",
      "Epoch 486: val_acc did not improve\n",
      "486 1.0000000000000002e-06\n",
      "Epoch-487  20 batches\tloss 0.6940 (0.6921)\taccu 56.250 (52.031)\n",
      "Epoch-487  40 batches\tloss 0.6947 (0.6916)\taccu 51.562 (52.773)\n",
      "Epoch-487  60 batches\tloss 0.6831 (0.6920)\taccu 62.500 (52.370)\n",
      "Epoch-487  80 batches\tloss 0.6930 (0.6917)\taccu 43.750 (52.520)\n",
      "Epoch-487 100 batches\tloss 0.6884 (0.6917)\taccu 51.562 (52.516)\n",
      "Epoch-487 120 batches\tloss 0.6906 (0.6919)\taccu 51.562 (52.370)\n",
      "Epoch-487 140 batches\tloss 0.6898 (0.6920)\taccu 54.688 (52.388)\n",
      "Epoch-487 38.4s\tTrain: loss 0.6921\taccu 52.1334\tValid: loss 0.6938\taccu 50.2704\n",
      "Epoch 487: val_acc did not improve\n",
      "487 1.0000000000000002e-06\n",
      "Epoch-488  20 batches\tloss 0.6970 (0.6915)\taccu 53.125 (53.281)\n",
      "Epoch-488  40 batches\tloss 0.6921 (0.6925)\taccu 54.688 (52.461)\n",
      "Epoch-488  60 batches\tloss 0.6951 (0.6925)\taccu 50.000 (52.135)\n",
      "Epoch-488  80 batches\tloss 0.7005 (0.6926)\taccu 45.312 (52.031)\n",
      "Epoch-488 100 batches\tloss 0.6913 (0.6925)\taccu 50.000 (52.141)\n",
      "Epoch-488 120 batches\tloss 0.6955 (0.6924)\taccu 45.312 (52.083)\n",
      "Epoch-488 140 batches\tloss 0.6904 (0.6922)\taccu 56.250 (52.188)\n",
      "Epoch-488 38.6s\tTrain: loss 0.6920\taccu 52.3337\tValid: loss 0.6937\taccu 50.1202\n",
      "Epoch 488: val_acc did not improve\n",
      "488 1.0000000000000002e-06\n",
      "Epoch-489  20 batches\tloss 0.6928 (0.6927)\taccu 51.562 (52.578)\n",
      "Epoch-489  40 batches\tloss 0.6821 (0.6925)\taccu 60.938 (52.344)\n",
      "Epoch-489  60 batches\tloss 0.6972 (0.6921)\taccu 43.750 (52.786)\n",
      "Epoch-489  80 batches\tloss 0.6922 (0.6921)\taccu 48.438 (52.988)\n",
      "Epoch-489 100 batches\tloss 0.6933 (0.6923)\taccu 53.125 (52.656)\n",
      "Epoch-489 120 batches\tloss 0.6866 (0.6921)\taccu 62.500 (52.799)\n",
      "Epoch-489 140 batches\tloss 0.6916 (0.6921)\taccu 51.562 (52.723)\n",
      "Epoch-489 38.7s\tTrain: loss 0.6920\taccu 52.8145\tValid: loss 0.6937\taccu 50.4708\n",
      "Epoch 489: val_acc did not improve\n",
      "489 1.0000000000000002e-06\n",
      "Epoch-490  20 batches\tloss 0.6943 (0.6930)\taccu 50.000 (50.859)\n",
      "Epoch-490  40 batches\tloss 0.6895 (0.6931)\taccu 56.250 (50.938)\n",
      "Epoch-490  60 batches\tloss 0.6890 (0.6928)\taccu 59.375 (51.484)\n",
      "Epoch-490  80 batches\tloss 0.6906 (0.6923)\taccu 50.000 (51.797)\n",
      "Epoch-490 100 batches\tloss 0.6911 (0.6925)\taccu 50.000 (51.797)\n",
      "Epoch-490 120 batches\tloss 0.6958 (0.6921)\taccu 50.000 (52.539)\n",
      "Epoch-490 140 batches\tloss 0.6883 (0.6921)\taccu 56.250 (52.545)\n",
      "Epoch-490 39.1s\tTrain: loss 0.6920\taccu 52.8045\tValid: loss 0.6937\taccu 50.5208\n",
      "Epoch 490: val_acc did not improve\n",
      "490 1.0000000000000002e-06\n",
      "Epoch-491  20 batches\tloss 0.6947 (0.6915)\taccu 43.750 (52.891)\n",
      "Epoch-491  40 batches\tloss 0.6900 (0.6918)\taccu 51.562 (52.852)\n",
      "Epoch-491  60 batches\tloss 0.6943 (0.6914)\taccu 56.250 (53.542)\n",
      "Epoch-491  80 batches\tloss 0.6941 (0.6922)\taccu 46.875 (52.422)\n",
      "Epoch-491 100 batches\tloss 0.6955 (0.6920)\taccu 54.688 (52.766)\n",
      "Epoch-491 120 batches\tloss 0.6956 (0.6918)\taccu 43.750 (53.008)\n",
      "Epoch-491 140 batches\tloss 0.6858 (0.6917)\taccu 57.812 (53.292)\n",
      "Epoch-491 40.2s\tTrain: loss 0.6917\taccu 53.3353\tValid: loss 0.6936\taccu 50.6410\n",
      "Epoch 491: val_acc did not improve\n",
      "491 1.0000000000000002e-06\n",
      "Epoch-492  20 batches\tloss 0.6984 (0.6917)\taccu 43.750 (52.578)\n",
      "Epoch-492  40 batches\tloss 0.6894 (0.6919)\taccu 48.438 (52.188)\n",
      "Epoch-492  60 batches\tloss 0.6978 (0.6920)\taccu 45.312 (52.161)\n",
      "Epoch-492  80 batches\tloss 0.6885 (0.6919)\taccu 59.375 (52.539)\n",
      "Epoch-492 100 batches\tloss 0.6965 (0.6919)\taccu 45.312 (52.812)\n",
      "Epoch-492 120 batches\tloss 0.6929 (0.6921)\taccu 51.562 (52.552)\n",
      "Epoch-492 140 batches\tloss 0.6878 (0.6918)\taccu 59.375 (52.913)\n",
      "Epoch-492 39.8s\tTrain: loss 0.6917\taccu 52.9848\tValid: loss 0.6937\taccu 50.3906\n",
      "Epoch 492: val_acc did not improve\n",
      "492 1.0000000000000002e-06\n",
      "Epoch-493  20 batches\tloss 0.6994 (0.6936)\taccu 39.062 (50.859)\n",
      "Epoch-493  40 batches\tloss 0.6868 (0.6920)\taccu 53.125 (52.305)\n",
      "Epoch-493  60 batches\tloss 0.6936 (0.6917)\taccu 50.000 (52.396)\n",
      "Epoch-493  80 batches\tloss 0.6977 (0.6918)\taccu 40.625 (52.441)\n",
      "Epoch-493 100 batches\tloss 0.6939 (0.6921)\taccu 53.125 (52.375)\n",
      "Epoch-493 120 batches\tloss 0.6887 (0.6917)\taccu 57.812 (52.982)\n",
      "Epoch-493 140 batches\tloss 0.6857 (0.6917)\taccu 57.812 (52.902)\n",
      "Epoch-493 38.6s\tTrain: loss 0.6916\taccu 52.8546\tValid: loss 0.6938\taccu 50.2604\n",
      "Epoch 493: val_acc did not improve\n",
      "493 1.0000000000000002e-06\n",
      "Epoch-494  20 batches\tloss 0.6995 (0.6935)\taccu 42.188 (51.016)\n",
      "Epoch-494  40 batches\tloss 0.6916 (0.6926)\taccu 56.250 (51.875)\n",
      "Epoch-494  60 batches\tloss 0.6848 (0.6919)\taccu 65.625 (52.708)\n",
      "Epoch-494  80 batches\tloss 0.6943 (0.6918)\taccu 50.000 (52.793)\n",
      "Epoch-494 100 batches\tloss 0.6930 (0.6916)\taccu 45.312 (52.656)\n",
      "Epoch-494 120 batches\tloss 0.6869 (0.6915)\taccu 54.688 (52.917)\n",
      "Epoch-494 140 batches\tloss 0.6917 (0.6916)\taccu 51.562 (52.924)\n",
      "Epoch-494 38.3s\tTrain: loss 0.6918\taccu 52.8345\tValid: loss 0.6938\taccu 50.6611\n",
      "Epoch 494: val_acc did not improve\n",
      "494 1.0000000000000002e-06\n",
      "Epoch-495  20 batches\tloss 0.6924 (0.6926)\taccu 51.562 (51.562)\n",
      "Epoch-495  40 batches\tloss 0.6897 (0.6916)\taccu 51.562 (52.930)\n",
      "Epoch-495  60 batches\tloss 0.6876 (0.6920)\taccu 60.938 (52.734)\n",
      "Epoch-495  80 batches\tloss 0.6908 (0.6921)\taccu 56.250 (52.324)\n",
      "Epoch-495 100 batches\tloss 0.6906 (0.6917)\taccu 56.250 (52.797)\n",
      "Epoch-495 120 batches\tloss 0.6894 (0.6916)\taccu 57.812 (52.813)\n",
      "Epoch-495 140 batches\tloss 0.6942 (0.6918)\taccu 51.562 (52.712)\n",
      "Epoch-495 38.6s\tTrain: loss 0.6918\taccu 52.4639\tValid: loss 0.6937\taccu 50.5208\n",
      "Epoch 495: val_acc did not improve\n",
      "495 1.0000000000000002e-06\n",
      "Epoch-496  20 batches\tloss 0.6948 (0.6912)\taccu 50.000 (54.062)\n",
      "Epoch-496  40 batches\tloss 0.6933 (0.6915)\taccu 51.562 (53.555)\n",
      "Epoch-496  60 batches\tloss 0.6960 (0.6916)\taccu 40.625 (52.865)\n",
      "Epoch-496  80 batches\tloss 0.6934 (0.6919)\taccu 54.688 (52.266)\n",
      "Epoch-496 100 batches\tloss 0.6943 (0.6919)\taccu 51.562 (52.609)\n",
      "Epoch-496 120 batches\tloss 0.6950 (0.6917)\taccu 42.188 (52.826)\n",
      "Epoch-496 140 batches\tloss 0.6942 (0.6918)\taccu 54.688 (52.746)\n",
      "Epoch-496 38.3s\tTrain: loss 0.6919\taccu 52.5040\tValid: loss 0.6937\taccu 50.2704\n",
      "Epoch 496: val_acc did not improve\n",
      "496 1.0000000000000002e-06\n",
      "Epoch-497  20 batches\tloss 0.6962 (0.6896)\taccu 42.188 (54.453)\n",
      "Epoch-497  40 batches\tloss 0.6852 (0.6903)\taccu 57.812 (53.711)\n",
      "Epoch-497  60 batches\tloss 0.6900 (0.6910)\taccu 48.438 (52.995)\n",
      "Epoch-497  80 batches\tloss 0.6853 (0.6916)\taccu 59.375 (52.500)\n",
      "Epoch-497 100 batches\tloss 0.6933 (0.6913)\taccu 50.000 (52.672)\n",
      "Epoch-497 120 batches\tloss 0.6914 (0.6912)\taccu 57.812 (53.255)\n",
      "Epoch-497 140 batches\tloss 0.6967 (0.6914)\taccu 46.875 (52.924)\n",
      "Epoch-497 38.3s\tTrain: loss 0.6915\taccu 52.7143\tValid: loss 0.6938\taccu 50.1803\n",
      "Epoch 497: val_acc did not improve\n",
      "497 1.0000000000000002e-06\n",
      "Epoch-498  20 batches\tloss 0.6917 (0.6921)\taccu 53.125 (53.438)\n",
      "Epoch-498  40 batches\tloss 0.6951 (0.6916)\taccu 43.750 (53.398)\n",
      "Epoch-498  60 batches\tloss 0.6953 (0.6918)\taccu 53.125 (53.438)\n",
      "Epoch-498  80 batches\tloss 0.6887 (0.6921)\taccu 59.375 (53.242)\n",
      "Epoch-498 100 batches\tloss 0.6912 (0.6923)\taccu 59.375 (52.750)\n",
      "Epoch-498 120 batches\tloss 0.6802 (0.6922)\taccu 65.625 (52.565)\n",
      "Epoch-498 140 batches\tloss 0.6964 (0.6917)\taccu 46.875 (52.812)\n",
      "Epoch-498 38.6s\tTrain: loss 0.6915\taccu 53.1951\tValid: loss 0.6937\taccu 50.3405\n",
      "Epoch 498: val_acc did not improve\n",
      "498 1.0000000000000002e-06\n",
      "Epoch-499  20 batches\tloss 0.6895 (0.6909)\taccu 56.250 (53.828)\n",
      "Epoch-499  40 batches\tloss 0.6841 (0.6916)\taccu 60.938 (52.734)\n",
      "Epoch-499  60 batches\tloss 0.6964 (0.6918)\taccu 46.875 (52.656)\n",
      "Epoch-499  80 batches\tloss 0.6994 (0.6919)\taccu 43.750 (52.461)\n",
      "Epoch-499 100 batches\tloss 0.6881 (0.6915)\taccu 56.250 (52.969)\n",
      "Epoch-499 120 batches\tloss 0.6837 (0.6916)\taccu 60.938 (52.995)\n",
      "Epoch-499 140 batches\tloss 0.6889 (0.6918)\taccu 54.688 (52.589)\n",
      "Epoch-499 38.4s\tTrain: loss 0.6919\taccu 52.6542\tValid: loss 0.6939\taccu 50.4207\n",
      "Epoch 499: val_acc did not improve\n",
      "499 1.0000000000000002e-06\n",
      "Epoch-500  20 batches\tloss 0.6941 (0.6906)\taccu 51.562 (54.609)\n",
      "Epoch-500  40 batches\tloss 0.6952 (0.6910)\taccu 43.750 (53.359)\n",
      "Epoch-500  60 batches\tloss 0.6986 (0.6913)\taccu 50.000 (53.333)\n",
      "Epoch-500  80 batches\tloss 0.6967 (0.6916)\taccu 50.000 (53.379)\n",
      "Epoch-500 100 batches\tloss 0.6920 (0.6916)\taccu 46.875 (53.516)\n",
      "Epoch-500 120 batches\tloss 0.6990 (0.6917)\taccu 50.000 (53.320)\n",
      "Epoch-500 140 batches\tloss 0.6930 (0.6916)\taccu 50.000 (53.248)\n",
      "Epoch-500 38.6s\tTrain: loss 0.6918\taccu 52.8646\tValid: loss 0.6937\taccu 50.1703\n",
      "Epoch 500: val_acc did not improve\n",
      "Best val_acc: 50.8814 from epoch-272\n",
      "Save train and validation log into into ./results/NTU/SGN\\0_log.csv\n",
      "Test: accuracy 50.280, time: 23.41s\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    num_classes = get_num_classes(dataset)\n",
    "    model = SGN(num_classes, dataset, seg, batch_size, do_train)\n",
    "\n",
    "    total = get_n_params(model)\n",
    "    # print(model)\n",
    "    print('The number of parameters: ', total)\n",
    "    print('The modes is:', network)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        print('It is using GPU!')\n",
    "        model = model.cuda()\n",
    "\n",
    "    criterion = LabelSmoothingLoss(num_classes, smoothing=0.1).cuda()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr,\n",
    "                           weight_decay=weight_decay)\n",
    "\n",
    "    if monitor == 'val_acc':\n",
    "        mode = 'max'\n",
    "        monitor_op = np.greater\n",
    "        best = -np.Inf\n",
    "        str_op = 'improve'\n",
    "    elif monitor == 'val_loss':\n",
    "        mode = 'min'\n",
    "        monitor_op = np.less\n",
    "        best = np.Inf\n",
    "        str_op = 'reduce'\n",
    "\n",
    "    scheduler = MultiStepLR(optimizer, milestones=[60, 90, 110], gamma=0.1)\n",
    "    # Data loading\n",
    "    ntu_loaders = NTUDataLoaders(dataset, case, seg=seg, train_X=train_x, train_Y=train_y, test_X=test_x, test_Y=test_y, val_X=val_x, val_Y=val_y, aug=0)\n",
    "    train_loader = ntu_loaders.get_train_loader(batch_size, workers)\n",
    "    val_loader = ntu_loaders.get_val_loader(batch_size, workers)\n",
    "    train_size = ntu_loaders.get_train_size()\n",
    "    val_size = ntu_loaders.get_val_size()\n",
    "\n",
    "    test_loader = ntu_loaders.get_test_loader(32, workers)\n",
    "\n",
    "    print('Train on %d samples, validate on %d samples' %\n",
    "          (train_size, val_size))\n",
    "\n",
    "    best_epoch = 0\n",
    "    output_dir = make_dir(dataset)\n",
    "\n",
    "    save_path = os.path.join(output_dir, network)\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "\n",
    "    checkpoint = osp.join(save_path, '%s_best.pth' % case)\n",
    "    earlystop_cnt = 0\n",
    "    csv_file = osp.join(save_path, '%s_log.csv' % case)\n",
    "    log_res = list()\n",
    "\n",
    "    lable_path = osp.join(save_path, '%s_lable.txt' % case)\n",
    "    pred_path = osp.join(save_path, '%s_pred.txt' % case)\n",
    "\n",
    "    # Training\n",
    "    if do_train == 1:\n",
    "        for epoch in range(start_epoch, max_epochs):\n",
    "\n",
    "            print(epoch, optimizer.param_groups[0]['lr'])\n",
    "\n",
    "            t_start = time.time()\n",
    "            train_loss, train_acc = train(\n",
    "                train_loader, model, criterion, optimizer, epoch)\n",
    "            val_loss, val_acc = validate(val_loader, model, criterion)\n",
    "            log_res += [[train_loss, train_acc.cpu().numpy(),\n",
    "                         val_loss, val_acc.cpu().numpy()]]\n",
    "\n",
    "            print('Epoch-{:<3d} {:.1f}s\\t'\n",
    "                  'Train: loss {:.4f}\\taccu {:.4f}\\tValid: loss {:.4f}\\taccu {:.4f}'\n",
    "                  .format(epoch + 1, time.time() - t_start, train_loss, train_acc, val_loss, val_acc))\n",
    "\n",
    "            current = val_loss if mode == 'min' else val_acc\n",
    "\n",
    "            # store tensor in cpu\n",
    "            current = current.cpu()\n",
    "\n",
    "            if monitor_op(current, best):\n",
    "                print('Epoch %d: %s %sd from %.4f to %.4f, '\n",
    "                      'saving model to %s'\n",
    "                      % (epoch + 1, monitor, str_op, best, current, checkpoint))\n",
    "                best = current\n",
    "                best_epoch = epoch + 1\n",
    "                save_checkpoint({\n",
    "                    'epoch': epoch + 1,\n",
    "                    'state_dict': model.state_dict(),\n",
    "                    'best': best,\n",
    "                    'monitor': monitor,\n",
    "                    'optimizer': optimizer.state_dict(),\n",
    "                }, checkpoint)\n",
    "                earlystop_cnt = 0\n",
    "            else:\n",
    "                print('Epoch %d: %s did not %s' % (epoch + 1, monitor, str_op))\n",
    "                earlystop_cnt += 1\n",
    "\n",
    "            scheduler.step()\n",
    "\n",
    "        print('Best %s: %.4f from epoch-%d' % (monitor, best, best_epoch))\n",
    "        with open(csv_file, 'w') as fw:\n",
    "            cw = csv.writer(fw)\n",
    "            cw.writerow(['loss', 'acc', 'val_loss', 'val_acc'])\n",
    "            cw.writerows(log_res)\n",
    "        print('Save train and validation log into into %s' % csv_file)\n",
    "\n",
    "    # Test\n",
    "    model = SGN(num_classes, dataset, seg, batch_size, 0)\n",
    "    model = model.cuda()\n",
    "    test(test_loader, model, checkpoint, lable_path, pred_path)\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
