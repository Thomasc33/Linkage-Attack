{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = {file_name: (frames, joints (xyz) * 25)}\n",
    "with open('X.pkl', 'rb') as f:\n",
    "    X_raw = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 63\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[39m# Flatten Video\u001b[39;00m\n\u001b[0;32m     62\u001b[0m video1 \u001b[39m=\u001b[39m video1\u001b[39m.\u001b[39mflatten()\n\u001b[1;32m---> 63\u001b[0m video2 \u001b[39m=\u001b[39m video2\u001b[39m.\u001b[39;49mflatten()\n\u001b[0;32m     65\u001b[0m \u001b[39m# Add to train\u001b[39;00m\n\u001b[0;32m     66\u001b[0m train\u001b[39m.\u001b[39mappend({actor: video1, random_actor: video2, \u001b[39m'\u001b[39m\u001b[39mis_same\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mFalse\u001b[39;00m})\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_x = {}\n",
    "test_x = {}\n",
    "\n",
    "# [{actor1: [frame], actor2: [frame]}]\n",
    "train = []\n",
    "test = [] \n",
    "same_samples_per_actor = 5000\n",
    "diff_samples_per_actor = 5000\n",
    "\n",
    "for file in X_raw:\n",
    "    actor = int(file[9:12])\n",
    "    action = int(file[17:20])\n",
    "    \n",
    "    is_train = action <= 60\n",
    "    if is_train:\n",
    "        if actor not in train_x:\n",
    "            train_x[actor] = []\n",
    "        if len(X_raw[file]) == 0:\n",
    "            continue\n",
    "        train_x[actor].append(X_raw[file])\n",
    "    else:\n",
    "        if actor not in test_x:\n",
    "            test_x[actor] = []\n",
    "        if len(X_raw[file]) == 0:\n",
    "            continue\n",
    "        test_x[actor].append(X_raw[file])\n",
    "\n",
    "for actor in train_x:\n",
    "    for i in range(same_samples_per_actor):\n",
    "        # Randomly select 2 frames from the same actor\n",
    "        video1 = random.choice(train_x[actor])\n",
    "        video2 = random.choice(train_x[actor])\n",
    "\n",
    "        # Pad or clip video to 50 frames\n",
    "        if len(video1) < 50: video1 = np.pad(video1, ((0, 50 - len(video1)), (0, 0)), 'constant')\n",
    "        elif len(video1) > 50: video1 = video1[:50]\n",
    "        if len(video2) < 50: video2 = np.pad(video2, ((0, 50 - len(video2)), (0, 0)), 'constant')\n",
    "        elif len(video2) > 50: video2 = video2[:50]\n",
    "        \n",
    "        # Flatten Video\n",
    "        video1 = video1.flatten()\n",
    "        video2 = video2.flatten()\n",
    "\n",
    "        # Add to train\n",
    "        train.append({actor: np.array([video1, video2]), 'is_same': True})\n",
    "\n",
    "    for i in range(diff_samples_per_actor):\n",
    "        # Randomly select 2 frames from different actors\n",
    "        while True: # Make sure the 2 frames are not from the same actor\n",
    "            random_actor = random.choice(list(train_x.keys()))\n",
    "            if random_actor != actor:\n",
    "                video1 = random.choice(train_x[actor])\n",
    "                video2 = random.choice(train_x[random_actor])\n",
    "\n",
    "                # Pad or clip video to 50 frames\n",
    "                if len(video1) < 50: video1 = np.pad(video1, ((0, 50 - len(video1)), (0, 0)), 'constant')\n",
    "                elif len(video1) > 50: video1 = video1[:50]\n",
    "                if len(video2) < 50: video2 = np.pad(video2, ((0, 50 - len(video2)), (0, 0)), 'constant')\n",
    "                elif len(video2) > 50: video2 = video2[:50]\n",
    "\n",
    "                # Flatten Video\n",
    "                video1 = video1.flatten()\n",
    "                video2 = video2.flatten()\n",
    "\n",
    "                # Add to train\n",
    "                train.append({actor: video1, random_actor: video2, 'is_same': False})\n",
    "                break\n",
    "\n",
    "for actor in test_x:\n",
    "    for i in range(same_samples_per_actor):\n",
    "        # Randomly select 2 frames from the same actor\n",
    "        video1 = random.choice(test_x[actor])\n",
    "        video2 = random.choice(test_x[actor])\n",
    "\n",
    "        # Pad or clip video to 50 frames\n",
    "        if len(video1) < 50: video1 = np.pad(video1, ((0, 50 - len(video1)), (0, 0)), 'constant')\n",
    "        elif len(video1) > 50: video1 = video1[:50]\n",
    "        if len(video2) < 50: video2 = np.pad(video2, ((0, 50 - len(video2)), (0, 0)), 'constant')\n",
    "        elif len(video2) > 50: video2 = video2[:50]\n",
    "\n",
    "        # Flatten Video\n",
    "        video1 = video1.flatten()\n",
    "        video2 = video2.flatten()\n",
    "\n",
    "        # Add to test\n",
    "        test.append({actor: np.array([video1, video2]), 'is_same': True})\n",
    "\n",
    "    for i in range(diff_samples_per_actor):\n",
    "        # Randomly select 2 frames from different actors\n",
    "        while True: # Make sure the 2 frames are not from the same actor\n",
    "            random_actor = random.choice(list(test_x.keys()))\n",
    "            if random_actor != actor:\n",
    "                video1 = random.choice(test_x[actor])\n",
    "                video2 = random.choice(test_x[random_actor])\n",
    "                \n",
    "                # Pad or clip video to 50 frames\n",
    "                if len(video1) < 50: video1 = np.pad(video1, ((0, 50 - len(video1)), (0, 0)), 'constant')\n",
    "                elif len(video1) > 50: video1 = video1[:50]\n",
    "                if len(video2) < 50: video2 = np.pad(video2, ((0, 50 - len(video2)), (0, 0)), 'constant')\n",
    "                elif len(video2) > 50: video2 = video2[:50]\n",
    "                \n",
    "                # Flatten Video\n",
    "                video1 = video1.flatten()\n",
    "                video2 = video2.flatten()\n",
    "\n",
    "                # Add to test\n",
    "                test.append({actor: video1, random_actor: video2, 'is_same': False})\n",
    "                break\n",
    "\n",
    "train = np.array(train)\n",
    "test = np.array(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for sample in train:\n",
    "    if sample['is_same']:\n",
    "        for actor in sample:\n",
    "            if actor != 'is_same':\n",
    "                X_train.append(np.concatenate([sample[actor][0], sample[actor][1]]))\n",
    "        y_train.append(1)\n",
    "    else:\n",
    "        temp = []\n",
    "        for actor in sample:\n",
    "            if actor != 'is_same':\n",
    "                temp.append(sample[actor])\n",
    "        X_train.append(np.concatenate(temp))\n",
    "        y_train.append(0)\n",
    "\n",
    "# X_train = np.array(X_train)\n",
    "# y_train = np.array(y_train)\n",
    "\n",
    "# I'll do a grid search later\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=30, random_state=42)\n",
    "# clf.fit(X_train, y_train)\n",
    "\n",
    "# Test\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for sample in test:\n",
    "    if sample['is_same']:\n",
    "        for actor in sample:\n",
    "            if actor != 'is_same':\n",
    "                X_test.append(np.concatenate([sample[actor][0], sample[actor][1]]))\n",
    "        y_test.append(1)\n",
    "    else:\n",
    "        temp = []\n",
    "        for actor in sample:\n",
    "            if actor != 'is_same':\n",
    "                temp.append(sample[actor])\n",
    "        X_test.append(np.concatenate(temp))\n",
    "        y_test.append(0)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "# y_pred = clf.predict(X_test)\n",
    "\n",
    "# print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "# print('Precision: ', precision_score(y_test, y_pred))\n",
    "# print('Recall: ', recall_score(y_test, y_pred))\n",
    "# print('F1 Score: ', f1_score(y_test, y_pred))\n",
    "# print('Confusion Matrix:\\n', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.6998275362318841\n",
      "Precision:  0.7058582890654627\n",
      "Recall:  0.6851797101449275\n",
      "F1 Score:  0.6953653001281084\n",
      "Confusion Matrix:\n",
      " [[246494  98506]\n",
      " [108613 236387]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=(1000, 100, 100), max_iter=1000, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred))\n",
    "print('Recall: ', recall_score(y_test, y_pred))\n",
    "print('F1 Score: ', f1_score(y_test, y_pred))\n",
    "print('Confusion Matrix:\\n', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Carrt\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.499895652173913\n",
      "Precision:  0.499901655466317\n",
      "Recall:  0.5304173913043478\n",
      "F1 Score:  0.5147076196101594\n",
      "Confusion Matrix:\n",
      " [[161934 183066]\n",
      " [162006 182994]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf_lr = LogisticRegression(random_state=42)\n",
    "clf_lr.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf_lr.predict(X_test)\n",
    "\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred))\n",
    "print('Recall: ', recall_score(y_test, y_pred))\n",
    "print('F1 Score: ', f1_score(y_test, y_pred))\n",
    "print('Confusion Matrix:\\n', confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mlp_classifier.pkl', 'wb') as f:\n",
    "    pickle.dump(clf, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "063dd9079dbbbc7ce9a24508feb60cfa7f5aa9bc9e0c912b3996301118c4566f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
