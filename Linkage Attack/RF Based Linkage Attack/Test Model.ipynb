{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_path = ''\n",
    "# x_path = 'C:/Users/Carrt/OneDrive/Code/Motion Privacy/Defense Models/Mean Skeleton/X_FileNameKey_SingleActor.pkl'\n",
    "# x_path = 'C:\\\\Users\\\\Carrt\\\\OneDrive\\\\Code\\\\Motion Privacy\\\\External Repositories\\\\Skeleton-anonymization\\\\X_resnet_file.pkl'\n",
    "x_path = 'C:\\\\Users\\\\Carrt\\\\OneDrive\\\\Code\\\\Motion Privacy\\\\External Repositories\\\\Skeleton-anonymization\\\\X_unet_file.pkl'\n",
    "\n",
    "with open(x_path, 'rb') as f:\n",
    "    X = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No overlap\n",
    "# val_files = 'C:\\\\Users\\\\Carrt\\\\OneDrive\\\\Code\\\\Motion Privacy\\\\Linkage Attack\\\\SGN Based Linkage Attack\\\\data\\\\ntu120_no_dupe_actors.pkl'\n",
    "\n",
    "# Overlap\n",
    "# val_files = 'C:\\\\Users\\\\Carrt\\\\OneDrive\\\\Code\\\\Motion Privacy\\\\Linkage Attack\\\\SGN Based Linkage Attack\\\\data\\\\ntu120.pkl'\n",
    "\n",
    "# Testing Data\n",
    "val_files = 'C:\\\\Users\\\\Carrt\\\\OneDrive\\\\Code\\\\Motion Privacy\\\\Skeleton Info\\\\File Sorting\\\\ntu60.pkl'\n",
    "\n",
    "# All Data\n",
    "# val_files = 'data/ntu120.pkl'\n",
    "\n",
    "with open(val_files, 'rb') as f:\n",
    "    files_ = pickle.load(f)\n",
    "\n",
    "to_del = []\n",
    "for file in X:\n",
    "    if file not in files_:\n",
    "        to_del.append(file)\n",
    "\n",
    "for file in to_del:\n",
    "    del X[file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def anonymizer_to_sgn(t, max_frames=300):\n",
    "    # (300, 150)\n",
    "    # [x:0,y:1,z:2][300][joints][actors]\n",
    "    xyz,frames,joints,actors = t.shape\n",
    "    # transpose to make loop simple\n",
    "    # [frame][actors][joints][xyz]\n",
    "    t = t.transpose(1,3,2,0)\n",
    "    # make empty array\n",
    "    frames = []\n",
    "    \n",
    "    joints_per_frame = xyz*joints*actors\n",
    "    \n",
    "    # crazy loop\n",
    "    for frame in t:\n",
    "        f = []\n",
    "        for actor in frame:\n",
    "            for joint in actor:\n",
    "                for xyz in joint:\n",
    "                    f.append(xyz)\n",
    "        \n",
    "        # Pad 0's to 150 joints (2 actors)\n",
    "        if len(f) < joints_per_frame:\n",
    "            f = np.pad(f, (0, joints_per_frame-len(f)), 'constant')\n",
    "            \n",
    "        frames.append(f)\n",
    "        \n",
    "    # to numpy array\n",
    "    X = np.array(frames, dtype=np.float32)\n",
    "    \n",
    "    if X.shape[0] < max_frames:\n",
    "        X = np.pad(X, ((0, max_frames-X.shape[0]), (0, 0)), 'constant')\n",
    "        \n",
    "    return X\n",
    "\n",
    "if 'External Repositories' in x_path:\n",
    "    X = {k: v[0] for k, v in X.items()}\n",
    "\n",
    "    for file in X:\n",
    "        X[file] = anonymizer_to_sgn(X[file])[:50,:75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8869375ed7b044818dc4c9dade4a3597",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_x = {}\n",
    "\n",
    "# [{actor1: [frame], actor2: [frame]}]\n",
    "test = [] \n",
    "same_samples_per_actor = 250\n",
    "diff_samples_per_actor = 250\n",
    "\n",
    "actor_data = {}\n",
    "for file in X:\n",
    "    actor = int(file[9:12])\n",
    "    action = int(file[17:20])\n",
    "\n",
    "    if actor not in actor_data:\n",
    "        actor_data[actor] = []\n",
    "    if len(X[file]) == 0:\n",
    "        continue\n",
    "    actor_data[actor].append(X[file])\n",
    "\n",
    "actor_keys = list(actor_data.keys())\n",
    "\n",
    "for actor in tqdm(actor_keys):\n",
    "    for i in range(same_samples_per_actor):\n",
    "        # Randomly select 2 frames from the same actor\n",
    "        video1 = random.choice(actor_data[actor])\n",
    "        video2 = random.choice(actor_data[actor])\n",
    "\n",
    "        # Pad or clip video to 50 frames\n",
    "        if len(video1) < 50: video1 = np.pad(video1, ((0, 50 - len(video1)), (0, 0)), 'constant')\n",
    "        elif len(video1) > 50: video1 = video1[:50]\n",
    "        if len(video2) < 50: video2 = np.pad(video2, ((0, 50 - len(video2)), (0, 0)), 'constant')\n",
    "        elif len(video2) > 50: video2 = video2[:50]\n",
    "\n",
    "        # Flatten Video\n",
    "        video1 = video1.flatten()\n",
    "        video2 = video2.flatten()\n",
    "\n",
    "        # Add to test\n",
    "        test.append({actor: np.array([video1, video2]), 'is_same': True})\n",
    "\n",
    "    for i in range(diff_samples_per_actor):\n",
    "        # Randomly select 2 frames from different actors\n",
    "        while True: # Make sure the 2 frames are not from the same actor\n",
    "            random_actor = random.choice(actor_keys)\n",
    "            if random_actor != actor:\n",
    "                video1 = random.choice(actor_data[actor])\n",
    "                video2 = random.choice(actor_data[random_actor])\n",
    "                \n",
    "                # Pad or clip video to 50 frames\n",
    "                if len(video1) < 50: video1 = np.pad(video1, ((0, 50 - len(video1)), (0, 0)), 'constant')\n",
    "                elif len(video1) > 50: video1 = video1[:50]\n",
    "                if len(video2) < 50: video2 = np.pad(video2, ((0, 50 - len(video2)), (0, 0)), 'constant')\n",
    "                elif len(video2) > 50: video2 = video2[:50]\n",
    "                \n",
    "                # Flatten Video\n",
    "                video1 = video1.flatten()\n",
    "                video2 = video2.flatten()\n",
    "\n",
    "                # Add to test\n",
    "                test.append({actor: video1, random_actor: video2, 'is_same': False})\n",
    "                break\n",
    "\n",
    "test = np.array(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for sample in test:\n",
    "    if sample['is_same']:\n",
    "        for actor in sample:\n",
    "            if actor != 'is_same':\n",
    "                X_test.append(np.concatenate([sample[actor][0], sample[actor][1]]))\n",
    "        y_test.append(1)\n",
    "    else:\n",
    "        temp = []\n",
    "        for actor in sample:\n",
    "            if actor != 'is_same':\n",
    "                temp.append(sample[actor])\n",
    "        X_test.append(np.concatenate(temp))\n",
    "        y_test.append(0)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('mlp_classifier.pkl', 'rb') as f:\n",
    "    clf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.5068\n",
      "Precision:  0.5080340264650284\n",
      "Recall:  0.43\n",
      "F1 Score:  0.46577123050259966\n",
      "Confusion Matrix:\n",
      " [[5836 4164]\n",
      " [5700 4300]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print('Accuracy: ', accuracy_score(y_test, y_pred))\n",
    "print('Precision: ', precision_score(y_test, y_pred))\n",
    "print('Recall: ', recall_score(y_test, y_pred))\n",
    "print('F1 Score: ', f1_score(y_test, y_pred))\n",
    "print('Confusion Matrix:\\n', confusion_matrix(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
