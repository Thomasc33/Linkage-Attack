{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports / Globals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = '/Users/thomas/Downloads/nturgb+d_skeletons'\n",
    "path = 'D:\\\\Datasets\\\\Motion Privacy\\\\NTU RGB+D 120\\\\Skeleton Data'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data organization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input format\n",
    "\n",
    "[J0 X, J0 Y, J0 Z, J1 X, J1 Y, J1 Z, ..., J25 Z]\n",
    "\n",
    "### Output format\n",
    "0 = Female, 1 = Male"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Genders\n",
    "Genders = pd.read_csv('Genders.csv')\n",
    "\n",
    "# Convert M to 1 and F to 0\n",
    "Genders = Genders.replace('M', 1).replace('F', 0)\n",
    "\n",
    "# Convert dataframe to oject where P is the key, and Gender is the value\n",
    "Genders = Genders.set_index('P').T.to_dict('list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to load X from pickle\n",
      "X loaded from pickle\n",
      "\n",
      "\n",
      "Lengths:\n",
      "P001 (145215, 75)\n",
      "P002 (63629, 75)\n",
      "P003 (108274, 75)\n",
      "P004 (50110, 75)\n",
      "P005 (19615, 75)\n",
      "P006 (67589, 75)\n",
      "P007 (424687, 75)\n",
      "P008 (567014, 75)\n",
      "P009 (53245, 75)\n",
      "P010 (52804, 75)\n",
      "P011 (63254, 75)\n",
      "P012 (27513, 75)\n",
      "P013 (67912, 75)\n",
      "P014 (26187, 75)\n",
      "P015 (291737, 75)\n",
      "P016 (267383, 75)\n",
      "P017 (296334, 75)\n",
      "P018 (146483, 75)\n",
      "P019 (327106, 75)\n",
      "P020 (53474, 75)\n",
      "P021 (86379, 75)\n",
      "P022 (30459, 75)\n",
      "P023 (27174, 75)\n",
      "P024 (26140, 75)\n",
      "P025 (274698, 75)\n",
      "P026 (27311, 75)\n",
      "P027 (112695, 75)\n",
      "P028 (93580, 75)\n",
      "P029 (25443, 75)\n",
      "P030 (21698, 75)\n",
      "P031 (23599, 75)\n",
      "P032 (27625, 75)\n",
      "P033 (24038, 75)\n",
      "P034 (23594, 75)\n",
      "P035 (22215, 75)\n",
      "P036 (22570, 75)\n",
      "P038 (27434, 75)\n",
      "P037 (110918, 75)\n",
      "P039 (46711, 75)\n",
      "P040 (19980, 75)\n",
      "P041 (165442, 75)\n",
      "P042 (69339, 75)\n",
      "P043 (131743, 75)\n",
      "P044 (112484, 75)\n",
      "P045 (18725, 75)\n",
      "P046 (34723, 75)\n",
      "P047 (16625, 75)\n",
      "P048 (63257, 75)\n",
      "P049 (46325, 75)\n",
      "P050 (37917, 75)\n",
      "P051 (54275, 75)\n",
      "P052 (21970, 75)\n",
      "P053 (19426, 75)\n",
      "P054 (18655, 75)\n",
      "P055 (45814, 75)\n",
      "P056 (48023, 75)\n",
      "P057 (42115, 75)\n",
      "P058 (47213, 75)\n",
      "P059 (46166, 75)\n",
      "P060 (43133, 75)\n",
      "P061 (36193, 75)\n",
      "P062 (40575, 75)\n",
      "P063 (41176, 75)\n",
      "P064 (42300, 75)\n",
      "P065 (45384, 75)\n",
      "P066 (43925, 75)\n",
      "P067 (76506, 75)\n",
      "P068 (27294, 75)\n",
      "P069 (18958, 75)\n",
      "P070 (37695, 75)\n",
      "P071 (18548, 75)\n",
      "P072 (14951, 75)\n",
      "P074 (27716, 75)\n",
      "P075 (55512, 75)\n",
      "P076 (32547, 75)\n",
      "P077 (16385, 75)\n",
      "P078 (17645, 75)\n",
      "P079 (15422, 75)\n",
      "P080 (30706, 75)\n",
      "P081 (37379, 75)\n",
      "P082 (25926, 75)\n",
      "P083 (13622, 75)\n",
      "P084 (16850, 75)\n",
      "P085 (45944, 75)\n",
      "P086 (8758, 75)\n",
      "P073 (17770, 75)\n",
      "P087 (15092, 75)\n",
      "P088 (26971, 75)\n",
      "P089 (13011, 75)\n",
      "P090 (14101, 75)\n",
      "P091 (14809, 75)\n",
      "P092 (16358, 75)\n",
      "P093 (17156, 75)\n",
      "P094 (14619, 75)\n",
      "P095 (14642, 75)\n",
      "P096 (30078, 75)\n",
      "P097 (16086, 75)\n",
      "P098 (15194, 75)\n",
      "P099 (15732, 75)\n",
      "P100 (19518, 75)\n",
      "P101 (11565, 75)\n",
      "P102 (17495, 75)\n",
      "P103 (19799, 75)\n",
      "P104 (12998, 75)\n",
      "P105 (15526, 75)\n",
      "P106 (17802, 75)\n"
     ]
    }
   ],
   "source": [
    "# Attempt to load X and Y from pickle before generating them\n",
    "X = {}\n",
    "try:\n",
    "    print('Attempting to load X from pickle')\n",
    "    with open('X.pkl', 'rb') as f:\n",
    "        X = pickle.load(f)\n",
    "    print('X loaded from pickle')\n",
    "except:\n",
    "    print('Could not load X and Y, generating them now')\n",
    "    \n",
    "    # Read the files\n",
    "    files = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "\n",
    "    # Get stats for each file based on name\n",
    "    files_ = []\n",
    "    for file in files:\n",
    "        data = {'file': file,\n",
    "                's': file[0:4],\n",
    "                'c': file[4:8],\n",
    "                'p': file[8:12],\n",
    "                'r': file[12:16],\n",
    "                'a': file[16:20]\n",
    "                }\n",
    "        files_.append(data)\n",
    "\n",
    "    # Generate X and Y\n",
    "    for file_ in tqdm(files_, desc='Files Parsed', position=0):\n",
    "        try:\n",
    "            file = join(path, file_['file'])\n",
    "            data = open(file, 'r')\n",
    "            lines = data.readlines()\n",
    "            frames_count = int(lines.pop(0).replace('\\n', ''))\n",
    "            file_['frames'] = frames_count\n",
    "        except UnicodeDecodeError: # .DS_Store file\n",
    "            print('UnicodeDecodeError: ', file)\n",
    "            continue\n",
    "\n",
    "        # Get P and add to X if not already there\n",
    "        p = file_['p']\n",
    "        if p not in X:\n",
    "            X[p] = []\n",
    "\n",
    "        # Skip file if 2 actors\n",
    "        if lines[0].replace('\\n', '') != '1': continue\n",
    "\n",
    "        for f in tqdm(range(frames_count), desc='Frames Parsed', position=1, leave=False):\n",
    "            try:\n",
    "                # Get actor count\n",
    "                actors = int(lines.pop(0).replace('\\n', ''))\n",
    "            \n",
    "                # Get actor info\n",
    "                t = lines.pop(0)\n",
    "\n",
    "                # Get joint count\n",
    "                joint_count = int(lines.pop(0).replace('\\n', ''))\n",
    "\n",
    "                # Get joint info\n",
    "                d = []\n",
    "                for j in range(joint_count):\n",
    "                    joint = lines.pop(0).replace('\\n', '').split(' ')\n",
    "                    d.extend(joint[0:3])\n",
    "\n",
    "                # Skip if not 25 joints\n",
    "                if len(d) != 75: continue\n",
    "\n",
    "                # Convert to numpy array\n",
    "                d = np.array(d)\n",
    "\n",
    "                # Append to X and Y\n",
    "                X[p].append(d)\n",
    "            except:\n",
    "                break\n",
    "        \n",
    "    # Convert to numpy arrays\n",
    "    for p in X:\n",
    "        X[p] = np.array(X[p], dtype=np.float16)\n",
    "\n",
    "    print('X Generated, saving to pickle...')\n",
    "\n",
    "    # Save the data\n",
    "    with open('X.pkl', 'wb') as f:\n",
    "        pickle.dump(X, f)\n",
    "\n",
    "    print('X Saved to pickle')\n",
    "\n",
    "# Print Lengths\n",
    "print('\\n\\nLengths:')\n",
    "for p in X:\n",
    "    print(p, X[p].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X Shape:  (3176693, 75)\n",
      "Train Y Shape:  (3176693,)\n",
      "Test X Shape:  (3244742, 75)\n",
      "Test Y Shape:  (3244742,)\n"
     ]
    }
   ],
   "source": [
    "# Default Male/Female split\n",
    "MALES = 30\n",
    "FEMALES = 15\n",
    "\n",
    "# Split into train and test\n",
    "def split_data(males, females):\n",
    "    # To save to txt file\n",
    "    attack_m = None\n",
    "    attack_f = None\n",
    "    retarget_m = None\n",
    "    retarget_f = None\n",
    "    remaining_m = None\n",
    "    remaining_f = None\n",
    "\n",
    "    # Choose males count random males\n",
    "    m = []\n",
    "    f = []\n",
    "    for p in Genders:\n",
    "        if Genders[p] == [1]:\n",
    "            m.append(p)\n",
    "        else:\n",
    "            f.append(p)\n",
    "    train_males = np.random.choice(list(m), males, replace=False)\n",
    "    train_females = np.random.choice(list(f), females, replace=False)\n",
    "    \n",
    "    # Combine to get male/female split\n",
    "    X_male = np.concatenate([X[x] for x in train_males])\n",
    "    X_female = np.concatenate([X[x] for x in train_females])\n",
    "    Y_male = np.ones(len(X_male))\n",
    "    Y_female = np.zeros(len(X_female))\n",
    "\n",
    "    # Combine to get train data\n",
    "    train_x = np.concatenate([X_male, X_female])\n",
    "    train_y = np.concatenate([Y_male, Y_female])\n",
    "\n",
    "    # Get the actors not in the train set\n",
    "    test_males = [x for x in m if x not in train_males]\n",
    "    test_females = [x for x in f if x not in train_females]\n",
    "\n",
    "    # Combine to get male/female split\n",
    "    X_male = np.concatenate([X[x] for x in test_males])\n",
    "    X_female = np.concatenate([X[x] for x in test_females])\n",
    "    Y_male = np.ones(len(X_male), dtype=np.int8)\n",
    "    Y_female = np.zeros(len(X_female), dtype=np.int8)\n",
    "\n",
    "    # Combine to get test data\n",
    "    test_x = np.concatenate([X_male, X_female])\n",
    "    test_y = np.concatenate([Y_male, Y_female])\n",
    "\n",
    "    # Print shapes\n",
    "    print('Train X Shape: ', train_x.shape)\n",
    "    print('Train Y Shape: ', train_y.shape)\n",
    "    print('Test X Shape: ', test_x.shape)\n",
    "    print('Test Y Shape: ', test_y.shape)\n",
    "\n",
    "    # Save actor split to txt file\n",
    "    attack_m = train_males\n",
    "    attack_f = train_females\n",
    "    # split test set into retarget and remaining\n",
    "    temp_m = np.random.choice(test_males, males, replace=False)\n",
    "    temp_f = np.random.choice(test_females, females, replace=False)\n",
    "    retarget_m = temp_m\n",
    "    retarget_f = temp_f\n",
    "    remaining_m = np.array([x for x in test_males if x not in temp_m])\n",
    "    remaining_f = np.array([x for x in test_females if x not in temp_f])\n",
    "\n",
    "    with open('actor split.txt', 'w') as f:\n",
    "        f.write(f\"Attacking Male Actors: {attack_m}\\n\")\n",
    "        f.write(f\"\\nAttacking Female Actors: {attack_f}\\n\")\n",
    "        f.write(f\"\\nDefending/Retargeting Male Actors: {retarget_m}\\n\")\n",
    "        f.write(f\"\\nDefending/Retargeting Female Actors: {retarget_f}\\n\")\n",
    "        f.write(f\"\\nRemaining Male Actors: {remaining_m}\\n\")\n",
    "        f.write(f\"\\nRemaining Female Actors: {remaining_f}\\n\")\n",
    "\n",
    "    return train_x, train_y, test_x, test_y\n",
    "\n",
    "train_x, train_y, test_x, test_y = split_data(MALES, FEMALES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array(['P100', 'P077', 'P004', 'P014', 'P040', 'P019', 'P074', 'P087',\n",
      "       'P025', 'P059', 'P066', 'P048', 'P105', 'P003', 'P021', 'P095',\n",
      "       'P049', 'P013', 'P043', 'P008', 'P057', 'P083', 'P068', 'P101',\n",
      "       'P072', 'P073', 'P085', 'P033', 'P096', 'P046'], dtype='<U4'), array(['P016', 'P089', 'P056', 'P090', 'P028', 'P012', 'P015', 'P061',\n",
      "       'P053', 'P081', 'P094', 'P102', 'P082', 'P091', 'P029'],\n",
      "      dtype='<U4'), array(['P099', 'P080', 'P060', 'P084', 'P007', 'P030', 'P067', 'P054',\n",
      "       'P009', 'P023', 'P076', 'P037', 'P098', 'P097', 'P047', 'P103',\n",
      "       'P104', 'P010', 'P034', 'P086', 'P020', 'P031', 'P106', 'P045',\n",
      "       'P064', 'P071', 'P063', 'P062', 'P051', 'P055'], dtype='<U4'), array(['P026', 'P011', 'P038', 'P017', 'P039', 'P022', 'P002', 'P050',\n",
      "       'P075', 'P001', 'P070', 'P032', 'P024', 'P069', 'P092'],\n",
      "      dtype='<U4'), array(['P005', 'P006', 'P027', 'P035', 'P041', 'P042', 'P044', 'P052',\n",
      "       'P058', 'P065', 'P079', 'P088'], dtype='<U4'), array(['P018', 'P036', 'P078', 'P093'], dtype='<U4')]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search will be done on 36 parameters...\n"
     ]
    }
   ],
   "source": [
    "# Define a grid of hyperparameters to search over\n",
    "n_estimators = [50, 100, 150, 500]\n",
    "max_depth = [10, 15, 20]\n",
    "min_samples_split = [2, 3, 5]\n",
    "\n",
    "# Create a grid of all possible combinations of the hyperparameters\n",
    "param_grid = list(product(n_estimators, max_depth, min_samples_split))\n",
    "\n",
    "print(f'Grid Search will be done on {len(param_grid)} parameters...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {}\n",
    "def train_split(MALES, FEMALES):\n",
    "    # Get train and test data\n",
    "    train_x, train_y, test_x, test_y = split_data(MALES, FEMALES)\n",
    "\n",
    "    # Initialize variables to store the best hyperparameters and their performance\n",
    "    best_score = 0\n",
    "    best_params = None\n",
    "\n",
    "    # Train and evaluate the random forest model for each combination of hyperparameters\n",
    "    for params in tqdm(param_grid):\n",
    "        print(f'Training with {params}...')\n",
    "        n_est, m_dep, m_sam = params\n",
    "        clf = RandomForestClassifier(n_estimators=n_est, max_depth=m_dep, min_samples_split=m_sam, n_jobs=-1, verbose=0)\n",
    "        clf.fit(train_x, train_y)\n",
    "        print('Fitting done, evaluating...')\n",
    "        pred_y = clf.predict(test_x)\n",
    "        score = accuracy_score(test_y, pred_y)\n",
    "        print(f'Accuracy: {score}')\n",
    "\n",
    "        # Update the best hyperparameters if the current model is better\n",
    "        if score > best_score:\n",
    "            print('New best score! Saving params...')\n",
    "            best_score = score\n",
    "            best_params = params\n",
    "    \n",
    "    # Train the final random forest model using the best hyperparameters\n",
    "    clf = RandomForestClassifier(n_estimators=best_params[0], max_depth=best_params[1], min_samples_split=best_params[2])\n",
    "    clf.fit(train_x, train_y)\n",
    "\n",
    "    # Save the final random forest model to a pickle file\n",
    "    with open(f'clf {MALES}.{FEMALES}.pkl', 'wb') as f:\n",
    "        pickle.dump(clf, f)\n",
    "\n",
    "    # Evaluate the performance of the final model on the test set\n",
    "    pred_y = clf.predict(test_x)\n",
    "    score = accuracy_score(test_y, pred_y)\n",
    "    print(\"Best parameters: \", best_params)\n",
    "    print(\"Test accuracy: \", score)\n",
    "\n",
    "    res[f'{MALES}-{FEMALES}'] = (best_params, score)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runtime was just under 10 hours on a xeon CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train X Shape:  (523907, 75)\n",
      "Train Y Shape:  (523907,)\n",
      "Test X Shape:  (5897528, 75)\n",
      "Test Y Shape:  (5897528,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/36 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with (50, 10, 2)...\n",
      "Fitting done, evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/36 [00:18<10:36, 18.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6621036814068538\n",
      "New best score! Saving params...\n",
      "Training with (50, 10, 3)...\n",
      "Fitting done, evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 2/36 [00:36<10:14, 18.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6584492689140263\n",
      "Training with (50, 10, 5)...\n",
      "Fitting done, evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 3/36 [00:54<09:58, 18.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6577325279337377\n",
      "Training with (50, 15, 2)...\n",
      "Fitting done, evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 4/36 [01:16<10:35, 19.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6562134168756808\n",
      "Training with (50, 15, 3)...\n",
      "Fitting done, evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 5/36 [01:39<10:48, 20.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6569111668482116\n",
      "Training with (50, 15, 5)...\n",
      "Fitting done, evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 6/36 [02:02<10:43, 21.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6586956433271703\n",
      "Training with (50, 20, 2)...\n",
      "Fitting done, evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 7/36 [02:27<10:59, 22.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6551236382430062\n",
      "Training with (50, 20, 3)...\n",
      "Fitting done, evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 8/36 [02:52<10:56, 23.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6557801845112053\n",
      "Training with (50, 20, 5)...\n",
      "Fitting done, evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 9/36 [03:17<10:46, 23.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6554842978278357\n",
      "Training with (100, 10, 2)...\n",
      "Fitting done, evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 10/36 [03:50<11:31, 26.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6609537080620898\n",
      "Training with (100, 10, 3)...\n",
      "Fitting done, evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 11/36 [04:22<11:50, 28.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6598054303430183\n",
      "Training with (100, 10, 5)...\n",
      "Fitting done, evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 12/36 [04:55<11:53, 29.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6606401868715164\n",
      "Training with (100, 15, 2)...\n",
      "Fitting done, evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 13/36 [05:36<12:43, 33.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6591660098943151\n",
      "Training with (100, 15, 3)...\n",
      "Fitting done, evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 14/36 [06:17<13:05, 35.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6575690696169649\n",
      "Training with (100, 15, 5)...\n",
      "Fitting done, evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 15/36 [06:59<13:05, 37.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.658955243620717\n",
      "Training with (100, 20, 2)...\n",
      "Fitting done, evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 16/36 [07:47<13:32, 40.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6563110849155782\n",
      "Training with (100, 20, 3)...\n",
      "Fitting done, evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 17/36 [08:34<13:30, 42.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6584292605308529\n",
      "Training with (100, 20, 5)...\n",
      "Fitting done, evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 18/36 [09:20<13:02, 43.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6576719940965096\n",
      "Training with (150, 10, 2)...\n",
      "Fitting done, evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 19/36 [10:08<12:44, 44.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6603722780120755\n",
      "Training with (150, 10, 3)...\n",
      "Fitting done, evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 20/36 [10:53<11:58, 44.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6607080118992229\n",
      "Training with (150, 10, 5)...\n",
      "Fitting done, evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 21/36 [11:38<11:14, 44.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6624879101888113\n",
      "New best score! Saving params...\n",
      "Training with (150, 15, 2)...\n",
      "Fitting done, evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 22/36 [12:35<11:19, 48.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6587853419263122\n",
      "Training with (150, 15, 3)...\n",
      "Fitting done, evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 23/36 [13:32<11:05, 51.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6576419815217495\n",
      "Training with (150, 15, 5)...\n",
      "Fitting done, evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 24/36 [14:30<10:35, 52.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6596068725744074\n",
      "Training with (150, 20, 2)...\n",
      "Fitting done, evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 25/36 [15:34<10:22, 56.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6574101894895624\n",
      "Training with (150, 20, 3)...\n",
      "Fitting done, evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 26/36 [16:39<09:50, 59.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6575555046114236\n",
      "Training with (150, 20, 5)...\n",
      "Fitting done, evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 27/36 [17:44<09:06, 60.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6572094274075511\n",
      "Training with (500, 10, 2)...\n",
      "Fitting done, evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 28/36 [20:08<11:26, 85.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6610198374641036\n",
      "Training with (500, 10, 3)...\n",
      "Fitting done, evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 29/36 [22:40<12:19, 105.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6617752387101851\n",
      "Training with (500, 10, 5)...\n",
      "Fitting done, evaluating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 30/36 [25:15<12:01, 120.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6606400173089471\n",
      "Training with (500, 15, 2)...\n"
     ]
    }
   ],
   "source": [
    "splits = [(10, 5), (20, 10), (30, 15)]\n",
    "for split in splits:\n",
    "    train_split(*split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('results.pkl', 'wb') as f:\n",
    "    pickle.dump(res, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "063dd9079dbbbc7ce9a24508feb60cfa7f5aa9bc9e0c912b3996301118c4566f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
